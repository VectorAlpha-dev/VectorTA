







.version 9.0
.target sm_89
.address_size 64



.visible .entry ema_batch_f32(
	.param .u64 ema_batch_f32_param_0,
	.param .u64 ema_batch_f32_param_1,
	.param .u64 ema_batch_f32_param_2,
	.param .u32 ema_batch_f32_param_3,
	.param .u32 ema_batch_f32_param_4,
	.param .u32 ema_batch_f32_param_5,
	.param .u64 ema_batch_f32_param_6
)
{
	.reg .pred 	%p<119>;
	.reg .f32 	%f<314>;
	.reg .b32 	%r<348>;
	.reg .b64 	%rd<142>;


	ld.param.u64 	%rd54, [ema_batch_f32_param_0];
	ld.param.u32 	%r174, [ema_batch_f32_param_3];
	ld.param.u32 	%r175, [ema_batch_f32_param_4];
	ld.param.u32 	%r176, [ema_batch_f32_param_5];
	ld.param.u64 	%rd57, [ema_batch_f32_param_6];
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd54;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p33, %r1, %r176;
	setp.lt.s32 	%p34, %r174, 1;
	or.pred  	%p35, %p34, %p33;
	@%p35 bra 	$L__BB0_127;

	ld.param.u64 	%rd122, [ema_batch_f32_param_1];
	cvta.to.global.u64 	%rd58, %rd122;
	mul.wide.s32 	%rd59, %r1, 4;
	add.s64 	%rd60, %rd58, %rd59;
	ld.global.nc.u32 	%r2, [%rd60];
	setp.lt.s32 	%p36, %r2, 1;
	setp.ge.s32 	%p37, %r175, %r174;
	or.pred  	%p38, %p37, %p36;
	@%p38 bra 	$L__BB0_127;

	mov.u32 	%r288, %ctaid.x;
	cvt.s64.s32 	%rd128, %r288;
	ld.param.u64 	%rd123, [ema_batch_f32_param_2];
	cvta.to.global.u64 	%rd61, %rd123;
	shl.b64 	%rd62, %rd128, 2;
	add.s64 	%rd63, %rd61, %rd62;
	ld.global.nc.f32 	%f1, [%rd63];
	mov.f32 	%f138, 0f3F800000;
	sub.ftz.f32 	%f2, %f138, %f1;
	cvt.s64.s32 	%rd64, %r174;
	mul.lo.s64 	%rd5, %rd64, %rd128;
	mov.u32 	%r3, %tid.x;
	setp.lt.s32 	%p39, %r3, %r175;
	@%p39 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_5;

$L__BB0_3:
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r289, %r3;

$L__BB0_4:
	cvt.s64.s32 	%rd65, %r289;
	add.s64 	%rd66, %rd5, %rd65;
	shl.b64 	%rd67, %rd66, 2;
	add.s64 	%rd68, %rd2, %rd67;
	mov.u32 	%r177, 2143289344;
	st.global.u32 	[%rd68], %r177;
	add.s32 	%r289, %r289, %r4;
	setp.lt.s32 	%p40, %r289, %r175;
	@%p40 bra 	$L__BB0_4;

$L__BB0_5:
	mov.u32 	%r178, %ntid.x;
	setp.lt.u32 	%p41, %r178, 32;
	cvt.s64.s32 	%rd69, %r175;
	mul.wide.s32 	%rd70, %r175, 4;
	add.s64 	%rd6, %rd3, %rd70;
	add.s64 	%rd71, %rd5, %rd69;
	shl.b64 	%rd72, %rd71, 2;
	add.s64 	%rd7, %rd2, %rd72;
	@%p41 bra 	$L__BB0_82;
	bra.uni 	$L__BB0_6;

$L__BB0_82:
	setp.ne.s32 	%p93, %r3, 0;
	@%p93 bra 	$L__BB0_127;

	ld.param.u32 	%r284, [ema_batch_f32_param_4];
	add.s32 	%r138, %r2, %r284;
	min.s32 	%r346, %r138, %r174;
	ld.global.f32 	%f297, [%rd6];
	st.global.f32 	[%rd7], %f297;
	add.s32 	%r339, %r284, 1;
	setp.ge.s32 	%p94, %r339, %r346;
	@%p94 bra 	$L__BB0_100;

	ld.param.u32 	%r285, [ema_batch_f32_param_4];
	mov.u32 	%r264, -2;
	sub.s32 	%r265, %r264, %r285;
	not.b32 	%r266, %r346;
	sub.s32 	%r141, %r265, %r266;
	mov.u32 	%r267, -3;
	sub.s32 	%r268, %r267, %r285;
	sub.s32 	%r269, %r268, %r266;
	and.b32  	%r342, %r141, 3;
	setp.lt.u32 	%p95, %r269, 3;
	mov.u32 	%r335, 1;
	@%p95 bra 	$L__BB0_95;

	sub.s32 	%r334, %r141, %r342;
	mov.u32 	%r335, 1;

$L__BB0_86:
	cvt.s64.s32 	%rd26, %r339;
	mul.wide.s32 	%rd95, %r339, 4;
	add.s64 	%rd27, %rd3, %rd95;
	ld.global.f32 	%f101, [%rd27];
	abs.ftz.f32 	%f215, %f101;
	setp.geu.ftz.f32 	%p96, %f215, 0f7F800000;
	@%p96 bra 	$L__BB0_88;

	add.s32 	%r335, %r335, 1;
	cvt.rn.f32.s32 	%f216, %r335;
	mov.f32 	%f217, 0f3F800000;
	div.approx.ftz.f32 	%f218, %f217, %f216;
	sub.ftz.f32 	%f219, %f101, %f297;
	fma.rn.ftz.f32 	%f297, %f219, %f218, %f297;

$L__BB0_88:
	add.s64 	%rd96, %rd5, %rd26;
	shl.b64 	%rd97, %rd96, 2;
	add.s64 	%rd28, %rd2, %rd97;
	st.global.f32 	[%rd28], %f297;
	ld.global.f32 	%f104, [%rd27+4];
	abs.ftz.f32 	%f220, %f104;
	setp.geu.ftz.f32 	%p97, %f220, 0f7F800000;
	@%p97 bra 	$L__BB0_90;

	add.s32 	%r335, %r335, 1;
	cvt.rn.f32.s32 	%f221, %r335;
	mov.f32 	%f222, 0f3F800000;
	div.approx.ftz.f32 	%f223, %f222, %f221;
	sub.ftz.f32 	%f224, %f104, %f297;
	fma.rn.ftz.f32 	%f297, %f224, %f223, %f297;

$L__BB0_90:
	st.global.f32 	[%rd28+4], %f297;
	ld.global.f32 	%f107, [%rd27+8];
	abs.ftz.f32 	%f225, %f107;
	setp.geu.ftz.f32 	%p98, %f225, 0f7F800000;
	@%p98 bra 	$L__BB0_92;

	add.s32 	%r335, %r335, 1;
	cvt.rn.f32.s32 	%f226, %r335;
	mov.f32 	%f227, 0f3F800000;
	div.approx.ftz.f32 	%f228, %f227, %f226;
	sub.ftz.f32 	%f229, %f107, %f297;
	fma.rn.ftz.f32 	%f297, %f229, %f228, %f297;

$L__BB0_92:
	st.global.f32 	[%rd28+8], %f297;
	ld.global.f32 	%f110, [%rd27+12];
	abs.ftz.f32 	%f230, %f110;
	setp.geu.ftz.f32 	%p99, %f230, 0f7F800000;
	@%p99 bra 	$L__BB0_94;

	add.s32 	%r335, %r335, 1;
	cvt.rn.f32.s32 	%f231, %r335;
	mov.f32 	%f232, 0f3F800000;
	div.approx.ftz.f32 	%f233, %f232, %f231;
	sub.ftz.f32 	%f234, %f110, %f297;
	fma.rn.ftz.f32 	%f297, %f234, %f233, %f297;

$L__BB0_94:
	st.global.f32 	[%rd28+12], %f297;
	cvt.u32.u64 	%r271, %rd26;
	add.s32 	%r339, %r271, 4;
	add.s32 	%r334, %r334, -4;
	setp.ne.s32 	%p100, %r334, 0;
	@%p100 bra 	$L__BB0_86;

$L__BB0_95:
	setp.eq.s32 	%p101, %r342, 0;
	@%p101 bra 	$L__BB0_100;

	cvt.s64.s32 	%rd98, %r339;
	add.s64 	%rd99, %rd5, %rd98;
	shl.b64 	%rd100, %rd99, 2;
	add.s64 	%rd135, %rd2, %rd100;
	mul.wide.s32 	%rd101, %r339, 4;
	add.s64 	%rd134, %rd3, %rd101;

$L__BB0_97:
	.pragma "nounroll";
	ld.global.f32 	%f116, [%rd134];
	abs.ftz.f32 	%f235, %f116;
	setp.geu.ftz.f32 	%p102, %f235, 0f7F800000;
	@%p102 bra 	$L__BB0_99;

	add.s32 	%r335, %r335, 1;
	cvt.rn.f32.s32 	%f236, %r335;
	mov.f32 	%f237, 0f3F800000;
	div.approx.ftz.f32 	%f238, %f237, %f236;
	sub.ftz.f32 	%f239, %f116, %f297;
	fma.rn.ftz.f32 	%f297, %f239, %f238, %f297;

$L__BB0_99:
	st.global.f32 	[%rd135], %f297;
	add.s64 	%rd135, %rd135, 4;
	add.s64 	%rd134, %rd134, 4;
	add.s32 	%r342, %r342, -1;
	setp.ne.s32 	%p103, %r342, 0;
	@%p103 bra 	$L__BB0_97;

$L__BB0_100:
	setp.ge.s32 	%p104, %r138, %r174;
	@%p104 bra 	$L__BB0_127;

	not.b32 	%r164, %r346;
	add.s32 	%r165, %r164, %r174;
	add.s32 	%r272, %r165, 1;
	and.b32  	%r345, %r272, 3;
	setp.eq.s32 	%p105, %r345, 0;
	@%p105 bra 	$L__BB0_108;

	cvt.s64.s32 	%rd102, %r346;
	add.s64 	%rd103, %rd5, %rd102;
	shl.b64 	%rd104, %rd103, 2;
	add.s64 	%rd138, %rd2, %rd104;
	mul.wide.s32 	%rd105, %r346, 4;
	add.s64 	%rd137, %rd3, %rd105;
	mov.u32 	%r273, 63;
	sub.s32 	%r274, %r273, %r164;
	mul.wide.s32 	%rd106, %r274, 4;
	add.s64 	%rd136, %rd54, %rd106;

$L__BB0_103:
	.pragma "nounroll";
	add.s32 	%r275, %r346, 64;
	setp.ge.s32 	%p106, %r275, %r174;
	@%p106 bra 	$L__BB0_105;


	prefetch.global.L2 [%rd136];


$L__BB0_105:
	ld.global.f32 	%f121, [%rd137];
	abs.ftz.f32 	%f240, %f121;
	setp.geu.ftz.f32 	%p107, %f240, 0f7F800000;
	@%p107 bra 	$L__BB0_107;

	sub.ftz.f32 	%f241, %f121, %f297;
	fma.rn.ftz.f32 	%f297, %f241, %f1, %f297;

$L__BB0_107:
	st.global.f32 	[%rd138], %f297;
	add.s32 	%r346, %r346, 1;
	add.s64 	%rd138, %rd138, 4;
	add.s64 	%rd137, %rd137, 4;
	add.s64 	%rd136, %rd136, 4;
	add.s32 	%r345, %r345, -1;
	setp.ne.s32 	%p108, %r345, 0;
	@%p108 bra 	$L__BB0_103;

$L__BB0_108:
	setp.lt.u32 	%p109, %r165, 3;
	@%p109 bra 	$L__BB0_127;

	add.s32 	%r276, %r346, 64;
	mul.wide.s32 	%rd44, %r276, 4;
	cvt.s64.s32 	%rd108, %r346;
	add.s64 	%rd109, %rd5, %rd108;
	shl.b64 	%rd110, %rd109, 2;
	add.s64 	%rd139, %rd2, %rd110;
	mul.wide.s32 	%rd111, %r346, 4;
	add.s64 	%rd141, %rd3, %rd111;
	mov.u64 	%rd112, 260;
	sub.s64 	%rd47, %rd112, %rd3;
	mov.u64 	%rd140, %rd54;

$L__BB0_110:
	add.s32 	%r277, %r346, 64;
	setp.ge.s32 	%p110, %r277, %r174;
	@%p110 bra 	$L__BB0_112;

	add.s64 	%rd113, %rd140, %rd44;

	prefetch.global.L2 [%rd113];


$L__BB0_112:
	ld.global.f32 	%f126, [%rd141];
	abs.ftz.f32 	%f242, %f126;
	setp.geu.ftz.f32 	%p111, %f242, 0f7F800000;
	@%p111 bra 	$L__BB0_114;

	sub.ftz.f32 	%f243, %f126, %f297;
	fma.rn.ftz.f32 	%f297, %f243, %f1, %f297;

$L__BB0_114:
	st.global.f32 	[%rd139], %f297;
	add.s32 	%r278, %r346, 65;
	setp.ge.s32 	%p112, %r278, %r174;
	@%p112 bra 	$L__BB0_116;

	add.s64 	%rd115, %rd54, %rd141;
	add.s64 	%rd114, %rd115, %rd47;

	prefetch.global.L2 [%rd114];


$L__BB0_116:
	ld.global.f32 	%f129, [%rd141+4];
	abs.ftz.f32 	%f244, %f129;
	setp.geu.ftz.f32 	%p113, %f244, 0f7F800000;
	@%p113 bra 	$L__BB0_118;

	sub.ftz.f32 	%f245, %f129, %f297;
	fma.rn.ftz.f32 	%f297, %f245, %f1, %f297;

$L__BB0_118:
	st.global.f32 	[%rd139+4], %f297;
	add.s32 	%r279, %r346, 66;
	setp.ge.s32 	%p114, %r279, %r174;
	@%p114 bra 	$L__BB0_120;

	add.s64 	%rd117, %rd54, %rd141;
	add.s64 	%rd118, %rd117, %rd47;
	add.s64 	%rd116, %rd118, 4;

	prefetch.global.L2 [%rd116];


$L__BB0_120:
	ld.global.f32 	%f132, [%rd141+8];
	abs.ftz.f32 	%f246, %f132;
	setp.geu.ftz.f32 	%p115, %f246, 0f7F800000;
	@%p115 bra 	$L__BB0_122;

	sub.ftz.f32 	%f247, %f132, %f297;
	fma.rn.ftz.f32 	%f297, %f247, %f1, %f297;

$L__BB0_122:
	st.global.f32 	[%rd139+8], %f297;
	add.s32 	%r280, %r346, 67;
	setp.ge.s32 	%p116, %r280, %r174;
	@%p116 bra 	$L__BB0_124;

	add.s64 	%rd120, %rd54, %rd141;
	add.s64 	%rd121, %rd120, %rd47;
	add.s64 	%rd119, %rd121, 8;

	prefetch.global.L2 [%rd119];


$L__BB0_124:
	ld.global.f32 	%f135, [%rd141+12];
	abs.ftz.f32 	%f248, %f135;
	setp.geu.ftz.f32 	%p117, %f248, 0f7F800000;
	@%p117 bra 	$L__BB0_126;

	sub.ftz.f32 	%f249, %f135, %f297;
	fma.rn.ftz.f32 	%f297, %f249, %f1, %f297;

$L__BB0_126:
	add.s64 	%rd141, %rd141, 16;
	add.s64 	%rd52, %rd139, 16;
	st.global.f32 	[%rd139+12], %f297;
	add.s64 	%rd140, %rd140, 16;
	add.s32 	%r346, %r346, 4;
	setp.lt.s32 	%p118, %r346, %r174;
	mov.u64 	%rd139, %rd52;
	@%p118 bra 	$L__BB0_110;
	bra.uni 	$L__BB0_127;

$L__BB0_6:
	setp.gt.u32 	%p42, %r3, 31;
	@%p42 bra 	$L__BB0_127;

	ld.param.u32 	%r281, [ema_batch_f32_param_4];
	add.s32 	%r7, %r2, %r281;
	min.s32 	%r311, %r7, %r174;
	setp.ne.s32 	%p43, %r3, 0;
	mov.f32 	%f251, 0f00000000;
	@%p43 bra 	$L__BB0_25;

	ld.param.u32 	%r282, [ema_batch_f32_param_4];
	ld.global.f32 	%f251, [%rd6];
	st.global.f32 	[%rd7], %f251;
	add.s32 	%r297, %r282, 1;
	setp.ge.s32 	%p44, %r297, %r311;
	@%p44 bra 	$L__BB0_25;

	ld.param.u32 	%r283, [ema_batch_f32_param_4];
	mov.u32 	%r180, -2;
	sub.s32 	%r181, %r180, %r283;
	not.b32 	%r182, %r311;
	sub.s32 	%r10, %r181, %r182;
	mov.u32 	%r183, -3;
	sub.s32 	%r184, %r183, %r283;
	sub.s32 	%r185, %r184, %r182;
	and.b32  	%r300, %r10, 3;
	setp.lt.u32 	%p45, %r185, 3;
	mov.u32 	%r293, 1;
	@%p45 bra 	$L__BB0_20;

	sub.s32 	%r292, %r10, %r300;
	mov.u32 	%r293, 1;

$L__BB0_11:
	mul.wide.s32 	%rd73, %r297, 4;
	add.s64 	%rd9, %rd3, %rd73;
	ld.global.f32 	%f5, [%rd9];
	abs.ftz.f32 	%f141, %f5;
	setp.geu.ftz.f32 	%p46, %f141, 0f7F800000;
	@%p46 bra 	$L__BB0_13;

	add.s32 	%r293, %r293, 1;
	cvt.rn.f32.s32 	%f142, %r293;
	mov.f32 	%f143, 0f3F800000;
	div.approx.ftz.f32 	%f144, %f143, %f142;
	sub.ftz.f32 	%f145, %f5, %f251;
	fma.rn.ftz.f32 	%f251, %f145, %f144, %f251;

$L__BB0_13:
	cvt.s64.s32 	%rd124, %r297;
	add.s64 	%rd74, %rd5, %rd124;
	shl.b64 	%rd75, %rd74, 2;
	add.s64 	%rd10, %rd2, %rd75;
	st.global.f32 	[%rd10], %f251;
	ld.global.f32 	%f8, [%rd9+4];
	abs.ftz.f32 	%f146, %f8;
	setp.geu.ftz.f32 	%p47, %f146, 0f7F800000;
	@%p47 bra 	$L__BB0_15;

	add.s32 	%r293, %r293, 1;
	cvt.rn.f32.s32 	%f147, %r293;
	mov.f32 	%f148, 0f3F800000;
	div.approx.ftz.f32 	%f149, %f148, %f147;
	sub.ftz.f32 	%f150, %f8, %f251;
	fma.rn.ftz.f32 	%f251, %f150, %f149, %f251;

$L__BB0_15:
	st.global.f32 	[%rd10+4], %f251;
	ld.global.f32 	%f11, [%rd9+8];
	abs.ftz.f32 	%f151, %f11;
	setp.geu.ftz.f32 	%p48, %f151, 0f7F800000;
	@%p48 bra 	$L__BB0_17;

	add.s32 	%r293, %r293, 1;
	cvt.rn.f32.s32 	%f152, %r293;
	mov.f32 	%f153, 0f3F800000;
	div.approx.ftz.f32 	%f154, %f153, %f152;
	sub.ftz.f32 	%f155, %f11, %f251;
	fma.rn.ftz.f32 	%f251, %f155, %f154, %f251;

$L__BB0_17:
	st.global.f32 	[%rd10+8], %f251;
	ld.global.f32 	%f14, [%rd9+12];
	abs.ftz.f32 	%f156, %f14;
	setp.geu.ftz.f32 	%p49, %f156, 0f7F800000;
	@%p49 bra 	$L__BB0_19;

	add.s32 	%r293, %r293, 1;
	cvt.rn.f32.s32 	%f157, %r293;
	mov.f32 	%f158, 0f3F800000;
	div.approx.ftz.f32 	%f159, %f158, %f157;
	sub.ftz.f32 	%f160, %f14, %f251;
	fma.rn.ftz.f32 	%f251, %f160, %f159, %f251;

$L__BB0_19:
	cvt.s64.s32 	%rd125, %r297;
	st.global.f32 	[%rd10+12], %f251;
	cvt.u32.u64 	%r187, %rd125;
	add.s32 	%r297, %r187, 4;
	add.s32 	%r292, %r292, -4;
	setp.ne.s32 	%p50, %r292, 0;
	@%p50 bra 	$L__BB0_11;

$L__BB0_20:
	setp.eq.s32 	%p51, %r300, 0;
	@%p51 bra 	$L__BB0_25;

	cvt.s64.s32 	%rd76, %r297;
	add.s64 	%rd77, %rd5, %rd76;
	shl.b64 	%rd78, %rd77, 2;
	add.s64 	%rd130, %rd2, %rd78;
	mul.wide.s32 	%rd79, %r297, 4;
	add.s64 	%rd129, %rd3, %rd79;

$L__BB0_22:
	.pragma "nounroll";
	ld.global.f32 	%f20, [%rd129];
	abs.ftz.f32 	%f161, %f20;
	setp.geu.ftz.f32 	%p52, %f161, 0f7F800000;
	@%p52 bra 	$L__BB0_24;

	add.s32 	%r293, %r293, 1;
	cvt.rn.f32.s32 	%f162, %r293;
	mov.f32 	%f163, 0f3F800000;
	div.approx.ftz.f32 	%f164, %f163, %f162;
	sub.ftz.f32 	%f165, %f20, %f251;
	fma.rn.ftz.f32 	%f251, %f165, %f164, %f251;

$L__BB0_24:
	st.global.f32 	[%rd130], %f251;
	add.s64 	%rd130, %rd130, 4;
	add.s64 	%rd129, %rd129, 4;
	add.s32 	%r300, %r300, -1;
	setp.ne.s32 	%p53, %r300, 0;
	@%p53 bra 	$L__BB0_22;

$L__BB0_25:
	ld.param.u32 	%r287, [ema_batch_f32_param_4];
	add.s32 	%r286, %r2, %r287;
	mov.b32 	%r188, %f251;
	mov.u32 	%r189, 31;
	mov.u32 	%r190, 0;
	mov.u32 	%r191, -1;
	shfl.sync.idx.b32 	%r315|%p1, %r188, %r190, %r189, %r191;
	setp.ge.s32 	%p54, %r286, %r174;
	@%p54 bra 	$L__BB0_127;

	not.b32 	%r192, %r311;
	add.s32 	%r35, %r192, %r174;
	and.b32  	%r193, %r35, 32;
	setp.ne.s32 	%p55, %r193, 0;
	@%p55 bra 	$L__BB0_45;

	@%p43 bra 	$L__BB0_30;

	add.s32 	%r36, %r311, 256;
	setp.ge.s32 	%p57, %r36, %r174;
	@%p57 bra 	$L__BB0_30;

	ld.param.u64 	%rd127, [ema_batch_f32_param_0];
	mul.wide.s32 	%rd81, %r36, 4;
	add.s64 	%rd80, %rd127, %rd81;

	prefetch.global.L2 [%rd80];


$L__BB0_30:
	add.s32 	%r37, %r311, %r3;
	setp.ge.s32 	%p58, %r37, %r174;
	mov.f32 	%f263, 0f00000000;
	mov.f32 	%f262, 0f3F800000;
	@%p58 bra 	$L__BB0_32;

	mul.wide.s32 	%rd82, %r37, 4;
	add.s64 	%rd83, %rd3, %rd82;
	ld.global.f32 	%f168, [%rd83];
	abs.ftz.f32 	%f169, %f168;
	setp.lt.ftz.f32 	%p59, %f169, 0f7F800000;
	mul.ftz.f32 	%f170, %f1, %f168;
	selp.f32 	%f262, %f2, 0f3F800000, %p59;
	selp.f32 	%f263, %f170, 0f00000000, %p59;

$L__BB0_32:
	mov.b32 	%r305, %f262;
	mov.u32 	%r194, 0;
	mov.u32 	%r195, 1;
	mov.u32 	%r196, -1;
	shfl.sync.up.b32 	%r39|%p2, %r305, %r195, %r194, %r196;
	mov.b32 	%r304, %f263;
	shfl.sync.up.b32 	%r41|%p3, %r304, %r195, %r194, %r196;
	setp.eq.s32 	%p60, %r3, 0;
	@%p60 bra 	$L__BB0_34;

	mov.b32 	%f171, %r41;
	mov.b32 	%f172, %r39;
	mul.ftz.f32 	%f28, %f262, %f172;
	fma.rn.ftz.f32 	%f263, %f262, %f171, %f263;
	mov.b32 	%r305, %f28;
	mov.b32 	%r304, %f263;
	mov.f32 	%f262, %f28;

$L__BB0_34:
	mov.u32 	%r198, 2;
	shfl.sync.up.b32 	%r46|%p4, %r305, %r198, %r194, %r196;
	shfl.sync.up.b32 	%r47|%p5, %r304, %r198, %r194, %r196;
	setp.lt.u32 	%p61, %r3, 2;
	@%p61 bra 	$L__BB0_36;

	mov.b32 	%f173, %r47;
	mov.b32 	%f174, %r46;
	mul.ftz.f32 	%f32, %f262, %f174;
	fma.rn.ftz.f32 	%f263, %f262, %f173, %f263;
	mov.b32 	%r305, %f32;
	mov.b32 	%r304, %f263;
	mov.f32 	%f262, %f32;

$L__BB0_36:
	mov.u32 	%r200, 0;
	mov.u32 	%r201, 4;
	mov.u32 	%r202, -1;
	shfl.sync.up.b32 	%r52|%p6, %r305, %r201, %r200, %r202;
	shfl.sync.up.b32 	%r53|%p7, %r304, %r201, %r200, %r202;
	setp.lt.u32 	%p62, %r3, 4;
	@%p62 bra 	$L__BB0_38;

	mov.b32 	%f175, %r53;
	mov.b32 	%f176, %r52;
	mul.ftz.f32 	%f36, %f262, %f176;
	fma.rn.ftz.f32 	%f263, %f262, %f175, %f263;
	mov.b32 	%r305, %f36;
	mov.b32 	%r304, %f263;
	mov.f32 	%f262, %f36;

$L__BB0_38:
	mov.u32 	%r204, 8;
	shfl.sync.up.b32 	%r58|%p8, %r305, %r204, %r200, %r202;
	shfl.sync.up.b32 	%r59|%p9, %r304, %r204, %r200, %r202;
	setp.lt.u32 	%p63, %r3, 8;
	@%p63 bra 	$L__BB0_40;

	mov.b32 	%f177, %r59;
	mov.b32 	%f178, %r58;
	mul.ftz.f32 	%f40, %f262, %f178;
	fma.rn.ftz.f32 	%f263, %f262, %f177, %f263;
	mov.b32 	%r305, %f40;
	mov.b32 	%r304, %f263;
	mov.f32 	%f262, %f40;

$L__BB0_40:
	mov.u32 	%r206, 0;
	mov.u32 	%r207, 16;
	mov.u32 	%r208, -1;
	shfl.sync.up.b32 	%r64|%p10, %r305, %r207, %r206, %r208;
	shfl.sync.up.b32 	%r65|%p11, %r304, %r207, %r206, %r208;
	setp.lt.u32 	%p64, %r3, 16;
	@%p64 bra 	$L__BB0_42;

	mov.b32 	%f179, %r65;
	mov.b32 	%f180, %r64;
	mul.ftz.f32 	%f44, %f262, %f180;
	fma.rn.ftz.f32 	%f263, %f262, %f179, %f263;
	mov.f32 	%f262, %f44;

$L__BB0_42:
	mov.b32 	%f181, %r315;
	fma.rn.ftz.f32 	%f48, %f262, %f181, %f263;
	@%p58 bra 	$L__BB0_44;

	cvt.s64.s32 	%rd84, %r37;
	add.s64 	%rd85, %rd5, %rd84;
	shl.b64 	%rd86, %rd85, 2;
	add.s64 	%rd87, %rd2, %rd86;
	st.global.f32 	[%rd87], %f48;

$L__BB0_44:
	sub.s32 	%r209, %r174, %r311;
	setp.gt.s32 	%p66, %r209, 31;
	mov.u32 	%r210, 31;
	add.s32 	%r211, %r209, -1;
	mov.u32 	%r212, -1;
	selp.b32 	%r213, 31, %r211, %p66;
	mov.b32 	%r214, %f48;
	shfl.sync.idx.b32 	%r315|%p67, %r214, %r213, %r210, %r212;
	add.s32 	%r311, %r311, 32;

$L__BB0_45:
	and.b32  	%r215, %r35, -32;
	setp.eq.s32 	%p68, %r215, 0;
	@%p68 bra 	$L__BB0_127;

	ld.param.u64 	%rd126, [ema_batch_f32_param_0];
	add.s32 	%r314, %r311, 288;
	add.s32 	%r216, %r311, 256;
	mul.wide.s32 	%rd88, %r216, 4;
	add.s64 	%rd133, %rd126, %rd88;
	add.s32 	%r217, %r174, -1;
	sub.s32 	%r313, %r217, %r311;
	add.s32 	%r312, %r3, %r311;
	cvt.s64.s32 	%rd89, %r312;
	mul.wide.s32 	%rd90, %r312, 4;
	add.s64 	%rd132, %rd3, %rd90;
	add.s64 	%rd91, %rd5, %rd89;
	shl.b64 	%rd92, %rd91, 2;
	add.s64 	%rd131, %rd2, %rd92;

$L__BB0_47:
	@%p43 bra 	$L__BB0_50;

	add.s32 	%r218, %r314, -32;
	setp.ge.s32 	%p70, %r218, %r174;
	@%p70 bra 	$L__BB0_50;


	prefetch.global.L2 [%rd133];


$L__BB0_50:
	setp.ge.s32 	%p71, %r312, %r174;
	mov.f32 	%f275, 0f00000000;
	mov.f32 	%f274, 0f3F800000;
	@%p71 bra 	$L__BB0_52;

	ld.global.f32 	%f184, [%rd132];
	abs.ftz.f32 	%f185, %f184;
	setp.lt.ftz.f32 	%p72, %f185, 0f7F800000;
	mul.ftz.f32 	%f186, %f1, %f184;
	selp.f32 	%f274, %f2, 0f3F800000, %p72;
	selp.f32 	%f275, %f186, 0f00000000, %p72;

$L__BB0_52:
	mov.b32 	%r319, %f274;
	mov.u32 	%r219, 0;
	mov.u32 	%r220, 1;
	mov.u32 	%r221, -1;
	shfl.sync.up.b32 	%r78|%p12, %r319, %r220, %r219, %r221;
	mov.b32 	%r318, %f275;
	shfl.sync.up.b32 	%r80|%p13, %r318, %r220, %r219, %r221;
	setp.eq.s32 	%p73, %r3, 0;
	@%p73 bra 	$L__BB0_54;

	mov.b32 	%f187, %r80;
	mov.b32 	%f188, %r78;
	mul.ftz.f32 	%f53, %f274, %f188;
	fma.rn.ftz.f32 	%f275, %f274, %f187, %f275;
	mov.b32 	%r319, %f53;
	mov.b32 	%r318, %f275;
	mov.f32 	%f274, %f53;

$L__BB0_54:
	mov.u32 	%r223, 2;
	shfl.sync.up.b32 	%r85|%p14, %r319, %r223, %r219, %r221;
	shfl.sync.up.b32 	%r86|%p15, %r318, %r223, %r219, %r221;
	setp.lt.u32 	%p74, %r3, 2;
	@%p74 bra 	$L__BB0_56;

	mov.b32 	%f189, %r86;
	mov.b32 	%f190, %r85;
	mul.ftz.f32 	%f57, %f274, %f190;
	fma.rn.ftz.f32 	%f275, %f274, %f189, %f275;
	mov.b32 	%r319, %f57;
	mov.b32 	%r318, %f275;
	mov.f32 	%f274, %f57;

$L__BB0_56:
	mov.u32 	%r225, 0;
	mov.u32 	%r226, 4;
	mov.u32 	%r227, -1;
	shfl.sync.up.b32 	%r91|%p16, %r319, %r226, %r225, %r227;
	shfl.sync.up.b32 	%r92|%p17, %r318, %r226, %r225, %r227;
	setp.lt.u32 	%p75, %r3, 4;
	@%p75 bra 	$L__BB0_58;

	mov.b32 	%f191, %r92;
	mov.b32 	%f192, %r91;
	mul.ftz.f32 	%f61, %f274, %f192;
	fma.rn.ftz.f32 	%f275, %f274, %f191, %f275;
	mov.b32 	%r319, %f61;
	mov.b32 	%r318, %f275;
	mov.f32 	%f274, %f61;

$L__BB0_58:
	mov.u32 	%r229, 8;
	shfl.sync.up.b32 	%r97|%p18, %r319, %r229, %r225, %r227;
	shfl.sync.up.b32 	%r98|%p19, %r318, %r229, %r225, %r227;
	setp.lt.u32 	%p76, %r3, 8;
	@%p76 bra 	$L__BB0_60;

	mov.b32 	%f193, %r98;
	mov.b32 	%f194, %r97;
	mul.ftz.f32 	%f65, %f274, %f194;
	fma.rn.ftz.f32 	%f275, %f274, %f193, %f275;
	mov.b32 	%r319, %f65;
	mov.b32 	%r318, %f275;
	mov.f32 	%f274, %f65;

$L__BB0_60:
	mov.u32 	%r231, 0;
	mov.u32 	%r232, 16;
	mov.u32 	%r233, -1;
	shfl.sync.up.b32 	%r103|%p20, %r319, %r232, %r231, %r233;
	shfl.sync.up.b32 	%r104|%p21, %r318, %r232, %r231, %r233;
	setp.lt.u32 	%p77, %r3, 16;
	@%p77 bra 	$L__BB0_62;

	mov.b32 	%f195, %r104;
	mov.b32 	%f196, %r103;
	mul.ftz.f32 	%f69, %f274, %f196;
	fma.rn.ftz.f32 	%f275, %f274, %f195, %f275;
	mov.f32 	%f274, %f69;

$L__BB0_62:
	mov.b32 	%f197, %r315;
	fma.rn.ftz.f32 	%f73, %f274, %f197, %f275;
	@%p71 bra 	$L__BB0_64;

	st.global.f32 	[%rd131], %f73;

$L__BB0_64:
	add.s32 	%r234, %r313, 1;
	setp.gt.s32 	%p80, %r234, 31;
	mov.u32 	%r235, 31;
	selp.b32 	%r236, 31, %r313, %p80;
	mov.b32 	%r237, %f73;
	mov.u32 	%r238, -1;
	shfl.sync.idx.b32 	%r105|%p22, %r237, %r236, %r235, %r238;
	@%p43 bra 	$L__BB0_67;

	setp.ge.s32 	%p81, %r314, %r174;
	@%p81 bra 	$L__BB0_67;

	add.s64 	%rd94, %rd133, 128;

	prefetch.global.L2 [%rd94];


$L__BB0_67:
	add.s32 	%r239, %r312, 32;
	setp.ge.s32 	%p82, %r239, %r174;
	mov.f32 	%f287, 0f00000000;
	mov.f32 	%f286, 0f3F800000;
	@%p82 bra 	$L__BB0_69;

	ld.global.f32 	%f200, [%rd132+128];
	abs.ftz.f32 	%f201, %f200;
	setp.lt.ftz.f32 	%p83, %f201, 0f7F800000;
	mul.ftz.f32 	%f202, %f1, %f200;
	selp.f32 	%f286, %f2, 0f3F800000, %p83;
	selp.f32 	%f287, %f202, 0f00000000, %p83;

$L__BB0_69:
	mov.b32 	%r327, %f286;
	mov.u32 	%r240, 0;
	mov.u32 	%r241, 1;
	mov.u32 	%r242, -1;
	shfl.sync.up.b32 	%r107|%p23, %r327, %r241, %r240, %r242;
	mov.b32 	%r326, %f287;
	shfl.sync.up.b32 	%r109|%p24, %r326, %r241, %r240, %r242;
	@%p73 bra 	$L__BB0_71;

	mov.b32 	%f203, %r109;
	mov.b32 	%f204, %r107;
	mul.ftz.f32 	%f78, %f286, %f204;
	fma.rn.ftz.f32 	%f287, %f286, %f203, %f287;
	mov.b32 	%r327, %f78;
	mov.b32 	%r326, %f287;
	mov.f32 	%f286, %f78;

$L__BB0_71:
	mov.u32 	%r244, 2;
	shfl.sync.up.b32 	%r114|%p25, %r327, %r244, %r240, %r242;
	shfl.sync.up.b32 	%r115|%p26, %r326, %r244, %r240, %r242;
	@%p74 bra 	$L__BB0_73;

	mov.b32 	%f205, %r115;
	mov.b32 	%f206, %r114;
	mul.ftz.f32 	%f82, %f286, %f206;
	fma.rn.ftz.f32 	%f287, %f286, %f205, %f287;
	mov.b32 	%r327, %f82;
	mov.b32 	%r326, %f287;
	mov.f32 	%f286, %f82;

$L__BB0_73:
	mov.u32 	%r246, 0;
	mov.u32 	%r247, 4;
	mov.u32 	%r248, -1;
	shfl.sync.up.b32 	%r120|%p27, %r327, %r247, %r246, %r248;
	shfl.sync.up.b32 	%r121|%p28, %r326, %r247, %r246, %r248;
	@%p75 bra 	$L__BB0_75;

	mov.b32 	%f207, %r121;
	mov.b32 	%f208, %r120;
	mul.ftz.f32 	%f86, %f286, %f208;
	fma.rn.ftz.f32 	%f287, %f286, %f207, %f287;
	mov.b32 	%r327, %f86;
	mov.b32 	%r326, %f287;
	mov.f32 	%f286, %f86;

$L__BB0_75:
	mov.u32 	%r250, 8;
	shfl.sync.up.b32 	%r126|%p29, %r327, %r250, %r246, %r248;
	shfl.sync.up.b32 	%r127|%p30, %r326, %r250, %r246, %r248;
	@%p76 bra 	$L__BB0_77;

	mov.b32 	%f209, %r127;
	mov.b32 	%f210, %r126;
	mul.ftz.f32 	%f90, %f286, %f210;
	fma.rn.ftz.f32 	%f287, %f286, %f209, %f287;
	mov.b32 	%r327, %f90;
	mov.b32 	%r326, %f287;
	mov.f32 	%f286, %f90;

$L__BB0_77:
	mov.u32 	%r252, 0;
	mov.u32 	%r253, 16;
	mov.u32 	%r254, -1;
	shfl.sync.up.b32 	%r132|%p31, %r327, %r253, %r252, %r254;
	shfl.sync.up.b32 	%r133|%p32, %r326, %r253, %r252, %r254;
	@%p77 bra 	$L__BB0_79;

	mov.b32 	%f211, %r133;
	mov.b32 	%f212, %r132;
	mul.ftz.f32 	%f94, %f286, %f212;
	fma.rn.ftz.f32 	%f287, %f286, %f211, %f287;
	mov.f32 	%f286, %f94;

$L__BB0_79:
	mov.b32 	%f213, %r105;
	fma.rn.ftz.f32 	%f98, %f286, %f213, %f287;
	@%p82 bra 	$L__BB0_81;

	st.global.f32 	[%rd131+128], %f98;

$L__BB0_81:
	add.s32 	%r256, %r313, -31;
	setp.gt.s32 	%p90, %r256, 31;
	mov.u32 	%r257, 31;
	add.s32 	%r258, %r313, -32;
	selp.b32 	%r259, 31, %r258, %p90;
	mov.b32 	%r260, %f98;
	mov.u32 	%r261, -1;
	shfl.sync.idx.b32 	%r315|%p91, %r260, %r259, %r257, %r261;
	add.s32 	%r135, %r314, 64;
	add.s32 	%r262, %r314, -224;
	add.s64 	%rd133, %rd133, 256;
	add.s32 	%r313, %r313, -64;
	add.s64 	%rd132, %rd132, 256;
	add.s32 	%r312, %r312, 64;
	add.s64 	%rd131, %rd131, 256;
	setp.lt.s32 	%p92, %r262, %r174;
	mov.u32 	%r314, %r135;
	@%p92 bra 	$L__BB0_47;

$L__BB0_127:
	ret;

}

.visible .entry ema_batch_f64_to_f32(
	.param .u64 ema_batch_f64_to_f32_param_0,
	.param .u64 ema_batch_f64_to_f32_param_1,
	.param .u32 ema_batch_f64_to_f32_param_2,
	.param .u32 ema_batch_f64_to_f32_param_3,
	.param .u32 ema_batch_f64_to_f32_param_4,
	.param .u64 ema_batch_f64_to_f32_param_5
)
{
	.reg .pred 	%p<78>;
	.reg .f32 	%f<63>;
	.reg .b32 	%r<219>;
	.reg .f64 	%fd<207>;
	.reg .b64 	%rd<99>;


	ld.param.u64 	%rd44, [ema_batch_f64_to_f32_param_0];
	ld.param.u32 	%r76, [ema_batch_f64_to_f32_param_2];
	ld.param.u32 	%r77, [ema_batch_f64_to_f32_param_3];
	ld.param.u32 	%r78, [ema_batch_f64_to_f32_param_4];
	ld.param.u64 	%rd45, [ema_batch_f64_to_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd45;
	cvta.to.global.u64 	%rd2, %rd44;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r78;
	setp.lt.s32 	%p2, %r76, 1;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB1_67;

	ld.param.u64 	%rd86, [ema_batch_f64_to_f32_param_1];
	cvta.to.global.u64 	%rd46, %rd86;
	mul.wide.s32 	%rd47, %r1, 4;
	add.s64 	%rd48, %rd46, %rd47;
	ld.global.nc.u32 	%r2, [%rd48];
	setp.lt.s32 	%p4, %r2, 1;
	setp.ge.s32 	%p5, %r77, %r76;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB1_67;

	mov.u32 	%r180, %ctaid.x;
	cvt.s64.s32 	%rd85, %r180;
	cvt.rn.f64.s32 	%fd78, %r2;
	add.f64 	%fd79, %fd78, 0d3FF0000000000000;
	mov.f64 	%fd80, 0d3FF0000000000000;
	mov.f64 	%fd81, 0d4000000000000000;
	div.rn.f64 	%fd1, %fd81, %fd79;
	sub.f64 	%fd2, %fd80, %fd1;
	cvt.s64.s32 	%rd49, %r76;
	mul.lo.s64 	%rd4, %rd49, %rd85;
	mov.u32 	%r3, %tid.x;
	setp.lt.s32 	%p7, %r3, %r77;
	@%p7 bra 	$L__BB1_3;
	bra.uni 	$L__BB1_5;

$L__BB1_3:
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r187, %r3;

$L__BB1_4:
	cvt.s64.s32 	%rd50, %r187;
	add.s64 	%rd51, %rd4, %rd50;
	shl.b64 	%rd52, %rd51, 2;
	add.s64 	%rd53, %rd1, %rd52;
	mov.u32 	%r79, 2143289344;
	st.global.u32 	[%rd53], %r79;
	add.s32 	%r187, %r187, %r4;
	setp.lt.s32 	%p8, %r187, %r77;
	@%p8 bra 	$L__BB1_4;

$L__BB1_5:
	mov.u32 	%r80, %ntid.x;
	setp.lt.u32 	%p9, %r80, 32;
	cvt.s64.s32 	%rd54, %r77;
	mul.wide.s32 	%rd55, %r77, 4;
	add.s64 	%rd5, %rd2, %rd55;
	add.s64 	%rd56, %rd4, %rd54;
	shl.b64 	%rd57, %rd56, 2;
	add.s64 	%rd6, %rd1, %rd57;
	@%p9 bra 	$L__BB1_42;
	bra.uni 	$L__BB1_6;

$L__BB1_42:
	setp.ne.s32 	%p57, %r3, 0;
	@%p57 bra 	$L__BB1_67;

	ld.param.u32 	%r178, [ema_batch_f64_to_f32_param_3];
	add.s32 	%r41, %r2, %r178;
	min.s32 	%r217, %r41, %r76;
	ld.global.nc.f32 	%f35, [%rd5];
	cvt.ftz.f64.f32 	%fd195, %f35;
	st.global.f32 	[%rd6], %f35;
	add.s32 	%r210, %r178, 1;
	setp.ge.s32 	%p58, %r210, %r217;
	@%p58 bra 	$L__BB1_60;

	ld.param.u32 	%r179, [ema_batch_f64_to_f32_param_3];
	mov.u32 	%r165, -2;
	sub.s32 	%r166, %r165, %r179;
	not.b32 	%r167, %r217;
	sub.s32 	%r44, %r166, %r167;
	mov.u32 	%r168, -3;
	sub.s32 	%r169, %r168, %r179;
	sub.s32 	%r170, %r169, %r167;
	and.b32  	%r213, %r44, 3;
	setp.lt.u32 	%p59, %r170, 3;
	mov.u32 	%r206, 1;
	@%p59 bra 	$L__BB1_55;

	sub.s32 	%r205, %r44, %r213;
	mov.u32 	%r206, 1;

$L__BB1_46:
	cvt.s64.s32 	%rd22, %r210;
	mul.wide.s32 	%rd69, %r210, 4;
	add.s64 	%rd23, %rd2, %rd69;
	ld.global.nc.f32 	%f13, [%rd23];
	abs.ftz.f32 	%f36, %f13;
	setp.geu.ftz.f32 	%p60, %f36, 0f7F800000;
	@%p60 bra 	$L__BB1_48;

	add.s32 	%r206, %r206, 1;
	cvt.rn.f64.s32 	%fd133, %r206;
	add.f64 	%fd134, %fd133, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd135, %f13;
	fma.rn.f64 	%fd136, %fd195, %fd134, %fd135;
	div.rn.f64 	%fd195, %fd136, %fd133;

$L__BB1_48:
	add.s64 	%rd70, %rd4, %rd22;
	shl.b64 	%rd71, %rd70, 2;
	add.s64 	%rd24, %rd1, %rd71;
	cvt.rn.ftz.f32.f64 	%f61, %fd195;
	st.global.f32 	[%rd24], %f61;
	ld.global.nc.f32 	%f15, [%rd23+4];
	abs.ftz.f32 	%f37, %f15;
	setp.geu.ftz.f32 	%p61, %f37, 0f7F800000;
	@%p61 bra 	$L__BB1_50;

	add.s32 	%r206, %r206, 1;
	cvt.rn.f64.s32 	%fd137, %r206;
	add.f64 	%fd138, %fd137, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd139, %f15;
	fma.rn.f64 	%fd140, %fd195, %fd138, %fd139;
	div.rn.f64 	%fd195, %fd140, %fd137;
	cvt.rn.ftz.f32.f64 	%f61, %fd195;

$L__BB1_50:
	st.global.f32 	[%rd24+4], %f61;
	ld.global.nc.f32 	%f18, [%rd23+8];
	abs.ftz.f32 	%f38, %f18;
	setp.geu.ftz.f32 	%p62, %f38, 0f7F800000;
	@%p62 bra 	$L__BB1_52;

	add.s32 	%r206, %r206, 1;
	cvt.rn.f64.s32 	%fd141, %r206;
	add.f64 	%fd142, %fd141, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd143, %f18;
	fma.rn.f64 	%fd144, %fd195, %fd142, %fd143;
	div.rn.f64 	%fd195, %fd144, %fd141;
	cvt.rn.ftz.f32.f64 	%f61, %fd195;

$L__BB1_52:
	st.global.f32 	[%rd24+8], %f61;
	ld.global.nc.f32 	%f21, [%rd23+12];
	abs.ftz.f32 	%f39, %f21;
	setp.geu.ftz.f32 	%p63, %f39, 0f7F800000;
	@%p63 bra 	$L__BB1_54;

	add.s32 	%r206, %r206, 1;
	cvt.rn.f64.s32 	%fd145, %r206;
	add.f64 	%fd146, %fd145, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd147, %f21;
	fma.rn.f64 	%fd148, %fd195, %fd146, %fd147;
	div.rn.f64 	%fd195, %fd148, %fd145;
	cvt.rn.ftz.f32.f64 	%f61, %fd195;

$L__BB1_54:
	st.global.f32 	[%rd24+12], %f61;
	cvt.u32.u64 	%r172, %rd22;
	add.s32 	%r210, %r172, 4;
	add.s32 	%r205, %r205, -4;
	setp.ne.s32 	%p64, %r205, 0;
	@%p64 bra 	$L__BB1_46;

$L__BB1_55:
	setp.eq.s32 	%p65, %r213, 0;
	@%p65 bra 	$L__BB1_60;

	cvt.s64.s32 	%rd72, %r210;
	add.s64 	%rd73, %rd4, %rd72;
	shl.b64 	%rd74, %rd73, 2;
	add.s64 	%rd94, %rd1, %rd74;
	mul.wide.s32 	%rd75, %r210, 4;
	add.s64 	%rd93, %rd2, %rd75;

$L__BB1_57:
	.pragma "nounroll";
	ld.global.nc.f32 	%f24, [%rd93];
	abs.ftz.f32 	%f40, %f24;
	setp.geu.ftz.f32 	%p66, %f40, 0f7F800000;
	@%p66 bra 	$L__BB1_59;

	add.s32 	%r206, %r206, 1;
	cvt.rn.f64.s32 	%fd149, %r206;
	add.f64 	%fd150, %fd149, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd151, %f24;
	fma.rn.f64 	%fd152, %fd195, %fd150, %fd151;
	div.rn.f64 	%fd195, %fd152, %fd149;

$L__BB1_59:
	cvt.rn.ftz.f32.f64 	%f41, %fd195;
	st.global.f32 	[%rd94], %f41;
	add.s64 	%rd94, %rd94, 4;
	add.s64 	%rd93, %rd93, 4;
	add.s32 	%r213, %r213, -1;
	setp.ne.s32 	%p67, %r213, 0;
	@%p67 bra 	$L__BB1_57;

$L__BB1_60:
	setp.ge.s32 	%p68, %r41, %r76;
	@%p68 bra 	$L__BB1_67;

	not.b32 	%r173, %r217;
	add.s32 	%r67, %r173, %r76;
	add.s32 	%r174, %r67, 1;
	and.b32  	%r216, %r174, 3;
	setp.eq.s32 	%p69, %r216, 0;
	@%p69 bra 	$L__BB1_64;

	cvt.s64.s32 	%rd76, %r217;
	add.s64 	%rd77, %rd4, %rd76;
	shl.b64 	%rd78, %rd77, 2;
	add.s64 	%rd96, %rd1, %rd78;
	mul.wide.s32 	%rd79, %r217, 4;
	add.s64 	%rd95, %rd2, %rd79;

$L__BB1_63:
	.pragma "nounroll";
	ld.global.nc.f32 	%f42, [%rd95];
	abs.ftz.f32 	%f43, %f42;
	setp.geu.ftz.f32 	%p70, %f43, 0f7F800000;
	cvt.ftz.f64.f32 	%fd153, %f42;
	mul.f64 	%fd154, %fd1, %fd153;
	fma.rn.f64 	%fd155, %fd2, %fd195, %fd154;
	selp.f64 	%fd195, %fd195, %fd155, %p70;
	cvt.rn.ftz.f32.f64 	%f44, %fd195;
	st.global.f32 	[%rd96], %f44;
	add.s32 	%r217, %r217, 1;
	add.s64 	%rd96, %rd96, 4;
	add.s64 	%rd95, %rd95, 4;
	add.s32 	%r216, %r216, -1;
	setp.ne.s32 	%p71, %r216, 0;
	@%p71 bra 	$L__BB1_63;

$L__BB1_64:
	setp.lt.u32 	%p72, %r67, 3;
	@%p72 bra 	$L__BB1_67;

	cvt.s64.s32 	%rd80, %r217;
	add.s64 	%rd81, %rd4, %rd80;
	shl.b64 	%rd82, %rd81, 2;
	add.s64 	%rd98, %rd1, %rd82;
	mul.wide.s32 	%rd83, %r217, 4;
	add.s64 	%rd84, %rd2, %rd83;
	add.s64 	%rd97, %rd84, 8;

$L__BB1_66:
	ld.global.nc.f32 	%f45, [%rd97+-8];
	abs.ftz.f32 	%f46, %f45;
	setp.geu.ftz.f32 	%p73, %f46, 0f7F800000;
	cvt.ftz.f64.f32 	%fd156, %f45;
	mul.f64 	%fd157, %fd1, %fd156;
	fma.rn.f64 	%fd158, %fd2, %fd195, %fd157;
	selp.f64 	%fd159, %fd195, %fd158, %p73;
	cvt.rn.ftz.f32.f64 	%f47, %fd159;
	st.global.f32 	[%rd98], %f47;
	ld.global.nc.f32 	%f48, [%rd97+-4];
	abs.ftz.f32 	%f49, %f48;
	setp.geu.ftz.f32 	%p74, %f49, 0f7F800000;
	cvt.ftz.f64.f32 	%fd160, %f48;
	mul.f64 	%fd161, %fd1, %fd160;
	fma.rn.f64 	%fd162, %fd2, %fd159, %fd161;
	selp.f64 	%fd163, %fd159, %fd162, %p74;
	cvt.rn.ftz.f32.f64 	%f50, %fd163;
	st.global.f32 	[%rd98+4], %f50;
	ld.global.nc.f32 	%f51, [%rd97];
	abs.ftz.f32 	%f52, %f51;
	setp.geu.ftz.f32 	%p75, %f52, 0f7F800000;
	cvt.ftz.f64.f32 	%fd164, %f51;
	mul.f64 	%fd165, %fd1, %fd164;
	fma.rn.f64 	%fd166, %fd2, %fd163, %fd165;
	selp.f64 	%fd167, %fd163, %fd166, %p75;
	cvt.rn.ftz.f32.f64 	%f53, %fd167;
	st.global.f32 	[%rd98+8], %f53;
	ld.global.nc.f32 	%f54, [%rd97+4];
	abs.ftz.f32 	%f55, %f54;
	setp.geu.ftz.f32 	%p76, %f55, 0f7F800000;
	cvt.ftz.f64.f32 	%fd168, %f54;
	mul.f64 	%fd169, %fd1, %fd168;
	fma.rn.f64 	%fd170, %fd2, %fd167, %fd169;
	selp.f64 	%fd195, %fd167, %fd170, %p76;
	cvt.rn.ftz.f32.f64 	%f56, %fd195;
	st.global.f32 	[%rd98+12], %f56;
	add.s64 	%rd98, %rd98, 16;
	add.s64 	%rd97, %rd97, 16;
	add.s32 	%r217, %r217, 4;
	setp.lt.s32 	%p77, %r217, %r76;
	@%p77 bra 	$L__BB1_66;
	bra.uni 	$L__BB1_67;

$L__BB1_6:
	setp.gt.u32 	%p10, %r3, 31;
	@%p10 bra 	$L__BB1_67;

	ld.param.u32 	%r175, [ema_batch_f64_to_f32_param_3];
	add.s32 	%r7, %r2, %r175;
	min.s32 	%r8, %r7, %r76;
	setp.ne.s32 	%p11, %r3, 0;
	mov.f64 	%fd172, 0d0000000000000000;
	@%p11 bra 	$L__BB1_25;

	ld.param.u32 	%r176, [ema_batch_f64_to_f32_param_3];
	ld.global.nc.f32 	%f25, [%rd5];
	cvt.ftz.f64.f32 	%fd172, %f25;
	st.global.f32 	[%rd6], %f25;
	add.s32 	%r195, %r176, 1;
	setp.ge.s32 	%p12, %r195, %r8;
	@%p12 bra 	$L__BB1_25;

	ld.param.u32 	%r177, [ema_batch_f64_to_f32_param_3];
	mov.u32 	%r82, -2;
	sub.s32 	%r83, %r82, %r177;
	not.b32 	%r84, %r8;
	sub.s32 	%r10, %r83, %r84;
	mov.u32 	%r85, -3;
	sub.s32 	%r86, %r85, %r177;
	sub.s32 	%r87, %r86, %r84;
	and.b32  	%r198, %r10, 3;
	setp.lt.u32 	%p13, %r87, 3;
	mov.u32 	%r191, 1;
	@%p13 bra 	$L__BB1_20;

	sub.s32 	%r190, %r10, %r198;
	mov.u32 	%r191, 1;

$L__BB1_11:
	mul.wide.s32 	%rd58, %r195, 4;
	add.s64 	%rd8, %rd2, %rd58;
	ld.global.nc.f32 	%f1, [%rd8];
	abs.ftz.f32 	%f26, %f1;
	setp.geu.ftz.f32 	%p14, %f26, 0f7F800000;
	@%p14 bra 	$L__BB1_13;

	add.s32 	%r191, %r191, 1;
	cvt.rn.f64.s32 	%fd84, %r191;
	add.f64 	%fd85, %fd84, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd86, %f1;
	fma.rn.f64 	%fd87, %fd172, %fd85, %fd86;
	div.rn.f64 	%fd172, %fd87, %fd84;

$L__BB1_13:
	cvt.s64.s32 	%rd88, %r195;
	add.s64 	%rd59, %rd4, %rd88;
	shl.b64 	%rd60, %rd59, 2;
	add.s64 	%rd9, %rd1, %rd60;
	cvt.rn.ftz.f32.f64 	%f58, %fd172;
	st.global.f32 	[%rd9], %f58;
	ld.global.nc.f32 	%f3, [%rd8+4];
	abs.ftz.f32 	%f27, %f3;
	setp.geu.ftz.f32 	%p15, %f27, 0f7F800000;
	@%p15 bra 	$L__BB1_15;

	add.s32 	%r191, %r191, 1;
	cvt.rn.f64.s32 	%fd88, %r191;
	add.f64 	%fd89, %fd88, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd90, %f3;
	fma.rn.f64 	%fd91, %fd172, %fd89, %fd90;
	div.rn.f64 	%fd172, %fd91, %fd88;
	cvt.rn.ftz.f32.f64 	%f58, %fd172;

$L__BB1_15:
	st.global.f32 	[%rd9+4], %f58;
	ld.global.nc.f32 	%f6, [%rd8+8];
	abs.ftz.f32 	%f28, %f6;
	setp.geu.ftz.f32 	%p16, %f28, 0f7F800000;
	@%p16 bra 	$L__BB1_17;

	add.s32 	%r191, %r191, 1;
	cvt.rn.f64.s32 	%fd92, %r191;
	add.f64 	%fd93, %fd92, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd94, %f6;
	fma.rn.f64 	%fd95, %fd172, %fd93, %fd94;
	div.rn.f64 	%fd172, %fd95, %fd92;
	cvt.rn.ftz.f32.f64 	%f58, %fd172;

$L__BB1_17:
	st.global.f32 	[%rd9+8], %f58;
	ld.global.nc.f32 	%f9, [%rd8+12];
	abs.ftz.f32 	%f29, %f9;
	setp.geu.ftz.f32 	%p17, %f29, 0f7F800000;
	@%p17 bra 	$L__BB1_19;

	add.s32 	%r191, %r191, 1;
	cvt.rn.f64.s32 	%fd96, %r191;
	add.f64 	%fd97, %fd96, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd98, %f9;
	fma.rn.f64 	%fd99, %fd172, %fd97, %fd98;
	div.rn.f64 	%fd172, %fd99, %fd96;
	cvt.rn.ftz.f32.f64 	%f58, %fd172;

$L__BB1_19:
	cvt.s64.s32 	%rd87, %r195;
	st.global.f32 	[%rd9+12], %f58;
	cvt.u32.u64 	%r89, %rd87;
	add.s32 	%r195, %r89, 4;
	add.s32 	%r190, %r190, -4;
	setp.ne.s32 	%p18, %r190, 0;
	@%p18 bra 	$L__BB1_11;

$L__BB1_20:
	setp.eq.s32 	%p19, %r198, 0;
	@%p19 bra 	$L__BB1_25;

	cvt.s64.s32 	%rd61, %r195;
	add.s64 	%rd62, %rd4, %rd61;
	shl.b64 	%rd63, %rd62, 2;
	add.s64 	%rd90, %rd1, %rd63;
	mul.wide.s32 	%rd64, %r195, 4;
	add.s64 	%rd89, %rd2, %rd64;

$L__BB1_22:
	.pragma "nounroll";
	ld.global.nc.f32 	%f12, [%rd89];
	abs.ftz.f32 	%f30, %f12;
	setp.geu.ftz.f32 	%p20, %f30, 0f7F800000;
	@%p20 bra 	$L__BB1_24;

	add.s32 	%r191, %r191, 1;
	cvt.rn.f64.s32 	%fd100, %r191;
	add.f64 	%fd101, %fd100, 0dBFF0000000000000;
	cvt.ftz.f64.f32 	%fd102, %f12;
	fma.rn.f64 	%fd103, %fd172, %fd101, %fd102;
	div.rn.f64 	%fd172, %fd103, %fd100;

$L__BB1_24:
	cvt.rn.ftz.f32.f64 	%f31, %fd172;
	st.global.f32 	[%rd90], %f31;
	add.s64 	%rd90, %rd90, 4;
	add.s64 	%rd89, %rd89, 4;
	add.s32 	%r198, %r198, -1;
	setp.ne.s32 	%p21, %r198, 0;
	@%p21 bra 	$L__BB1_22;

$L__BB1_25:
	ld.param.u32 	%r182, [ema_batch_f64_to_f32_param_3];
	add.s32 	%r181, %r2, %r182;

	mov.b64 {%r90,%r91}, %fd172;

	mov.u32 	%r94, 31;
	mov.u32 	%r95, 0;
	mov.u32 	%r96, -1;
	shfl.sync.idx.b32 	%r93|%p22, %r91, %r95, %r94, %r96;
	shfl.sync.idx.b32 	%r92|%p23, %r90, %r95, %r94, %r96;

	mov.b64 %fd181, {%r92,%r93};

	setp.ge.s32 	%p24, %r181, %r76;
	@%p24 bra 	$L__BB1_67;

	add.s32 	%r186, %r2, %r175;
	ld.param.u32 	%r185, [ema_batch_f64_to_f32_param_3];
	add.s32 	%r184, %r2, %r185;
	min.s32 	%r202, %r184, %r76;
	not.b32 	%r97, %r76;
	not.b32 	%r98, %r184;
	max.s32 	%r99, %r97, %r98;
	add.s32 	%r201, %r76, %r99;
	add.s32 	%r100, %r3, -1;
	sub.s32 	%r200, %r100, %r99;
	cvt.s64.s32 	%rd65, %r200;
	mul.wide.s32 	%rd66, %r200, 4;
	add.s64 	%rd92, %rd2, %rd66;
	add.s64 	%rd67, %rd4, %rd65;
	shl.b64 	%rd68, %rd67, 2;
	add.s64 	%rd91, %rd1, %rd68;

$L__BB1_27:
	setp.ge.s32 	%p25, %r200, %r76;
	mov.f64 	%fd185, 0d0000000000000000;
	mov.f64 	%fd184, 0d3FF0000000000000;
	@%p25 bra 	$L__BB1_29;

	ld.global.nc.f32 	%f32, [%rd92];
	abs.ftz.f32 	%f33, %f32;
	setp.lt.ftz.f32 	%p26, %f33, 0f7F800000;
	cvt.ftz.f64.f32 	%fd108, %f32;
	mul.f64 	%fd109, %fd1, %fd108;
	selp.f64 	%fd184, %fd2, 0d3FF0000000000000, %p26;
	selp.f64 	%fd185, %fd109, 0d0000000000000000, %p26;

$L__BB1_29:

	mov.b64 {%r101,%r102}, %fd184;

	mov.u32 	%r109, 0;
	mov.u32 	%r110, 1;
	mov.u32 	%r111, -1;
	shfl.sync.up.b32 	%r104|%p27, %r102, %r110, %r109, %r111;
	shfl.sync.up.b32 	%r103|%p28, %r101, %r110, %r109, %r111;

	mov.b64 %fd111, {%r103,%r104};


	mov.b64 {%r105,%r106}, %fd185;

	shfl.sync.up.b32 	%r108|%p29, %r106, %r110, %r109, %r111;
	shfl.sync.up.b32 	%r107|%p30, %r105, %r110, %r109, %r111;

	mov.b64 %fd113, {%r107,%r108};

	setp.eq.s32 	%p31, %r3, 0;
	@%p31 bra 	$L__BB1_31;

	mul.f64 	%fd27, %fd184, %fd111;
	fma.rn.f64 	%fd185, %fd184, %fd113, %fd185;
	mov.f64 	%fd184, %fd27;

$L__BB1_31:

	mov.b64 {%r112,%r113}, %fd184;

	mov.u32 	%r121, 2;
	shfl.sync.up.b32 	%r115|%p32, %r113, %r121, %r109, %r111;
	shfl.sync.up.b32 	%r114|%p33, %r112, %r121, %r109, %r111;

	mov.b64 %fd115, {%r114,%r115};


	mov.b64 {%r116,%r117}, %fd185;

	shfl.sync.up.b32 	%r119|%p34, %r117, %r121, %r109, %r111;
	shfl.sync.up.b32 	%r118|%p35, %r116, %r121, %r109, %r111;

	mov.b64 %fd117, {%r118,%r119};

	setp.lt.u32 	%p36, %r3, 2;
	@%p36 bra 	$L__BB1_33;

	mul.f64 	%fd33, %fd184, %fd115;
	fma.rn.f64 	%fd185, %fd184, %fd117, %fd185;
	mov.f64 	%fd184, %fd33;

$L__BB1_33:

	mov.b64 {%r123,%r124}, %fd184;

	mov.u32 	%r131, 0;
	mov.u32 	%r132, 4;
	mov.u32 	%r133, -1;
	shfl.sync.up.b32 	%r126|%p37, %r124, %r132, %r131, %r133;
	shfl.sync.up.b32 	%r125|%p38, %r123, %r132, %r131, %r133;

	mov.b64 %fd119, {%r125,%r126};


	mov.b64 {%r127,%r128}, %fd185;

	shfl.sync.up.b32 	%r130|%p39, %r128, %r132, %r131, %r133;
	shfl.sync.up.b32 	%r129|%p40, %r127, %r132, %r131, %r133;

	mov.b64 %fd121, {%r129,%r130};

	setp.lt.u32 	%p41, %r3, 4;
	@%p41 bra 	$L__BB1_35;

	mul.f64 	%fd39, %fd184, %fd119;
	fma.rn.f64 	%fd185, %fd184, %fd121, %fd185;
	mov.f64 	%fd184, %fd39;

$L__BB1_35:

	mov.b64 {%r134,%r135}, %fd184;

	mov.u32 	%r143, 8;
	shfl.sync.up.b32 	%r137|%p42, %r135, %r143, %r131, %r133;
	shfl.sync.up.b32 	%r136|%p43, %r134, %r143, %r131, %r133;

	mov.b64 %fd123, {%r136,%r137};


	mov.b64 {%r138,%r139}, %fd185;

	shfl.sync.up.b32 	%r141|%p44, %r139, %r143, %r131, %r133;
	shfl.sync.up.b32 	%r140|%p45, %r138, %r143, %r131, %r133;

	mov.b64 %fd125, {%r140,%r141};

	setp.lt.u32 	%p46, %r3, 8;
	@%p46 bra 	$L__BB1_37;

	mul.f64 	%fd45, %fd184, %fd123;
	fma.rn.f64 	%fd185, %fd184, %fd125, %fd185;
	mov.f64 	%fd184, %fd45;

$L__BB1_37:

	mov.b64 {%r145,%r146}, %fd184;

	mov.u32 	%r153, 0;
	mov.u32 	%r154, 16;
	mov.u32 	%r155, -1;
	shfl.sync.up.b32 	%r148|%p47, %r146, %r154, %r153, %r155;
	shfl.sync.up.b32 	%r147|%p48, %r145, %r154, %r153, %r155;

	mov.b64 %fd127, {%r147,%r148};


	mov.b64 {%r149,%r150}, %fd185;

	shfl.sync.up.b32 	%r152|%p49, %r150, %r154, %r153, %r155;
	shfl.sync.up.b32 	%r151|%p50, %r149, %r154, %r153, %r155;

	mov.b64 %fd129, {%r151,%r152};

	setp.lt.u32 	%p51, %r3, 16;
	@%p51 bra 	$L__BB1_39;

	mul.f64 	%fd51, %fd184, %fd127;
	fma.rn.f64 	%fd185, %fd184, %fd129, %fd185;
	mov.f64 	%fd184, %fd51;

$L__BB1_39:
	fma.rn.f64 	%fd55, %fd184, %fd181, %fd185;
	@%p25 bra 	$L__BB1_41;

	cvt.rn.ftz.f32.f64 	%f34, %fd55;
	st.global.f32 	[%rd91], %f34;

$L__BB1_41:
	add.s32 	%r160, %r201, 1;
	setp.gt.s32 	%p53, %r160, 31;
	mov.u32 	%r161, 31;
	selp.b32 	%r162, 31, %r201, %p53;

	mov.b64 {%r156,%r157}, %fd55;

	mov.u32 	%r163, -1;
	shfl.sync.idx.b32 	%r159|%p54, %r157, %r162, %r161, %r163;
	shfl.sync.idx.b32 	%r158|%p55, %r156, %r162, %r161, %r163;

	mov.b64 %fd181, {%r158,%r159};

	add.s32 	%r201, %r201, -32;
	add.s64 	%rd92, %rd92, 128;
	add.s32 	%r200, %r200, 32;
	add.s64 	%rd91, %rd91, 128;
	add.s32 	%r202, %r202, 32;
	setp.lt.s32 	%p56, %r202, %r76;
	@%p56 bra 	$L__BB1_27;

$L__BB1_67:
	ret;

}

.visible .entry ema_many_series_one_param_f32(
	.param .u64 ema_many_series_one_param_f32_param_0,
	.param .u64 ema_many_series_one_param_f32_param_1,
	.param .u32 ema_many_series_one_param_f32_param_2,
	.param .f32 ema_many_series_one_param_f32_param_3,
	.param .u32 ema_many_series_one_param_f32_param_4,
	.param .u32 ema_many_series_one_param_f32_param_5,
	.param .u64 ema_many_series_one_param_f32_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .f32 	%f<95>;
	.reg .b32 	%r<80>;
	.reg .b64 	%rd<62>;


	ld.param.u64 	%rd38, [ema_many_series_one_param_f32_param_0];
	ld.param.u64 	%rd37, [ema_many_series_one_param_f32_param_1];
	ld.param.u32 	%r42, [ema_many_series_one_param_f32_param_2];
	ld.param.f32 	%f40, [ema_many_series_one_param_f32_param_3];
	ld.param.u32 	%r43, [ema_many_series_one_param_f32_param_4];
	ld.param.u32 	%r44, [ema_many_series_one_param_f32_param_5];
	ld.param.u64 	%rd39, [ema_many_series_one_param_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd39;
	cvta.to.global.u64 	%rd2, %rd38;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r43;
	setp.lt.s32 	%p2, %r42, 1;
	or.pred  	%p3, %p2, %p1;
	setp.lt.s32 	%p4, %r44, 1;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	$L__BB2_40;

	cvta.to.global.u64 	%rd40, %rd37;
	mul.wide.s32 	%rd41, %r1, 4;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.nc.u32 	%r45, [%rd42];
	max.s32 	%r2, %r45, 0;
	setp.ge.s32 	%p6, %r2, %r44;
	@%p6 bra 	$L__BB2_40;

	mov.u32 	%r3, %tid.x;
	setp.ge.s32 	%p7, %r3, %r2;
	@%p7 bra 	$L__BB2_5;

	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r63, %r3;

$L__BB2_4:
	mad.lo.s32 	%r46, %r63, %r43, %r1;
	mul.wide.s32 	%rd43, %r46, 4;
	add.s64 	%rd44, %rd1, %rd43;
	mov.u32 	%r47, 2143289344;
	st.global.u32 	[%rd44], %r47;
	add.s32 	%r63, %r63, %r4;
	setp.lt.s32 	%p8, %r63, %r2;
	@%p8 bra 	$L__BB2_4;

$L__BB2_5:
	setp.ne.s32 	%p9, %r3, 0;
	@%p9 bra 	$L__BB2_40;

	add.s32 	%r7, %r2, %r42;
	min.s32 	%r78, %r7, %r44;
	mad.lo.s32 	%r48, %r2, %r43, %r1;
	mul.wide.s32 	%rd45, %r48, 4;
	add.s64 	%rd46, %rd2, %rd45;
	ld.global.nc.f32 	%f78, [%rd46];
	add.s64 	%rd47, %rd1, %rd45;
	st.global.f32 	[%rd47], %f78;
	add.s32 	%r71, %r2, 1;
	setp.ge.s32 	%p10, %r71, %r78;
	@%p10 bra 	$L__BB2_23;

	mov.u32 	%r50, -2;
	sub.s32 	%r51, %r50, %r2;
	not.b32 	%r52, %r78;
	sub.s32 	%r10, %r51, %r52;
	mov.u32 	%r53, -3;
	sub.s32 	%r54, %r53, %r2;
	sub.s32 	%r55, %r54, %r52;
	and.b32  	%r74, %r10, 3;
	setp.lt.u32 	%p11, %r55, 3;
	mov.u32 	%r67, 1;
	@%p11 bra 	$L__BB2_18;

	sub.s32 	%r66, %r10, %r74;
	mul.wide.s32 	%rd3, %r43, 4;
	mov.u32 	%r67, 1;

$L__BB2_9:
	mad.lo.s32 	%r57, %r71, %r43, %r1;
	cvt.s64.s32 	%rd4, %r57;
	mul.wide.s32 	%rd48, %r57, 4;
	add.s64 	%rd5, %rd2, %rd48;
	ld.global.nc.f32 	%f3, [%rd5];
	abs.ftz.f32 	%f42, %f3;
	setp.geu.ftz.f32 	%p12, %f42, 0f7F800000;
	@%p12 bra 	$L__BB2_11;

	add.s32 	%r67, %r67, 1;
	cvt.rn.f32.s32 	%f43, %r67;
	mov.f32 	%f44, 0f3F800000;
	div.approx.ftz.f32 	%f45, %f44, %f43;
	sub.ftz.f32 	%f46, %f3, %f78;
	fma.rn.ftz.f32 	%f78, %f46, %f45, %f78;

$L__BB2_11:
	shl.b64 	%rd49, %rd4, 2;
	add.s64 	%rd6, %rd1, %rd49;
	st.global.f32 	[%rd6], %f78;
	add.s64 	%rd7, %rd5, %rd3;
	ld.global.nc.f32 	%f6, [%rd7];
	abs.ftz.f32 	%f47, %f6;
	setp.geu.ftz.f32 	%p13, %f47, 0f7F800000;
	@%p13 bra 	$L__BB2_13;

	add.s32 	%r67, %r67, 1;
	cvt.rn.f32.s32 	%f48, %r67;
	mov.f32 	%f49, 0f3F800000;
	div.approx.ftz.f32 	%f50, %f49, %f48;
	sub.ftz.f32 	%f51, %f6, %f78;
	fma.rn.ftz.f32 	%f78, %f51, %f50, %f78;

$L__BB2_13:
	add.s64 	%rd8, %rd6, %rd3;
	st.global.f32 	[%rd8], %f78;
	add.s64 	%rd9, %rd7, %rd3;
	ld.global.nc.f32 	%f9, [%rd9];
	abs.ftz.f32 	%f52, %f9;
	setp.geu.ftz.f32 	%p14, %f52, 0f7F800000;
	@%p14 bra 	$L__BB2_15;

	add.s32 	%r67, %r67, 1;
	cvt.rn.f32.s32 	%f53, %r67;
	mov.f32 	%f54, 0f3F800000;
	div.approx.ftz.f32 	%f55, %f54, %f53;
	sub.ftz.f32 	%f56, %f9, %f78;
	fma.rn.ftz.f32 	%f78, %f56, %f55, %f78;

$L__BB2_15:
	add.s64 	%rd10, %rd8, %rd3;
	st.global.f32 	[%rd10], %f78;
	add.s64 	%rd50, %rd9, %rd3;
	ld.global.nc.f32 	%f12, [%rd50];
	abs.ftz.f32 	%f57, %f12;
	setp.geu.ftz.f32 	%p15, %f57, 0f7F800000;
	@%p15 bra 	$L__BB2_17;

	add.s32 	%r67, %r67, 1;
	cvt.rn.f32.s32 	%f58, %r67;
	mov.f32 	%f59, 0f3F800000;
	div.approx.ftz.f32 	%f60, %f59, %f58;
	sub.ftz.f32 	%f61, %f12, %f78;
	fma.rn.ftz.f32 	%f78, %f61, %f60, %f78;

$L__BB2_17:
	add.s64 	%rd51, %rd10, %rd3;
	st.global.f32 	[%rd51], %f78;
	add.s32 	%r71, %r71, 4;
	add.s32 	%r66, %r66, -4;
	setp.ne.s32 	%p16, %r66, 0;
	@%p16 bra 	$L__BB2_9;

$L__BB2_18:
	setp.eq.s32 	%p17, %r74, 0;
	@%p17 bra 	$L__BB2_23;

	mad.lo.s32 	%r58, %r71, %r43, %r1;
	mul.wide.s32 	%rd52, %r58, 4;
	add.s64 	%rd57, %rd1, %rd52;
	mul.wide.s32 	%rd12, %r43, 4;
	add.s64 	%rd56, %rd2, %rd52;

$L__BB2_20:
	.pragma "nounroll";
	ld.global.nc.f32 	%f18, [%rd56];
	abs.ftz.f32 	%f62, %f18;
	setp.geu.ftz.f32 	%p18, %f62, 0f7F800000;
	@%p18 bra 	$L__BB2_22;

	add.s32 	%r67, %r67, 1;
	cvt.rn.f32.s32 	%f63, %r67;
	mov.f32 	%f64, 0f3F800000;
	div.approx.ftz.f32 	%f65, %f64, %f63;
	sub.ftz.f32 	%f66, %f18, %f78;
	fma.rn.ftz.f32 	%f78, %f66, %f65, %f78;

$L__BB2_22:
	st.global.f32 	[%rd57], %f78;
	add.s64 	%rd57, %rd57, %rd12;
	add.s64 	%rd56, %rd56, %rd12;
	add.s32 	%r74, %r74, -1;
	setp.ne.s32 	%p19, %r74, 0;
	@%p19 bra 	$L__BB2_20;

$L__BB2_23:
	setp.ge.s32 	%p20, %r7, %r44;
	@%p20 bra 	$L__BB2_40;

	not.b32 	%r59, %r78;
	add.s32 	%r33, %r59, %r44;
	add.s32 	%r60, %r33, 1;
	and.b32  	%r77, %r60, 3;
	setp.eq.s32 	%p21, %r77, 0;
	@%p21 bra 	$L__BB2_29;

	mad.lo.s32 	%r61, %r43, %r78, %r1;
	mul.wide.s32 	%rd53, %r61, 4;
	add.s64 	%rd59, %rd1, %rd53;
	mul.wide.s32 	%rd19, %r43, 4;
	add.s64 	%rd58, %rd2, %rd53;

$L__BB2_26:
	.pragma "nounroll";
	ld.global.nc.f32 	%f23, [%rd58];
	abs.ftz.f32 	%f67, %f23;
	setp.geu.ftz.f32 	%p22, %f67, 0f7F800000;
	@%p22 bra 	$L__BB2_28;

	sub.ftz.f32 	%f68, %f23, %f78;
	fma.rn.ftz.f32 	%f78, %f68, %f40, %f78;

$L__BB2_28:
	st.global.f32 	[%rd59], %f78;
	add.s32 	%r78, %r78, 1;
	add.s64 	%rd59, %rd59, %rd19;
	add.s64 	%rd58, %rd58, %rd19;
	add.s32 	%r77, %r77, -1;
	setp.ne.s32 	%p23, %r77, 0;
	@%p23 bra 	$L__BB2_26;

$L__BB2_29:
	setp.lt.u32 	%p24, %r33, 3;
	@%p24 bra 	$L__BB2_40;

	mad.lo.s32 	%r62, %r78, %r43, %r1;
	mul.wide.s32 	%rd54, %r62, 4;
	add.s64 	%rd60, %rd1, %rd54;
	mul.wide.s32 	%rd26, %r43, 4;
	add.s64 	%rd61, %rd2, %rd54;

$L__BB2_31:
	ld.global.nc.f32 	%f28, [%rd61];
	abs.ftz.f32 	%f69, %f28;
	setp.geu.ftz.f32 	%p25, %f69, 0f7F800000;
	@%p25 bra 	$L__BB2_33;

	sub.ftz.f32 	%f70, %f28, %f78;
	fma.rn.ftz.f32 	%f78, %f70, %f40, %f78;

$L__BB2_33:
	st.global.f32 	[%rd60], %f78;
	add.s64 	%rd30, %rd61, %rd26;
	ld.global.nc.f32 	%f31, [%rd30];
	abs.ftz.f32 	%f71, %f31;
	setp.geu.ftz.f32 	%p26, %f71, 0f7F800000;
	@%p26 bra 	$L__BB2_35;

	sub.ftz.f32 	%f72, %f31, %f78;
	fma.rn.ftz.f32 	%f78, %f72, %f40, %f78;

$L__BB2_35:
	add.s64 	%rd31, %rd60, %rd26;
	st.global.f32 	[%rd31], %f78;
	add.s64 	%rd32, %rd30, %rd26;
	ld.global.nc.f32 	%f34, [%rd32];
	abs.ftz.f32 	%f73, %f34;
	setp.geu.ftz.f32 	%p27, %f73, 0f7F800000;
	@%p27 bra 	$L__BB2_37;

	sub.ftz.f32 	%f74, %f34, %f78;
	fma.rn.ftz.f32 	%f78, %f74, %f40, %f78;

$L__BB2_37:
	add.s64 	%rd33, %rd31, %rd26;
	st.global.f32 	[%rd33], %f78;
	add.s64 	%rd34, %rd32, %rd26;
	ld.global.nc.f32 	%f37, [%rd34];
	abs.ftz.f32 	%f75, %f37;
	setp.geu.ftz.f32 	%p28, %f75, 0f7F800000;
	@%p28 bra 	$L__BB2_39;

	sub.ftz.f32 	%f76, %f37, %f78;
	fma.rn.ftz.f32 	%f78, %f76, %f40, %f78;

$L__BB2_39:
	add.s64 	%rd61, %rd34, %rd26;
	add.s64 	%rd55, %rd33, %rd26;
	add.s64 	%rd60, %rd55, %rd26;
	st.global.f32 	[%rd55], %f78;
	add.s32 	%r78, %r78, 4;
	setp.lt.s32 	%p29, %r78, %r44;
	@%p29 bra 	$L__BB2_31;

$L__BB2_40:
	ret;

}

.visible .entry ema_many_series_one_param_f32_coalesced(
	.param .u64 ema_many_series_one_param_f32_coalesced_param_0,
	.param .u64 ema_many_series_one_param_f32_coalesced_param_1,
	.param .u32 ema_many_series_one_param_f32_coalesced_param_2,
	.param .f32 ema_many_series_one_param_f32_coalesced_param_3,
	.param .u32 ema_many_series_one_param_f32_coalesced_param_4,
	.param .u32 ema_many_series_one_param_f32_coalesced_param_5,
	.param .u64 ema_many_series_one_param_f32_coalesced_param_6
)
{
	.reg .pred 	%p<32>;
	.reg .f32 	%f<95>;
	.reg .b32 	%r<96>;
	.reg .b64 	%rd<72>;


	ld.param.u64 	%rd43, [ema_many_series_one_param_f32_coalesced_param_0];
	ld.param.u64 	%rd42, [ema_many_series_one_param_f32_coalesced_param_1];
	ld.param.u32 	%r47, [ema_many_series_one_param_f32_coalesced_param_2];
	ld.param.f32 	%f40, [ema_many_series_one_param_f32_coalesced_param_3];
	ld.param.u32 	%r48, [ema_many_series_one_param_f32_coalesced_param_4];
	ld.param.u32 	%r49, [ema_many_series_one_param_f32_coalesced_param_5];
	ld.param.u64 	%rd44, [ema_many_series_one_param_f32_coalesced_param_6];
	cvta.to.global.u64 	%rd1, %rd44;
	cvta.to.global.u64 	%rd2, %rd43;
	mov.u32 	%r50, %ntid.x;
	mov.u32 	%r51, %ctaid.x;
	mov.u32 	%r52, %tid.x;
	mad.lo.s32 	%r1, %r51, %r50, %r52;
	setp.ge.s32 	%p1, %r1, %r48;
	setp.lt.s32 	%p2, %r47, 1;
	or.pred  	%p3, %p2, %p1;
	setp.lt.s32 	%p4, %r49, 1;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	$L__BB3_42;

	cvta.to.global.u64 	%rd45, %rd42;
	mul.wide.s32 	%rd46, %r1, 4;
	add.s64 	%rd47, %rd45, %rd46;
	ld.global.nc.u32 	%r53, [%rd47];
	setp.lt.s32 	%p6, %r53, 1;
	setp.gt.s32 	%p7, %r53, 0;
	selp.b32 	%r2, %r53, 0, %p7;
	add.s32 	%r94, %r2, %r47;
	min.s32 	%r4, %r94, %r49;
	@%p6 bra 	$L__BB3_8;

	add.s32 	%r55, %r2, -1;
	and.b32  	%r79, %r2, 3;
	setp.lt.u32 	%p8, %r55, 3;
	mov.u32 	%r78, 0;
	@%p8 bra 	$L__BB3_5;

	sub.s32 	%r77, %r2, %r79;
	mul.wide.s32 	%rd3, %r48, 4;
	mov.u32 	%r78, 0;

$L__BB3_4:
	mad.lo.s32 	%r57, %r78, %r48, %r1;
	mul.wide.s32 	%rd48, %r57, 4;
	add.s64 	%rd49, %rd1, %rd48;
	mov.u32 	%r58, 2143289344;
	st.global.u32 	[%rd49], %r58;
	add.s64 	%rd50, %rd49, %rd3;
	st.global.u32 	[%rd50], %r58;
	add.s64 	%rd51, %rd50, %rd3;
	st.global.u32 	[%rd51], %r58;
	add.s64 	%rd52, %rd51, %rd3;
	st.global.u32 	[%rd52], %r58;
	add.s32 	%r78, %r78, 4;
	add.s32 	%r77, %r77, -4;
	setp.ne.s32 	%p9, %r77, 0;
	@%p9 bra 	$L__BB3_4;

$L__BB3_5:
	setp.eq.s32 	%p10, %r79, 0;
	@%p10 bra 	$L__BB3_8;

	mad.lo.s32 	%r59, %r78, %r48, %r1;
	mul.wide.s32 	%rd53, %r59, 4;
	add.s64 	%rd65, %rd1, %rd53;
	mul.wide.s32 	%rd5, %r48, 4;

$L__BB3_7:
	.pragma "nounroll";
	mov.u32 	%r60, 2143289344;
	st.global.u32 	[%rd65], %r60;
	add.s64 	%rd65, %rd65, %rd5;
	add.s32 	%r79, %r79, -1;
	setp.ne.s32 	%p11, %r79, 0;
	@%p11 bra 	$L__BB3_7;

$L__BB3_8:
	mad.lo.s32 	%r61, %r2, %r48, %r1;
	mul.wide.s32 	%rd54, %r61, 4;
	add.s64 	%rd55, %rd2, %rd54;
	ld.global.nc.f32 	%f78, [%rd55];
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f78;
	add.s32 	%r87, %r2, 1;
	setp.ge.s32 	%p12, %r87, %r4;
	@%p12 bra 	$L__BB3_25;

	mov.u32 	%r63, -2;
	sub.s32 	%r64, %r63, %r2;
	not.b32 	%r65, %r4;
	sub.s32 	%r15, %r64, %r65;
	mov.u32 	%r66, -3;
	sub.s32 	%r67, %r66, %r2;
	sub.s32 	%r68, %r67, %r65;
	and.b32  	%r90, %r15, 3;
	setp.lt.u32 	%p13, %r68, 3;
	mov.u32 	%r83, 1;
	@%p13 bra 	$L__BB3_20;

	sub.s32 	%r82, %r15, %r90;
	mul.wide.s32 	%rd8, %r48, 4;
	mov.u32 	%r83, 1;

$L__BB3_11:
	mad.lo.s32 	%r70, %r87, %r48, %r1;
	cvt.s64.s32 	%rd9, %r70;
	mul.wide.s32 	%rd57, %r70, 4;
	add.s64 	%rd10, %rd2, %rd57;
	ld.global.nc.f32 	%f3, [%rd10];
	abs.ftz.f32 	%f42, %f3;
	setp.geu.ftz.f32 	%p14, %f42, 0f7F800000;
	@%p14 bra 	$L__BB3_13;

	add.s32 	%r83, %r83, 1;
	cvt.rn.f32.s32 	%f43, %r83;
	mov.f32 	%f44, 0f3F800000;
	div.approx.ftz.f32 	%f45, %f44, %f43;
	sub.ftz.f32 	%f46, %f3, %f78;
	fma.rn.ftz.f32 	%f78, %f46, %f45, %f78;

$L__BB3_13:
	shl.b64 	%rd58, %rd9, 2;
	add.s64 	%rd11, %rd1, %rd58;
	st.global.f32 	[%rd11], %f78;
	add.s64 	%rd12, %rd10, %rd8;
	ld.global.nc.f32 	%f6, [%rd12];
	abs.ftz.f32 	%f47, %f6;
	setp.geu.ftz.f32 	%p15, %f47, 0f7F800000;
	@%p15 bra 	$L__BB3_15;

	add.s32 	%r83, %r83, 1;
	cvt.rn.f32.s32 	%f48, %r83;
	mov.f32 	%f49, 0f3F800000;
	div.approx.ftz.f32 	%f50, %f49, %f48;
	sub.ftz.f32 	%f51, %f6, %f78;
	fma.rn.ftz.f32 	%f78, %f51, %f50, %f78;

$L__BB3_15:
	add.s64 	%rd13, %rd11, %rd8;
	st.global.f32 	[%rd13], %f78;
	add.s64 	%rd14, %rd12, %rd8;
	ld.global.nc.f32 	%f9, [%rd14];
	abs.ftz.f32 	%f52, %f9;
	setp.geu.ftz.f32 	%p16, %f52, 0f7F800000;
	@%p16 bra 	$L__BB3_17;

	add.s32 	%r83, %r83, 1;
	cvt.rn.f32.s32 	%f53, %r83;
	mov.f32 	%f54, 0f3F800000;
	div.approx.ftz.f32 	%f55, %f54, %f53;
	sub.ftz.f32 	%f56, %f9, %f78;
	fma.rn.ftz.f32 	%f78, %f56, %f55, %f78;

$L__BB3_17:
	add.s64 	%rd15, %rd13, %rd8;
	st.global.f32 	[%rd15], %f78;
	add.s64 	%rd59, %rd14, %rd8;
	ld.global.nc.f32 	%f12, [%rd59];
	abs.ftz.f32 	%f57, %f12;
	setp.geu.ftz.f32 	%p17, %f57, 0f7F800000;
	@%p17 bra 	$L__BB3_19;

	add.s32 	%r83, %r83, 1;
	cvt.rn.f32.s32 	%f58, %r83;
	mov.f32 	%f59, 0f3F800000;
	div.approx.ftz.f32 	%f60, %f59, %f58;
	sub.ftz.f32 	%f61, %f12, %f78;
	fma.rn.ftz.f32 	%f78, %f61, %f60, %f78;

$L__BB3_19:
	add.s64 	%rd60, %rd15, %rd8;
	st.global.f32 	[%rd60], %f78;
	add.s32 	%r87, %r87, 4;
	add.s32 	%r82, %r82, -4;
	setp.ne.s32 	%p18, %r82, 0;
	@%p18 bra 	$L__BB3_11;

$L__BB3_20:
	setp.eq.s32 	%p19, %r90, 0;
	@%p19 bra 	$L__BB3_25;

	mad.lo.s32 	%r71, %r87, %r48, %r1;
	mul.wide.s32 	%rd61, %r71, 4;
	add.s64 	%rd67, %rd1, %rd61;
	mul.wide.s32 	%rd17, %r48, 4;
	add.s64 	%rd66, %rd2, %rd61;

$L__BB3_22:
	.pragma "nounroll";
	ld.global.nc.f32 	%f18, [%rd66];
	abs.ftz.f32 	%f62, %f18;
	setp.geu.ftz.f32 	%p20, %f62, 0f7F800000;
	@%p20 bra 	$L__BB3_24;

	add.s32 	%r83, %r83, 1;
	cvt.rn.f32.s32 	%f63, %r83;
	mov.f32 	%f64, 0f3F800000;
	div.approx.ftz.f32 	%f65, %f64, %f63;
	sub.ftz.f32 	%f66, %f18, %f78;
	fma.rn.ftz.f32 	%f78, %f66, %f65, %f78;

$L__BB3_24:
	st.global.f32 	[%rd67], %f78;
	add.s64 	%rd67, %rd67, %rd17;
	add.s64 	%rd66, %rd66, %rd17;
	add.s32 	%r90, %r90, -1;
	setp.ne.s32 	%p21, %r90, 0;
	@%p21 bra 	$L__BB3_22;

$L__BB3_25:
	setp.ge.s32 	%p22, %r94, %r49;
	@%p22 bra 	$L__BB3_42;

	not.b32 	%r72, %r94;
	add.s32 	%r38, %r72, %r49;
	add.s32 	%r73, %r38, 1;
	and.b32  	%r93, %r73, 3;
	setp.eq.s32 	%p23, %r93, 0;
	@%p23 bra 	$L__BB3_31;

	mad.lo.s32 	%r74, %r48, %r94, %r1;
	mul.wide.s32 	%rd62, %r74, 4;
	add.s64 	%rd69, %rd1, %rd62;
	mul.wide.s32 	%rd24, %r48, 4;
	add.s64 	%rd68, %rd2, %rd62;

$L__BB3_28:
	.pragma "nounroll";
	ld.global.nc.f32 	%f23, [%rd68];
	abs.ftz.f32 	%f67, %f23;
	setp.geu.ftz.f32 	%p24, %f67, 0f7F800000;
	@%p24 bra 	$L__BB3_30;

	sub.ftz.f32 	%f68, %f23, %f78;
	fma.rn.ftz.f32 	%f78, %f68, %f40, %f78;

$L__BB3_30:
	st.global.f32 	[%rd69], %f78;
	add.s32 	%r94, %r94, 1;
	add.s64 	%rd69, %rd69, %rd24;
	add.s64 	%rd68, %rd68, %rd24;
	add.s32 	%r93, %r93, -1;
	setp.ne.s32 	%p25, %r93, 0;
	@%p25 bra 	$L__BB3_28;

$L__BB3_31:
	setp.lt.u32 	%p26, %r38, 3;
	@%p26 bra 	$L__BB3_42;

	mad.lo.s32 	%r75, %r94, %r48, %r1;
	mul.wide.s32 	%rd63, %r75, 4;
	add.s64 	%rd70, %rd1, %rd63;
	mul.wide.s32 	%rd31, %r48, 4;
	add.s64 	%rd71, %rd2, %rd63;

$L__BB3_33:
	ld.global.nc.f32 	%f28, [%rd71];
	abs.ftz.f32 	%f69, %f28;
	setp.geu.ftz.f32 	%p27, %f69, 0f7F800000;
	@%p27 bra 	$L__BB3_35;

	sub.ftz.f32 	%f70, %f28, %f78;
	fma.rn.ftz.f32 	%f78, %f70, %f40, %f78;

$L__BB3_35:
	st.global.f32 	[%rd70], %f78;
	add.s64 	%rd35, %rd71, %rd31;
	ld.global.nc.f32 	%f31, [%rd35];
	abs.ftz.f32 	%f71, %f31;
	setp.geu.ftz.f32 	%p28, %f71, 0f7F800000;
	@%p28 bra 	$L__BB3_37;

	sub.ftz.f32 	%f72, %f31, %f78;
	fma.rn.ftz.f32 	%f78, %f72, %f40, %f78;

$L__BB3_37:
	add.s64 	%rd36, %rd70, %rd31;
	st.global.f32 	[%rd36], %f78;
	add.s64 	%rd37, %rd35, %rd31;
	ld.global.nc.f32 	%f34, [%rd37];
	abs.ftz.f32 	%f73, %f34;
	setp.geu.ftz.f32 	%p29, %f73, 0f7F800000;
	@%p29 bra 	$L__BB3_39;

	sub.ftz.f32 	%f74, %f34, %f78;
	fma.rn.ftz.f32 	%f78, %f74, %f40, %f78;

$L__BB3_39:
	add.s64 	%rd38, %rd36, %rd31;
	st.global.f32 	[%rd38], %f78;
	add.s64 	%rd39, %rd37, %rd31;
	ld.global.nc.f32 	%f37, [%rd39];
	abs.ftz.f32 	%f75, %f37;
	setp.geu.ftz.f32 	%p30, %f75, 0f7F800000;
	@%p30 bra 	$L__BB3_41;

	sub.ftz.f32 	%f76, %f37, %f78;
	fma.rn.ftz.f32 	%f78, %f76, %f40, %f78;

$L__BB3_41:
	add.s64 	%rd71, %rd39, %rd31;
	add.s64 	%rd64, %rd38, %rd31;
	add.s64 	%rd70, %rd64, %rd31;
	st.global.f32 	[%rd64], %f78;
	add.s32 	%r94, %r94, 4;
	setp.lt.s32 	%p31, %r94, %r49;
	@%p31 bra 	$L__BB3_33;

$L__BB3_42:
	ret;

}

