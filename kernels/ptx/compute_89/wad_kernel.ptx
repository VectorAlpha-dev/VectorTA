//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36424714
// Cuda compilation tools, release 13.0, V13.0.88
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_89
.address_size 64

	// .globl	wad_batch_f32

.visible .entry wad_batch_f32(
	.param .u64 wad_batch_f32_param_0,
	.param .u64 wad_batch_f32_param_1,
	.param .u64 wad_batch_f32_param_2,
	.param .u32 wad_batch_f32_param_3,
	.param .u32 wad_batch_f32_param_4,
	.param .u64 wad_batch_f32_param_5
)
{
	.reg .pred 	%p<17>;
	.reg .f32 	%f<29>;
	.reg .b32 	%r<45>;
	.reg .b64 	%rd<33>;


	ld.param.u64 	%rd16, [wad_batch_f32_param_0];
	ld.param.u64 	%rd17, [wad_batch_f32_param_1];
	ld.param.u64 	%rd18, [wad_batch_f32_param_2];
	ld.param.u32 	%r18, [wad_batch_f32_param_3];
	ld.param.u32 	%r19, [wad_batch_f32_param_4];
	ld.param.u64 	%rd19, [wad_batch_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd18;
	cvta.to.global.u64 	%rd2, %rd19;
	setp.lt.s32 	%p1, %r19, 1;
	setp.lt.s32 	%p2, %r18, 1;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB0_12;

	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r20, %ctaid.x;
	mov.u32 	%r21, %tid.x;
	mad.lo.s32 	%r41, %r20, %r1, %r21;
	setp.ge.s32 	%p4, %r41, %r19;
	@%p4 bra 	$L__BB0_12;

	setp.gt.s32 	%p5, %r18, 1;
	@%p5 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_3;

$L__BB0_8:
	ld.global.nc.f32 	%f1, [%rd1];
	add.s64 	%rd4, %rd2, 4;
	cvta.to.global.u64 	%rd5, %rd16;
	cvta.to.global.u64 	%rd6, %rd17;

$L__BB0_9:
	mul.lo.s32 	%r37, %r41, %r18;
	mul.wide.s32 	%rd27, %r37, 4;
	add.s64 	%rd28, %rd2, %rd27;
	mov.f32 	%f27, 0f00000000;
	mov.u32 	%r38, 0;
	st.global.u32 	[%rd28], %r38;
	add.s64 	%rd32, %rd4, %rd27;
	mov.u32 	%r44, 1;
	mov.u64 	%rd29, %rd5;
	mov.u64 	%rd30, %rd6;
	mov.u64 	%rd31, %rd1;
	mov.f32 	%f26, %f1;
	mov.f32 	%f28, %f27;

$L__BB0_10:
	.pragma "nounroll";
	add.s64 	%rd12, %rd29, 4;
	add.s64 	%rd13, %rd30, 4;
	add.s64 	%rd14, %rd31, 4;
	ld.global.nc.f32 	%f10, [%rd29+4];
	setp.gt.ftz.f32 	%p10, %f26, %f10;
	selp.f32 	%f11, %f26, %f10, %p10;
	ld.global.nc.f32 	%f12, [%rd30+4];
	setp.lt.ftz.f32 	%p11, %f26, %f12;
	selp.f32 	%f13, %f26, %f12, %p11;
	ld.global.nc.f32 	%f5, [%rd31+4];
	setp.gt.ftz.f32 	%p12, %f5, %f26;
	sub.ftz.f32 	%f14, %f5, %f13;
	setp.lt.ftz.f32 	%p13, %f5, %f26;
	sub.ftz.f32 	%f15, %f5, %f11;
	selp.f32 	%f16, %f15, 0f00000000, %p13;
	selp.f32 	%f17, %f14, %f16, %p12;
	add.ftz.f32 	%f6, %f27, %f17;
	abs.ftz.f32 	%f18, %f17;
	abs.ftz.f32 	%f19, %f27;
	setp.ltu.ftz.f32 	%p14, %f19, %f18;
	sub.ftz.f32 	%f20, %f27, %f6;
	add.ftz.f32 	%f21, %f17, %f20;
	sub.ftz.f32 	%f22, %f17, %f6;
	add.ftz.f32 	%f23, %f27, %f22;
	selp.f32 	%f24, %f23, %f21, %p14;
	add.ftz.f32 	%f28, %f28, %f24;
	add.ftz.f32 	%f25, %f6, %f28;
	st.global.f32 	[%rd32], %f25;
	add.s64 	%rd32, %rd32, 4;
	add.s32 	%r44, %r44, 1;
	setp.lt.s32 	%p15, %r44, %r18;
	mov.u64 	%rd29, %rd12;
	mov.u64 	%rd30, %rd13;
	mov.u64 	%rd31, %rd14;
	mov.f32 	%f26, %f5;
	mov.f32 	%f27, %f6;
	@%p15 bra 	$L__BB0_10;

	add.s32 	%r41, %r41, %r3;
	setp.lt.s32 	%p16, %r41, %r19;
	@%p16 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_12;

$L__BB0_3:
	add.s32 	%r22, %r3, %r19;
	add.s32 	%r23, %r41, %r3;
	not.b32 	%r24, %r23;
	add.s32 	%r25, %r22, %r24;
	div.u32 	%r5, %r25, %r3;
	add.s32 	%r26, %r5, 1;
	and.b32  	%r40, %r26, 3;
	setp.eq.s32 	%p6, %r40, 0;
	@%p6 bra 	$L__BB0_5;

$L__BB0_4:
	.pragma "nounroll";
	mul.lo.s32 	%r27, %r41, %r18;
	mul.wide.s32 	%rd20, %r27, 4;
	add.s64 	%rd21, %rd2, %rd20;
	mov.u32 	%r28, 0;
	st.global.u32 	[%rd21], %r28;
	add.s32 	%r41, %r41, %r3;
	add.s32 	%r40, %r40, -1;
	setp.ne.s32 	%p7, %r40, 0;
	@%p7 bra 	$L__BB0_4;

$L__BB0_5:
	setp.lt.u32 	%p8, %r5, 3;
	@%p8 bra 	$L__BB0_12;

	mul.lo.s32 	%r30, %r3, %r18;
	mul.wide.s32 	%rd3, %r30, 4;

$L__BB0_7:
	mul.lo.s32 	%r31, %r41, %r18;
	mul.wide.s32 	%rd22, %r31, 4;
	add.s64 	%rd23, %rd2, %rd22;
	mov.u32 	%r32, 0;
	st.global.u32 	[%rd23], %r32;
	add.s64 	%rd24, %rd23, %rd3;
	st.global.u32 	[%rd24], %r32;
	add.s32 	%r33, %r41, %r3;
	add.s32 	%r34, %r33, %r3;
	add.s64 	%rd25, %rd24, %rd3;
	st.global.u32 	[%rd25], %r32;
	add.s32 	%r35, %r34, %r3;
	add.s64 	%rd26, %rd25, %rd3;
	st.global.u32 	[%rd26], %r32;
	add.s32 	%r41, %r35, %r3;
	setp.lt.s32 	%p9, %r41, %r19;
	@%p9 bra 	$L__BB0_7;

$L__BB0_12:
	ret;

}
	// .globl	wad_many_series_one_param_f32
.visible .entry wad_many_series_one_param_f32(
	.param .u64 wad_many_series_one_param_f32_param_0,
	.param .u64 wad_many_series_one_param_f32_param_1,
	.param .u64 wad_many_series_one_param_f32_param_2,
	.param .u32 wad_many_series_one_param_f32_param_3,
	.param .u32 wad_many_series_one_param_f32_param_4,
	.param .u64 wad_many_series_one_param_f32_param_5
)
{
	.reg .pred 	%p<17>;
	.reg .f32 	%f<29>;
	.reg .b32 	%r<41>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd21, [wad_many_series_one_param_f32_param_0];
	ld.param.u64 	%rd22, [wad_many_series_one_param_f32_param_1];
	ld.param.u64 	%rd23, [wad_many_series_one_param_f32_param_2];
	ld.param.u32 	%r16, [wad_many_series_one_param_f32_param_3];
	ld.param.u32 	%r17, [wad_many_series_one_param_f32_param_4];
	ld.param.u64 	%rd24, [wad_many_series_one_param_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd23;
	cvta.to.global.u64 	%rd2, %rd24;
	setp.lt.s32 	%p1, %r16, 1;
	setp.lt.s32 	%p2, %r17, 1;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB1_12;

	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r1, %r18, %r19;
	mov.u32 	%r20, %ctaid.x;
	mov.u32 	%r21, %tid.x;
	mad.lo.s32 	%r37, %r20, %r18, %r21;
	setp.ge.s32 	%p4, %r37, %r16;
	@%p4 bra 	$L__BB1_12;

	setp.gt.s32 	%p5, %r17, 1;
	@%p5 bra 	$L__BB1_8;
	bra.uni 	$L__BB1_3;

$L__BB1_8:
	mul.wide.s32 	%rd5, %r16, 4;
	add.s64 	%rd4, %rd2, %rd5;
	add.s64 	%rd6, %rd1, %rd5;
	cvta.to.global.u64 	%rd7, %rd21;
	cvta.to.global.u64 	%rd8, %rd22;

$L__BB1_9:
	mul.wide.s32 	%rd32, %r37, 4;
	add.s64 	%rd33, %rd2, %rd32;
	mov.f32 	%f27, 0f00000000;
	mov.u32 	%r33, 0;
	st.global.u32 	[%rd33], %r33;
	add.s64 	%rd34, %rd1, %rd32;
	ld.global.nc.f32 	%f26, [%rd34];
	add.s64 	%rd39, %rd4, %rd32;
	add.s64 	%rd38, %rd6, %rd32;
	add.s32 	%r34, %r16, %r37;
	mul.wide.s32 	%rd35, %r34, 4;
	add.s64 	%rd37, %rd8, %rd35;
	add.s64 	%rd36, %rd7, %rd35;
	mov.u32 	%r40, 1;
	mov.f32 	%f28, %f27;

$L__BB1_10:
	.pragma "nounroll";
	ld.global.nc.f32 	%f10, [%rd36];
	setp.gt.ftz.f32 	%p10, %f26, %f10;
	selp.f32 	%f11, %f26, %f10, %p10;
	ld.global.nc.f32 	%f12, [%rd37];
	setp.lt.ftz.f32 	%p11, %f26, %f12;
	selp.f32 	%f13, %f26, %f12, %p11;
	ld.global.nc.f32 	%f5, [%rd38];
	setp.gt.ftz.f32 	%p12, %f5, %f26;
	sub.ftz.f32 	%f14, %f5, %f13;
	setp.lt.ftz.f32 	%p13, %f5, %f26;
	sub.ftz.f32 	%f15, %f5, %f11;
	selp.f32 	%f16, %f15, 0f00000000, %p13;
	selp.f32 	%f17, %f14, %f16, %p12;
	add.ftz.f32 	%f6, %f27, %f17;
	abs.ftz.f32 	%f18, %f17;
	abs.ftz.f32 	%f19, %f27;
	setp.ltu.ftz.f32 	%p14, %f19, %f18;
	sub.ftz.f32 	%f20, %f27, %f6;
	add.ftz.f32 	%f21, %f17, %f20;
	sub.ftz.f32 	%f22, %f17, %f6;
	add.ftz.f32 	%f23, %f27, %f22;
	selp.f32 	%f24, %f23, %f21, %p14;
	add.ftz.f32 	%f28, %f28, %f24;
	add.ftz.f32 	%f25, %f6, %f28;
	st.global.f32 	[%rd39], %f25;
	add.s64 	%rd39, %rd39, %rd5;
	add.s64 	%rd38, %rd38, %rd5;
	add.s64 	%rd37, %rd37, %rd5;
	add.s64 	%rd36, %rd36, %rd5;
	add.s32 	%r40, %r40, 1;
	setp.lt.s32 	%p15, %r40, %r17;
	mov.f32 	%f26, %f5;
	mov.f32 	%f27, %f6;
	@%p15 bra 	$L__BB1_10;

	add.s32 	%r37, %r37, %r1;
	setp.lt.s32 	%p16, %r37, %r16;
	@%p16 bra 	$L__BB1_9;
	bra.uni 	$L__BB1_12;

$L__BB1_3:
	add.s32 	%r22, %r1, %r16;
	add.s32 	%r23, %r37, %r1;
	not.b32 	%r24, %r23;
	add.s32 	%r25, %r22, %r24;
	div.u32 	%r3, %r25, %r1;
	add.s32 	%r26, %r3, 1;
	and.b32  	%r36, %r26, 3;
	setp.eq.s32 	%p6, %r36, 0;
	@%p6 bra 	$L__BB1_5;

$L__BB1_4:
	.pragma "nounroll";
	mul.wide.s32 	%rd25, %r37, 4;
	add.s64 	%rd26, %rd2, %rd25;
	mov.u32 	%r27, 0;
	st.global.u32 	[%rd26], %r27;
	add.s32 	%r37, %r37, %r1;
	add.s32 	%r36, %r36, -1;
	setp.ne.s32 	%p7, %r36, 0;
	@%p7 bra 	$L__BB1_4;

$L__BB1_5:
	setp.lt.u32 	%p8, %r3, 3;
	@%p8 bra 	$L__BB1_12;

	mul.wide.s32 	%rd3, %r1, 4;

$L__BB1_7:
	mul.wide.s32 	%rd27, %r37, 4;
	add.s64 	%rd28, %rd2, %rd27;
	mov.u32 	%r28, 0;
	st.global.u32 	[%rd28], %r28;
	add.s64 	%rd29, %rd28, %rd3;
	st.global.u32 	[%rd29], %r28;
	add.s32 	%r29, %r37, %r1;
	add.s32 	%r30, %r29, %r1;
	add.s64 	%rd30, %rd29, %rd3;
	st.global.u32 	[%rd30], %r28;
	add.s32 	%r31, %r30, %r1;
	add.s64 	%rd31, %rd30, %rd3;
	st.global.u32 	[%rd31], %r28;
	add.s32 	%r37, %r31, %r1;
	setp.lt.s32 	%p9, %r37, %r16;
	@%p9 bra 	$L__BB1_7;

$L__BB1_12:
	ret;

}
	// .globl	wad_series_f32
.visible .entry wad_series_f32(
	.param .u64 wad_series_f32_param_0,
	.param .u64 wad_series_f32_param_1,
	.param .u64 wad_series_f32_param_2,
	.param .u32 wad_series_f32_param_3,
	.param .u32 wad_series_f32_param_4,
	.param .u64 wad_series_f32_param_5
)
{
	.reg .pred 	%p<17>;
	.reg .f32 	%f<29>;
	.reg .b32 	%r<45>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd20, [wad_series_f32_param_0];
	ld.param.u64 	%rd21, [wad_series_f32_param_1];
	ld.param.u64 	%rd22, [wad_series_f32_param_2];
	ld.param.u32 	%r18, [wad_series_f32_param_3];
	ld.param.u32 	%r19, [wad_series_f32_param_4];
	ld.param.u64 	%rd23, [wad_series_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd22;
	cvta.to.global.u64 	%rd2, %rd23;
	setp.lt.s32 	%p1, %r19, 1;
	setp.lt.s32 	%p2, %r18, 1;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB2_12;

	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r20, %ctaid.x;
	mov.u32 	%r21, %tid.x;
	mad.lo.s32 	%r41, %r20, %r1, %r21;
	setp.ge.s32 	%p4, %r41, %r19;
	@%p4 bra 	$L__BB2_12;

	setp.gt.s32 	%p5, %r18, 1;
	@%p5 bra 	$L__BB2_8;
	bra.uni 	$L__BB2_3;

$L__BB2_8:
	add.s64 	%rd4, %rd2, 4;
	add.s64 	%rd5, %rd1, 4;
	cvta.to.global.u64 	%rd31, %rd21;
	add.s64 	%rd6, %rd31, 4;
	cvta.to.global.u64 	%rd32, %rd20;
	add.s64 	%rd7, %rd32, 4;

$L__BB2_9:
	mul.lo.s32 	%r37, %r41, %r18;
	mul.wide.s32 	%rd33, %r37, 4;
	add.s64 	%rd34, %rd2, %rd33;
	mov.f32 	%f27, 0f00000000;
	mov.u32 	%r38, 0;
	st.global.u32 	[%rd34], %r38;
	add.s64 	%rd35, %rd1, %rd33;
	ld.global.nc.f32 	%f26, [%rd35];
	add.s64 	%rd39, %rd4, %rd33;
	add.s64 	%rd38, %rd5, %rd33;
	add.s64 	%rd37, %rd6, %rd33;
	add.s64 	%rd36, %rd7, %rd33;
	mov.u32 	%r44, 1;
	mov.f32 	%f28, %f27;

$L__BB2_10:
	.pragma "nounroll";
	ld.global.nc.f32 	%f10, [%rd36];
	setp.gt.ftz.f32 	%p10, %f26, %f10;
	selp.f32 	%f11, %f26, %f10, %p10;
	ld.global.nc.f32 	%f12, [%rd37];
	setp.lt.ftz.f32 	%p11, %f26, %f12;
	selp.f32 	%f13, %f26, %f12, %p11;
	ld.global.nc.f32 	%f5, [%rd38];
	setp.gt.ftz.f32 	%p12, %f5, %f26;
	sub.ftz.f32 	%f14, %f5, %f13;
	setp.lt.ftz.f32 	%p13, %f5, %f26;
	sub.ftz.f32 	%f15, %f5, %f11;
	selp.f32 	%f16, %f15, 0f00000000, %p13;
	selp.f32 	%f17, %f14, %f16, %p12;
	add.ftz.f32 	%f6, %f27, %f17;
	abs.ftz.f32 	%f18, %f17;
	abs.ftz.f32 	%f19, %f27;
	setp.ltu.ftz.f32 	%p14, %f19, %f18;
	sub.ftz.f32 	%f20, %f27, %f6;
	add.ftz.f32 	%f21, %f17, %f20;
	sub.ftz.f32 	%f22, %f17, %f6;
	add.ftz.f32 	%f23, %f27, %f22;
	selp.f32 	%f24, %f23, %f21, %p14;
	add.ftz.f32 	%f28, %f28, %f24;
	add.ftz.f32 	%f25, %f6, %f28;
	st.global.f32 	[%rd39], %f25;
	add.s64 	%rd39, %rd39, 4;
	add.s64 	%rd38, %rd38, 4;
	add.s64 	%rd37, %rd37, 4;
	add.s64 	%rd36, %rd36, 4;
	add.s32 	%r44, %r44, 1;
	setp.lt.s32 	%p15, %r44, %r18;
	mov.f32 	%f26, %f5;
	mov.f32 	%f27, %f6;
	@%p15 bra 	$L__BB2_10;

	add.s32 	%r41, %r41, %r3;
	setp.lt.s32 	%p16, %r41, %r19;
	@%p16 bra 	$L__BB2_9;
	bra.uni 	$L__BB2_12;

$L__BB2_3:
	add.s32 	%r22, %r3, %r19;
	add.s32 	%r23, %r41, %r3;
	not.b32 	%r24, %r23;
	add.s32 	%r25, %r22, %r24;
	div.u32 	%r5, %r25, %r3;
	add.s32 	%r26, %r5, 1;
	and.b32  	%r40, %r26, 3;
	setp.eq.s32 	%p6, %r40, 0;
	@%p6 bra 	$L__BB2_5;

$L__BB2_4:
	.pragma "nounroll";
	mul.lo.s32 	%r27, %r41, %r18;
	mul.wide.s32 	%rd24, %r27, 4;
	add.s64 	%rd25, %rd2, %rd24;
	mov.u32 	%r28, 0;
	st.global.u32 	[%rd25], %r28;
	add.s32 	%r41, %r41, %r3;
	add.s32 	%r40, %r40, -1;
	setp.ne.s32 	%p7, %r40, 0;
	@%p7 bra 	$L__BB2_4;

$L__BB2_5:
	setp.lt.u32 	%p8, %r5, 3;
	@%p8 bra 	$L__BB2_12;

	mul.lo.s32 	%r30, %r3, %r18;
	mul.wide.s32 	%rd3, %r30, 4;

$L__BB2_7:
	mul.lo.s32 	%r31, %r41, %r18;
	mul.wide.s32 	%rd26, %r31, 4;
	add.s64 	%rd27, %rd2, %rd26;
	mov.u32 	%r32, 0;
	st.global.u32 	[%rd27], %r32;
	add.s64 	%rd28, %rd27, %rd3;
	st.global.u32 	[%rd28], %r32;
	add.s32 	%r33, %r41, %r3;
	add.s32 	%r34, %r33, %r3;
	add.s64 	%rd29, %rd28, %rd3;
	st.global.u32 	[%rd29], %r32;
	add.s32 	%r35, %r34, %r3;
	add.s64 	%rd30, %rd29, %rd3;
	st.global.u32 	[%rd30], %r32;
	add.s32 	%r41, %r35, %r3;
	setp.lt.s32 	%p9, %r41, %r19;
	@%p9 bra 	$L__BB2_7;

$L__BB2_12:
	ret;

}
	// .globl	wad_compute_single_row_f32
.visible .entry wad_compute_single_row_f32(
	.param .u64 wad_compute_single_row_f32_param_0,
	.param .u64 wad_compute_single_row_f32_param_1,
	.param .u64 wad_compute_single_row_f32_param_2,
	.param .u32 wad_compute_single_row_f32_param_3,
	.param .u64 wad_compute_single_row_f32_param_4
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<29>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<21>;


	ld.param.u64 	%rd13, [wad_compute_single_row_f32_param_0];
	ld.param.u64 	%rd14, [wad_compute_single_row_f32_param_1];
	ld.param.u64 	%rd15, [wad_compute_single_row_f32_param_2];
	ld.param.u32 	%r3, [wad_compute_single_row_f32_param_3];
	ld.param.u64 	%rd16, [wad_compute_single_row_f32_param_4];
	cvta.to.global.u64 	%rd19, %rd15;
	cvta.to.global.u64 	%rd20, %rd16;
	setp.lt.s32 	%p1, %r3, 1;
	@%p1 bra 	$L__BB3_4;

	mov.u32 	%r4, 0;
	st.global.u32 	[%rd20], %r4;
	setp.eq.s32 	%p2, %r3, 1;
	@%p2 bra 	$L__BB3_4;

	ld.global.nc.f32 	%f26, [%rd19];
	cvta.to.global.u64 	%rd18, %rd14;
	cvta.to.global.u64 	%rd17, %rd13;
	mov.f32 	%f27, 0f00000000;
	mov.u32 	%r6, 1;
	mov.f32 	%f28, %f27;

$L__BB3_3:
	.pragma "nounroll";
	add.s64 	%rd9, %rd17, 4;
	add.s64 	%rd10, %rd18, 4;
	add.s64 	%rd11, %rd19, 4;
	ld.global.nc.f32 	%f10, [%rd17+4];
	setp.gt.ftz.f32 	%p3, %f26, %f10;
	selp.f32 	%f11, %f26, %f10, %p3;
	ld.global.nc.f32 	%f12, [%rd18+4];
	setp.lt.ftz.f32 	%p4, %f26, %f12;
	selp.f32 	%f13, %f26, %f12, %p4;
	ld.global.nc.f32 	%f5, [%rd19+4];
	setp.gt.ftz.f32 	%p5, %f5, %f26;
	sub.ftz.f32 	%f14, %f5, %f13;
	setp.lt.ftz.f32 	%p6, %f5, %f26;
	sub.ftz.f32 	%f15, %f5, %f11;
	selp.f32 	%f16, %f15, 0f00000000, %p6;
	selp.f32 	%f17, %f14, %f16, %p5;
	add.ftz.f32 	%f6, %f27, %f17;
	abs.ftz.f32 	%f18, %f17;
	abs.ftz.f32 	%f19, %f27;
	setp.ltu.ftz.f32 	%p7, %f19, %f18;
	sub.ftz.f32 	%f20, %f27, %f6;
	add.ftz.f32 	%f21, %f17, %f20;
	sub.ftz.f32 	%f22, %f17, %f6;
	add.ftz.f32 	%f23, %f27, %f22;
	selp.f32 	%f24, %f23, %f21, %p7;
	add.ftz.f32 	%f28, %f28, %f24;
	add.ftz.f32 	%f25, %f6, %f28;
	add.s64 	%rd12, %rd20, 4;
	st.global.f32 	[%rd20+4], %f25;
	add.s32 	%r6, %r6, 1;
	setp.lt.s32 	%p8, %r6, %r3;
	mov.u64 	%rd17, %rd9;
	mov.u64 	%rd18, %rd10;
	mov.u64 	%rd19, %rd11;
	mov.u64 	%rd20, %rd12;
	mov.f32 	%f26, %f5;
	mov.f32 	%f27, %f6;
	@%p8 bra 	$L__BB3_3;

$L__BB3_4:
	ret;

}
	// .globl	broadcast_row_f32
.visible .entry broadcast_row_f32(
	.param .u64 broadcast_row_f32_param_0,
	.param .u32 broadcast_row_f32_param_1,
	.param .u32 broadcast_row_f32_param_2,
	.param .u64 broadcast_row_f32_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<14>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd3, [broadcast_row_f32_param_0];
	ld.param.u32 	%r7, [broadcast_row_f32_param_1];
	ld.param.u32 	%r8, [broadcast_row_f32_param_2];
	ld.param.u64 	%rd4, [broadcast_row_f32_param_3];
	setp.lt.s32 	%p1, %r8, 1;
	setp.lt.s32 	%p2, %r7, 1;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB4_4;

	mul.lo.s32 	%r1, %r8, %r7;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r9, %ctaid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r13, %r9, %r2, %r10;
	setp.ge.s32 	%p4, %r13, %r1;
	@%p4 bra 	$L__BB4_4;

	mov.u32 	%r11, %nctaid.x;
	mul.lo.s32 	%r4, %r2, %r11;
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;

$L__BB4_3:
	rem.s32 	%r12, %r13, %r7;
	mul.wide.s32 	%rd5, %r12, 4;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	mul.wide.s32 	%rd7, %r13, 4;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f32 	[%rd8], %f1;
	add.s32 	%r13, %r13, %r4;
	setp.lt.s32 	%p5, %r13, %r1;
	@%p5 bra 	$L__BB4_3;

$L__BB4_4:
	ret;

}

