







.version 9.0
.target sm_89
.address_size 64


.extern .shared .align 16 .b8 smem[];
.extern .shared .align 16 .b8 s_w[];

.visible .entry vpwma_batch_f32(
	.param .u64 vpwma_batch_f32_param_0,
	.param .u64 vpwma_batch_f32_param_1,
	.param .u64 vpwma_batch_f32_param_2,
	.param .u64 vpwma_batch_f32_param_3,
	.param .u64 vpwma_batch_f32_param_4,
	.param .u32 vpwma_batch_f32_param_5,
	.param .u32 vpwma_batch_f32_param_6,
	.param .u32 vpwma_batch_f32_param_7,
	.param .u32 vpwma_batch_f32_param_8,
	.param .u64 vpwma_batch_f32_param_9
)
{
	.reg .pred 	%p<40>;
	.reg .f32 	%f<77>;
	.reg .b32 	%r<142>;
	.reg .b64 	%rd<56>;


	ld.param.u64 	%rd12, [vpwma_batch_f32_param_0];
	ld.param.u64 	%rd13, [vpwma_batch_f32_param_1];
	ld.param.u64 	%rd14, [vpwma_batch_f32_param_2];
	ld.param.u64 	%rd15, [vpwma_batch_f32_param_3];
	ld.param.u64 	%rd16, [vpwma_batch_f32_param_4];
	ld.param.u32 	%r71, [vpwma_batch_f32_param_5];
	ld.param.u32 	%r72, [vpwma_batch_f32_param_6];
	ld.param.u32 	%r73, [vpwma_batch_f32_param_7];
	ld.param.u32 	%r74, [vpwma_batch_f32_param_8];
	ld.param.u64 	%rd17, [vpwma_batch_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd15;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd14;
	cvta.to.global.u64 	%rd6, %rd13;
	mov.u32 	%r75, %nctaid.x;
	setp.eq.s32 	%p1, %r75, %r74;
	mov.u32 	%r1, %ctaid.x;
	@%p1 bra 	$L__BB0_20;
	bra.uni 	$L__BB0_1;

$L__BB0_20:
	setp.ge.s32 	%p19, %r1, %r74;
	@%p19 bra 	$L__BB0_47;

	cvt.s64.s32 	%rd11, %r1;
	mul.wide.s32 	%rd41, %r1, 4;
	add.s64 	%rd42, %rd6, %rd41;
	add.s64 	%rd43, %rd5, %rd41;
	ld.global.nc.u32 	%r28, [%rd43];
	setp.lt.s32 	%p20, %r28, 1;
	ld.global.nc.u32 	%r94, [%rd42];
	setp.lt.s32 	%p21, %r94, 2;
	or.pred  	%p22, %p21, %p20;
	@%p22 bra 	$L__BB0_47;

	mul.lo.s32 	%r29, %r1, %r71;
	shl.b64 	%rd44, %rd11, 2;
	add.s64 	%rd45, %rd4, %rd44;
	ld.global.nc.f32 	%f10, [%rd45];
	add.s32 	%r133, %r28, %r73;
	min.s32 	%r31, %r133, %r71;
	mov.u32 	%r32, %tid.x;
	setp.ge.s32 	%p23, %r32, %r28;
	@%p23 bra 	$L__BB0_25;

	mov.u32 	%r33, %ntid.x;
	mul.lo.s32 	%r34, %r1, %r72;
	mov.u32 	%r131, %r32;

$L__BB0_24:
	add.s32 	%r95, %r131, %r34;
	mul.wide.s32 	%rd46, %r95, 4;
	add.s64 	%rd47, %rd1, %rd46;
	ld.global.nc.f32 	%f42, [%rd47];
	shl.b32 	%r96, %r131, 2;
	mov.u32 	%r97, smem;
	add.s32 	%r98, %r97, %r96;
	st.shared.f32 	[%r98], %f42;
	add.s32 	%r131, %r131, %r33;
	setp.lt.s32 	%p24, %r131, %r28;
	@%p24 bra 	$L__BB0_24;

$L__BB0_25:
	bar.sync 	0;
	setp.ge.s32 	%p25, %r32, %r31;
	@%p25 bra 	$L__BB0_28;

	mov.u32 	%r37, %ntid.x;
	mov.u32 	%r132, %r32;

$L__BB0_27:
	add.s32 	%r99, %r132, %r29;
	mul.wide.s32 	%rd48, %r99, 4;
	add.s64 	%rd49, %rd3, %rd48;
	mov.u32 	%r100, 2147483647;
	st.global.u32 	[%rd49], %r100;
	add.s32 	%r132, %r132, %r37;
	setp.lt.s32 	%p26, %r132, %r31;
	@%p26 bra 	$L__BB0_27;

$L__BB0_28:
	setp.ge.s32 	%p27, %r133, %r71;
	bar.sync 	0;
	@%p27 bra 	$L__BB0_47;

	add.s32 	%r40, %r28, -1;
	mov.u32 	%r101, 1;
	sub.s32 	%r41, %r101, %r28;
	mov.u32 	%r42, %ntid.x;
	add.s32 	%r43, %r40, %r28;
	and.b32  	%r44, %r28, 3;
	sub.s32 	%r45, %r28, %r44;
	mul.ftz.f32 	%f11, %f10, 0f00000000;
	shl.b32 	%r102, %r28, 3;
	mov.u32 	%r103, smem;
	add.s32 	%r104, %r103, %r102;
	add.s32 	%r46, %r104, -8;

$L__BB0_30:
	sub.s32 	%r105, %r71, %r133;
	min.s32 	%r48, %r105, 256;
	add.s32 	%r49, %r40, %r48;
	setp.ge.s32 	%p28, %r32, %r49;
	@%p28 bra 	$L__BB0_33;

	add.s32 	%r50, %r133, %r41;
	mov.u32 	%r134, %r32;

$L__BB0_32:
	add.s32 	%r106, %r50, %r134;
	mul.wide.s32 	%rd50, %r106, 4;
	add.s64 	%rd51, %rd2, %rd50;
	ld.global.nc.f32 	%f43, [%rd51];
	add.s32 	%r107, %r134, %r28;
	shl.b32 	%r108, %r107, 2;
	mov.u32 	%r109, smem;
	add.s32 	%r110, %r109, %r108;
	st.shared.f32 	[%r110], %f43;
	add.s32 	%r134, %r134, %r42;
	setp.lt.s32 	%p29, %r134, %r49;
	@%p29 bra 	$L__BB0_32;

$L__BB0_33:
	bar.sync 	0;
	setp.ge.s32 	%p30, %r32, %r48;
	@%p30 bra 	$L__BB0_46;

	setp.gt.s32 	%p31, %r28, 0;
	add.s32 	%r53, %r133, %r29;
	@%p31 bra 	$L__BB0_37;
	bra.uni 	$L__BB0_35;

$L__BB0_37:
	mov.u32 	%r136, %r32;

$L__BB0_38:
	setp.lt.u32 	%p33, %r40, 3;
	mov.f32 	%f76, 0f00000000;
	mov.u32 	%r141, 0;
	@%p33 bra 	$L__BB0_41;

	shl.b32 	%r115, %r136, 2;
	add.s32 	%r138, %r46, %r115;
	mov.f32 	%f76, 0f00000000;
	mov.u32 	%r141, 0;
	mov.u32 	%r137, %r103;
	mov.u32 	%r140, %r45;

$L__BB0_40:
	.pragma "nounroll";
	ld.shared.v4.f32 	{%f47, %f48, %f49, %f50}, [%r137];
	ld.shared.f32 	%f55, [%r138+4];
	fma.rn.ftz.f32 	%f56, %f47, %f55, %f76;
	ld.shared.f32 	%f57, [%r138];
	fma.rn.ftz.f32 	%f58, %f48, %f57, %f56;
	ld.shared.f32 	%f59, [%r138+-4];
	fma.rn.ftz.f32 	%f60, %f49, %f59, %f58;
	ld.shared.f32 	%f61, [%r138+-8];
	fma.rn.ftz.f32 	%f76, %f50, %f61, %f60;
	add.s32 	%r141, %r141, 4;
	add.s32 	%r138, %r138, -16;
	add.s32 	%r137, %r137, 16;
	add.s32 	%r140, %r140, -4;
	setp.ne.s32 	%p34, %r140, 0;
	@%p34 bra 	$L__BB0_40;

$L__BB0_41:
	setp.eq.s32 	%p35, %r44, 0;
	@%p35 bra 	$L__BB0_45;

	setp.eq.s32 	%p36, %r44, 1;
	add.s32 	%r116, %r43, %r136;
	sub.s32 	%r117, %r116, %r141;
	shl.b32 	%r118, %r117, 2;
	add.s32 	%r67, %r103, %r118;
	ld.shared.f32 	%f62, [%r67];
	shl.b32 	%r120, %r141, 2;
	add.s32 	%r68, %r103, %r120;
	ld.shared.f32 	%f63, [%r68];
	fma.rn.ftz.f32 	%f76, %f63, %f62, %f76;
	@%p36 bra 	$L__BB0_45;

	setp.eq.s32 	%p37, %r44, 2;
	ld.shared.f32 	%f64, [%r67+-4];
	ld.shared.f32 	%f65, [%r68+4];
	fma.rn.ftz.f32 	%f76, %f65, %f64, %f76;
	@%p37 bra 	$L__BB0_45;

	ld.shared.f32 	%f66, [%r67+-8];
	ld.shared.f32 	%f67, [%r68+8];
	fma.rn.ftz.f32 	%f76, %f67, %f66, %f76;

$L__BB0_45:
	add.s32 	%r121, %r53, %r136;
	mul.wide.s32 	%rd54, %r121, 4;
	add.s64 	%rd55, %rd3, %rd54;
	mul.ftz.f32 	%f68, %f10, %f76;
	st.global.f32 	[%rd55], %f68;
	add.s32 	%r136, %r136, %r42;
	setp.lt.s32 	%p38, %r136, %r48;
	@%p38 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_46;

$L__BB0_35:
	mov.u32 	%r135, %r32;

$L__BB0_36:
	add.s32 	%r111, %r53, %r135;
	mul.wide.s32 	%rd52, %r111, 4;
	add.s64 	%rd53, %rd3, %rd52;
	st.global.f32 	[%rd53], %f11;
	add.s32 	%r135, %r135, %r42;
	setp.lt.s32 	%p32, %r135, %r48;
	@%p32 bra 	$L__BB0_36;

$L__BB0_46:
	bar.sync 	0;
	add.s32 	%r133, %r133, 256;
	setp.lt.s32 	%p39, %r133, %r71;
	@%p39 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_47;

$L__BB0_1:
	mov.u32 	%r76, %ntid.x;
	mov.u32 	%r77, %tid.x;
	mad.lo.s32 	%r2, %r1, %r76, %r77;
	setp.ge.s32 	%p2, %r2, %r74;
	@%p2 bra 	$L__BB0_47;

	cvt.s64.s32 	%rd7, %r2;
	mul.wide.s32 	%rd18, %r2, 4;
	add.s64 	%rd19, %rd6, %rd18;
	add.s64 	%rd20, %rd5, %rd18;
	ld.global.nc.u32 	%r3, [%rd20];
	setp.lt.s32 	%p3, %r3, 1;
	ld.global.nc.u32 	%r78, [%rd19];
	setp.lt.s32 	%p4, %r78, 2;
	or.pred  	%p5, %p4, %p3;
	@%p5 bra 	$L__BB0_47;

	shl.b64 	%rd21, %rd7, 2;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.nc.f32 	%f1, [%rd22];
	mul.lo.s32 	%r4, %r2, %r71;
	add.s32 	%r127, %r3, %r73;
	min.s32 	%r6, %r127, %r71;
	setp.lt.s32 	%p6, %r6, 1;
	@%p6 bra 	$L__BB0_9;

	add.s32 	%r80, %r6, -1;
	and.b32  	%r126, %r6, 3;
	setp.lt.u32 	%p7, %r80, 3;
	mov.u32 	%r124, 0;
	@%p7 bra 	$L__BB0_7;

	sub.s32 	%r123, %r6, %r126;
	mov.u32 	%r124, 0;

$L__BB0_6:
	add.s32 	%r82, %r124, %r4;
	mul.wide.s32 	%rd23, %r82, 4;
	add.s64 	%rd24, %rd3, %rd23;
	mov.u32 	%r83, 2147483647;
	st.global.u32 	[%rd24], %r83;
	st.global.u32 	[%rd24+4], %r83;
	st.global.u32 	[%rd24+8], %r83;
	st.global.u32 	[%rd24+12], %r83;
	add.s32 	%r124, %r124, 4;
	add.s32 	%r123, %r123, -4;
	setp.ne.s32 	%p8, %r123, 0;
	@%p8 bra 	$L__BB0_6;

$L__BB0_7:
	setp.eq.s32 	%p9, %r126, 0;
	@%p9 bra 	$L__BB0_9;

$L__BB0_8:
	.pragma "nounroll";
	add.s32 	%r84, %r124, %r4;
	mul.wide.s32 	%rd25, %r84, 4;
	add.s64 	%rd26, %rd3, %rd25;
	mov.u32 	%r85, 2147483647;
	st.global.u32 	[%rd26], %r85;
	add.s32 	%r124, %r124, 1;
	add.s32 	%r126, %r126, -1;
	setp.ne.s32 	%p10, %r126, 0;
	@%p10 bra 	$L__BB0_8;

$L__BB0_9:
	setp.ge.s32 	%p11, %r127, %r71;
	@%p11 bra 	$L__BB0_47;

	mul.lo.s32 	%r86, %r2, %r72;
	cvt.s64.s32 	%rd8, %r86;
	add.s32 	%r18, %r3, -1;
	and.b32  	%r19, %r3, 3;
	sub.s32 	%r20, %r3, %r19;

$L__BB0_11:
	mov.f32 	%f72, 0f00000000;
	@%p3 bra 	$L__BB0_19;

	setp.lt.u32 	%p13, %r18, 3;
	mov.f32 	%f72, 0f00000000;
	mov.u32 	%r130, 0;
	@%p13 bra 	$L__BB0_15;

	mov.f32 	%f72, 0f00000000;
	mov.u32 	%r130, 0;
	mov.u32 	%r129, %r20;

$L__BB0_14:
	.pragma "nounroll";
	sub.s32 	%r89, %r127, %r130;
	mul.wide.s32 	%rd27, %r89, 4;
	add.s64 	%rd28, %rd2, %rd27;
	cvt.s64.s32 	%rd29, %r130;
	add.s64 	%rd30, %rd29, %rd8;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd1, %rd31;
	ld.global.nc.f32 	%f24, [%rd32];
	ld.global.nc.f32 	%f25, [%rd28];
	fma.rn.ftz.f32 	%f26, %f25, %f24, %f72;
	ld.global.nc.f32 	%f27, [%rd32+4];
	ld.global.nc.f32 	%f28, [%rd28+-4];
	fma.rn.ftz.f32 	%f29, %f28, %f27, %f26;
	ld.global.nc.f32 	%f30, [%rd32+8];
	ld.global.nc.f32 	%f31, [%rd28+-8];
	fma.rn.ftz.f32 	%f32, %f31, %f30, %f29;
	ld.global.nc.f32 	%f33, [%rd32+12];
	ld.global.nc.f32 	%f34, [%rd28+-12];
	fma.rn.ftz.f32 	%f72, %f34, %f33, %f32;
	add.s32 	%r130, %r130, 4;
	add.s32 	%r129, %r129, -4;
	setp.ne.s32 	%p14, %r129, 0;
	@%p14 bra 	$L__BB0_14;

$L__BB0_15:
	setp.eq.s32 	%p15, %r19, 0;
	@%p15 bra 	$L__BB0_19;

	setp.eq.s32 	%p16, %r19, 1;
	sub.s32 	%r90, %r127, %r130;
	mul.wide.s32 	%rd33, %r90, 4;
	add.s64 	%rd34, %rd2, %rd33;
	cvt.s64.s32 	%rd35, %r130;
	add.s64 	%rd36, %rd35, %rd8;
	shl.b64 	%rd37, %rd36, 2;
	add.s64 	%rd9, %rd1, %rd37;
	ld.global.nc.f32 	%f35, [%rd9];
	ld.global.nc.f32 	%f36, [%rd34];
	fma.rn.ftz.f32 	%f72, %f36, %f35, %f72;
	@%p16 bra 	$L__BB0_19;

	setp.eq.s32 	%p17, %r19, 2;
	add.s32 	%r91, %r130, 1;
	sub.s32 	%r92, %r127, %r91;
	mul.wide.s32 	%rd38, %r92, 4;
	add.s64 	%rd10, %rd2, %rd38;
	ld.global.nc.f32 	%f37, [%rd9+4];
	ld.global.nc.f32 	%f38, [%rd10];
	fma.rn.ftz.f32 	%f72, %f38, %f37, %f72;
	@%p17 bra 	$L__BB0_19;

	ld.global.nc.f32 	%f39, [%rd9+8];
	ld.global.nc.f32 	%f40, [%rd10+-4];
	fma.rn.ftz.f32 	%f72, %f40, %f39, %f72;

$L__BB0_19:
	add.s32 	%r93, %r127, %r4;
	mul.wide.s32 	%rd39, %r93, 4;
	add.s64 	%rd40, %rd3, %rd39;
	mul.ftz.f32 	%f41, %f1, %f72;
	st.global.f32 	[%rd40], %f41;
	add.s32 	%r127, %r127, 1;
	setp.lt.s32 	%p18, %r127, %r71;
	@%p18 bra 	$L__BB0_11;

$L__BB0_47:
	ret;

}

.visible .entry vpwma_many_series_one_param_f32(
	.param .u64 vpwma_many_series_one_param_f32_param_0,
	.param .u64 vpwma_many_series_one_param_f32_param_1,
	.param .u32 vpwma_many_series_one_param_f32_param_2,
	.param .u32 vpwma_many_series_one_param_f32_param_3,
	.param .u32 vpwma_many_series_one_param_f32_param_4,
	.param .u64 vpwma_many_series_one_param_f32_param_5,
	.param .f32 vpwma_many_series_one_param_f32_param_6,
	.param .u64 vpwma_many_series_one_param_f32_param_7
)
{
	.reg .pred 	%p<24>;
	.reg .f32 	%f<42>;
	.reg .b32 	%r<99>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd9, [vpwma_many_series_one_param_f32_param_0];
	ld.param.u64 	%rd7, [vpwma_many_series_one_param_f32_param_1];
	ld.param.u32 	%r45, [vpwma_many_series_one_param_f32_param_2];
	ld.param.u32 	%r46, [vpwma_many_series_one_param_f32_param_3];
	ld.param.u32 	%r47, [vpwma_many_series_one_param_f32_param_4];
	ld.param.u64 	%rd8, [vpwma_many_series_one_param_f32_param_5];
	ld.param.f32 	%f11, [vpwma_many_series_one_param_f32_param_6];
	ld.param.u64 	%rd10, [vpwma_many_series_one_param_f32_param_7];
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd2, %rd10;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r48, %ctaid.x;
	mov.u32 	%r84, %tid.x;
	mad.lo.s32 	%r3, %r48, %r1, %r84;
	add.s32 	%r4, %r47, -1;
	setp.lt.s32 	%p1, %r47, 2;
	@%p1 bra 	$L__BB1_30;

	setp.ge.s32 	%p2, %r3, %r45;
	mov.u32 	%r83, 0;
	@%p2 bra 	$L__BB1_3;

	cvta.to.global.u64 	%rd11, %rd7;
	mul.wide.s32 	%rd12, %r3, 4;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.nc.u32 	%r83, [%rd13];

$L__BB1_3:
	add.s32 	%r50, %r83, %r4;
	setp.lt.s32 	%p3, %r3, %r45;
	selp.b32 	%r94, %r50, 0, %p3;
	setp.ge.s32 	%p4, %r84, %r4;
	@%p4 bra 	$L__BB1_6;

	cvta.to.global.u64 	%rd3, %rd8;

$L__BB1_5:
	mul.wide.s32 	%rd14, %r84, 4;
	add.s64 	%rd15, %rd3, %rd14;
	ld.global.nc.f32 	%f12, [%rd15];
	shl.b32 	%r51, %r84, 2;
	mov.u32 	%r52, s_w;
	add.s32 	%r53, %r52, %r51;
	st.shared.f32 	[%r53], %f12;
	add.s32 	%r84, %r84, %r1;
	setp.lt.s32 	%p5, %r84, %r4;
	@%p5 bra 	$L__BB1_5;

$L__BB1_6:
	bar.sync 	0;
	@%p2 bra 	$L__BB1_30;

	min.s32 	%r10, %r94, %r46;
	setp.lt.s32 	%p7, %r10, 1;
	@%p7 bra 	$L__BB1_13;

	add.s32 	%r55, %r10, -1;
	and.b32  	%r89, %r10, 3;
	setp.lt.u32 	%p8, %r55, 3;
	mov.u32 	%r87, 0;
	@%p8 bra 	$L__BB1_11;

	sub.s32 	%r86, %r10, %r89;
	mul.wide.s32 	%rd4, %r45, 4;
	mov.u32 	%r87, 0;

$L__BB1_10:
	mad.lo.s32 	%r57, %r87, %r45, %r3;
	mul.wide.s32 	%rd16, %r57, 4;
	add.s64 	%rd17, %rd2, %rd16;
	mov.u32 	%r58, 2147483647;
	st.global.u32 	[%rd17], %r58;
	add.s64 	%rd18, %rd17, %rd4;
	st.global.u32 	[%rd18], %r58;
	add.s64 	%rd19, %rd18, %rd4;
	st.global.u32 	[%rd19], %r58;
	add.s64 	%rd20, %rd19, %rd4;
	st.global.u32 	[%rd20], %r58;
	add.s32 	%r87, %r87, 4;
	add.s32 	%r86, %r86, -4;
	setp.ne.s32 	%p9, %r86, 0;
	@%p9 bra 	$L__BB1_10;

$L__BB1_11:
	setp.eq.s32 	%p10, %r89, 0;
	@%p10 bra 	$L__BB1_13;

$L__BB1_12:
	.pragma "nounroll";
	mad.lo.s32 	%r59, %r87, %r45, %r3;
	mul.wide.s32 	%rd21, %r59, 4;
	add.s64 	%rd22, %rd2, %rd21;
	mov.u32 	%r60, 2147483647;
	st.global.u32 	[%rd22], %r60;
	add.s32 	%r87, %r87, 1;
	add.s32 	%r89, %r89, -1;
	setp.ne.s32 	%p11, %r89, 0;
	@%p11 bra 	$L__BB1_12;

$L__BB1_13:
	setp.ge.s32 	%p12, %r94, %r46;
	@%p12 bra 	$L__BB1_30;

	setp.gt.s32 	%p13, %r47, 1;
	@%p13 bra 	$L__BB1_21;
	bra.uni 	$L__BB1_15;

$L__BB1_21:
	add.s32 	%r30, %r47, -2;
	shl.b32 	%r31, %r45, 2;
	and.b32  	%r32, %r4, 3;
	add.s32 	%r66, %r32, 1;
	sub.s32 	%r33, %r66, %r47;
	neg.s32 	%r67, %r45;
	mul.wide.s32 	%rd6, %r67, 4;

$L__BB1_22:
	setp.lt.u32 	%p18, %r30, 3;
	mov.f32 	%f41, 0f00000000;
	mov.u32 	%r98, 0;
	@%p18 bra 	$L__BB1_25;

	mad.lo.s32 	%r96, %r45, %r94, %r3;
	mov.f32 	%f41, 0f00000000;
	mov.u32 	%r98, 0;
	mov.u32 	%r95, s_w;

$L__BB1_24:
	.pragma "nounroll";
	ld.shared.v4.f32 	{%f16, %f17, %f18, %f19}, [%r95];
	mul.wide.s32 	%rd30, %r96, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.nc.f32 	%f24, [%rd31];
	fma.rn.ftz.f32 	%f25, %f16, %f24, %f41;
	add.s64 	%rd32, %rd31, %rd6;
	ld.global.nc.f32 	%f26, [%rd32];
	fma.rn.ftz.f32 	%f27, %f17, %f26, %f25;
	add.s64 	%rd33, %rd32, %rd6;
	ld.global.nc.f32 	%f28, [%rd33];
	fma.rn.ftz.f32 	%f29, %f18, %f28, %f27;
	add.s64 	%rd34, %rd33, %rd6;
	ld.global.nc.f32 	%f30, [%rd34];
	fma.rn.ftz.f32 	%f41, %f19, %f30, %f29;
	sub.s32 	%r96, %r96, %r31;
	add.s32 	%r95, %r95, 16;
	add.s32 	%r98, %r98, 4;
	add.s32 	%r71, %r33, %r98;
	setp.ne.s32 	%p19, %r71, 0;
	@%p19 bra 	$L__BB1_24;

$L__BB1_25:
	setp.eq.s32 	%p20, %r32, 0;
	@%p20 bra 	$L__BB1_29;

	setp.eq.s32 	%p21, %r32, 1;
	sub.s32 	%r72, %r94, %r98;
	mad.lo.s32 	%r73, %r72, %r45, %r3;
	mul.wide.s32 	%rd35, %r73, 4;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.nc.f32 	%f31, [%rd36];
	shl.b32 	%r74, %r98, 2;
	mov.u32 	%r75, s_w;
	add.s32 	%r43, %r75, %r74;
	ld.shared.f32 	%f32, [%r43];
	fma.rn.ftz.f32 	%f41, %f32, %f31, %f41;
	@%p21 bra 	$L__BB1_29;

	setp.eq.s32 	%p22, %r32, 2;
	add.s32 	%r76, %r98, 1;
	sub.s32 	%r77, %r94, %r76;
	mad.lo.s32 	%r78, %r77, %r45, %r3;
	mul.wide.s32 	%rd37, %r78, 4;
	add.s64 	%rd38, %rd1, %rd37;
	ld.global.nc.f32 	%f33, [%rd38];
	ld.shared.f32 	%f34, [%r43+4];
	fma.rn.ftz.f32 	%f41, %f34, %f33, %f41;
	@%p22 bra 	$L__BB1_29;

	add.s32 	%r79, %r98, 2;
	sub.s32 	%r80, %r94, %r79;
	mad.lo.s32 	%r81, %r80, %r45, %r3;
	mul.wide.s32 	%rd39, %r81, 4;
	add.s64 	%rd40, %rd1, %rd39;
	ld.global.nc.f32 	%f35, [%rd40];
	ld.shared.f32 	%f36, [%r43+8];
	fma.rn.ftz.f32 	%f41, %f36, %f35, %f41;

$L__BB1_29:
	mad.lo.s32 	%r82, %r94, %r45, %r3;
	mul.wide.s32 	%rd41, %r82, 4;
	add.s64 	%rd42, %rd2, %rd41;
	mul.ftz.f32 	%f37, %f41, %f11;
	st.global.f32 	[%rd42], %f37;
	add.s32 	%r94, %r94, 1;
	setp.lt.s32 	%p23, %r94, %r46;
	@%p23 bra 	$L__BB1_22;
	bra.uni 	$L__BB1_30;

$L__BB1_15:
	sub.s32 	%r61, %r46, %r94;
	and.b32  	%r91, %r61, 3;
	setp.eq.s32 	%p14, %r91, 0;
	mov.u32 	%r92, %r94;
	@%p14 bra 	$L__BB1_18;

	mul.ftz.f32 	%f1, %f11, 0f00000000;
	mov.u32 	%r92, %r94;

$L__BB1_17:
	.pragma "nounroll";
	mad.lo.s32 	%r62, %r92, %r45, %r3;
	mul.wide.s32 	%rd23, %r62, 4;
	add.s64 	%rd24, %rd2, %rd23;
	st.global.f32 	[%rd24], %f1;
	add.s32 	%r92, %r92, 1;
	add.s32 	%r91, %r91, -1;
	setp.ne.s32 	%p15, %r91, 0;
	@%p15 bra 	$L__BB1_17;

$L__BB1_18:
	not.b32 	%r63, %r94;
	add.s32 	%r64, %r63, %r46;
	setp.lt.u32 	%p16, %r64, 3;
	@%p16 bra 	$L__BB1_30;

	mul.ftz.f32 	%f2, %f11, 0f00000000;
	mul.wide.s32 	%rd5, %r45, 4;

$L__BB1_20:
	mad.lo.s32 	%r65, %r92, %r45, %r3;
	mul.wide.s32 	%rd25, %r65, 4;
	add.s64 	%rd26, %rd2, %rd25;
	st.global.f32 	[%rd26], %f2;
	add.s64 	%rd27, %rd26, %rd5;
	st.global.f32 	[%rd27], %f2;
	add.s64 	%rd28, %rd27, %rd5;
	st.global.f32 	[%rd28], %f2;
	add.s64 	%rd29, %rd28, %rd5;
	st.global.f32 	[%rd29], %f2;
	add.s32 	%r92, %r92, 4;
	setp.lt.s32 	%p17, %r92, %r46;
	@%p17 bra 	$L__BB1_20;

$L__BB1_30:
	ret;

}

