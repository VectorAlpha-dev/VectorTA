







.version 9.0
.target sm_89
.address_size 64

	

.visible .entry vwmacd_batch_f32(
	.param .u64 vwmacd_batch_f32_param_0,
	.param .u64 vwmacd_batch_f32_param_1,
	.param .u64 vwmacd_batch_f32_param_2,
	.param .u64 vwmacd_batch_f32_param_3,
	.param .u64 vwmacd_batch_f32_param_4,
	.param .u32 vwmacd_batch_f32_param_5,
	.param .u32 vwmacd_batch_f32_param_6,
	.param .u32 vwmacd_batch_f32_param_7,
	.param .u64 vwmacd_batch_f32_param_8,
	.param .u64 vwmacd_batch_f32_param_9,
	.param .u64 vwmacd_batch_f32_param_10
)
{
	.reg .pred 	%p<81>;
	.reg .f32 	%f<106>;
	.reg .b32 	%r<186>;
	.reg .f64 	%fd<97>;
	.reg .b64 	%rd<163>;


	ld.param.u64 	%rd94, [vwmacd_batch_f32_param_0];
	ld.param.u64 	%rd95, [vwmacd_batch_f32_param_1];
	ld.param.u64 	%rd91, [vwmacd_batch_f32_param_2];
	ld.param.u64 	%rd92, [vwmacd_batch_f32_param_3];
	ld.param.u64 	%rd93, [vwmacd_batch_f32_param_4];
	ld.param.u32 	%r79, [vwmacd_batch_f32_param_5];
	ld.param.u32 	%r80, [vwmacd_batch_f32_param_6];
	ld.param.u32 	%r81, [vwmacd_batch_f32_param_7];
	ld.param.u64 	%rd96, [vwmacd_batch_f32_param_8];
	ld.param.u64 	%rd97, [vwmacd_batch_f32_param_9];
	ld.param.u64 	%rd98, [vwmacd_batch_f32_param_10];
	cvta.to.global.u64 	%rd144, %rd95;
	cvta.to.global.u64 	%rd143, %rd94;
	cvta.to.global.u64 	%rd3, %rd98;
	cvta.to.global.u64 	%rd4, %rd97;
	cvta.to.global.u64 	%rd5, %rd96;
	mov.u32 	%r82, %ntid.x;
	mov.u32 	%r83, %ctaid.x;
	mov.u32 	%r84, %tid.x;
	mad.lo.s32 	%r1, %r83, %r82, %r84;
	setp.ge.s32 	%p7, %r1, %r81;
	@%p7 bra 	$L__BB0_77;

	cvta.to.global.u64 	%rd99, %rd91;
	mul.wide.s32 	%rd100, %r1, 4;
	add.s64 	%rd101, %rd99, %rd100;
	cvta.to.global.u64 	%rd102, %rd92;
	add.s64 	%rd103, %rd102, %rd100;
	cvta.to.global.u64 	%rd104, %rd93;
	add.s64 	%rd105, %rd104, %rd100;
	ld.global.nc.u32 	%r2, [%rd103];
	ld.global.nc.u32 	%r3, [%rd101];
	max.s32 	%r4, %r3, %r2;
	add.s32 	%r170, %r4, %r80;
	add.s32 	%r166, %r170, -1;
	ld.global.nc.u32 	%r7, [%rd105];
	add.s32 	%r8, %r166, %r7;
	add.s32 	%r184, %r8, -1;
	mul.lo.s32 	%r10, %r1, %r79;
	setp.lt.s32 	%p8, %r79, 1;
	@%p8 bra 	$L__BB0_8;

	add.s32 	%r86, %r79, -1;
	and.b32  	%r162, %r79, 3;
	setp.lt.u32 	%p9, %r86, 3;
	mov.u32 	%r161, 0;
	@%p9 bra 	$L__BB0_5;

	sub.s32 	%r160, %r79, %r162;
	mul.wide.s32 	%rd6, %r10, 4;
	mov.u32 	%r161, 0;
	mov.u64 	%rd136, %rd5;
	mov.u64 	%rd137, %rd4;
	mov.u64 	%rd138, %rd3;

$L__BB0_4:
	add.s64 	%rd106, %rd136, %rd6;
	mov.u32 	%r88, 2147483647;
	st.global.u32 	[%rd106], %r88;
	add.s64 	%rd107, %rd137, %rd6;
	st.global.u32 	[%rd107], %r88;
	add.s64 	%rd108, %rd138, %rd6;
	st.global.u32 	[%rd108], %r88;
	st.global.u32 	[%rd106+4], %r88;
	st.global.u32 	[%rd107+4], %r88;
	st.global.u32 	[%rd108+4], %r88;
	st.global.u32 	[%rd106+8], %r88;
	st.global.u32 	[%rd107+8], %r88;
	st.global.u32 	[%rd108+8], %r88;
	st.global.u32 	[%rd106+12], %r88;
	st.global.u32 	[%rd107+12], %r88;
	st.global.u32 	[%rd108+12], %r88;
	add.s32 	%r161, %r161, 4;
	add.s64 	%rd138, %rd138, 16;
	add.s64 	%rd137, %rd137, 16;
	add.s64 	%rd136, %rd136, 16;
	add.s32 	%r160, %r160, -4;
	setp.ne.s32 	%p10, %r160, 0;
	@%p10 bra 	$L__BB0_4;

$L__BB0_5:
	setp.eq.s32 	%p11, %r162, 0;
	@%p11 bra 	$L__BB0_8;

	add.s32 	%r89, %r161, %r10;
	mul.wide.s32 	%rd109, %r89, 4;
	add.s64 	%rd141, %rd3, %rd109;
	add.s64 	%rd140, %rd4, %rd109;
	add.s64 	%rd139, %rd5, %rd109;

$L__BB0_7:
	.pragma "nounroll";
	mov.u32 	%r90, 2147483647;
	st.global.u32 	[%rd139], %r90;
	st.global.u32 	[%rd140], %r90;
	st.global.u32 	[%rd141], %r90;
	add.s64 	%rd141, %rd141, 4;
	add.s64 	%rd140, %rd140, 4;
	add.s64 	%rd139, %rd139, 4;
	add.s32 	%r162, %r162, -1;
	setp.ne.s32 	%p12, %r162, 0;
	@%p12 bra 	$L__BB0_7;

$L__BB0_8:
	setp.gt.s32 	%p13, %r170, %r79;
	add.s32 	%r91, %r166, %r10;
	cvt.s64.s32 	%rd22, %r91;
	mul.wide.s32 	%rd110, %r91, 4;
	add.s64 	%rd23, %rd5, %rd110;
	@%p13 bra 	$L__BB0_38;

	max.s32 	%r92, %r170, %r79;
	add.s32 	%r93, %r92, 1;
	sub.s32 	%r94, %r93, %r170;
	and.b32  	%r95, %r94, 1;
	setp.eq.b32 	%p14, %r95, 1;
	mov.pred 	%p15, 0;
	xor.pred  	%p16, %p14, %p15;
	not.pred 	%p17, %p16;
	@%p17 bra 	$L__BB0_19;

	sub.s32 	%r20, %r166, %r3;
	sub.s32 	%r21, %r166, %r2;
	mul.wide.s32 	%rd111, %r166, 8;
	add.s64 	%rd112, %rd143, %rd111;
	ld.global.nc.f64 	%fd87, [%rd112];
	add.s64 	%rd113, %rd144, %rd111;
	ld.global.nc.f64 	%fd88, [%rd113];
	setp.lt.s32 	%p18, %r20, 0;
	mov.f64 	%fd85, %fd87;
	mov.f64 	%fd86, %fd88;
	@%p18 bra 	$L__BB0_12;

	mul.wide.s32 	%rd114, %r20, 8;
	add.s64 	%rd115, %rd143, %rd114;
	ld.global.nc.f64 	%fd31, [%rd115];
	sub.f64 	%fd85, %fd87, %fd31;
	add.s64 	%rd116, %rd144, %rd114;
	ld.global.nc.f64 	%fd32, [%rd116];
	sub.f64 	%fd86, %fd88, %fd32;

$L__BB0_12:
	setp.lt.s32 	%p19, %r21, 0;
	@%p19 bra 	$L__BB0_14;

	mul.wide.s32 	%rd117, %r21, 8;
	add.s64 	%rd118, %rd143, %rd117;
	ld.global.nc.f64 	%fd33, [%rd118];
	sub.f64 	%fd87, %fd87, %fd33;
	add.s64 	%rd119, %rd144, %rd117;
	ld.global.nc.f64 	%fd34, [%rd119];
	sub.f64 	%fd88, %fd88, %fd34;

$L__BB0_14:
	abs.f64 	%fd35, %fd86;
	setp.gtu.f64 	%p21, %fd35, 0d7FF0000000000000;
	mov.pred 	%p78, 0;
	@%p21 bra 	$L__BB0_16;

	abs.f64 	%fd36, %fd88;
	setp.le.f64 	%p78, %fd36, 0d7FF0000000000000;

$L__BB0_16:
	setp.eq.f64 	%p22, %fd86, 0d0000000000000000;
	not.pred 	%p23, %p78;
	or.pred  	%p24, %p22, %p23;
	setp.eq.f64 	%p25, %fd88, 0d0000000000000000;
	mov.f32 	%f90, 0f7FFFFFFF;
	or.pred  	%p26, %p25, %p24;
	@%p26 bra 	$L__BB0_18;

	div.rn.f64 	%fd37, %fd85, %fd86;
	div.rn.f64 	%fd38, %fd87, %fd88;
	sub.f64 	%fd39, %fd37, %fd38;
	cvt.rn.ftz.f32.f64 	%f90, %fd39;

$L__BB0_18:
	st.global.f32 	[%rd23], %f90;
	mov.u32 	%r166, %r170;

$L__BB0_19:
	setp.ge.s32 	%p27, %r170, %r79;
	@%p27 bra 	$L__BB0_38;

	sub.s32 	%r96, %r3, %r166;
	mul.wide.s32 	%rd120, %r96, 8;
	neg.s64 	%rd24, %rd120;
	sub.s32 	%r165, %r166, %r3;
	sub.s32 	%r97, %r2, %r166;
	mul.wide.s32 	%rd121, %r97, 8;
	neg.s64 	%rd25, %rd121;
	sub.s32 	%r164, %r166, %r2;
	add.s32 	%r98, %r166, %r10;
	mul.wide.s32 	%rd122, %r98, 4;
	add.s64 	%rd142, %rd5, %rd122;
	mul.wide.s32 	%rd27, %r166, 8;

$L__BB0_21:
	add.s64 	%rd31, %rd143, %rd27;
	ld.global.nc.f64 	%fd91, [%rd31];
	add.s64 	%rd32, %rd144, %rd27;
	ld.global.nc.f64 	%fd92, [%rd32];
	add.s64 	%rd33, %rd143, %rd24;
	add.s64 	%rd34, %rd144, %rd24;
	setp.lt.s32 	%p28, %r165, 0;
	mov.f64 	%fd89, %fd91;
	mov.f64 	%fd90, %fd92;
	@%p28 bra 	$L__BB0_23;

	ld.global.nc.f64 	%fd40, [%rd33];
	sub.f64 	%fd89, %fd91, %fd40;
	ld.global.nc.f64 	%fd41, [%rd34];
	sub.f64 	%fd90, %fd92, %fd41;

$L__BB0_23:
	add.s64 	%rd35, %rd143, %rd25;
	add.s64 	%rd36, %rd144, %rd25;
	setp.lt.s32 	%p29, %r164, 0;
	@%p29 bra 	$L__BB0_25;

	ld.global.nc.f64 	%fd42, [%rd35];
	sub.f64 	%fd91, %fd91, %fd42;
	ld.global.nc.f64 	%fd43, [%rd36];
	sub.f64 	%fd92, %fd92, %fd43;

$L__BB0_25:
	abs.f64 	%fd44, %fd90;
	setp.gtu.f64 	%p31, %fd44, 0d7FF0000000000000;
	mov.pred 	%p79, 0;
	@%p31 bra 	$L__BB0_27;

	abs.f64 	%fd45, %fd92;
	setp.le.f64 	%p79, %fd45, 0d7FF0000000000000;

$L__BB0_27:
	setp.eq.f64 	%p32, %fd90, 0d0000000000000000;
	not.pred 	%p33, %p79;
	or.pred  	%p34, %p32, %p33;
	setp.eq.f64 	%p35, %fd92, 0d0000000000000000;
	mov.f32 	%f91, 0f7FFFFFFF;
	or.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB0_29;

	div.rn.f64 	%fd46, %fd89, %fd90;
	div.rn.f64 	%fd47, %fd91, %fd92;
	sub.f64 	%fd48, %fd46, %fd47;
	cvt.rn.ftz.f32.f64 	%f91, %fd48;

$L__BB0_29:
	st.global.f32 	[%rd142], %f91;
	ld.global.nc.f64 	%fd95, [%rd31+8];
	ld.global.nc.f64 	%fd96, [%rd32+8];
	add.s32 	%r99, %r165, 1;
	setp.lt.s32 	%p37, %r99, 0;
	mov.f64 	%fd93, %fd95;
	mov.f64 	%fd94, %fd96;
	@%p37 bra 	$L__BB0_31;

	ld.global.nc.f64 	%fd49, [%rd33+8];
	sub.f64 	%fd93, %fd95, %fd49;
	ld.global.nc.f64 	%fd50, [%rd34+8];
	sub.f64 	%fd94, %fd96, %fd50;

$L__BB0_31:
	add.s32 	%r100, %r164, 1;
	setp.lt.s32 	%p38, %r100, 0;
	@%p38 bra 	$L__BB0_33;

	ld.global.nc.f64 	%fd51, [%rd35+8];
	sub.f64 	%fd95, %fd95, %fd51;
	ld.global.nc.f64 	%fd52, [%rd36+8];
	sub.f64 	%fd96, %fd96, %fd52;

$L__BB0_33:
	abs.f64 	%fd53, %fd94;
	setp.gtu.f64 	%p40, %fd53, 0d7FF0000000000000;
	mov.pred 	%p80, 0;
	@%p40 bra 	$L__BB0_35;

	abs.f64 	%fd54, %fd96;
	setp.le.f64 	%p80, %fd54, 0d7FF0000000000000;

$L__BB0_35:
	setp.eq.f64 	%p41, %fd94, 0d0000000000000000;
	not.pred 	%p42, %p80;
	or.pred  	%p43, %p41, %p42;
	setp.eq.f64 	%p44, %fd96, 0d0000000000000000;
	mov.f32 	%f92, 0f7FFFFFFF;
	or.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB0_37;

	div.rn.f64 	%fd55, %fd93, %fd94;
	div.rn.f64 	%fd56, %fd95, %fd96;
	sub.f64 	%fd57, %fd55, %fd56;
	cvt.rn.ftz.f32.f64 	%f92, %fd57;

$L__BB0_37:
	st.global.f32 	[%rd142+4], %f92;
	add.s64 	%rd144, %rd144, 16;
	add.s64 	%rd143, %rd143, 16;
	add.s32 	%r165, %r165, 2;
	add.s32 	%r164, %r164, 2;
	add.s64 	%rd142, %rd142, 8;
	add.s32 	%r166, %r166, 2;
	setp.lt.s32 	%p46, %r166, %r79;
	@%p46 bra 	$L__BB0_21;

$L__BB0_38:
	@%p13 bra 	$L__BB0_53;

	add.s32 	%r101, %r7, 1;
	cvt.rn.f32.s32 	%f40, %r101;
	mov.f32 	%f41, 0f40000000;
	div.approx.ftz.f32 	%f7, %f41, %f40;
	mov.f32 	%f42, 0f3F800000;
	sub.ftz.f32 	%f8, %f42, %f7;
	min.s32 	%r176, %r8, %r79;
	ld.global.f32 	%f97, [%rd23];
	shl.b64 	%rd123, %rd22, 2;
	add.s64 	%rd124, %rd4, %rd123;
	st.global.f32 	[%rd124], %f97;
	setp.ge.s32 	%p48, %r170, %r176;
	@%p48 bra 	$L__BB0_46;

	not.b32 	%r103, %r80;
	sub.s32 	%r104, %r103, %r4;
	neg.s32 	%r105, %r7;
	sub.s32 	%r106, %r105, %r80;
	sub.s32 	%r107, %r106, %r4;
	not.b32 	%r108, %r79;
	max.s32 	%r32, %r107, %r108;
	sub.s32 	%r109, %r104, %r32;
	mov.u32 	%r110, -2;
	sub.s32 	%r111, %r110, %r80;
	sub.s32 	%r112, %r111, %r4;
	sub.s32 	%r113, %r112, %r32;
	and.b32  	%r173, %r109, 3;
	setp.lt.u32 	%p49, %r113, 3;
	mov.u32 	%r171, 1;
	@%p49 bra 	$L__BB0_43;

	add.s32 	%r115, %r170, %r10;
	mul.wide.s32 	%rd40, %r115, 4;
	add.s32 	%r116, %r170, %r32;
	add.s32 	%r117, %r116, %r173;
	neg.s32 	%r167, %r117;
	mov.u32 	%r171, 1;
	mov.u64 	%rd145, %rd5;
	mov.u64 	%rd146, %rd4;

$L__BB0_42:
	add.s64 	%rd125, %rd145, %rd40;
	cvt.ftz.f64.f32 	%fd58, %f97;
	cvt.rn.f64.s32 	%fd59, %r171;
	ld.global.f32 	%f44, [%rd125];
	cvt.ftz.f64.f32 	%fd60, %f44;
	fma.rn.f64 	%fd61, %fd58, %fd59, %fd60;
	add.s32 	%r118, %r171, 1;
	cvt.rn.f64.s32 	%fd62, %r118;
	div.rn.f64 	%fd63, %fd61, %fd62;
	cvt.rn.ftz.f32.f64 	%f45, %fd63;
	add.s64 	%rd126, %rd146, %rd40;
	st.global.f32 	[%rd126], %f45;
	cvt.ftz.f64.f32 	%fd64, %f45;
	ld.global.f32 	%f46, [%rd125+4];
	cvt.ftz.f64.f32 	%fd65, %f46;
	fma.rn.f64 	%fd66, %fd64, %fd62, %fd65;
	add.s32 	%r119, %r171, 2;
	cvt.rn.f64.s32 	%fd67, %r119;
	div.rn.f64 	%fd68, %fd66, %fd67;
	cvt.rn.ftz.f32.f64 	%f47, %fd68;
	st.global.f32 	[%rd126+4], %f47;
	cvt.ftz.f64.f32 	%fd69, %f47;
	ld.global.f32 	%f48, [%rd125+8];
	cvt.ftz.f64.f32 	%fd70, %f48;
	fma.rn.f64 	%fd71, %fd69, %fd67, %fd70;
	add.s32 	%r120, %r171, 3;
	cvt.rn.f64.s32 	%fd72, %r120;
	div.rn.f64 	%fd73, %fd71, %fd72;
	cvt.rn.ftz.f32.f64 	%f49, %fd73;
	st.global.f32 	[%rd126+8], %f49;
	cvt.ftz.f64.f32 	%fd74, %f49;
	ld.global.f32 	%f50, [%rd125+12];
	cvt.ftz.f64.f32 	%fd75, %f50;
	fma.rn.f64 	%fd76, %fd74, %fd72, %fd75;
	add.s32 	%r171, %r171, 4;
	cvt.rn.f64.s32 	%fd77, %r171;
	div.rn.f64 	%fd78, %fd76, %fd77;
	cvt.rn.ftz.f32.f64 	%f97, %fd78;
	st.global.f32 	[%rd126+12], %f97;
	add.s32 	%r170, %r170, 4;
	add.s64 	%rd146, %rd146, 16;
	add.s64 	%rd145, %rd145, 16;
	add.s32 	%r167, %r167, -4;
	setp.ne.s32 	%p50, %r167, 1;
	@%p50 bra 	$L__BB0_42;

$L__BB0_43:
	setp.eq.s32 	%p51, %r173, 0;
	@%p51 bra 	$L__BB0_46;

	add.s32 	%r121, %r170, %r10;
	mul.wide.s32 	%rd127, %r121, 4;
	add.s64 	%rd148, %rd4, %rd127;
	add.s64 	%rd147, %rd5, %rd127;
	add.s32 	%r172, %r171, 1;

$L__BB0_45:
	.pragma "nounroll";
	add.s32 	%r122, %r172, -1;
	cvt.rn.f64.s32 	%fd79, %r122;
	cvt.ftz.f64.f32 	%fd80, %f97;
	ld.global.f32 	%f51, [%rd147];
	cvt.ftz.f64.f32 	%fd81, %f51;
	fma.rn.f64 	%fd82, %fd80, %fd79, %fd81;
	cvt.rn.f64.s32 	%fd83, %r172;
	div.rn.f64 	%fd84, %fd82, %fd83;
	cvt.rn.ftz.f32.f64 	%f97, %fd84;
	st.global.f32 	[%rd148], %f97;
	add.s64 	%rd148, %rd148, 4;
	add.s64 	%rd147, %rd147, 4;
	add.s32 	%r172, %r172, 1;
	add.s32 	%r173, %r173, -1;
	setp.ne.s32 	%p52, %r173, 0;
	@%p52 bra 	$L__BB0_45;

$L__BB0_46:
	setp.ge.s32 	%p53, %r8, %r79;
	@%p53 bra 	$L__BB0_53;

	neg.s32 	%r123, %r7;
	sub.s32 	%r124, %r123, %r80;
	sub.s32 	%r125, %r124, %r4;
	not.b32 	%r126, %r79;
	max.s32 	%r49, %r125, %r126;
	add.s32 	%r50, %r49, %r79;
	add.s32 	%r127, %r50, 1;
	and.b32  	%r175, %r127, 3;
	setp.eq.s32 	%p54, %r175, 0;
	@%p54 bra 	$L__BB0_50;

	add.s32 	%r128, %r10, -1;
	sub.s32 	%r129, %r128, %r49;
	mul.wide.s32 	%rd128, %r129, 4;
	add.s64 	%rd150, %rd4, %rd128;
	add.s64 	%rd149, %rd5, %rd128;

$L__BB0_49:
	.pragma "nounroll";
	ld.global.f32 	%f52, [%rd149];
	mul.ftz.f32 	%f53, %f7, %f52;
	fma.rn.ftz.f32 	%f97, %f8, %f97, %f53;
	st.global.f32 	[%rd150], %f97;
	add.s32 	%r176, %r176, 1;
	add.s64 	%rd150, %rd150, 4;
	add.s64 	%rd149, %rd149, 4;
	add.s32 	%r175, %r175, -1;
	setp.ne.s32 	%p55, %r175, 0;
	@%p55 bra 	$L__BB0_49;

$L__BB0_50:
	setp.lt.u32 	%p56, %r50, 3;
	@%p56 bra 	$L__BB0_53;

	add.s32 	%r130, %r176, %r10;
	mul.wide.s32 	%rd57, %r130, 4;
	mov.u64 	%rd151, %rd5;
	mov.u64 	%rd152, %rd4;

$L__BB0_52:
	add.s64 	%rd129, %rd151, %rd57;
	ld.global.f32 	%f54, [%rd129];
	mul.ftz.f32 	%f55, %f7, %f54;
	fma.rn.ftz.f32 	%f56, %f8, %f97, %f55;
	add.s64 	%rd130, %rd152, %rd57;
	st.global.f32 	[%rd130], %f56;
	ld.global.f32 	%f57, [%rd129+4];
	mul.ftz.f32 	%f58, %f7, %f57;
	fma.rn.ftz.f32 	%f59, %f8, %f56, %f58;
	st.global.f32 	[%rd130+4], %f59;
	ld.global.f32 	%f60, [%rd129+8];
	mul.ftz.f32 	%f61, %f7, %f60;
	fma.rn.ftz.f32 	%f62, %f8, %f59, %f61;
	st.global.f32 	[%rd130+8], %f62;
	ld.global.f32 	%f63, [%rd129+12];
	mul.ftz.f32 	%f64, %f7, %f63;
	fma.rn.ftz.f32 	%f97, %f8, %f62, %f64;
	st.global.f32 	[%rd130+12], %f97;
	add.s64 	%rd152, %rd152, 16;
	add.s64 	%rd151, %rd151, 16;
	add.s32 	%r176, %r176, 4;
	setp.lt.s32 	%p57, %r176, %r79;
	@%p57 bra 	$L__BB0_52;

$L__BB0_53:
	min.s32 	%r59, %r184, %r79;
	setp.lt.s32 	%p58, %r59, 1;
	@%p58 bra 	$L__BB0_60;

	mov.u32 	%r132, 1;
	sub.s32 	%r133, %r132, %r7;
	sub.s32 	%r134, %r133, %r80;
	sub.s32 	%r60, %r134, %r4;
	not.b32 	%r135, %r79;
	max.s32 	%r136, %r60, %r135;
	mov.u32 	%r137, -2;
	sub.s32 	%r138, %r137, %r136;
	and.b32  	%r181, %r59, 3;
	setp.lt.u32 	%p59, %r138, 3;
	mov.u32 	%r180, 0;
	@%p59 bra 	$L__BB0_57;

	mul.wide.s32 	%rd62, %r10, 4;
	add.s32 	%r142, %r136, %r181;
	neg.s32 	%r178, %r142;
	mov.u32 	%r180, 0;
	mov.u64 	%rd153, %rd4;
	mov.u64 	%rd154, %rd3;

$L__BB0_56:
	add.s64 	%rd131, %rd153, %rd62;
	mov.u32 	%r143, 2147483647;
	st.global.u32 	[%rd131], %r143;
	add.s64 	%rd132, %rd154, %rd62;
	st.global.u32 	[%rd132], %r143;
	st.global.u32 	[%rd131+4], %r143;
	st.global.u32 	[%rd132+4], %r143;
	st.global.u32 	[%rd131+8], %r143;
	st.global.u32 	[%rd132+8], %r143;
	st.global.u32 	[%rd131+12], %r143;
	st.global.u32 	[%rd132+12], %r143;
	add.s32 	%r180, %r180, 4;
	add.s64 	%rd154, %rd154, 16;
	add.s64 	%rd153, %rd153, 16;
	add.s32 	%r178, %r178, -4;
	setp.ne.s32 	%p60, %r178, 1;
	@%p60 bra 	$L__BB0_56;

$L__BB0_57:
	setp.eq.s32 	%p61, %r181, 0;
	@%p61 bra 	$L__BB0_60;

	add.s32 	%r144, %r180, %r10;
	mul.wide.s32 	%rd133, %r144, 4;
	add.s64 	%rd156, %rd3, %rd133;
	add.s64 	%rd155, %rd4, %rd133;

$L__BB0_59:
	.pragma "nounroll";
	mov.u32 	%r145, 2147483647;
	st.global.u32 	[%rd155], %r145;
	st.global.u32 	[%rd156], %r145;
	add.s64 	%rd156, %rd156, 4;
	add.s64 	%rd155, %rd155, 4;
	add.s32 	%r181, %r181, -1;
	setp.ne.s32 	%p62, %r181, 0;
	@%p62 bra 	$L__BB0_59;

$L__BB0_60:
	setp.gt.s32 	%p63, %r8, %r79;
	@%p63 bra 	$L__BB0_77;

	max.s32 	%r70, %r8, %r79;
	add.s32 	%r146, %r70, 2;
	sub.s32 	%r147, %r146, %r7;
	sub.s32 	%r148, %r147, %r80;
	sub.s32 	%r149, %r148, %r4;
	and.b32  	%r183, %r149, 3;
	setp.eq.s32 	%p64, %r183, 0;
	@%p64 bra 	$L__BB0_66;

	add.s32 	%r150, %r7, %r80;
	add.s32 	%r151, %r150, %r4;
	add.s32 	%r152, %r151, %r10;
	add.s32 	%r153, %r152, -2;
	mul.wide.s32 	%rd134, %r153, 4;
	add.s64 	%rd159, %rd3, %rd134;
	add.s64 	%rd158, %rd4, %rd134;
	add.s64 	%rd157, %rd5, %rd134;

$L__BB0_63:
	.pragma "nounroll";
	ld.global.f32 	%f22, [%rd157];
	abs.ftz.f32 	%f66, %f22;
	setp.gtu.ftz.f32 	%p65, %f66, 0f7F800000;
	mov.f32 	%f101, 0f7FFFFFFF;
	@%p65 bra 	$L__BB0_65;

	ld.global.f32 	%f67, [%rd158];
	abs.ftz.f32 	%f68, %f67;
	setp.le.ftz.f32 	%p66, %f68, 0f7F800000;
	sub.ftz.f32 	%f69, %f22, %f67;
	selp.f32 	%f101, %f69, 0f7FFFFFFF, %p66;

$L__BB0_65:
	st.global.f32 	[%rd159], %f101;
	add.s32 	%r184, %r184, 1;
	add.s64 	%rd159, %rd159, 4;
	add.s64 	%rd158, %rd158, 4;
	add.s64 	%rd157, %rd157, 4;
	add.s32 	%r183, %r183, -1;
	setp.ne.s32 	%p67, %r183, 0;
	@%p67 bra 	$L__BB0_63;

$L__BB0_66:
	add.s32 	%r154, %r70, 1;
	sub.s32 	%r155, %r154, %r7;
	sub.s32 	%r156, %r155, %r80;
	sub.s32 	%r157, %r156, %r4;
	setp.lt.u32 	%p68, %r157, 3;
	@%p68 bra 	$L__BB0_77;

	add.s32 	%r158, %r184, %r10;
	mul.wide.s32 	%rd135, %r158, 4;
	add.s64 	%rd160, %rd5, %rd135;
	add.s64 	%rd161, %rd4, %rd135;
	add.s64 	%rd162, %rd3, %rd135;

$L__BB0_68:
	ld.global.f32 	%f25, [%rd160];
	abs.ftz.f32 	%f71, %f25;
	setp.gtu.ftz.f32 	%p69, %f71, 0f7F800000;
	mov.f32 	%f103, 0f7FFFFFFF;
	mov.f32 	%f102, %f103;
	@%p69 bra 	$L__BB0_70;

	ld.global.f32 	%f72, [%rd161];
	abs.ftz.f32 	%f73, %f72;
	setp.le.ftz.f32 	%p70, %f73, 0f7F800000;
	sub.ftz.f32 	%f74, %f25, %f72;
	selp.f32 	%f102, %f74, 0f7FFFFFFF, %p70;

$L__BB0_70:
	st.global.f32 	[%rd162], %f102;
	ld.global.f32 	%f28, [%rd160+4];
	abs.ftz.f32 	%f76, %f28;
	setp.gtu.ftz.f32 	%p71, %f76, 0f7F800000;
	@%p71 bra 	$L__BB0_72;

	ld.global.f32 	%f77, [%rd161+4];
	abs.ftz.f32 	%f78, %f77;
	setp.le.ftz.f32 	%p72, %f78, 0f7F800000;
	sub.ftz.f32 	%f79, %f28, %f77;
	selp.f32 	%f103, %f79, 0f7FFFFFFF, %p72;

$L__BB0_72:
	st.global.f32 	[%rd162+4], %f103;
	ld.global.f32 	%f31, [%rd160+8];
	abs.ftz.f32 	%f81, %f31;
	setp.gtu.ftz.f32 	%p73, %f81, 0f7F800000;
	mov.f32 	%f105, 0f7FFFFFFF;
	mov.f32 	%f104, %f105;
	@%p73 bra 	$L__BB0_74;

	ld.global.f32 	%f82, [%rd161+8];
	abs.ftz.f32 	%f83, %f82;
	setp.le.ftz.f32 	%p74, %f83, 0f7F800000;
	sub.ftz.f32 	%f84, %f31, %f82;
	selp.f32 	%f104, %f84, 0f7FFFFFFF, %p74;

$L__BB0_74:
	st.global.f32 	[%rd162+8], %f104;
	ld.global.f32 	%f34, [%rd160+12];
	abs.ftz.f32 	%f86, %f34;
	setp.gtu.ftz.f32 	%p75, %f86, 0f7F800000;
	@%p75 bra 	$L__BB0_76;

	ld.global.f32 	%f87, [%rd161+12];
	abs.ftz.f32 	%f88, %f87;
	setp.le.ftz.f32 	%p76, %f88, 0f7F800000;
	sub.ftz.f32 	%f89, %f34, %f87;
	selp.f32 	%f105, %f89, 0f7FFFFFFF, %p76;

$L__BB0_76:
	add.s64 	%rd161, %rd161, 16;
	add.s64 	%rd160, %rd160, 16;
	add.s64 	%rd90, %rd162, 16;
	st.global.f32 	[%rd162+12], %f105;
	add.s32 	%r184, %r184, 4;
	setp.lt.s32 	%p77, %r184, %r79;
	mov.u64 	%rd162, %rd90;
	@%p77 bra 	$L__BB0_68;

$L__BB0_77:
	ret;

}
	
.visible .entry vwmacd_many_series_one_param_time_major_f32(
	.param .u64 vwmacd_many_series_one_param_time_major_f32_param_0,
	.param .u64 vwmacd_many_series_one_param_time_major_f32_param_1,
	.param .u64 vwmacd_many_series_one_param_time_major_f32_param_2,
	.param .u32 vwmacd_many_series_one_param_time_major_f32_param_3,
	.param .u32 vwmacd_many_series_one_param_time_major_f32_param_4,
	.param .u32 vwmacd_many_series_one_param_time_major_f32_param_5,
	.param .u32 vwmacd_many_series_one_param_time_major_f32_param_6,
	.param .u32 vwmacd_many_series_one_param_time_major_f32_param_7,
	.param .u64 vwmacd_many_series_one_param_time_major_f32_param_8,
	.param .u64 vwmacd_many_series_one_param_time_major_f32_param_9,
	.param .u64 vwmacd_many_series_one_param_time_major_f32_param_10
)
{
	.reg .pred 	%p<81>;
	.reg .f32 	%f<106>;
	.reg .b32 	%r<206>;
	.reg .f64 	%fd<97>;
	.reg .b64 	%rd<224>;


	ld.param.u64 	%rd120, [vwmacd_many_series_one_param_time_major_f32_param_0];
	ld.param.u64 	%rd121, [vwmacd_many_series_one_param_time_major_f32_param_1];
	ld.param.u64 	%rd119, [vwmacd_many_series_one_param_time_major_f32_param_2];
	ld.param.u32 	%r88, [vwmacd_many_series_one_param_time_major_f32_param_3];
	ld.param.u32 	%r89, [vwmacd_many_series_one_param_time_major_f32_param_4];
	ld.param.u32 	%r90, [vwmacd_many_series_one_param_time_major_f32_param_5];
	ld.param.u32 	%r91, [vwmacd_many_series_one_param_time_major_f32_param_6];
	ld.param.u32 	%r92, [vwmacd_many_series_one_param_time_major_f32_param_7];
	ld.param.u64 	%rd122, [vwmacd_many_series_one_param_time_major_f32_param_8];
	ld.param.u64 	%rd123, [vwmacd_many_series_one_param_time_major_f32_param_9];
	ld.param.u64 	%rd124, [vwmacd_many_series_one_param_time_major_f32_param_10];
	cvta.to.global.u64 	%rd1, %rd121;
	cvta.to.global.u64 	%rd2, %rd120;
	cvta.to.global.u64 	%rd3, %rd124;
	cvta.to.global.u64 	%rd4, %rd123;
	cvta.to.global.u64 	%rd5, %rd122;
	mov.u32 	%r93, %ntid.x;
	mov.u32 	%r94, %ctaid.x;
	mov.u32 	%r95, %tid.x;
	mad.lo.s32 	%r1, %r94, %r93, %r95;
	setp.ge.s32 	%p7, %r1, %r91;
	@%p7 bra 	$L__BB1_77;

	cvta.to.global.u64 	%rd125, %rd119;
	cvt.s64.s32 	%rd6, %r1;
	mul.wide.s32 	%rd126, %r1, 4;
	add.s64 	%rd127, %rd125, %rd126;
	max.s32 	%r2, %r88, %r89;
	ld.global.nc.u32 	%r3, [%rd127];
	add.s32 	%r190, %r3, %r2;
	add.s32 	%r186, %r190, -1;
	add.s32 	%r6, %r186, %r90;
	add.s32 	%r204, %r6, -1;
	setp.lt.s32 	%p8, %r92, 1;
	@%p8 bra 	$L__BB1_8;

	add.s32 	%r97, %r92, -1;
	and.b32  	%r178, %r92, 3;
	setp.lt.u32 	%p9, %r97, 3;
	mov.u32 	%r177, 0;
	@%p9 bra 	$L__BB1_5;

	sub.s32 	%r176, %r92, %r178;
	shl.b64 	%rd128, %rd6, 2;
	add.s64 	%rd194, %rd5, %rd128;
	mul.wide.s32 	%rd8, %r91, 4;
	add.s64 	%rd195, %rd4, %rd128;
	add.s64 	%rd196, %rd3, %rd128;
	mov.u32 	%r177, 0;

$L__BB1_4:
	mov.u32 	%r99, 2147483647;
	st.global.u32 	[%rd194], %r99;
	st.global.u32 	[%rd195], %r99;
	st.global.u32 	[%rd196], %r99;
	add.s64 	%rd129, %rd194, %rd8;
	st.global.u32 	[%rd129], %r99;
	add.s64 	%rd130, %rd195, %rd8;
	st.global.u32 	[%rd130], %r99;
	add.s64 	%rd131, %rd196, %rd8;
	st.global.u32 	[%rd131], %r99;
	add.s64 	%rd132, %rd129, %rd8;
	st.global.u32 	[%rd132], %r99;
	add.s64 	%rd133, %rd130, %rd8;
	st.global.u32 	[%rd133], %r99;
	add.s64 	%rd134, %rd131, %rd8;
	st.global.u32 	[%rd134], %r99;
	add.s64 	%rd135, %rd132, %rd8;
	add.s64 	%rd194, %rd135, %rd8;
	st.global.u32 	[%rd135], %r99;
	add.s64 	%rd136, %rd133, %rd8;
	add.s64 	%rd195, %rd136, %rd8;
	st.global.u32 	[%rd136], %r99;
	add.s64 	%rd137, %rd134, %rd8;
	add.s64 	%rd196, %rd137, %rd8;
	st.global.u32 	[%rd137], %r99;
	add.s32 	%r177, %r177, 4;
	add.s32 	%r176, %r176, -4;
	setp.ne.s32 	%p10, %r176, 0;
	@%p10 bra 	$L__BB1_4;

$L__BB1_5:
	setp.eq.s32 	%p11, %r178, 0;
	@%p11 bra 	$L__BB1_8;

	mad.lo.s32 	%r100, %r177, %r91, %r1;
	mul.wide.s32 	%rd138, %r100, 4;
	add.s64 	%rd199, %rd3, %rd138;
	mul.wide.s32 	%rd18, %r91, 4;
	add.s64 	%rd198, %rd4, %rd138;
	add.s64 	%rd197, %rd5, %rd138;

$L__BB1_7:
	.pragma "nounroll";
	mov.u32 	%r101, 2147483647;
	st.global.u32 	[%rd197], %r101;
	st.global.u32 	[%rd198], %r101;
	st.global.u32 	[%rd199], %r101;
	add.s64 	%rd199, %rd199, %rd18;
	add.s64 	%rd198, %rd198, %rd18;
	add.s64 	%rd197, %rd197, %rd18;
	add.s32 	%r178, %r178, -1;
	setp.ne.s32 	%p12, %r178, 0;
	@%p12 bra 	$L__BB1_7;

$L__BB1_8:
	setp.gt.s32 	%p13, %r190, %r92;
	mad.lo.s32 	%r102, %r186, %r91, %r1;
	cvt.s64.s32 	%rd27, %r102;
	mul.wide.s32 	%rd139, %r102, 4;
	add.s64 	%rd28, %rd5, %rd139;
	@%p13 bra 	$L__BB1_38;

	max.s32 	%r103, %r190, %r92;
	add.s32 	%r104, %r103, 1;
	sub.s32 	%r105, %r104, %r190;
	and.b32  	%r106, %r105, 1;
	setp.eq.b32 	%p14, %r106, 1;
	mov.pred 	%p15, 0;
	xor.pred  	%p16, %p14, %p15;
	not.pred 	%p17, %p16;
	@%p17 bra 	$L__BB1_19;

	sub.s32 	%r17, %r186, %r88;
	sub.s32 	%r18, %r186, %r89;
	mul.wide.s32 	%rd140, %r102, 8;
	add.s64 	%rd141, %rd2, %rd140;
	ld.global.nc.f64 	%fd87, [%rd141];
	add.s64 	%rd142, %rd1, %rd140;
	ld.global.nc.f64 	%fd88, [%rd142];
	setp.lt.s32 	%p18, %r17, 0;
	mov.f64 	%fd85, %fd87;
	mov.f64 	%fd86, %fd88;
	@%p18 bra 	$L__BB1_12;

	mad.lo.s32 	%r108, %r17, %r91, %r1;
	mul.wide.s32 	%rd143, %r108, 8;
	add.s64 	%rd144, %rd2, %rd143;
	ld.global.nc.f64 	%fd31, [%rd144];
	sub.f64 	%fd85, %fd87, %fd31;
	add.s64 	%rd145, %rd1, %rd143;
	ld.global.nc.f64 	%fd32, [%rd145];
	sub.f64 	%fd86, %fd88, %fd32;

$L__BB1_12:
	setp.lt.s32 	%p19, %r18, 0;
	@%p19 bra 	$L__BB1_14;

	mad.lo.s32 	%r109, %r18, %r91, %r1;
	mul.wide.s32 	%rd146, %r109, 8;
	add.s64 	%rd147, %rd2, %rd146;
	ld.global.nc.f64 	%fd33, [%rd147];
	sub.f64 	%fd87, %fd87, %fd33;
	add.s64 	%rd148, %rd1, %rd146;
	ld.global.nc.f64 	%fd34, [%rd148];
	sub.f64 	%fd88, %fd88, %fd34;

$L__BB1_14:
	abs.f64 	%fd35, %fd86;
	setp.gtu.f64 	%p21, %fd35, 0d7FF0000000000000;
	mov.pred 	%p78, 0;
	@%p21 bra 	$L__BB1_16;

	abs.f64 	%fd36, %fd88;
	setp.le.f64 	%p78, %fd36, 0d7FF0000000000000;

$L__BB1_16:
	setp.eq.f64 	%p22, %fd86, 0d0000000000000000;
	not.pred 	%p23, %p78;
	or.pred  	%p24, %p22, %p23;
	setp.eq.f64 	%p25, %fd88, 0d0000000000000000;
	mov.f32 	%f90, 0f7FFFFFFF;
	or.pred  	%p26, %p25, %p24;
	@%p26 bra 	$L__BB1_18;

	div.rn.f64 	%fd37, %fd85, %fd86;
	div.rn.f64 	%fd38, %fd87, %fd88;
	sub.f64 	%fd39, %fd37, %fd38;
	cvt.rn.ftz.f32.f64 	%f90, %fd39;

$L__BB1_18:
	st.global.f32 	[%rd28], %f90;
	mov.u32 	%r186, %r190;

$L__BB1_19:
	setp.ge.s32 	%p27, %r190, %r92;
	@%p27 bra 	$L__BB1_38;

	sub.s32 	%r184, %r186, %r88;
	mad.lo.s32 	%r185, %r91, %r184, %r1;
	sub.s32 	%r182, %r186, %r89;
	mad.lo.s32 	%r183, %r91, %r182, %r1;
	add.s32 	%r110, %r186, 1;
	sub.s32 	%r111, %r110, %r89;
	mad.lo.s32 	%r181, %r91, %r111, %r1;
	sub.s32 	%r112, %r110, %r88;
	mad.lo.s32 	%r180, %r91, %r112, %r1;
	mad.lo.s32 	%r113, %r91, %r110, %r1;
	mul.wide.s32 	%rd149, %r113, 4;
	add.s64 	%rd205, %rd5, %rd149;
	shl.b32 	%r26, %r91, 1;
	mul.wide.s32 	%rd30, %r26, 4;
	mul.wide.s32 	%rd150, %r113, 8;
	add.s64 	%rd204, %rd1, %rd150;
	mul.wide.s32 	%rd32, %r26, 8;
	add.s64 	%rd203, %rd2, %rd150;
	mad.lo.s32 	%r114, %r186, %r91, %r1;
	mul.wide.s32 	%rd151, %r114, 4;
	add.s64 	%rd202, %rd5, %rd151;
	mul.wide.s32 	%rd152, %r114, 8;
	add.s64 	%rd201, %rd1, %rd152;
	add.s64 	%rd200, %rd2, %rd152;

$L__BB1_21:
	ld.global.nc.f64 	%fd91, [%rd200];
	ld.global.nc.f64 	%fd92, [%rd201];
	setp.lt.s32 	%p28, %r184, 0;
	mov.f64 	%fd89, %fd91;
	mov.f64 	%fd90, %fd92;
	@%p28 bra 	$L__BB1_23;

	mul.wide.s32 	%rd153, %r185, 8;
	add.s64 	%rd154, %rd2, %rd153;
	ld.global.nc.f64 	%fd40, [%rd154];
	sub.f64 	%fd89, %fd91, %fd40;
	add.s64 	%rd155, %rd1, %rd153;
	ld.global.nc.f64 	%fd41, [%rd155];
	sub.f64 	%fd90, %fd92, %fd41;

$L__BB1_23:
	setp.lt.s32 	%p29, %r182, 0;
	@%p29 bra 	$L__BB1_25;

	mul.wide.s32 	%rd156, %r183, 8;
	add.s64 	%rd157, %rd2, %rd156;
	ld.global.nc.f64 	%fd42, [%rd157];
	sub.f64 	%fd91, %fd91, %fd42;
	add.s64 	%rd158, %rd1, %rd156;
	ld.global.nc.f64 	%fd43, [%rd158];
	sub.f64 	%fd92, %fd92, %fd43;

$L__BB1_25:
	abs.f64 	%fd44, %fd90;
	setp.gtu.f64 	%p31, %fd44, 0d7FF0000000000000;
	mov.pred 	%p79, 0;
	@%p31 bra 	$L__BB1_27;

	abs.f64 	%fd45, %fd92;
	setp.le.f64 	%p79, %fd45, 0d7FF0000000000000;

$L__BB1_27:
	setp.eq.f64 	%p32, %fd90, 0d0000000000000000;
	not.pred 	%p33, %p79;
	or.pred  	%p34, %p32, %p33;
	setp.eq.f64 	%p35, %fd92, 0d0000000000000000;
	mov.f32 	%f91, 0f7FFFFFFF;
	or.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB1_29;

	div.rn.f64 	%fd46, %fd89, %fd90;
	div.rn.f64 	%fd47, %fd91, %fd92;
	sub.f64 	%fd48, %fd46, %fd47;
	cvt.rn.ftz.f32.f64 	%f91, %fd48;

$L__BB1_29:
	st.global.f32 	[%rd202], %f91;
	ld.global.nc.f64 	%fd95, [%rd203];
	ld.global.nc.f64 	%fd96, [%rd204];
	add.s32 	%r115, %r184, 1;
	setp.lt.s32 	%p37, %r115, 0;
	mov.f64 	%fd93, %fd95;
	mov.f64 	%fd94, %fd96;
	@%p37 bra 	$L__BB1_31;

	mul.wide.s32 	%rd159, %r180, 8;
	add.s64 	%rd160, %rd2, %rd159;
	ld.global.nc.f64 	%fd49, [%rd160];
	sub.f64 	%fd93, %fd95, %fd49;
	add.s64 	%rd161, %rd1, %rd159;
	ld.global.nc.f64 	%fd50, [%rd161];
	sub.f64 	%fd94, %fd96, %fd50;

$L__BB1_31:
	add.s32 	%r116, %r182, 1;
	setp.lt.s32 	%p38, %r116, 0;
	@%p38 bra 	$L__BB1_33;

	mul.wide.s32 	%rd162, %r181, 8;
	add.s64 	%rd163, %rd2, %rd162;
	ld.global.nc.f64 	%fd51, [%rd163];
	sub.f64 	%fd95, %fd95, %fd51;
	add.s64 	%rd164, %rd1, %rd162;
	ld.global.nc.f64 	%fd52, [%rd164];
	sub.f64 	%fd96, %fd96, %fd52;

$L__BB1_33:
	abs.f64 	%fd53, %fd94;
	setp.gtu.f64 	%p40, %fd53, 0d7FF0000000000000;
	mov.pred 	%p80, 0;
	@%p40 bra 	$L__BB1_35;

	abs.f64 	%fd54, %fd96;
	setp.le.f64 	%p80, %fd54, 0d7FF0000000000000;

$L__BB1_35:
	setp.eq.f64 	%p41, %fd94, 0d0000000000000000;
	not.pred 	%p42, %p80;
	or.pred  	%p43, %p41, %p42;
	setp.eq.f64 	%p44, %fd96, 0d0000000000000000;
	mov.f32 	%f92, 0f7FFFFFFF;
	or.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB1_37;

	div.rn.f64 	%fd55, %fd93, %fd94;
	div.rn.f64 	%fd56, %fd95, %fd96;
	sub.f64 	%fd57, %fd55, %fd56;
	cvt.rn.ftz.f32.f64 	%f92, %fd57;

$L__BB1_37:
	st.global.f32 	[%rd205], %f92;
	add.s32 	%r185, %r185, %r26;
	add.s32 	%r184, %r184, 2;
	add.s32 	%r183, %r183, %r26;
	add.s32 	%r182, %r182, 2;
	add.s32 	%r181, %r181, %r26;
	add.s32 	%r180, %r180, %r26;
	add.s64 	%rd205, %rd205, %rd30;
	add.s64 	%rd204, %rd204, %rd32;
	add.s64 	%rd203, %rd203, %rd32;
	add.s64 	%rd202, %rd202, %rd30;
	add.s64 	%rd201, %rd201, %rd32;
	add.s64 	%rd200, %rd200, %rd32;
	add.s32 	%r186, %r186, 2;
	setp.lt.s32 	%p46, %r186, %r92;
	@%p46 bra 	$L__BB1_21;

$L__BB1_38:
	@%p13 bra 	$L__BB1_53;

	add.s32 	%r117, %r90, 1;
	cvt.rn.f32.s32 	%f40, %r117;
	mov.f32 	%f41, 0f40000000;
	div.approx.ftz.f32 	%f7, %f41, %f40;
	mov.f32 	%f42, 0f3F800000;
	sub.ftz.f32 	%f8, %f42, %f7;
	min.s32 	%r196, %r6, %r92;
	ld.global.f32 	%f97, [%rd28];
	shl.b64 	%rd165, %rd27, 2;
	add.s64 	%rd166, %rd4, %rd165;
	st.global.f32 	[%rd166], %f97;
	setp.ge.s32 	%p48, %r190, %r196;
	@%p48 bra 	$L__BB1_46;

	not.b32 	%r119, %r3;
	sub.s32 	%r120, %r119, %r2;
	neg.s32 	%r121, %r3;
	sub.s32 	%r122, %r121, %r90;
	sub.s32 	%r123, %r122, %r2;
	not.b32 	%r124, %r92;
	max.s32 	%r42, %r123, %r124;
	sub.s32 	%r125, %r120, %r42;
	mov.u32 	%r126, -2;
	sub.s32 	%r127, %r126, %r3;
	sub.s32 	%r128, %r127, %r2;
	sub.s32 	%r129, %r128, %r42;
	and.b32  	%r193, %r125, 3;
	setp.lt.u32 	%p49, %r129, 3;
	mov.u32 	%r191, 1;
	@%p49 bra 	$L__BB1_43;

	mad.lo.s32 	%r131, %r91, %r190, %r1;
	add.s32 	%r132, %r190, %r42;
	add.s32 	%r133, %r132, %r193;
	neg.s32 	%r187, %r133;
	mul.wide.s32 	%rd167, %r131, 4;
	add.s64 	%rd206, %rd5, %rd167;
	mul.wide.s32 	%rd50, %r91, 4;
	add.s64 	%rd207, %rd4, %rd167;
	mov.u32 	%r191, 1;

$L__BB1_42:
	cvt.ftz.f64.f32 	%fd58, %f97;
	cvt.rn.f64.s32 	%fd59, %r191;
	ld.global.f32 	%f44, [%rd206];
	cvt.ftz.f64.f32 	%fd60, %f44;
	fma.rn.f64 	%fd61, %fd58, %fd59, %fd60;
	add.s32 	%r134, %r191, 1;
	cvt.rn.f64.s32 	%fd62, %r134;
	div.rn.f64 	%fd63, %fd61, %fd62;
	cvt.rn.ftz.f32.f64 	%f45, %fd63;
	st.global.f32 	[%rd207], %f45;
	add.s64 	%rd168, %rd206, %rd50;
	cvt.ftz.f64.f32 	%fd64, %f45;
	ld.global.f32 	%f46, [%rd168];
	cvt.ftz.f64.f32 	%fd65, %f46;
	fma.rn.f64 	%fd66, %fd64, %fd62, %fd65;
	add.s32 	%r135, %r191, 2;
	cvt.rn.f64.s32 	%fd67, %r135;
	div.rn.f64 	%fd68, %fd66, %fd67;
	cvt.rn.ftz.f32.f64 	%f47, %fd68;
	add.s64 	%rd169, %rd207, %rd50;
	st.global.f32 	[%rd169], %f47;
	add.s64 	%rd170, %rd168, %rd50;
	cvt.ftz.f64.f32 	%fd69, %f47;
	ld.global.f32 	%f48, [%rd170];
	cvt.ftz.f64.f32 	%fd70, %f48;
	fma.rn.f64 	%fd71, %fd69, %fd67, %fd70;
	add.s32 	%r136, %r191, 3;
	cvt.rn.f64.s32 	%fd72, %r136;
	div.rn.f64 	%fd73, %fd71, %fd72;
	cvt.rn.ftz.f32.f64 	%f49, %fd73;
	add.s64 	%rd171, %rd169, %rd50;
	st.global.f32 	[%rd171], %f49;
	add.s64 	%rd172, %rd170, %rd50;
	add.s64 	%rd206, %rd172, %rd50;
	cvt.ftz.f64.f32 	%fd74, %f49;
	ld.global.f32 	%f50, [%rd172];
	cvt.ftz.f64.f32 	%fd75, %f50;
	fma.rn.f64 	%fd76, %fd74, %fd72, %fd75;
	add.s32 	%r191, %r191, 4;
	cvt.rn.f64.s32 	%fd77, %r191;
	div.rn.f64 	%fd78, %fd76, %fd77;
	cvt.rn.ftz.f32.f64 	%f97, %fd78;
	add.s64 	%rd173, %rd171, %rd50;
	add.s64 	%rd207, %rd173, %rd50;
	st.global.f32 	[%rd173], %f97;
	add.s32 	%r190, %r190, 4;
	add.s32 	%r187, %r187, -4;
	setp.ne.s32 	%p50, %r187, 1;
	@%p50 bra 	$L__BB1_42;

$L__BB1_43:
	setp.eq.s32 	%p51, %r193, 0;
	@%p51 bra 	$L__BB1_46;

	mad.lo.s32 	%r137, %r190, %r91, %r1;
	mul.wide.s32 	%rd174, %r137, 4;
	add.s64 	%rd209, %rd4, %rd174;
	mul.wide.s32 	%rd57, %r91, 4;
	add.s64 	%rd208, %rd5, %rd174;
	add.s32 	%r192, %r191, 1;

$L__BB1_45:
	.pragma "nounroll";
	add.s32 	%r138, %r192, -1;
	cvt.rn.f64.s32 	%fd79, %r138;
	cvt.ftz.f64.f32 	%fd80, %f97;
	ld.global.f32 	%f51, [%rd208];
	cvt.ftz.f64.f32 	%fd81, %f51;
	fma.rn.f64 	%fd82, %fd80, %fd79, %fd81;
	cvt.rn.f64.s32 	%fd83, %r192;
	div.rn.f64 	%fd84, %fd82, %fd83;
	cvt.rn.ftz.f32.f64 	%f97, %fd84;
	st.global.f32 	[%rd209], %f97;
	add.s64 	%rd209, %rd209, %rd57;
	add.s64 	%rd208, %rd208, %rd57;
	add.s32 	%r192, %r192, 1;
	add.s32 	%r193, %r193, -1;
	setp.ne.s32 	%p52, %r193, 0;
	@%p52 bra 	$L__BB1_45;

$L__BB1_46:
	setp.ge.s32 	%p53, %r6, %r92;
	@%p53 bra 	$L__BB1_53;

	neg.s32 	%r139, %r3;
	sub.s32 	%r140, %r139, %r90;
	sub.s32 	%r141, %r140, %r2;
	not.b32 	%r142, %r92;
	max.s32 	%r143, %r141, %r142;
	add.s32 	%r59, %r143, %r92;
	add.s32 	%r144, %r59, 1;
	and.b32  	%r195, %r144, 3;
	setp.eq.s32 	%p54, %r195, 0;
	@%p54 bra 	$L__BB1_50;

	mad.lo.s32 	%r145, %r91, %r196, %r1;
	mul.wide.s32 	%rd175, %r145, 4;
	add.s64 	%rd211, %rd4, %rd175;
	mul.wide.s32 	%rd64, %r91, 4;
	add.s64 	%rd210, %rd5, %rd175;

$L__BB1_49:
	.pragma "nounroll";
	ld.global.f32 	%f52, [%rd210];
	mul.ftz.f32 	%f53, %f7, %f52;
	fma.rn.ftz.f32 	%f97, %f8, %f97, %f53;
	st.global.f32 	[%rd211], %f97;
	add.s32 	%r196, %r196, 1;
	add.s64 	%rd211, %rd211, %rd64;
	add.s64 	%rd210, %rd210, %rd64;
	add.s32 	%r195, %r195, -1;
	setp.ne.s32 	%p55, %r195, 0;
	@%p55 bra 	$L__BB1_49;

$L__BB1_50:
	setp.lt.u32 	%p56, %r59, 3;
	@%p56 bra 	$L__BB1_53;

	mad.lo.s32 	%r146, %r196, %r91, %r1;
	mul.wide.s32 	%rd176, %r146, 4;
	add.s64 	%rd212, %rd5, %rd176;
	mul.wide.s32 	%rd71, %r91, 4;
	add.s64 	%rd213, %rd4, %rd176;

$L__BB1_52:
	ld.global.f32 	%f54, [%rd212];
	mul.ftz.f32 	%f55, %f7, %f54;
	fma.rn.ftz.f32 	%f56, %f8, %f97, %f55;
	st.global.f32 	[%rd213], %f56;
	add.s64 	%rd177, %rd212, %rd71;
	ld.global.f32 	%f57, [%rd177];
	mul.ftz.f32 	%f58, %f7, %f57;
	fma.rn.ftz.f32 	%f59, %f8, %f56, %f58;
	add.s64 	%rd178, %rd213, %rd71;
	st.global.f32 	[%rd178], %f59;
	add.s64 	%rd179, %rd177, %rd71;
	ld.global.f32 	%f60, [%rd179];
	mul.ftz.f32 	%f61, %f7, %f60;
	fma.rn.ftz.f32 	%f62, %f8, %f59, %f61;
	add.s64 	%rd180, %rd178, %rd71;
	st.global.f32 	[%rd180], %f62;
	add.s64 	%rd181, %rd179, %rd71;
	add.s64 	%rd212, %rd181, %rd71;
	ld.global.f32 	%f63, [%rd181];
	mul.ftz.f32 	%f64, %f7, %f63;
	fma.rn.ftz.f32 	%f97, %f8, %f62, %f64;
	add.s64 	%rd182, %rd180, %rd71;
	add.s64 	%rd213, %rd182, %rd71;
	st.global.f32 	[%rd182], %f97;
	add.s32 	%r196, %r196, 4;
	setp.lt.s32 	%p57, %r196, %r92;
	@%p57 bra 	$L__BB1_52;

$L__BB1_53:
	min.s32 	%r68, %r204, %r92;
	setp.lt.s32 	%p58, %r68, 1;
	@%p58 bra 	$L__BB1_60;

	mov.u32 	%r148, 1;
	sub.s32 	%r149, %r148, %r3;
	sub.s32 	%r150, %r149, %r90;
	sub.s32 	%r69, %r150, %r2;
	not.b32 	%r151, %r92;
	max.s32 	%r152, %r69, %r151;
	mov.u32 	%r153, -2;
	sub.s32 	%r154, %r153, %r152;
	and.b32  	%r201, %r68, 3;
	setp.lt.u32 	%p59, %r154, 3;
	mov.u32 	%r200, 0;
	@%p59 bra 	$L__BB1_57;

	add.s32 	%r158, %r152, %r201;
	neg.s32 	%r198, %r158;
	mov.u32 	%r200, 0;
	shl.b64 	%rd183, %rd6, 2;
	add.s64 	%rd214, %rd4, %rd183;
	mul.wide.s32 	%rd78, %r91, 4;
	add.s64 	%rd215, %rd3, %rd183;

$L__BB1_56:
	mov.u32 	%r159, 2147483647;
	st.global.u32 	[%rd214], %r159;
	st.global.u32 	[%rd215], %r159;
	add.s64 	%rd184, %rd214, %rd78;
	st.global.u32 	[%rd184], %r159;
	add.s64 	%rd185, %rd215, %rd78;
	st.global.u32 	[%rd185], %r159;
	add.s64 	%rd186, %rd184, %rd78;
	st.global.u32 	[%rd186], %r159;
	add.s64 	%rd187, %rd185, %rd78;
	st.global.u32 	[%rd187], %r159;
	add.s64 	%rd188, %rd186, %rd78;
	add.s64 	%rd214, %rd188, %rd78;
	st.global.u32 	[%rd188], %r159;
	add.s64 	%rd189, %rd187, %rd78;
	add.s64 	%rd215, %rd189, %rd78;
	st.global.u32 	[%rd189], %r159;
	add.s32 	%r200, %r200, 4;
	add.s32 	%r198, %r198, -4;
	setp.ne.s32 	%p60, %r198, 1;
	@%p60 bra 	$L__BB1_56;

$L__BB1_57:
	setp.eq.s32 	%p61, %r201, 0;
	@%p61 bra 	$L__BB1_60;

	mad.lo.s32 	%r160, %r200, %r91, %r1;
	mul.wide.s32 	%rd190, %r160, 4;
	add.s64 	%rd217, %rd3, %rd190;
	mul.wide.s32 	%rd85, %r91, 4;
	add.s64 	%rd216, %rd4, %rd190;

$L__BB1_59:
	.pragma "nounroll";
	mov.u32 	%r161, 2147483647;
	st.global.u32 	[%rd216], %r161;
	st.global.u32 	[%rd217], %r161;
	add.s64 	%rd217, %rd217, %rd85;
	add.s64 	%rd216, %rd216, %rd85;
	add.s32 	%r201, %r201, -1;
	setp.ne.s32 	%p62, %r201, 0;
	@%p62 bra 	$L__BB1_59;

$L__BB1_60:
	setp.gt.s32 	%p63, %r6, %r92;
	@%p63 bra 	$L__BB1_77;

	max.s32 	%r79, %r6, %r92;
	add.s32 	%r162, %r79, 2;
	sub.s32 	%r163, %r162, %r3;
	sub.s32 	%r164, %r163, %r90;
	sub.s32 	%r165, %r164, %r2;
	and.b32  	%r203, %r165, 3;
	setp.eq.s32 	%p64, %r203, 0;
	@%p64 bra 	$L__BB1_66;

	add.s32 	%r166, %r3, %r90;
	add.s32 	%r167, %r166, %r2;
	add.s32 	%r168, %r167, -2;
	mad.lo.s32 	%r169, %r91, %r168, %r1;
	mul.wide.s32 	%rd191, %r169, 4;
	add.s64 	%rd220, %rd3, %rd191;
	mul.wide.s32 	%rd92, %r91, 4;
	add.s64 	%rd219, %rd4, %rd191;
	add.s64 	%rd218, %rd5, %rd191;

$L__BB1_63:
	.pragma "nounroll";
	ld.global.f32 	%f22, [%rd218];
	abs.ftz.f32 	%f66, %f22;
	setp.gtu.ftz.f32 	%p65, %f66, 0f7F800000;
	mov.f32 	%f101, 0f7FFFFFFF;
	@%p65 bra 	$L__BB1_65;

	ld.global.f32 	%f67, [%rd219];
	abs.ftz.f32 	%f68, %f67;
	setp.le.ftz.f32 	%p66, %f68, 0f7F800000;
	sub.ftz.f32 	%f69, %f22, %f67;
	selp.f32 	%f101, %f69, 0f7FFFFFFF, %p66;

$L__BB1_65:
	st.global.f32 	[%rd220], %f101;
	add.s32 	%r204, %r204, 1;
	add.s64 	%rd220, %rd220, %rd92;
	add.s64 	%rd219, %rd219, %rd92;
	add.s64 	%rd218, %rd218, %rd92;
	add.s32 	%r203, %r203, -1;
	setp.ne.s32 	%p67, %r203, 0;
	@%p67 bra 	$L__BB1_63;

$L__BB1_66:
	add.s32 	%r170, %r79, 1;
	sub.s32 	%r171, %r170, %r3;
	sub.s32 	%r172, %r171, %r90;
	sub.s32 	%r173, %r172, %r2;
	setp.lt.u32 	%p68, %r173, 3;
	@%p68 bra 	$L__BB1_77;

	mad.lo.s32 	%r174, %r204, %r91, %r1;
	mul.wide.s32 	%rd192, %r174, 4;
	add.s64 	%rd221, %rd5, %rd192;
	mul.wide.s32 	%rd102, %r91, 4;
	add.s64 	%rd222, %rd4, %rd192;
	add.s64 	%rd223, %rd3, %rd192;

$L__BB1_68:
	ld.global.f32 	%f25, [%rd221];
	abs.ftz.f32 	%f71, %f25;
	setp.gtu.ftz.f32 	%p69, %f71, 0f7F800000;
	mov.f32 	%f103, 0f7FFFFFFF;
	mov.f32 	%f102, %f103;
	@%p69 bra 	$L__BB1_70;

	ld.global.f32 	%f72, [%rd222];
	abs.ftz.f32 	%f73, %f72;
	setp.le.ftz.f32 	%p70, %f73, 0f7F800000;
	sub.ftz.f32 	%f74, %f25, %f72;
	selp.f32 	%f102, %f74, 0f7FFFFFFF, %p70;

$L__BB1_70:
	st.global.f32 	[%rd223], %f102;
	add.s64 	%rd108, %rd221, %rd102;
	add.s64 	%rd109, %rd222, %rd102;
	ld.global.f32 	%f28, [%rd108];
	abs.ftz.f32 	%f76, %f28;
	setp.gtu.ftz.f32 	%p71, %f76, 0f7F800000;
	@%p71 bra 	$L__BB1_72;

	ld.global.f32 	%f77, [%rd109];
	abs.ftz.f32 	%f78, %f77;
	setp.le.ftz.f32 	%p72, %f78, 0f7F800000;
	sub.ftz.f32 	%f79, %f28, %f77;
	selp.f32 	%f103, %f79, 0f7FFFFFFF, %p72;

$L__BB1_72:
	add.s64 	%rd110, %rd223, %rd102;
	st.global.f32 	[%rd110], %f103;
	add.s64 	%rd111, %rd108, %rd102;
	add.s64 	%rd112, %rd109, %rd102;
	ld.global.f32 	%f31, [%rd111];
	abs.ftz.f32 	%f81, %f31;
	setp.gtu.ftz.f32 	%p73, %f81, 0f7F800000;
	mov.f32 	%f105, 0f7FFFFFFF;
	mov.f32 	%f104, %f105;
	@%p73 bra 	$L__BB1_74;

	ld.global.f32 	%f82, [%rd112];
	abs.ftz.f32 	%f83, %f82;
	setp.le.ftz.f32 	%p74, %f83, 0f7F800000;
	sub.ftz.f32 	%f84, %f31, %f82;
	selp.f32 	%f104, %f84, 0f7FFFFFFF, %p74;

$L__BB1_74:
	add.s64 	%rd113, %rd110, %rd102;
	st.global.f32 	[%rd113], %f104;
	add.s64 	%rd114, %rd111, %rd102;
	add.s64 	%rd115, %rd112, %rd102;
	ld.global.f32 	%f34, [%rd114];
	abs.ftz.f32 	%f86, %f34;
	setp.gtu.ftz.f32 	%p75, %f86, 0f7F800000;
	@%p75 bra 	$L__BB1_76;

	ld.global.f32 	%f87, [%rd115];
	abs.ftz.f32 	%f88, %f87;
	setp.le.ftz.f32 	%p76, %f88, 0f7F800000;
	sub.ftz.f32 	%f89, %f34, %f87;
	selp.f32 	%f105, %f89, 0f7FFFFFFF, %p76;

$L__BB1_76:
	add.s64 	%rd222, %rd115, %rd102;
	add.s64 	%rd221, %rd114, %rd102;
	add.s64 	%rd193, %rd113, %rd102;
	add.s64 	%rd223, %rd193, %rd102;
	st.global.f32 	[%rd193], %f105;
	add.s32 	%r204, %r204, 4;
	setp.lt.s32 	%p77, %r204, %r92;
	@%p77 bra 	$L__BB1_68;

$L__BB1_77:
	ret;

}

