







.version 9.0
.target sm_89
.address_size 64



.visible .entry ehlers_ecema_batch_f32(
	.param .u64 ehlers_ecema_batch_f32_param_0,
	.param .u64 ehlers_ecema_batch_f32_param_1,
	.param .u64 ehlers_ecema_batch_f32_param_2,
	.param .u64 ehlers_ecema_batch_f32_param_3,
	.param .u64 ehlers_ecema_batch_f32_param_4,
	.param .u32 ehlers_ecema_batch_f32_param_5,
	.param .u32 ehlers_ecema_batch_f32_param_6,
	.param .u32 ehlers_ecema_batch_f32_param_7,
	.param .u64 ehlers_ecema_batch_f32_param_8
)
{
	.reg .pred 	%p<89>;
	.reg .b16 	%rs<22>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<120>;
	.reg .f64 	%fd<119>;
	.reg .b64 	%rd<77>;


	ld.param.u64 	%rd37, [ehlers_ecema_batch_f32_param_0];
	ld.param.u64 	%rd33, [ehlers_ecema_batch_f32_param_1];
	ld.param.u64 	%rd34, [ehlers_ecema_batch_f32_param_2];
	ld.param.u64 	%rd35, [ehlers_ecema_batch_f32_param_3];
	ld.param.u64 	%rd36, [ehlers_ecema_batch_f32_param_4];
	ld.param.u32 	%r52, [ehlers_ecema_batch_f32_param_5];
	ld.param.u32 	%r54, [ehlers_ecema_batch_f32_param_6];
	ld.param.u32 	%r116, [ehlers_ecema_batch_f32_param_7];
	ld.param.u64 	%rd38, [ehlers_ecema_batch_f32_param_8];
	cvta.to.global.u64 	%rd1, %rd37;
	cvta.to.global.u64 	%rd2, %rd38;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p2, %r1, %r54;
	@%p2 bra 	$L__BB0_66;

	cvta.to.global.u64 	%rd39, %rd33;
	cvt.s64.s32 	%rd40, %r1;
	mul.wide.s32 	%rd41, %r1, 4;
	add.s64 	%rd42, %rd39, %rd41;
	ld.global.nc.u32 	%r2, [%rd42];
	cvta.to.global.u64 	%rd43, %rd34;
	add.s64 	%rd44, %rd43, %rd41;
	ld.global.nc.u32 	%r3, [%rd44];
	cvta.to.global.u64 	%rd45, %rd35;
	add.s64 	%rd46, %rd45, %rd40;
	ld.global.nc.u8 	%rs1, [%rd46];
	cvta.to.global.u64 	%rd47, %rd36;
	add.s64 	%rd48, %rd47, %rd40;
	ld.global.nc.u8 	%rs2, [%rd48];
	mul.lo.s32 	%r4, %r1, %r52;
	mov.u32 	%r113, %tid.x;
	setp.ne.s32 	%p3, %r113, 0;
	@%p3 bra 	$L__BB0_9;

	setp.gt.s32 	%p4, %r2, 0;
	setp.gt.s32 	%p5, %r3, 0;
	and.pred  	%p6, %p4, %p5;
	setp.lt.s32 	%p7, %r52, 1;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB0_9;

	add.s32 	%r56, %r52, -1;
	and.b32  	%r104, %r52, 3;
	setp.lt.u32 	%p9, %r56, 3;
	mov.u32 	%r103, 0;
	@%p9 bra 	$L__BB0_6;

	sub.s32 	%r102, %r52, %r104;
	mul.wide.s32 	%rd49, %r4, 4;
	add.s64 	%rd67, %rd2, %rd49;
	mov.u32 	%r103, 0;

$L__BB0_5:
	mov.u32 	%r58, 2143289344;
	st.global.u32 	[%rd67], %r58;
	st.global.u32 	[%rd67+4], %r58;
	st.global.u32 	[%rd67+8], %r58;
	st.global.u32 	[%rd67+12], %r58;
	add.s32 	%r103, %r103, 4;
	add.s64 	%rd67, %rd67, 16;
	add.s32 	%r102, %r102, -4;
	setp.ne.s32 	%p10, %r102, 0;
	@%p10 bra 	$L__BB0_5;

$L__BB0_6:
	setp.eq.s32 	%p11, %r104, 0;
	@%p11 bra 	$L__BB0_9;

	add.s32 	%r59, %r103, %r4;
	mul.wide.s32 	%rd50, %r59, 4;
	add.s64 	%rd68, %rd2, %rd50;

$L__BB0_8:
	.pragma "nounroll";
	mov.u32 	%r60, 2143289344;
	st.global.u32 	[%rd68], %r60;
	add.s64 	%rd68, %rd68, 4;
	add.s32 	%r104, %r104, -1;
	setp.ne.s32 	%p12, %r104, 0;
	@%p12 bra 	$L__BB0_8;

$L__BB0_9:
	bar.sync 	0;
	setp.lt.s32 	%p13, %r3, 1;
	setp.lt.s32 	%p14, %r2, 1;
	or.pred  	%p15, %p14, %p13;
	@%p15 bra 	$L__BB0_66;

	@%p3 bra 	$L__BB0_18;

	setp.gt.s32 	%p17, %r116, -1;
	setp.gt.s32 	%p18, %r52, %r116;
	and.pred  	%p19, %p17, %p18;
	setp.lt.s32 	%p20, %r52, 1;
	or.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB0_18;

	add.s32 	%r62, %r52, -1;
	and.b32  	%r108, %r52, 3;
	setp.lt.u32 	%p22, %r62, 3;
	mov.u32 	%r107, 0;
	@%p22 bra 	$L__BB0_15;

	sub.s32 	%r106, %r52, %r108;
	mul.wide.s32 	%rd51, %r4, 4;
	add.s64 	%rd69, %rd2, %rd51;
	mov.u32 	%r107, 0;

$L__BB0_14:
	mov.u32 	%r64, 2143289344;
	st.global.u32 	[%rd69], %r64;
	st.global.u32 	[%rd69+4], %r64;
	st.global.u32 	[%rd69+8], %r64;
	st.global.u32 	[%rd69+12], %r64;
	add.s32 	%r107, %r107, 4;
	add.s64 	%rd69, %rd69, 16;
	add.s32 	%r106, %r106, -4;
	setp.ne.s32 	%p23, %r106, 0;
	@%p23 bra 	$L__BB0_14;

$L__BB0_15:
	setp.eq.s32 	%p24, %r108, 0;
	@%p24 bra 	$L__BB0_18;

	add.s32 	%r65, %r107, %r4;
	mul.wide.s32 	%rd52, %r65, 4;
	add.s64 	%rd70, %rd2, %rd52;

$L__BB0_17:
	.pragma "nounroll";
	mov.u32 	%r66, 2143289344;
	st.global.u32 	[%rd70], %r66;
	add.s64 	%rd70, %rd70, 4;
	add.s32 	%r108, %r108, -1;
	setp.ne.s32 	%p25, %r108, 0;
	@%p25 bra 	$L__BB0_17;

$L__BB0_18:
	bar.sync 	0;
	setp.le.s32 	%p26, %r52, %r116;
	setp.lt.s32 	%p27, %r116, 0;
	or.pred  	%p28, %p27, %p26;
	@%p28 bra 	$L__BB0_66;

	setp.eq.s16 	%p30, %rs1, 0;
	sub.s32 	%r67, %r52, %r116;
	setp.lt.s32 	%p31, %r67, %r2;
	and.pred  	%p1, %p31, %p30;
	not.pred 	%p32, %p1;
	or.pred  	%p33, %p3, %p32;
	setp.lt.s32 	%p34, %r52, 1;
	or.pred  	%p35, %p33, %p34;
	@%p35 bra 	$L__BB0_26;

	add.s32 	%r69, %r52, -1;
	and.b32  	%r112, %r52, 3;
	setp.lt.u32 	%p36, %r69, 3;
	mov.u32 	%r111, 0;
	@%p36 bra 	$L__BB0_23;

	sub.s32 	%r110, %r52, %r112;
	mul.wide.s32 	%rd53, %r4, 4;
	add.s64 	%rd71, %rd2, %rd53;
	mov.u32 	%r111, 0;

$L__BB0_22:
	mov.u32 	%r71, 2143289344;
	st.global.u32 	[%rd71], %r71;
	st.global.u32 	[%rd71+4], %r71;
	st.global.u32 	[%rd71+8], %r71;
	st.global.u32 	[%rd71+12], %r71;
	add.s32 	%r111, %r111, 4;
	add.s64 	%rd71, %rd71, 16;
	add.s32 	%r110, %r110, -4;
	setp.ne.s32 	%p37, %r110, 0;
	@%p37 bra 	$L__BB0_22;

$L__BB0_23:
	setp.eq.s32 	%p38, %r112, 0;
	@%p38 bra 	$L__BB0_26;

	add.s32 	%r72, %r111, %r4;
	mul.wide.s32 	%rd54, %r72, 4;
	add.s64 	%rd72, %rd2, %rd54;

$L__BB0_25:
	.pragma "nounroll";
	mov.u32 	%r73, 2143289344;
	st.global.u32 	[%rd72], %r73;
	add.s64 	%rd72, %rd72, 4;
	add.s32 	%r112, %r112, -1;
	setp.ne.s32 	%p39, %r112, 0;
	@%p39 bra 	$L__BB0_25;

$L__BB0_26:
	bar.sync 	0;
	@%p1 bra 	$L__BB0_66;

	setp.ne.s16 	%p40, %rs1, 0;
	add.s32 	%r33, %r2, %r116;
	add.s32 	%r74, %r33, -1;
	selp.b32 	%r34, %r116, %r74, %p40;
	setp.lt.s32 	%p41, %r34, %r52;
	@%p41 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_28;

$L__BB0_32:
	setp.ge.s32 	%p44, %r113, %r34;
	@%p44 bra 	$L__BB0_35;

	mov.u32 	%r38, %ntid.x;

$L__BB0_34:
	add.s32 	%r77, %r113, %r4;
	mul.wide.s32 	%rd57, %r77, 4;
	add.s64 	%rd58, %rd2, %rd57;
	mov.u32 	%r78, 2143289344;
	st.global.u32 	[%rd58], %r78;
	add.s32 	%r113, %r113, %r38;
	setp.lt.s32 	%p45, %r113, %r34;
	@%p45 bra 	$L__BB0_34;

$L__BB0_35:
	bar.sync 	0;
	@%p3 bra 	$L__BB0_66;

	cvt.rn.f64.s32 	%fd37, %r2;
	add.f64 	%fd38, %fd37, 0d3FF0000000000000;
	mov.f64 	%fd39, 0d3FF0000000000000;
	mov.f64 	%fd40, 0d4000000000000000;
	div.rn.f64 	%fd1, %fd40, %fd38;
	sub.f64 	%fd2, %fd39, %fd1;
	min.s32 	%r79, %r33, %r52;
	selp.b32 	%r41, %r116, %r79, %p40;
	cvt.rn.f64.s32 	%fd41, %r3;
	add.f64 	%fd3, %fd41, 0d3FF0000000000000;
	neg.f64 	%fd4, %fd3;
	mul.f64 	%fd5, %fd41, 0dBFB999999999999A;
	neg.s32 	%r42, %r3;
	mul.f64 	%fd6, %fd41, 0d3FB999999999999A;
	@%p40 bra 	$L__BB0_54;
	bra.uni 	$L__BB0_37;

$L__BB0_54:
	add.s32 	%r92, %r116, %r4;
	mul.wide.s32 	%rd63, %r92, 4;
	add.s64 	%rd76, %rd2, %rd63;
	mul.wide.s32 	%rd64, %r116, 4;
	add.s64 	%rd75, %rd1, %rd64;
	mov.f64 	%fd76, 0d0000000000000000;
	mov.u16 	%rs21, 0;
	mov.f64 	%fd118, %fd76;
	mov.f64 	%fd116, %fd76;

$L__BB0_55:
	ld.global.nc.f32 	%f4, [%rd75];
	cvt.ftz.f64.f32 	%fd77, %f4;
	abs.f64 	%fd78, %fd77;
	setp.geu.f64 	%p70, %fd78, 0d7FF0000000000000;
	mul.f64 	%fd79, %fd1, %fd77;
	fma.rn.f64 	%fd80, %fd2, %fd116, %fd79;
	selp.f64 	%fd116, %fd116, %fd80, %p70;
	setp.lt.s32 	%p71, %r116, %r34;
	@%p71 bra 	$L__BB0_65;

	setp.gt.s32 	%p72, %r116, 0;
	setp.ne.s16 	%p73, %rs2, 0;
	and.pred  	%p74, %p73, %p72;
	selp.s32 	%r93, -1, 0, %p74;
	mul.wide.s32 	%rd65, %r93, 4;
	add.s64 	%rd66, %rd75, %rd65;
	ld.global.nc.f32 	%f5, [%rd66];
	cvt.ftz.f64.f32 	%fd28, %f5;
	and.b16  	%rs16, %rs21, 255;
	setp.eq.s16 	%p75, %rs16, 0;
	selp.f64 	%fd29, 0d0000000000000000, %fd118, %p75;
	abs.f64 	%fd82, %fd1;
	setp.geu.f64 	%p76, %fd82, 0d7FF0000000000000;
	mov.f64 	%fd117, %fd76;
	@%p76 bra 	$L__BB0_64;

	abs.f64 	%fd84, %fd116;
	setp.geu.f64 	%p77, %fd84, 0d7FF0000000000000;
	mov.f64 	%fd117, %fd76;
	@%p77 bra 	$L__BB0_64;

	abs.f64 	%fd86, %fd29;
	setp.geu.f64 	%p78, %fd86, 0d7FF0000000000000;
	mov.f64 	%fd117, %fd76;
	@%p78 bra 	$L__BB0_64;

	abs.f64 	%fd88, %fd28;
	setp.geu.f64 	%p79, %fd88, 0d7FF0000000000000;
	mov.f64 	%fd117, %fd76;
	@%p79 bra 	$L__BB0_64;

	mul.f64 	%fd89, %fd2, %fd29;
	fma.rn.f64 	%fd90, %fd1, %fd116, %fd89;
	sub.f64 	%fd30, %fd28, %fd90;
	sub.f64 	%fd91, %fd28, %fd29;
	mul.f64 	%fd92, %fd1, %fd91;
	mul.f64 	%fd31, %fd92, 0d3FB999999999999A;
	abs.f64 	%fd93, %fd31;
	setp.geu.f64 	%p80, %fd93, 0d7FF0000000000000;
	setp.le.f64 	%p81, %fd93, 0d0010000000000000;
	or.pred  	%p82, %p80, %p81;
	mov.f64 	%fd117, %fd5;
	@%p82 bra 	$L__BB0_64;

	div.rn.f64 	%fd32, %fd30, %fd31;
	setp.le.f64 	%p83, %fd32, %fd4;
	mov.f64 	%fd117, %fd5;
	@%p83 bra 	$L__BB0_64;

	setp.ge.f64 	%p84, %fd32, %fd3;
	mov.f64 	%fd117, %fd6;
	@%p84 bra 	$L__BB0_64;

	cvt.rmi.s32.f64 	%r94, %fd32;
	add.s32 	%r95, %r94, 1;
	setp.lt.s32 	%p85, %r94, %r42;
	min.s32 	%r96, %r94, %r3;
	selp.b32 	%r97, %r42, %r96, %p85;
	setp.lt.s32 	%p86, %r95, %r42;
	min.s32 	%r98, %r95, %r3;
	selp.b32 	%r99, %r42, %r98, %p86;
	cvt.rn.f64.s32 	%fd94, %r97;
	mul.f64 	%fd95, %fd31, %fd94;
	sub.f64 	%fd96, %fd30, %fd95;
	abs.f64 	%fd97, %fd96;
	cvt.rn.f64.s32 	%fd98, %r99;
	mul.f64 	%fd99, %fd31, %fd98;
	sub.f64 	%fd100, %fd30, %fd99;
	abs.f64 	%fd101, %fd100;
	setp.lt.f64 	%p87, %fd101, %fd97;
	selp.b32 	%r100, %r99, %r97, %p87;
	cvt.rn.f64.s32 	%fd102, %r100;
	mul.f64 	%fd117, %fd102, 0d3FB999999999999A;

$L__BB0_64:
	sub.f64 	%fd103, %fd28, %fd29;
	fma.rn.f64 	%fd104, %fd103, %fd117, %fd116;
	mul.f64 	%fd105, %fd1, %fd104;
	fma.rn.f64 	%fd118, %fd2, %fd29, %fd105;
	cvt.rn.ftz.f32.f64 	%f6, %fd118;
	st.global.f32 	[%rd76], %f6;
	mov.u16 	%rs21, 1;

$L__BB0_65:
	add.s64 	%rd76, %rd76, 4;
	add.s64 	%rd75, %rd75, 4;
	add.s32 	%r116, %r116, 1;
	setp.lt.s32 	%p88, %r116, %r52;
	@%p88 bra 	$L__BB0_55;
	bra.uni 	$L__BB0_66;

$L__BB0_28:
	setp.ge.s32 	%p42, %r113, %r52;
	@%p42 bra 	$L__BB0_31;

	mov.u32 	%r35, %ntid.x;

$L__BB0_30:
	add.s32 	%r75, %r113, %r4;
	mul.wide.s32 	%rd55, %r75, 4;
	add.s64 	%rd56, %rd2, %rd55;
	mov.u32 	%r76, 2143289344;
	st.global.u32 	[%rd56], %r76;
	add.s32 	%r113, %r113, %r35;
	setp.lt.s32 	%p43, %r113, %r52;
	@%p43 bra 	$L__BB0_30;

$L__BB0_31:
	bar.sync 	0;

$L__BB0_66:
	ret;

$L__BB0_37:
	mul.wide.s32 	%rd59, %r116, 4;
	add.s64 	%rd74, %rd1, %rd59;
	add.s32 	%r82, %r116, %r4;
	mul.wide.s32 	%rd60, %r82, 4;
	add.s64 	%rd73, %rd2, %rd60;
	mov.f64 	%fd114, 0d0000000000000000;
	mov.u32 	%r115, 0;
	mov.u16 	%rs19, 0;
	mov.u32 	%r117, %r115;
	mov.f64 	%fd109, %fd114;
	mov.f64 	%fd110, %fd114;

$L__BB0_38:
	ld.global.nc.f32 	%f1, [%rd74];
	cvt.ftz.f64.f32 	%fd10, %f1;
	setp.eq.s32 	%p48, %r115, 0;
	mov.u32 	%r118, 1;
	mov.f64 	%fd111, %fd10;
	mov.f64 	%fd112, %fd10;
	@%p48 bra 	$L__BB0_43;

	setp.lt.s32 	%p49, %r116, %r41;
	abs.f64 	%fd11, %fd10;
	@%p49 bra 	$L__BB0_41;
	bra.uni 	$L__BB0_40;

$L__BB0_41:
	setp.geu.f64 	%p51, %fd11, 0d7FF0000000000000;
	mov.f64 	%fd111, %fd109;
	mov.f64 	%fd112, %fd109;
	mov.u32 	%r118, %r117;
	@%p51 bra 	$L__BB0_43;

	add.s32 	%r118, %r117, 1;
	cvt.rn.f64.s32 	%fd47, %r118;
	add.f64 	%fd48, %fd47, 0dBFF0000000000000;
	fma.rn.f64 	%fd49, %fd109, %fd48, %fd10;
	div.rn.f64 	%fd111, %fd49, %fd47;
	mov.f64 	%fd112, %fd111;
	bra.uni 	$L__BB0_43;

$L__BB0_40:
	setp.geu.f64 	%p50, %fd11, 0d7FF0000000000000;
	mul.f64 	%fd45, %fd1, %fd10;
	fma.rn.f64 	%fd46, %fd2, %fd110, %fd45;
	selp.f64 	%fd111, %fd110, %fd46, %p50;
	mov.f64 	%fd112, %fd109;
	mov.u32 	%r118, %r117;

$L__BB0_43:
	setp.lt.s32 	%p52, %r116, %r34;
	mov.f64 	%fd113, 0d0000000000000000;
	@%p52 bra 	$L__BB0_53;

	setp.gt.s32 	%p53, %r116, 0;
	setp.ne.s16 	%p54, %rs2, 0;
	and.pred  	%p55, %p54, %p53;
	selp.s32 	%r84, -1, 0, %p55;
	mul.wide.s32 	%rd61, %r84, 4;
	add.s64 	%rd62, %rd74, %rd61;
	ld.global.nc.f32 	%f2, [%rd62];
	cvt.ftz.f64.f32 	%fd16, %f2;
	and.b16  	%rs12, %rs19, 255;
	setp.eq.s16 	%p56, %rs12, 0;
	selp.f64 	%fd17, %fd111, %fd114, %p56;
	abs.f64 	%fd51, %fd1;
	setp.geu.f64 	%p57, %fd51, 0d7FF0000000000000;
	@%p57 bra 	$L__BB0_52;

	abs.f64 	%fd53, %fd111;
	setp.geu.f64 	%p58, %fd53, 0d7FF0000000000000;
	@%p58 bra 	$L__BB0_52;

	abs.f64 	%fd55, %fd17;
	setp.geu.f64 	%p59, %fd55, 0d7FF0000000000000;
	@%p59 bra 	$L__BB0_52;

	abs.f64 	%fd57, %fd16;
	setp.geu.f64 	%p60, %fd57, 0d7FF0000000000000;
	@%p60 bra 	$L__BB0_52;

	mul.f64 	%fd58, %fd2, %fd17;
	fma.rn.f64 	%fd59, %fd1, %fd111, %fd58;
	sub.f64 	%fd18, %fd16, %fd59;
	sub.f64 	%fd60, %fd16, %fd17;
	mul.f64 	%fd61, %fd1, %fd60;
	mul.f64 	%fd19, %fd61, 0d3FB999999999999A;
	abs.f64 	%fd62, %fd19;
	setp.geu.f64 	%p61, %fd62, 0d7FF0000000000000;
	setp.le.f64 	%p62, %fd62, 0d0010000000000000;
	or.pred  	%p63, %p61, %p62;
	mov.f64 	%fd113, %fd5;
	@%p63 bra 	$L__BB0_52;

	div.rn.f64 	%fd20, %fd18, %fd19;
	setp.le.f64 	%p64, %fd20, %fd4;
	mov.f64 	%fd113, %fd5;
	@%p64 bra 	$L__BB0_52;

	setp.ge.f64 	%p65, %fd20, %fd3;
	mov.f64 	%fd113, %fd6;
	@%p65 bra 	$L__BB0_52;

	cvt.rmi.s32.f64 	%r85, %fd20;
	add.s32 	%r86, %r85, 1;
	setp.lt.s32 	%p66, %r85, %r42;
	min.s32 	%r87, %r85, %r3;
	selp.b32 	%r88, %r42, %r87, %p66;
	setp.lt.s32 	%p67, %r86, %r42;
	min.s32 	%r89, %r86, %r3;
	selp.b32 	%r90, %r42, %r89, %p67;
	cvt.rn.f64.s32 	%fd63, %r88;
	mul.f64 	%fd64, %fd19, %fd63;
	sub.f64 	%fd65, %fd18, %fd64;
	abs.f64 	%fd66, %fd65;
	cvt.rn.f64.s32 	%fd67, %r90;
	mul.f64 	%fd68, %fd19, %fd67;
	sub.f64 	%fd69, %fd18, %fd68;
	abs.f64 	%fd70, %fd69;
	setp.lt.f64 	%p68, %fd70, %fd66;
	selp.b32 	%r91, %r90, %r88, %p68;
	cvt.rn.f64.s32 	%fd71, %r91;
	mul.f64 	%fd113, %fd71, 0d3FB999999999999A;

$L__BB0_52:
	sub.f64 	%fd72, %fd16, %fd17;
	fma.rn.f64 	%fd73, %fd72, %fd113, %fd111;
	mul.f64 	%fd74, %fd1, %fd73;
	fma.rn.f64 	%fd114, %fd2, %fd17, %fd74;
	cvt.rn.ftz.f32.f64 	%f3, %fd114;
	st.global.f32 	[%rd73], %f3;
	mov.u16 	%rs19, 1;

$L__BB0_53:
	add.s32 	%r115, %r115, 1;
	add.s64 	%rd74, %rd74, 4;
	add.s64 	%rd73, %rd73, 4;
	add.s32 	%r116, %r116, 1;
	setp.lt.s32 	%p69, %r116, %r52;
	mov.u32 	%r117, %r118;
	mov.f64 	%fd109, %fd112;
	mov.f64 	%fd110, %fd111;
	@%p69 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_66;

}

.visible .entry ehlers_ecema_batch_thread_per_combo_f32(
	.param .u64 ehlers_ecema_batch_thread_per_combo_f32_param_0,
	.param .u64 ehlers_ecema_batch_thread_per_combo_f32_param_1,
	.param .u64 ehlers_ecema_batch_thread_per_combo_f32_param_2,
	.param .u64 ehlers_ecema_batch_thread_per_combo_f32_param_3,
	.param .u64 ehlers_ecema_batch_thread_per_combo_f32_param_4,
	.param .u32 ehlers_ecema_batch_thread_per_combo_f32_param_5,
	.param .u32 ehlers_ecema_batch_thread_per_combo_f32_param_6,
	.param .u32 ehlers_ecema_batch_thread_per_combo_f32_param_7,
	.param .u64 ehlers_ecema_batch_thread_per_combo_f32_param_8
)
{
	.reg .pred 	%p<50>;
	.reg .b16 	%rs<16>;
	.reg .f32 	%f<88>;
	.reg .b32 	%r<74>;
	.reg .f64 	%fd<34>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd15, [ehlers_ecema_batch_thread_per_combo_f32_param_0];
	ld.param.u64 	%rd16, [ehlers_ecema_batch_thread_per_combo_f32_param_1];
	ld.param.u64 	%rd17, [ehlers_ecema_batch_thread_per_combo_f32_param_2];
	ld.param.u64 	%rd18, [ehlers_ecema_batch_thread_per_combo_f32_param_3];
	ld.param.u64 	%rd19, [ehlers_ecema_batch_thread_per_combo_f32_param_4];
	ld.param.u32 	%r31, [ehlers_ecema_batch_thread_per_combo_f32_param_5];
	ld.param.u32 	%r33, [ehlers_ecema_batch_thread_per_combo_f32_param_6];
	ld.param.u32 	%r73, [ehlers_ecema_batch_thread_per_combo_f32_param_7];
	ld.param.u64 	%rd20, [ehlers_ecema_batch_thread_per_combo_f32_param_8];
	cvta.to.global.u64 	%rd1, %rd20;
	mov.u32 	%r34, %ntid.x;
	mov.u32 	%r35, %ctaid.x;
	mov.u32 	%r36, %tid.x;
	mad.lo.s32 	%r1, %r35, %r34, %r36;
	setp.ge.s32 	%p1, %r1, %r33;
	@%p1 bra 	$L__BB1_39;

	cvta.to.global.u64 	%rd21, %rd16;
	cvt.s64.s32 	%rd2, %r1;
	mul.wide.s32 	%rd22, %r1, 4;
	add.s64 	%rd23, %rd21, %rd22;
	cvta.to.global.u64 	%rd24, %rd17;
	add.s64 	%rd25, %rd24, %rd22;
	cvta.to.global.u64 	%rd26, %rd18;
	add.s64 	%rd27, %rd26, %rd2;
	ld.global.nc.u8 	%rs1, [%rd27];
	ld.global.nc.u32 	%r2, [%rd23];
	setp.lt.s32 	%p2, %r2, 1;
	setp.lt.s32 	%p3, %r31, 1;
	or.pred  	%p4, %p3, %p2;
	ld.global.nc.u32 	%r3, [%rd25];
	setp.lt.s32 	%p5, %r3, 1;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB1_39;

	setp.lt.s32 	%p7, %r73, 0;
	setp.le.s32 	%p8, %r31, %r73;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB1_39;

	setp.eq.s16 	%p10, %rs1, 0;
	sub.s32 	%r37, %r31, %r73;
	setp.lt.s32 	%p11, %r37, %r2;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB1_39;

	setp.ne.s16 	%p13, %rs1, 0;
	mul.lo.s32 	%r4, %r1, %r31;
	add.s32 	%r5, %r2, %r73;
	add.s32 	%r38, %r5, -1;
	selp.b32 	%r6, %r73, %r38, %p13;
	setp.lt.s32 	%p14, %r6, %r31;
	@%p14 bra 	$L__BB1_11;
	bra.uni 	$L__BB1_5;

$L__BB1_11:
	cvta.to.global.u64 	%rd31, %rd19;
	add.s64 	%rd32, %rd31, %rd2;
	ld.global.nc.u8 	%rs2, [%rd32];
	setp.lt.s32 	%p19, %r6, 1;
	@%p19 bra 	$L__BB1_18;

	add.s32 	%r47, %r6, -1;
	and.b32  	%r71, %r6, 3;
	setp.lt.u32 	%p20, %r47, 3;
	mov.u32 	%r70, 0;
	@%p20 bra 	$L__BB1_15;

	sub.s32 	%r69, %r6, %r71;
	mov.u32 	%r70, 0;

$L__BB1_14:
	add.s32 	%r49, %r70, %r4;
	mul.wide.s32 	%rd33, %r49, 4;
	add.s64 	%rd34, %rd1, %rd33;
	mov.u32 	%r50, 2143289344;
	st.global.u32 	[%rd34], %r50;
	st.global.u32 	[%rd34+4], %r50;
	st.global.u32 	[%rd34+8], %r50;
	st.global.u32 	[%rd34+12], %r50;
	add.s32 	%r70, %r70, 4;
	add.s32 	%r69, %r69, -4;
	setp.ne.s32 	%p21, %r69, 0;
	@%p21 bra 	$L__BB1_14;

$L__BB1_15:
	setp.eq.s32 	%p22, %r71, 0;
	@%p22 bra 	$L__BB1_18;

	add.s32 	%r51, %r70, %r4;
	mul.wide.s32 	%rd35, %r51, 4;
	add.s64 	%rd42, %rd1, %rd35;

$L__BB1_17:
	.pragma "nounroll";
	mov.u32 	%r52, 2143289344;
	st.global.u32 	[%rd42], %r52;
	add.s64 	%rd42, %rd42, 4;
	add.s32 	%r71, %r71, -1;
	setp.ne.s32 	%p23, %r71, 0;
	@%p23 bra 	$L__BB1_17;

$L__BB1_18:
	mov.u16 	%rs15, 0;
	cvt.rn.f32.s32 	%f37, %r2;
	add.ftz.f32 	%f38, %f37, 0f3F800000;
	mov.f32 	%f39, 0f40000000;
	div.approx.ftz.f32 	%f1, %f39, %f38;
	min.s32 	%r54, %r5, %r31;
	selp.b32 	%r25, %r73, %r54, %p13;
	cvt.ftz.f64.f32 	%fd1, %f1;
	mov.f64 	%fd11, 0d3FF0000000000000;
	sub.f64 	%fd2, %fd11, %fd1;
	cvt.rn.f64.s32 	%fd12, %r3;
	add.f64 	%fd3, %fd12, 0d3FF0000000000000;
	neg.f64 	%fd4, %fd3;
	mul.f64 	%fd13, %fd12, 0dBFB999999999999A;
	cvt.rn.ftz.f32.f64 	%f2, %fd13;
	neg.s32 	%r26, %r3;
	mul.f64 	%fd14, %fd12, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f3, %fd14;
	cvta.to.global.u64 	%rd36, %rd15;
	mul.wide.s32 	%rd37, %r73, 4;
	add.s64 	%rd44, %rd36, %rd37;
	add.s32 	%r55, %r73, %r4;
	mul.wide.s32 	%rd38, %r55, 4;
	add.s64 	%rd43, %rd1, %rd38;
	mov.f32 	%f36, 0f00000000;
	mov.u32 	%r72, 1;
	mov.f32 	%f87, %f36;
	mov.f32 	%f86, %f36;
	mov.f32 	%f6, %f36;
	mov.f32 	%f7, %f36;
	mov.f32 	%f79, %f36;
	mov.f32 	%f80, %f36;

$L__BB1_19:
	ld.global.nc.f32 	%f10, [%rd44];
	@%p13 bra 	$L__BB1_26;
	bra.uni 	$L__BB1_20;

$L__BB1_26:
	abs.ftz.f32 	%f55, %f10;
	setp.geu.ftz.f32 	%p30, %f55, 0f7F800000;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f79;
	mov.f32 	%f83, %f7;
	mov.f32 	%f84, %f6;
	@%p30 bra 	$L__BB1_28;

	sub.ftz.f32 	%f56, %f10, %f79;
	mov.f32 	%f57, 0f00000000;
	fma.rn.ftz.f32 	%f58, %f1, %f56, %f57;
	sub.ftz.f32 	%f59, %f58, %f80;
	add.ftz.f32 	%f82, %f79, %f59;
	sub.ftz.f32 	%f60, %f82, %f79;
	sub.ftz.f32 	%f81, %f60, %f59;
	mov.f32 	%f83, %f7;
	mov.f32 	%f84, %f6;
	bra.uni 	$L__BB1_28;

$L__BB1_20:
	setp.eq.s32 	%p26, %r72, 1;
	mov.f32 	%f83, 0f00000000;
	mov.f32 	%f81, %f36;
	mov.f32 	%f82, %f10;
	mov.f32 	%f84, %f10;
	@%p26 bra 	$L__BB1_28;

	setp.lt.s32 	%p27, %r73, %r25;
	abs.ftz.f32 	%f11, %f10;
	@%p27 bra 	$L__BB1_24;
	bra.uni 	$L__BB1_22;

$L__BB1_24:
	setp.geu.ftz.f32 	%p29, %f11, 0f7F800000;
	mov.f32 	%f81, %f36;
	mov.f32 	%f82, %f6;
	mov.f32 	%f83, %f7;
	mov.f32 	%f84, %f6;
	@%p29 bra 	$L__BB1_28;

	cvt.rn.f32.s32 	%f49, %r72;
	rcp.approx.ftz.f32 	%f50, %f49;
	sub.ftz.f32 	%f51, %f10, %f6;
	mul.ftz.f32 	%f52, %f50, %f51;
	sub.ftz.f32 	%f53, %f52, %f7;
	add.ftz.f32 	%f82, %f6, %f53;
	sub.ftz.f32 	%f54, %f82, %f6;
	sub.ftz.f32 	%f83, %f54, %f53;
	mov.f32 	%f81, %f36;
	mov.f32 	%f84, %f82;
	bra.uni 	$L__BB1_28;

$L__BB1_22:
	setp.geu.ftz.f32 	%p28, %f11, 0f7F800000;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f79;
	mov.f32 	%f83, %f7;
	mov.f32 	%f84, %f6;
	@%p28 bra 	$L__BB1_28;

	sub.ftz.f32 	%f42, %f10, %f79;
	mov.f32 	%f43, 0f00000000;
	fma.rn.ftz.f32 	%f44, %f1, %f42, %f43;
	sub.ftz.f32 	%f45, %f44, %f80;
	add.ftz.f32 	%f82, %f79, %f45;
	sub.ftz.f32 	%f46, %f82, %f79;
	sub.ftz.f32 	%f81, %f46, %f45;
	mov.f32 	%f83, %f7;
	mov.f32 	%f84, %f6;

$L__BB1_28:
	setp.lt.s32 	%p31, %r73, %r6;
	mov.f32 	%f85, 0f00000000;
	@%p31 bra 	$L__BB1_38;

	setp.gt.s32 	%p32, %r73, 0;
	setp.ne.s16 	%p33, %rs2, 0;
	and.pred  	%p34, %p33, %p32;
	selp.s32 	%r56, -1, 0, %p34;
	mul.wide.s32 	%rd39, %r56, 4;
	add.s64 	%rd40, %rd44, %rd39;
	selp.f32 	%f62, 0f00000000, %f82, %p13;
	and.b16  	%rs13, %rs15, 255;
	setp.eq.s16 	%p36, %rs13, 0;
	selp.f32 	%f22, %f62, %f87, %p36;
	selp.f32 	%f23, 0f00000000, %f86, %p36;
	selp.b16 	%rs15, 1, %rs15, %p36;
	cvt.ftz.f64.f32 	%fd5, %f82;
	cvt.ftz.f64.f32 	%fd6, %f22;
	ld.global.nc.f32 	%f24, [%rd40];
	cvt.ftz.f64.f32 	%fd7, %f24;
	abs.f64 	%fd15, %fd1;
	setp.geu.f64 	%p37, %fd15, 0d7FF0000000000000;
	@%p37 bra 	$L__BB1_37;

	abs.f64 	%fd16, %fd5;
	setp.geu.f64 	%p38, %fd16, 0d7FF0000000000000;
	@%p38 bra 	$L__BB1_37;

	abs.f64 	%fd17, %fd6;
	setp.geu.f64 	%p39, %fd17, 0d7FF0000000000000;
	@%p39 bra 	$L__BB1_37;

	abs.f64 	%fd18, %fd7;
	setp.geu.f64 	%p40, %fd18, 0d7FF0000000000000;
	@%p40 bra 	$L__BB1_37;

	mul.f64 	%fd19, %fd2, %fd6;
	fma.rn.f64 	%fd20, %fd1, %fd5, %fd19;
	sub.f64 	%fd8, %fd7, %fd20;
	sub.f64 	%fd21, %fd7, %fd6;
	mul.f64 	%fd22, %fd21, %fd1;
	mul.f64 	%fd9, %fd22, 0d3FB999999999999A;
	abs.f64 	%fd23, %fd9;
	setp.geu.f64 	%p41, %fd23, 0d7FF0000000000000;
	setp.le.f64 	%p42, %fd23, 0d0010000000000000;
	or.pred  	%p43, %p41, %p42;
	mov.f32 	%f85, %f2;
	@%p43 bra 	$L__BB1_37;

	div.rn.f64 	%fd10, %fd8, %fd9;
	setp.le.f64 	%p44, %fd10, %fd4;
	mov.f32 	%f85, %f2;
	@%p44 bra 	$L__BB1_37;

	setp.ge.f64 	%p45, %fd10, %fd3;
	mov.f32 	%f85, %f3;
	@%p45 bra 	$L__BB1_37;

	cvt.rmi.s32.f64 	%r57, %fd10;
	add.s32 	%r58, %r57, 1;
	setp.lt.s32 	%p46, %r57, %r26;
	min.s32 	%r59, %r57, %r3;
	selp.b32 	%r60, %r26, %r59, %p46;
	setp.lt.s32 	%p47, %r58, %r26;
	min.s32 	%r61, %r58, %r3;
	selp.b32 	%r62, %r26, %r61, %p47;
	cvt.rn.f64.s32 	%fd24, %r60;
	mul.f64 	%fd25, %fd9, %fd24;
	sub.f64 	%fd26, %fd8, %fd25;
	abs.f64 	%fd27, %fd26;
	cvt.rn.f64.s32 	%fd28, %r62;
	mul.f64 	%fd29, %fd9, %fd28;
	sub.f64 	%fd30, %fd8, %fd29;
	abs.f64 	%fd31, %fd30;
	setp.lt.f64 	%p48, %fd31, %fd27;
	selp.b32 	%r63, %r62, %r60, %p48;
	cvt.rn.f64.s32 	%fd32, %r63;
	mul.f64 	%fd33, %fd32, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f85, %fd33;

$L__BB1_37:
	sub.ftz.f32 	%f66, %f24, %f22;
	sub.ftz.f32 	%f67, %f82, %f22;
	fma.rn.ftz.f32 	%f68, %f66, %f85, %f67;
	mov.f32 	%f69, 0f00000000;
	fma.rn.ftz.f32 	%f70, %f1, %f68, %f69;
	sub.ftz.f32 	%f71, %f70, %f23;
	add.ftz.f32 	%f87, %f22, %f71;
	sub.ftz.f32 	%f72, %f87, %f22;
	sub.ftz.f32 	%f86, %f72, %f71;
	st.global.f32 	[%rd43], %f87;

$L__BB1_38:
	add.s32 	%r72, %r72, 1;
	add.s64 	%rd44, %rd44, 4;
	add.s64 	%rd43, %rd43, 4;
	add.s32 	%r73, %r73, 1;
	setp.lt.s32 	%p49, %r73, %r31;
	mov.f32 	%f6, %f84;
	mov.f32 	%f7, %f83;
	mov.f32 	%f79, %f82;
	mov.f32 	%f80, %f81;
	@%p49 bra 	$L__BB1_19;
	bra.uni 	$L__BB1_39;

$L__BB1_5:
	add.s32 	%r40, %r31, -1;
	and.b32  	%r67, %r31, 3;
	setp.lt.u32 	%p15, %r40, 3;
	mov.u32 	%r66, 0;
	@%p15 bra 	$L__BB1_8;

	sub.s32 	%r65, %r31, %r67;
	mov.u32 	%r66, 0;

$L__BB1_7:
	add.s32 	%r42, %r66, %r4;
	mul.wide.s32 	%rd28, %r42, 4;
	add.s64 	%rd29, %rd1, %rd28;
	mov.u32 	%r43, 2143289344;
	st.global.u32 	[%rd29], %r43;
	st.global.u32 	[%rd29+4], %r43;
	st.global.u32 	[%rd29+8], %r43;
	st.global.u32 	[%rd29+12], %r43;
	add.s32 	%r66, %r66, 4;
	add.s32 	%r65, %r65, -4;
	setp.ne.s32 	%p16, %r65, 0;
	@%p16 bra 	$L__BB1_7;

$L__BB1_8:
	setp.eq.s32 	%p17, %r67, 0;
	@%p17 bra 	$L__BB1_39;

	add.s32 	%r44, %r66, %r4;
	mul.wide.s32 	%rd30, %r44, 4;
	add.s64 	%rd41, %rd1, %rd30;

$L__BB1_10:
	.pragma "nounroll";
	mov.u32 	%r45, 2143289344;
	st.global.u32 	[%rd41], %r45;
	add.s64 	%rd41, %rd41, 4;
	add.s32 	%r67, %r67, -1;
	setp.eq.s32 	%p18, %r67, 0;
	@%p18 bra 	$L__BB1_39;
	bra.uni 	$L__BB1_10;

$L__BB1_39:
	ret;

}

.visible .entry ehlers_ecema_many_series_one_param_time_major_f32(
	.param .u64 ehlers_ecema_many_series_one_param_time_major_f32_param_0,
	.param .u32 ehlers_ecema_many_series_one_param_time_major_f32_param_1,
	.param .u32 ehlers_ecema_many_series_one_param_time_major_f32_param_2,
	.param .u32 ehlers_ecema_many_series_one_param_time_major_f32_param_3,
	.param .u32 ehlers_ecema_many_series_one_param_time_major_f32_param_4,
	.param .u8 ehlers_ecema_many_series_one_param_time_major_f32_param_5,
	.param .u8 ehlers_ecema_many_series_one_param_time_major_f32_param_6,
	.param .u64 ehlers_ecema_many_series_one_param_time_major_f32_param_7,
	.param .u64 ehlers_ecema_many_series_one_param_time_major_f32_param_8
)
{
	.reg .pred 	%p<89>;
	.reg .b16 	%rs<17>;
	.reg .f32 	%f<127>;
	.reg .b32 	%r<119>;
	.reg .f64 	%fd<60>;
	.reg .b64 	%rd<73>;


	ld.param.u8 	%rs8, [ehlers_ecema_many_series_one_param_time_major_f32_param_6];
	ld.param.u8 	%rs7, [ehlers_ecema_many_series_one_param_time_major_f32_param_5];
	ld.param.u64 	%rd33, [ehlers_ecema_many_series_one_param_time_major_f32_param_0];
	ld.param.u32 	%r47, [ehlers_ecema_many_series_one_param_time_major_f32_param_1];
	ld.param.u32 	%r48, [ehlers_ecema_many_series_one_param_time_major_f32_param_2];
	ld.param.u32 	%r49, [ehlers_ecema_many_series_one_param_time_major_f32_param_3];
	ld.param.u32 	%r50, [ehlers_ecema_many_series_one_param_time_major_f32_param_4];
	ld.param.u64 	%rd32, [ehlers_ecema_many_series_one_param_time_major_f32_param_7];
	ld.param.u64 	%rd34, [ehlers_ecema_many_series_one_param_time_major_f32_param_8];
	cvta.to.global.u64 	%rd1, %rd33;
	cvta.to.global.u64 	%rd2, %rd34;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p2, %r1, %r47;
	@%p2 bra 	$L__BB2_69;

	mov.u32 	%r114, %tid.x;
	setp.ne.s32 	%p3, %r114, 0;
	@%p3 bra 	$L__BB2_9;

	setp.gt.s32 	%p4, %r49, 0;
	setp.gt.s32 	%p5, %r50, 0;
	and.pred  	%p6, %p4, %p5;
	setp.lt.s32 	%p7, %r48, 1;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB2_9;

	add.s32 	%r52, %r48, -1;
	and.b32  	%r105, %r48, 3;
	setp.lt.u32 	%p9, %r52, 3;
	mov.u32 	%r104, 0;
	@%p9 bra 	$L__BB2_6;

	sub.s32 	%r103, %r48, %r105;
	mul.wide.s32 	%rd3, %r47, 4;
	mov.u32 	%r104, 0;

$L__BB2_5:
	mad.lo.s32 	%r54, %r104, %r47, %r1;
	mul.wide.s32 	%rd35, %r54, 4;
	add.s64 	%rd36, %rd2, %rd35;
	mov.u32 	%r55, 2143289344;
	st.global.u32 	[%rd36], %r55;
	add.s64 	%rd37, %rd36, %rd3;
	st.global.u32 	[%rd37], %r55;
	add.s64 	%rd38, %rd37, %rd3;
	st.global.u32 	[%rd38], %r55;
	add.s64 	%rd39, %rd38, %rd3;
	st.global.u32 	[%rd39], %r55;
	add.s32 	%r104, %r104, 4;
	add.s32 	%r103, %r103, -4;
	setp.ne.s32 	%p10, %r103, 0;
	@%p10 bra 	$L__BB2_5;

$L__BB2_6:
	setp.eq.s32 	%p11, %r105, 0;
	@%p11 bra 	$L__BB2_9;

	mad.lo.s32 	%r56, %r104, %r47, %r1;
	mul.wide.s32 	%rd40, %r56, 4;
	add.s64 	%rd66, %rd2, %rd40;
	mul.wide.s32 	%rd5, %r47, 4;

$L__BB2_8:
	.pragma "nounroll";
	mov.u32 	%r57, 2143289344;
	st.global.u32 	[%rd66], %r57;
	add.s64 	%rd66, %rd66, %rd5;
	add.s32 	%r105, %r105, -1;
	setp.ne.s32 	%p12, %r105, 0;
	@%p12 bra 	$L__BB2_8;

$L__BB2_9:
	bar.sync 	0;
	setp.lt.s32 	%p13, %r50, 1;
	setp.lt.s32 	%p14, %r49, 1;
	or.pred  	%p15, %p14, %p13;
	@%p15 bra 	$L__BB2_69;

	cvta.to.global.u64 	%rd41, %rd32;
	mul.wide.s32 	%rd42, %r1, 4;
	add.s64 	%rd43, %rd41, %rd42;
	ld.global.nc.u32 	%r117, [%rd43];
	@%p3 bra 	$L__BB2_18;

	setp.gt.s32 	%p17, %r117, -1;
	setp.lt.s32 	%p18, %r117, %r48;
	and.pred  	%p19, %p17, %p18;
	setp.lt.s32 	%p20, %r48, 1;
	or.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB2_18;

	add.s32 	%r59, %r48, -1;
	and.b32  	%r109, %r48, 3;
	setp.lt.u32 	%p22, %r59, 3;
	mov.u32 	%r108, 0;
	@%p22 bra 	$L__BB2_15;

	sub.s32 	%r107, %r48, %r109;
	mul.wide.s32 	%rd8, %r47, 4;
	mov.u32 	%r108, 0;

$L__BB2_14:
	mad.lo.s32 	%r61, %r108, %r47, %r1;
	mul.wide.s32 	%rd44, %r61, 4;
	add.s64 	%rd45, %rd2, %rd44;
	mov.u32 	%r62, 2143289344;
	st.global.u32 	[%rd45], %r62;
	add.s64 	%rd46, %rd45, %rd8;
	st.global.u32 	[%rd46], %r62;
	add.s64 	%rd47, %rd46, %rd8;
	st.global.u32 	[%rd47], %r62;
	add.s64 	%rd48, %rd47, %rd8;
	st.global.u32 	[%rd48], %r62;
	add.s32 	%r108, %r108, 4;
	add.s32 	%r107, %r107, -4;
	setp.ne.s32 	%p23, %r107, 0;
	@%p23 bra 	$L__BB2_14;

$L__BB2_15:
	setp.eq.s32 	%p24, %r109, 0;
	@%p24 bra 	$L__BB2_18;

	mad.lo.s32 	%r63, %r108, %r47, %r1;
	mul.wide.s32 	%rd49, %r63, 4;
	add.s64 	%rd67, %rd2, %rd49;
	mul.wide.s32 	%rd10, %r47, 4;

$L__BB2_17:
	.pragma "nounroll";
	mov.u32 	%r64, 2143289344;
	st.global.u32 	[%rd67], %r64;
	add.s64 	%rd67, %rd67, %rd10;
	add.s32 	%r109, %r109, -1;
	setp.ne.s32 	%p25, %r109, 0;
	@%p25 bra 	$L__BB2_17;

$L__BB2_18:
	bar.sync 	0;
	setp.ge.s32 	%p26, %r117, %r48;
	setp.lt.s32 	%p27, %r117, 0;
	or.pred  	%p28, %p27, %p26;
	@%p28 bra 	$L__BB2_69;

	setp.eq.s16 	%p30, %rs7, 0;
	sub.s32 	%r65, %r48, %r117;
	setp.lt.s32 	%p31, %r65, %r49;
	and.pred  	%p1, %p31, %p30;
	not.pred 	%p32, %p1;
	or.pred  	%p33, %p3, %p32;
	setp.lt.s32 	%p34, %r48, 1;
	or.pred  	%p35, %p33, %p34;
	@%p35 bra 	$L__BB2_26;

	add.s32 	%r67, %r48, -1;
	and.b32  	%r113, %r48, 3;
	setp.lt.u32 	%p36, %r67, 3;
	mov.u32 	%r112, 0;
	@%p36 bra 	$L__BB2_23;

	sub.s32 	%r111, %r48, %r113;
	mul.wide.s32 	%rd13, %r47, 4;
	mov.u32 	%r112, 0;

$L__BB2_22:
	mad.lo.s32 	%r69, %r112, %r47, %r1;
	mul.wide.s32 	%rd50, %r69, 4;
	add.s64 	%rd51, %rd2, %rd50;
	mov.u32 	%r70, 2143289344;
	st.global.u32 	[%rd51], %r70;
	add.s64 	%rd52, %rd51, %rd13;
	st.global.u32 	[%rd52], %r70;
	add.s64 	%rd53, %rd52, %rd13;
	st.global.u32 	[%rd53], %r70;
	add.s64 	%rd54, %rd53, %rd13;
	st.global.u32 	[%rd54], %r70;
	add.s32 	%r112, %r112, 4;
	add.s32 	%r111, %r111, -4;
	setp.ne.s32 	%p37, %r111, 0;
	@%p37 bra 	$L__BB2_22;

$L__BB2_23:
	setp.eq.s32 	%p38, %r113, 0;
	@%p38 bra 	$L__BB2_26;

	mad.lo.s32 	%r71, %r112, %r47, %r1;
	mul.wide.s32 	%rd55, %r71, 4;
	add.s64 	%rd68, %rd2, %rd55;
	mul.wide.s32 	%rd15, %r47, 4;

$L__BB2_25:
	.pragma "nounroll";
	mov.u32 	%r72, 2143289344;
	st.global.u32 	[%rd68], %r72;
	add.s64 	%rd68, %rd68, %rd15;
	add.s32 	%r113, %r113, -1;
	setp.ne.s32 	%p39, %r113, 0;
	@%p39 bra 	$L__BB2_25;

$L__BB2_26:
	bar.sync 	0;
	@%p1 bra 	$L__BB2_69;

	setp.ne.s16 	%p40, %rs7, 0;
	add.s32 	%r31, %r117, %r49;
	add.s32 	%r73, %r31, -1;
	selp.b32 	%r32, %r117, %r73, %p40;
	setp.lt.s32 	%p41, %r32, %r48;
	@%p41 bra 	$L__BB2_32;
	bra.uni 	$L__BB2_28;

$L__BB2_32:
	setp.ge.s32 	%p44, %r114, %r32;
	@%p44 bra 	$L__BB2_35;

	mov.u32 	%r36, %ntid.x;

$L__BB2_34:
	mad.lo.s32 	%r76, %r114, %r47, %r1;
	mul.wide.s32 	%rd58, %r76, 4;
	add.s64 	%rd59, %rd2, %rd58;
	mov.u32 	%r77, 2143289344;
	st.global.u32 	[%rd59], %r77;
	add.s32 	%r114, %r114, %r36;
	setp.lt.s32 	%p45, %r114, %r32;
	@%p45 bra 	$L__BB2_34;

$L__BB2_35:
	bar.sync 	0;
	@%p3 bra 	$L__BB2_69;

	cvt.rn.f32.s32 	%f47, %r49;
	add.ftz.f32 	%f48, %f47, 0f3F800000;
	mov.f32 	%f49, 0f40000000;
	div.approx.ftz.f32 	%f1, %f49, %f48;
	min.s32 	%r78, %r31, %r48;
	selp.b32 	%r39, %r117, %r78, %p40;
	cvt.ftz.f64.f32 	%fd1, %f1;
	mov.f64 	%fd17, 0d3FF0000000000000;
	sub.f64 	%fd2, %fd17, %fd1;
	cvt.rn.f64.s32 	%fd18, %r50;
	add.f64 	%fd3, %fd18, 0d3FF0000000000000;
	neg.f64 	%fd4, %fd3;
	mul.f64 	%fd19, %fd18, 0dBFB999999999999A;
	cvt.rn.ftz.f32.f64 	%f2, %fd19;
	neg.s32 	%r40, %r50;
	mul.f64 	%fd20, %fd18, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f3, %fd20;
	@%p40 bra 	$L__BB2_55;
	bra.uni 	$L__BB2_37;

$L__BB2_55:
	mad.lo.s32 	%r91, %r117, %r47, %r1;
	mul.wide.s32 	%rd63, %r91, 4;
	add.s64 	%rd72, %rd2, %rd63;
	mul.wide.s32 	%rd26, %r47, 4;
	add.s64 	%rd71, %rd1, %rd63;
	mov.f32 	%f126, 0f00000000;
	mov.u16 	%rs16, 0;
	mov.f32 	%f125, %f126;
	mov.f32 	%f123, %f126;
	mov.f32 	%f122, %f126;

$L__BB2_56:
	ld.global.nc.f32 	%f33, [%rd71];
	abs.ftz.f32 	%f86, %f33;
	setp.geu.ftz.f32 	%p70, %f86, 0f7F800000;
	@%p70 bra 	$L__BB2_58;

	sub.ftz.f32 	%f87, %f33, %f123;
	mov.f32 	%f88, 0f00000000;
	fma.rn.ftz.f32 	%f89, %f1, %f87, %f88;
	sub.ftz.f32 	%f90, %f89, %f122;
	add.ftz.f32 	%f34, %f123, %f90;
	sub.ftz.f32 	%f91, %f34, %f123;
	sub.ftz.f32 	%f122, %f91, %f90;
	mov.f32 	%f123, %f34;

$L__BB2_58:
	setp.lt.s32 	%p71, %r117, %r32;
	mov.f32 	%f124, 0f00000000;
	@%p71 bra 	$L__BB2_68;

	setp.ne.s16 	%p72, %rs8, 0;
	setp.gt.s32 	%p73, %r117, 0;
	and.pred  	%p74, %p72, %p73;
	selp.s32 	%r92, -1, 0, %p74;
	add.s32 	%r93, %r117, %r92;
	mad.lo.s32 	%r94, %r93, %r47, %r1;
	mul.wide.s32 	%rd64, %r94, 4;
	add.s64 	%rd65, %rd1, %rd64;
	and.b16  	%rs12, %rs16, 255;
	setp.eq.s16 	%p75, %rs12, 0;
	selp.f32 	%f38, 0f00000000, %f125, %p75;
	selp.f32 	%f39, 0f00000000, %f126, %p75;
	selp.b16 	%rs16, 1, %rs16, %p75;
	cvt.ftz.f64.f32 	%fd11, %f123;
	cvt.ftz.f64.f32 	%fd40, %f126;
	selp.f64 	%fd12, 0d0000000000000000, %fd40, %p75;
	ld.global.nc.f32 	%f40, [%rd65];
	cvt.ftz.f64.f32 	%fd13, %f40;
	abs.f64 	%fd41, %fd1;
	setp.geu.f64 	%p76, %fd41, 0d7FF0000000000000;
	@%p76 bra 	$L__BB2_67;

	abs.f64 	%fd42, %fd11;
	setp.geu.f64 	%p77, %fd42, 0d7FF0000000000000;
	@%p77 bra 	$L__BB2_67;

	abs.f64 	%fd43, %fd12;
	setp.geu.f64 	%p78, %fd43, 0d7FF0000000000000;
	@%p78 bra 	$L__BB2_67;

	abs.f64 	%fd44, %fd13;
	setp.geu.f64 	%p79, %fd44, 0d7FF0000000000000;
	@%p79 bra 	$L__BB2_67;

	mul.f64 	%fd45, %fd2, %fd12;
	fma.rn.f64 	%fd46, %fd1, %fd11, %fd45;
	sub.f64 	%fd14, %fd13, %fd46;
	sub.f64 	%fd47, %fd13, %fd12;
	mul.f64 	%fd48, %fd47, %fd1;
	mul.f64 	%fd15, %fd48, 0d3FB999999999999A;
	abs.f64 	%fd49, %fd15;
	setp.geu.f64 	%p80, %fd49, 0d7FF0000000000000;
	setp.le.f64 	%p81, %fd49, 0d0010000000000000;
	or.pred  	%p82, %p80, %p81;
	mov.f32 	%f124, %f2;
	@%p82 bra 	$L__BB2_67;

	div.rn.f64 	%fd16, %fd14, %fd15;
	setp.le.f64 	%p83, %fd16, %fd4;
	mov.f32 	%f124, %f2;
	@%p83 bra 	$L__BB2_67;

	setp.ge.f64 	%p84, %fd16, %fd3;
	mov.f32 	%f124, %f3;
	@%p84 bra 	$L__BB2_67;

	cvt.rmi.s32.f64 	%r95, %fd16;
	add.s32 	%r96, %r95, 1;
	setp.lt.s32 	%p85, %r95, %r40;
	min.s32 	%r97, %r95, %r50;
	selp.b32 	%r98, %r40, %r97, %p85;
	setp.lt.s32 	%p86, %r96, %r40;
	min.s32 	%r99, %r96, %r50;
	selp.b32 	%r100, %r40, %r99, %p86;
	cvt.rn.f64.s32 	%fd50, %r98;
	mul.f64 	%fd51, %fd15, %fd50;
	sub.f64 	%fd52, %fd14, %fd51;
	abs.f64 	%fd53, %fd52;
	cvt.rn.f64.s32 	%fd54, %r100;
	mul.f64 	%fd55, %fd15, %fd54;
	sub.f64 	%fd56, %fd14, %fd55;
	abs.f64 	%fd57, %fd56;
	setp.lt.f64 	%p87, %fd57, %fd53;
	selp.b32 	%r101, %r100, %r98, %p87;
	cvt.rn.f64.s32 	%fd58, %r101;
	mul.f64 	%fd59, %fd58, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f124, %fd59;

$L__BB2_67:
	sub.ftz.f32 	%f96, %f40, %f39;
	sub.ftz.f32 	%f97, %f123, %f39;
	fma.rn.ftz.f32 	%f98, %f96, %f124, %f97;
	mov.f32 	%f99, 0f00000000;
	fma.rn.ftz.f32 	%f100, %f1, %f98, %f99;
	sub.ftz.f32 	%f101, %f100, %f38;
	add.ftz.f32 	%f126, %f39, %f101;
	sub.ftz.f32 	%f102, %f126, %f39;
	sub.ftz.f32 	%f125, %f102, %f101;
	st.global.f32 	[%rd72], %f126;

$L__BB2_68:
	add.s64 	%rd72, %rd72, %rd26;
	add.s64 	%rd71, %rd71, %rd26;
	add.s32 	%r117, %r117, 1;
	setp.lt.s32 	%p88, %r117, %r48;
	@%p88 bra 	$L__BB2_56;
	bra.uni 	$L__BB2_69;

$L__BB2_28:
	setp.ge.s32 	%p42, %r114, %r48;
	@%p42 bra 	$L__BB2_31;

	mov.u32 	%r33, %ntid.x;

$L__BB2_30:
	mad.lo.s32 	%r74, %r114, %r47, %r1;
	mul.wide.s32 	%rd56, %r74, 4;
	add.s64 	%rd57, %rd2, %rd56;
	mov.u32 	%r75, 2143289344;
	st.global.u32 	[%rd57], %r75;
	add.s32 	%r114, %r114, %r33;
	setp.lt.s32 	%p43, %r114, %r48;
	@%p43 bra 	$L__BB2_30;

$L__BB2_31:
	bar.sync 	0;

$L__BB2_69:
	ret;

$L__BB2_37:
	mad.lo.s32 	%r80, %r117, %r47, %r1;
	mul.wide.s32 	%rd60, %r80, 4;
	add.s64 	%rd70, %rd2, %rd60;
	mul.wide.s32 	%rd19, %r47, 4;
	add.s64 	%rd69, %rd1, %rd60;
	mov.f32 	%f55, 0f00000000;
	mov.u16 	%rs14, 0;
	mov.u32 	%r116, 1;
	mov.f32 	%f117, %f55;
	mov.f32 	%f116, %f55;
	mov.f32 	%f107, %f55;
	mov.f32 	%f108, %f55;
	mov.f32 	%f109, %f55;
	mov.f32 	%f110, %f55;

$L__BB2_38:
	ld.global.nc.f32 	%f10, [%rd69];
	setp.eq.s32 	%p48, %r116, 1;
	mov.f32 	%f111, %f55;
	mov.f32 	%f112, %f10;
	mov.f32 	%f113, %f55;
	mov.f32 	%f114, %f10;
	@%p48 bra 	$L__BB2_44;

	setp.lt.s32 	%p49, %r117, %r39;
	abs.ftz.f32 	%f11, %f10;
	@%p49 bra 	$L__BB2_42;
	bra.uni 	$L__BB2_40;

$L__BB2_42:
	setp.geu.ftz.f32 	%p51, %f11, 0f7F800000;
	mov.f32 	%f111, %f55;
	mov.f32 	%f112, %f107;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;
	@%p51 bra 	$L__BB2_44;

	cvt.rn.f32.s32 	%f65, %r116;
	rcp.approx.ftz.f32 	%f66, %f65;
	sub.ftz.f32 	%f67, %f10, %f107;
	mul.ftz.f32 	%f68, %f66, %f67;
	sub.ftz.f32 	%f69, %f68, %f108;
	add.ftz.f32 	%f112, %f107, %f69;
	sub.ftz.f32 	%f70, %f112, %f107;
	sub.ftz.f32 	%f113, %f70, %f69;
	mov.f32 	%f111, %f55;
	mov.f32 	%f114, %f112;
	bra.uni 	$L__BB2_44;

$L__BB2_40:
	setp.geu.ftz.f32 	%p50, %f11, 0f7F800000;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, %f109;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;
	@%p50 bra 	$L__BB2_44;

	sub.ftz.f32 	%f58, %f10, %f109;
	mov.f32 	%f59, 0f00000000;
	fma.rn.ftz.f32 	%f60, %f1, %f58, %f59;
	sub.ftz.f32 	%f61, %f60, %f110;
	add.ftz.f32 	%f112, %f109, %f61;
	sub.ftz.f32 	%f62, %f112, %f109;
	sub.ftz.f32 	%f111, %f62, %f61;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;

$L__BB2_44:
	setp.lt.s32 	%p52, %r117, %r32;
	mov.f32 	%f115, 0f00000000;
	@%p52 bra 	$L__BB2_54;

	setp.ne.s16 	%p53, %rs8, 0;
	setp.gt.s32 	%p54, %r117, 0;
	and.pred  	%p55, %p53, %p54;
	selp.s32 	%r81, -1, 0, %p55;
	add.s32 	%r82, %r117, %r81;
	mad.lo.s32 	%r83, %r82, %r47, %r1;
	mul.wide.s32 	%rd61, %r83, 4;
	add.s64 	%rd62, %rd1, %rd61;
	and.b16  	%rs10, %rs14, 255;
	setp.eq.s16 	%p56, %rs10, 0;
	selp.f32 	%f20, %f112, %f117, %p56;
	selp.f32 	%f21, 0f00000000, %f116, %p56;
	selp.b16 	%rs14, 1, %rs14, %p56;
	cvt.ftz.f64.f32 	%fd5, %f112;
	cvt.ftz.f64.f32 	%fd6, %f20;
	ld.global.nc.f32 	%f22, [%rd62];
	cvt.ftz.f64.f32 	%fd7, %f22;
	abs.f64 	%fd21, %fd1;
	setp.geu.f64 	%p57, %fd21, 0d7FF0000000000000;
	@%p57 bra 	$L__BB2_53;

	abs.f64 	%fd22, %fd5;
	setp.geu.f64 	%p58, %fd22, 0d7FF0000000000000;
	@%p58 bra 	$L__BB2_53;

	abs.f64 	%fd23, %fd6;
	setp.geu.f64 	%p59, %fd23, 0d7FF0000000000000;
	@%p59 bra 	$L__BB2_53;

	abs.f64 	%fd24, %fd7;
	setp.geu.f64 	%p60, %fd24, 0d7FF0000000000000;
	@%p60 bra 	$L__BB2_53;

	mul.f64 	%fd25, %fd2, %fd6;
	fma.rn.f64 	%fd26, %fd1, %fd5, %fd25;
	sub.f64 	%fd8, %fd7, %fd26;
	sub.f64 	%fd27, %fd7, %fd6;
	mul.f64 	%fd28, %fd27, %fd1;
	mul.f64 	%fd9, %fd28, 0d3FB999999999999A;
	abs.f64 	%fd29, %fd9;
	setp.geu.f64 	%p61, %fd29, 0d7FF0000000000000;
	setp.le.f64 	%p62, %fd29, 0d0010000000000000;
	or.pred  	%p63, %p61, %p62;
	mov.f32 	%f115, %f2;
	@%p63 bra 	$L__BB2_53;

	div.rn.f64 	%fd10, %fd8, %fd9;
	setp.le.f64 	%p64, %fd10, %fd4;
	mov.f32 	%f115, %f2;
	@%p64 bra 	$L__BB2_53;

	setp.ge.f64 	%p65, %fd10, %fd3;
	mov.f32 	%f115, %f3;
	@%p65 bra 	$L__BB2_53;

	cvt.rmi.s32.f64 	%r84, %fd10;
	add.s32 	%r85, %r84, 1;
	setp.lt.s32 	%p66, %r84, %r40;
	min.s32 	%r86, %r84, %r50;
	selp.b32 	%r87, %r40, %r86, %p66;
	setp.lt.s32 	%p67, %r85, %r40;
	min.s32 	%r88, %r85, %r50;
	selp.b32 	%r89, %r40, %r88, %p67;
	cvt.rn.f64.s32 	%fd30, %r87;
	mul.f64 	%fd31, %fd9, %fd30;
	sub.f64 	%fd32, %fd8, %fd31;
	abs.f64 	%fd33, %fd32;
	cvt.rn.f64.s32 	%fd34, %r89;
	mul.f64 	%fd35, %fd9, %fd34;
	sub.f64 	%fd36, %fd8, %fd35;
	abs.f64 	%fd37, %fd36;
	setp.lt.f64 	%p68, %fd37, %fd33;
	selp.b32 	%r90, %r89, %r87, %p68;
	cvt.rn.f64.s32 	%fd38, %r90;
	mul.f64 	%fd39, %fd38, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f115, %fd39;

$L__BB2_53:
	sub.ftz.f32 	%f75, %f22, %f20;
	sub.ftz.f32 	%f76, %f112, %f20;
	fma.rn.ftz.f32 	%f77, %f75, %f115, %f76;
	mov.f32 	%f78, 0f00000000;
	fma.rn.ftz.f32 	%f79, %f1, %f77, %f78;
	sub.ftz.f32 	%f80, %f79, %f21;
	add.ftz.f32 	%f117, %f20, %f80;
	sub.ftz.f32 	%f81, %f117, %f20;
	sub.ftz.f32 	%f116, %f81, %f80;
	st.global.f32 	[%rd70], %f117;

$L__BB2_54:
	add.s32 	%r116, %r116, 1;
	add.s64 	%rd70, %rd70, %rd19;
	add.s64 	%rd69, %rd69, %rd19;
	add.s32 	%r117, %r117, 1;
	setp.lt.s32 	%p69, %r117, %r48;
	mov.f32 	%f107, %f114;
	mov.f32 	%f108, %f113;
	mov.f32 	%f109, %f112;
	mov.f32 	%f110, %f111;
	@%p69 bra 	$L__BB2_38;
	bra.uni 	$L__BB2_69;

}

.visible .entry ehlers_ecema_many_series_one_param_1d_f32(
	.param .u64 ehlers_ecema_many_series_one_param_1d_f32_param_0,
	.param .u32 ehlers_ecema_many_series_one_param_1d_f32_param_1,
	.param .u32 ehlers_ecema_many_series_one_param_1d_f32_param_2,
	.param .u32 ehlers_ecema_many_series_one_param_1d_f32_param_3,
	.param .u32 ehlers_ecema_many_series_one_param_1d_f32_param_4,
	.param .u8 ehlers_ecema_many_series_one_param_1d_f32_param_5,
	.param .u8 ehlers_ecema_many_series_one_param_1d_f32_param_6,
	.param .u64 ehlers_ecema_many_series_one_param_1d_f32_param_7,
	.param .u64 ehlers_ecema_many_series_one_param_1d_f32_param_8
)
{
	.reg .pred 	%p<66>;
	.reg .b16 	%rs<17>;
	.reg .f32 	%f<127>;
	.reg .b32 	%r<89>;
	.reg .f64 	%fd<60>;
	.reg .b64 	%rd<57>;


	ld.param.u8 	%rs8, [ehlers_ecema_many_series_one_param_1d_f32_param_6];
	ld.param.u8 	%rs7, [ehlers_ecema_many_series_one_param_1d_f32_param_5];
	ld.param.u64 	%rd28, [ehlers_ecema_many_series_one_param_1d_f32_param_0];
	ld.param.u32 	%r31, [ehlers_ecema_many_series_one_param_1d_f32_param_1];
	ld.param.u32 	%r32, [ehlers_ecema_many_series_one_param_1d_f32_param_2];
	ld.param.u32 	%r33, [ehlers_ecema_many_series_one_param_1d_f32_param_3];
	ld.param.u32 	%r34, [ehlers_ecema_many_series_one_param_1d_f32_param_4];
	ld.param.u64 	%rd27, [ehlers_ecema_many_series_one_param_1d_f32_param_7];
	ld.param.u64 	%rd29, [ehlers_ecema_many_series_one_param_1d_f32_param_8];
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd29;
	mov.u32 	%r35, %ntid.x;
	mov.u32 	%r36, %ctaid.x;
	mov.u32 	%r37, %tid.x;
	mad.lo.s32 	%r1, %r36, %r35, %r37;
	setp.ge.s32 	%p1, %r1, %r31;
	@%p1 bra 	$L__BB3_51;

	setp.lt.s32 	%p2, %r32, 1;
	setp.lt.s32 	%p3, %r33, 1;
	or.pred  	%p4, %p2, %p3;
	setp.lt.s32 	%p5, %r34, 1;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB3_51;

	cvta.to.global.u64 	%rd30, %rd27;
	mul.wide.s32 	%rd31, %r1, 4;
	add.s64 	%rd32, %rd30, %rd31;
	ld.global.nc.u32 	%r87, [%rd32];
	setp.lt.s32 	%p7, %r87, 0;
	setp.ge.s32 	%p8, %r87, %r32;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB3_51;

	setp.eq.s16 	%p10, %rs7, 0;
	sub.s32 	%r38, %r32, %r87;
	setp.lt.s32 	%p11, %r38, %r33;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB3_51;

	setp.ne.s16 	%p13, %rs7, 0;
	add.s32 	%r3, %r87, %r33;
	add.s32 	%r39, %r3, -1;
	selp.b32 	%r4, %r87, %r39, %p13;
	setp.lt.s32 	%p14, %r4, %r32;
	@%p14 bra 	$L__BB3_11;
	bra.uni 	$L__BB3_5;

$L__BB3_11:
	setp.lt.s32 	%p19, %r4, 1;
	@%p19 bra 	$L__BB3_18;

	add.s32 	%r48, %r4, -1;
	and.b32  	%r85, %r4, 3;
	setp.lt.u32 	%p20, %r48, 3;
	mov.u32 	%r84, 0;
	@%p20 bra 	$L__BB3_15;

	sub.s32 	%r83, %r4, %r85;
	mul.wide.s32 	%rd8, %r31, 4;
	mov.u32 	%r84, 0;

$L__BB3_14:
	mad.lo.s32 	%r50, %r84, %r31, %r1;
	mul.wide.s32 	%rd39, %r50, 4;
	add.s64 	%rd40, %rd2, %rd39;
	mov.u32 	%r51, 2143289344;
	st.global.u32 	[%rd40], %r51;
	add.s64 	%rd41, %rd40, %rd8;
	st.global.u32 	[%rd41], %r51;
	add.s64 	%rd42, %rd41, %rd8;
	st.global.u32 	[%rd42], %r51;
	add.s64 	%rd43, %rd42, %rd8;
	st.global.u32 	[%rd43], %r51;
	add.s32 	%r84, %r84, 4;
	add.s32 	%r83, %r83, -4;
	setp.ne.s32 	%p21, %r83, 0;
	@%p21 bra 	$L__BB3_14;

$L__BB3_15:
	setp.eq.s32 	%p22, %r85, 0;
	@%p22 bra 	$L__BB3_18;

	mad.lo.s32 	%r52, %r84, %r31, %r1;
	mul.wide.s32 	%rd44, %r52, 4;
	add.s64 	%rd52, %rd2, %rd44;
	mul.wide.s32 	%rd10, %r31, 4;

$L__BB3_17:
	.pragma "nounroll";
	mov.u32 	%r53, 2143289344;
	st.global.u32 	[%rd52], %r53;
	add.s64 	%rd52, %rd52, %rd10;
	add.s32 	%r85, %r85, -1;
	setp.ne.s32 	%p23, %r85, 0;
	@%p23 bra 	$L__BB3_17;

$L__BB3_18:
	cvt.rn.f32.s32 	%f47, %r33;
	add.ftz.f32 	%f48, %f47, 0f3F800000;
	mov.f32 	%f49, 0f40000000;
	div.approx.ftz.f32 	%f1, %f49, %f48;
	min.s32 	%r54, %r3, %r32;
	selp.b32 	%r23, %r87, %r54, %p13;
	cvt.ftz.f64.f32 	%fd1, %f1;
	mov.f64 	%fd17, 0d3FF0000000000000;
	sub.f64 	%fd2, %fd17, %fd1;
	cvt.rn.f64.s32 	%fd18, %r34;
	add.f64 	%fd3, %fd18, 0d3FF0000000000000;
	neg.f64 	%fd4, %fd3;
	mul.f64 	%fd19, %fd18, 0dBFB999999999999A;
	cvt.rn.ftz.f32.f64 	%f2, %fd19;
	neg.s32 	%r24, %r34;
	mul.f64 	%fd20, %fd18, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f3, %fd20;
	@%p13 bra 	$L__BB3_37;
	bra.uni 	$L__BB3_19;

$L__BB3_37:
	mad.lo.s32 	%r67, %r87, %r31, %r1;
	mul.wide.s32 	%rd48, %r67, 4;
	add.s64 	%rd56, %rd2, %rd48;
	mul.wide.s32 	%rd21, %r31, 4;
	add.s64 	%rd55, %rd1, %rd48;
	mov.f32 	%f126, 0f00000000;
	mov.u16 	%rs16, 0;
	mov.f32 	%f125, %f126;
	mov.f32 	%f123, %f126;
	mov.f32 	%f122, %f126;

$L__BB3_38:
	ld.global.nc.f32 	%f33, [%rd55];
	abs.ftz.f32 	%f86, %f33;
	setp.geu.ftz.f32 	%p47, %f86, 0f7F800000;
	@%p47 bra 	$L__BB3_40;

	sub.ftz.f32 	%f87, %f33, %f123;
	mov.f32 	%f88, 0f00000000;
	fma.rn.ftz.f32 	%f89, %f1, %f87, %f88;
	sub.ftz.f32 	%f90, %f89, %f122;
	add.ftz.f32 	%f34, %f123, %f90;
	sub.ftz.f32 	%f91, %f34, %f123;
	sub.ftz.f32 	%f122, %f91, %f90;
	mov.f32 	%f123, %f34;

$L__BB3_40:
	setp.lt.s32 	%p48, %r87, %r4;
	mov.f32 	%f124, 0f00000000;
	@%p48 bra 	$L__BB3_50;

	setp.ne.s16 	%p49, %rs8, 0;
	setp.gt.s32 	%p50, %r87, 0;
	and.pred  	%p51, %p49, %p50;
	selp.s32 	%r68, -1, 0, %p51;
	add.s32 	%r69, %r87, %r68;
	mad.lo.s32 	%r70, %r69, %r31, %r1;
	mul.wide.s32 	%rd49, %r70, 4;
	add.s64 	%rd50, %rd1, %rd49;
	and.b16  	%rs12, %rs16, 255;
	setp.eq.s16 	%p52, %rs12, 0;
	selp.f32 	%f38, 0f00000000, %f125, %p52;
	selp.f32 	%f39, 0f00000000, %f126, %p52;
	selp.b16 	%rs16, 1, %rs16, %p52;
	cvt.ftz.f64.f32 	%fd11, %f123;
	cvt.ftz.f64.f32 	%fd40, %f126;
	selp.f64 	%fd12, 0d0000000000000000, %fd40, %p52;
	ld.global.nc.f32 	%f40, [%rd50];
	cvt.ftz.f64.f32 	%fd13, %f40;
	abs.f64 	%fd41, %fd1;
	setp.geu.f64 	%p53, %fd41, 0d7FF0000000000000;
	@%p53 bra 	$L__BB3_49;

	abs.f64 	%fd42, %fd11;
	setp.geu.f64 	%p54, %fd42, 0d7FF0000000000000;
	@%p54 bra 	$L__BB3_49;

	abs.f64 	%fd43, %fd12;
	setp.geu.f64 	%p55, %fd43, 0d7FF0000000000000;
	@%p55 bra 	$L__BB3_49;

	abs.f64 	%fd44, %fd13;
	setp.geu.f64 	%p56, %fd44, 0d7FF0000000000000;
	@%p56 bra 	$L__BB3_49;

	mul.f64 	%fd45, %fd2, %fd12;
	fma.rn.f64 	%fd46, %fd1, %fd11, %fd45;
	sub.f64 	%fd14, %fd13, %fd46;
	sub.f64 	%fd47, %fd13, %fd12;
	mul.f64 	%fd48, %fd47, %fd1;
	mul.f64 	%fd15, %fd48, 0d3FB999999999999A;
	abs.f64 	%fd49, %fd15;
	setp.geu.f64 	%p57, %fd49, 0d7FF0000000000000;
	setp.le.f64 	%p58, %fd49, 0d0010000000000000;
	or.pred  	%p59, %p57, %p58;
	mov.f32 	%f124, %f2;
	@%p59 bra 	$L__BB3_49;

	div.rn.f64 	%fd16, %fd14, %fd15;
	setp.le.f64 	%p60, %fd16, %fd4;
	mov.f32 	%f124, %f2;
	@%p60 bra 	$L__BB3_49;

	setp.ge.f64 	%p61, %fd16, %fd3;
	mov.f32 	%f124, %f3;
	@%p61 bra 	$L__BB3_49;

	cvt.rmi.s32.f64 	%r71, %fd16;
	add.s32 	%r72, %r71, 1;
	setp.lt.s32 	%p62, %r71, %r24;
	min.s32 	%r73, %r71, %r34;
	selp.b32 	%r74, %r24, %r73, %p62;
	setp.lt.s32 	%p63, %r72, %r24;
	min.s32 	%r75, %r72, %r34;
	selp.b32 	%r76, %r24, %r75, %p63;
	cvt.rn.f64.s32 	%fd50, %r74;
	mul.f64 	%fd51, %fd15, %fd50;
	sub.f64 	%fd52, %fd14, %fd51;
	abs.f64 	%fd53, %fd52;
	cvt.rn.f64.s32 	%fd54, %r76;
	mul.f64 	%fd55, %fd15, %fd54;
	sub.f64 	%fd56, %fd14, %fd55;
	abs.f64 	%fd57, %fd56;
	setp.lt.f64 	%p64, %fd57, %fd53;
	selp.b32 	%r77, %r76, %r74, %p64;
	cvt.rn.f64.s32 	%fd58, %r77;
	mul.f64 	%fd59, %fd58, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f124, %fd59;

$L__BB3_49:
	sub.ftz.f32 	%f96, %f40, %f39;
	sub.ftz.f32 	%f97, %f123, %f39;
	fma.rn.ftz.f32 	%f98, %f96, %f124, %f97;
	mov.f32 	%f99, 0f00000000;
	fma.rn.ftz.f32 	%f100, %f1, %f98, %f99;
	sub.ftz.f32 	%f101, %f100, %f38;
	add.ftz.f32 	%f126, %f39, %f101;
	sub.ftz.f32 	%f102, %f126, %f39;
	sub.ftz.f32 	%f125, %f102, %f101;
	st.global.f32 	[%rd56], %f126;

$L__BB3_50:
	add.s64 	%rd56, %rd56, %rd21;
	add.s64 	%rd55, %rd55, %rd21;
	add.s32 	%r87, %r87, 1;
	setp.lt.s32 	%p65, %r87, %r32;
	@%p65 bra 	$L__BB3_38;
	bra.uni 	$L__BB3_51;

$L__BB3_5:
	add.s32 	%r41, %r32, -1;
	and.b32  	%r81, %r32, 3;
	setp.lt.u32 	%p15, %r41, 3;
	mov.u32 	%r80, 0;
	@%p15 bra 	$L__BB3_8;

	sub.s32 	%r79, %r32, %r81;
	mul.wide.s32 	%rd3, %r31, 4;
	mov.u32 	%r80, 0;

$L__BB3_7:
	mad.lo.s32 	%r43, %r80, %r31, %r1;
	mul.wide.s32 	%rd33, %r43, 4;
	add.s64 	%rd34, %rd2, %rd33;
	mov.u32 	%r44, 2143289344;
	st.global.u32 	[%rd34], %r44;
	add.s64 	%rd35, %rd34, %rd3;
	st.global.u32 	[%rd35], %r44;
	add.s64 	%rd36, %rd35, %rd3;
	st.global.u32 	[%rd36], %r44;
	add.s64 	%rd37, %rd36, %rd3;
	st.global.u32 	[%rd37], %r44;
	add.s32 	%r80, %r80, 4;
	add.s32 	%r79, %r79, -4;
	setp.ne.s32 	%p16, %r79, 0;
	@%p16 bra 	$L__BB3_7;

$L__BB3_8:
	setp.eq.s32 	%p17, %r81, 0;
	@%p17 bra 	$L__BB3_51;

	mad.lo.s32 	%r45, %r80, %r31, %r1;
	mul.wide.s32 	%rd38, %r45, 4;
	add.s64 	%rd51, %rd2, %rd38;
	mul.wide.s32 	%rd5, %r31, 4;

$L__BB3_10:
	.pragma "nounroll";
	mov.u32 	%r46, 2143289344;
	st.global.u32 	[%rd51], %r46;
	add.s64 	%rd51, %rd51, %rd5;
	add.s32 	%r81, %r81, -1;
	setp.eq.s32 	%p18, %r81, 0;
	@%p18 bra 	$L__BB3_51;
	bra.uni 	$L__BB3_10;

$L__BB3_19:
	mad.lo.s32 	%r56, %r87, %r31, %r1;
	mul.wide.s32 	%rd45, %r56, 4;
	add.s64 	%rd54, %rd2, %rd45;
	mul.wide.s32 	%rd14, %r31, 4;
	add.s64 	%rd53, %rd1, %rd45;
	mov.f32 	%f55, 0f00000000;
	mov.u16 	%rs14, 0;
	mov.u32 	%r86, 1;
	mov.f32 	%f117, %f55;
	mov.f32 	%f116, %f55;
	mov.f32 	%f107, %f55;
	mov.f32 	%f108, %f55;
	mov.f32 	%f109, %f55;
	mov.f32 	%f110, %f55;

$L__BB3_20:
	ld.global.nc.f32 	%f10, [%rd53];
	setp.eq.s32 	%p25, %r86, 1;
	mov.f32 	%f111, %f55;
	mov.f32 	%f112, %f10;
	mov.f32 	%f113, %f55;
	mov.f32 	%f114, %f10;
	@%p25 bra 	$L__BB3_26;

	setp.lt.s32 	%p26, %r87, %r23;
	abs.ftz.f32 	%f11, %f10;
	@%p26 bra 	$L__BB3_24;
	bra.uni 	$L__BB3_22;

$L__BB3_24:
	setp.geu.ftz.f32 	%p28, %f11, 0f7F800000;
	mov.f32 	%f111, %f55;
	mov.f32 	%f112, %f107;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;
	@%p28 bra 	$L__BB3_26;

	cvt.rn.f32.s32 	%f65, %r86;
	rcp.approx.ftz.f32 	%f66, %f65;
	sub.ftz.f32 	%f67, %f10, %f107;
	mul.ftz.f32 	%f68, %f66, %f67;
	sub.ftz.f32 	%f69, %f68, %f108;
	add.ftz.f32 	%f112, %f107, %f69;
	sub.ftz.f32 	%f70, %f112, %f107;
	sub.ftz.f32 	%f113, %f70, %f69;
	mov.f32 	%f111, %f55;
	mov.f32 	%f114, %f112;
	bra.uni 	$L__BB3_26;

$L__BB3_22:
	setp.geu.ftz.f32 	%p27, %f11, 0f7F800000;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, %f109;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;
	@%p27 bra 	$L__BB3_26;

	sub.ftz.f32 	%f58, %f10, %f109;
	mov.f32 	%f59, 0f00000000;
	fma.rn.ftz.f32 	%f60, %f1, %f58, %f59;
	sub.ftz.f32 	%f61, %f60, %f110;
	add.ftz.f32 	%f112, %f109, %f61;
	sub.ftz.f32 	%f62, %f112, %f109;
	sub.ftz.f32 	%f111, %f62, %f61;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;

$L__BB3_26:
	setp.lt.s32 	%p29, %r87, %r4;
	mov.f32 	%f115, 0f00000000;
	@%p29 bra 	$L__BB3_36;

	setp.ne.s16 	%p30, %rs8, 0;
	setp.gt.s32 	%p31, %r87, 0;
	and.pred  	%p32, %p30, %p31;
	selp.s32 	%r57, -1, 0, %p32;
	add.s32 	%r58, %r87, %r57;
	mad.lo.s32 	%r59, %r58, %r31, %r1;
	mul.wide.s32 	%rd46, %r59, 4;
	add.s64 	%rd47, %rd1, %rd46;
	and.b16  	%rs10, %rs14, 255;
	setp.eq.s16 	%p33, %rs10, 0;
	selp.f32 	%f20, %f112, %f117, %p33;
	selp.f32 	%f21, 0f00000000, %f116, %p33;
	selp.b16 	%rs14, 1, %rs14, %p33;
	cvt.ftz.f64.f32 	%fd5, %f112;
	cvt.ftz.f64.f32 	%fd6, %f20;
	ld.global.nc.f32 	%f22, [%rd47];
	cvt.ftz.f64.f32 	%fd7, %f22;
	abs.f64 	%fd21, %fd1;
	setp.geu.f64 	%p34, %fd21, 0d7FF0000000000000;
	@%p34 bra 	$L__BB3_35;

	abs.f64 	%fd22, %fd5;
	setp.geu.f64 	%p35, %fd22, 0d7FF0000000000000;
	@%p35 bra 	$L__BB3_35;

	abs.f64 	%fd23, %fd6;
	setp.geu.f64 	%p36, %fd23, 0d7FF0000000000000;
	@%p36 bra 	$L__BB3_35;

	abs.f64 	%fd24, %fd7;
	setp.geu.f64 	%p37, %fd24, 0d7FF0000000000000;
	@%p37 bra 	$L__BB3_35;

	mul.f64 	%fd25, %fd2, %fd6;
	fma.rn.f64 	%fd26, %fd1, %fd5, %fd25;
	sub.f64 	%fd8, %fd7, %fd26;
	sub.f64 	%fd27, %fd7, %fd6;
	mul.f64 	%fd28, %fd27, %fd1;
	mul.f64 	%fd9, %fd28, 0d3FB999999999999A;
	abs.f64 	%fd29, %fd9;
	setp.geu.f64 	%p38, %fd29, 0d7FF0000000000000;
	setp.le.f64 	%p39, %fd29, 0d0010000000000000;
	or.pred  	%p40, %p38, %p39;
	mov.f32 	%f115, %f2;
	@%p40 bra 	$L__BB3_35;

	div.rn.f64 	%fd10, %fd8, %fd9;
	setp.le.f64 	%p41, %fd10, %fd4;
	mov.f32 	%f115, %f2;
	@%p41 bra 	$L__BB3_35;

	setp.ge.f64 	%p42, %fd10, %fd3;
	mov.f32 	%f115, %f3;
	@%p42 bra 	$L__BB3_35;

	cvt.rmi.s32.f64 	%r60, %fd10;
	add.s32 	%r61, %r60, 1;
	setp.lt.s32 	%p43, %r60, %r24;
	min.s32 	%r62, %r60, %r34;
	selp.b32 	%r63, %r24, %r62, %p43;
	setp.lt.s32 	%p44, %r61, %r24;
	min.s32 	%r64, %r61, %r34;
	selp.b32 	%r65, %r24, %r64, %p44;
	cvt.rn.f64.s32 	%fd30, %r63;
	mul.f64 	%fd31, %fd9, %fd30;
	sub.f64 	%fd32, %fd8, %fd31;
	abs.f64 	%fd33, %fd32;
	cvt.rn.f64.s32 	%fd34, %r65;
	mul.f64 	%fd35, %fd9, %fd34;
	sub.f64 	%fd36, %fd8, %fd35;
	abs.f64 	%fd37, %fd36;
	setp.lt.f64 	%p45, %fd37, %fd33;
	selp.b32 	%r66, %r65, %r63, %p45;
	cvt.rn.f64.s32 	%fd38, %r66;
	mul.f64 	%fd39, %fd38, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f115, %fd39;

$L__BB3_35:
	sub.ftz.f32 	%f75, %f22, %f20;
	sub.ftz.f32 	%f76, %f112, %f20;
	fma.rn.ftz.f32 	%f77, %f75, %f115, %f76;
	mov.f32 	%f78, 0f00000000;
	fma.rn.ftz.f32 	%f79, %f1, %f77, %f78;
	sub.ftz.f32 	%f80, %f79, %f21;
	add.ftz.f32 	%f117, %f20, %f80;
	sub.ftz.f32 	%f81, %f117, %f20;
	sub.ftz.f32 	%f116, %f81, %f80;
	st.global.f32 	[%rd54], %f117;

$L__BB3_36:
	add.s32 	%r86, %r86, 1;
	add.s64 	%rd54, %rd54, %rd14;
	add.s64 	%rd53, %rd53, %rd14;
	add.s32 	%r87, %r87, 1;
	setp.lt.s32 	%p46, %r87, %r32;
	mov.f32 	%f107, %f114;
	mov.f32 	%f108, %f113;
	mov.f32 	%f109, %f112;
	mov.f32 	%f110, %f111;
	@%p46 bra 	$L__BB3_20;

$L__BB3_51:
	ret;

}

.visible .entry ehlers_ecema_many_series_one_param_2d_f32(
	.param .u64 ehlers_ecema_many_series_one_param_2d_f32_param_0,
	.param .u32 ehlers_ecema_many_series_one_param_2d_f32_param_1,
	.param .u32 ehlers_ecema_many_series_one_param_2d_f32_param_2,
	.param .u32 ehlers_ecema_many_series_one_param_2d_f32_param_3,
	.param .u32 ehlers_ecema_many_series_one_param_2d_f32_param_4,
	.param .u8 ehlers_ecema_many_series_one_param_2d_f32_param_5,
	.param .u8 ehlers_ecema_many_series_one_param_2d_f32_param_6,
	.param .u64 ehlers_ecema_many_series_one_param_2d_f32_param_7,
	.param .u64 ehlers_ecema_many_series_one_param_2d_f32_param_8
)
{
	.reg .pred 	%p<66>;
	.reg .b16 	%rs<17>;
	.reg .f32 	%f<127>;
	.reg .b32 	%r<99>;
	.reg .f64 	%fd<60>;
	.reg .b64 	%rd<57>;


	ld.param.u8 	%rs8, [ehlers_ecema_many_series_one_param_2d_f32_param_6];
	ld.param.u8 	%rs7, [ehlers_ecema_many_series_one_param_2d_f32_param_5];
	ld.param.u64 	%rd28, [ehlers_ecema_many_series_one_param_2d_f32_param_0];
	ld.param.u32 	%r33, [ehlers_ecema_many_series_one_param_2d_f32_param_1];
	ld.param.u32 	%r34, [ehlers_ecema_many_series_one_param_2d_f32_param_2];
	ld.param.u32 	%r35, [ehlers_ecema_many_series_one_param_2d_f32_param_3];
	ld.param.u32 	%r36, [ehlers_ecema_many_series_one_param_2d_f32_param_4];
	ld.param.u64 	%rd27, [ehlers_ecema_many_series_one_param_2d_f32_param_7];
	ld.param.u64 	%rd29, [ehlers_ecema_many_series_one_param_2d_f32_param_8];
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd29;
	mov.u32 	%r37, %ctaid.y;
	mov.u32 	%r38, %nctaid.x;
	mov.u32 	%r39, %ctaid.x;
	mov.u32 	%r40, %tid.y;
	add.s32 	%r41, %r40, %r39;
	mad.lo.s32 	%r42, %r37, %r38, %r41;
	mov.u32 	%r43, %ntid.x;
	mul.lo.s32 	%r1, %r42, %r43;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r3, %r1, %r2;
	setp.ge.s32 	%p1, %r3, %r33;
	@%p1 bra 	$L__BB4_51;

	setp.lt.s32 	%p2, %r34, 1;
	setp.lt.s32 	%p3, %r35, 1;
	or.pred  	%p4, %p2, %p3;
	setp.lt.s32 	%p5, %r36, 1;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB4_51;

	cvta.to.global.u64 	%rd30, %rd27;
	mul.wide.s32 	%rd31, %r3, 4;
	add.s64 	%rd32, %rd30, %rd31;
	ld.global.nc.u32 	%r97, [%rd32];
	setp.lt.s32 	%p7, %r97, 0;
	setp.ge.s32 	%p8, %r97, %r34;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB4_51;

	setp.eq.s16 	%p10, %rs7, 0;
	sub.s32 	%r44, %r34, %r97;
	setp.lt.s32 	%p11, %r44, %r35;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB4_51;

	setp.ne.s16 	%p13, %rs7, 0;
	add.s32 	%r5, %r97, %r35;
	add.s32 	%r45, %r5, -1;
	selp.b32 	%r6, %r97, %r45, %p13;
	setp.lt.s32 	%p14, %r6, %r34;
	@%p14 bra 	$L__BB4_11;
	bra.uni 	$L__BB4_5;

$L__BB4_11:
	setp.lt.s32 	%p19, %r6, 1;
	@%p19 bra 	$L__BB4_18;

	add.s32 	%r55, %r6, -1;
	and.b32  	%r95, %r6, 3;
	setp.lt.u32 	%p20, %r55, 3;
	mov.u32 	%r94, 0;
	@%p20 bra 	$L__BB4_15;

	sub.s32 	%r93, %r6, %r95;
	mul.wide.s32 	%rd8, %r33, 4;
	mov.u32 	%r94, 0;

$L__BB4_14:
	mad.lo.s32 	%r57, %r94, %r33, %r3;
	mul.wide.s32 	%rd39, %r57, 4;
	add.s64 	%rd40, %rd2, %rd39;
	mov.u32 	%r58, 2143289344;
	st.global.u32 	[%rd40], %r58;
	add.s64 	%rd41, %rd40, %rd8;
	st.global.u32 	[%rd41], %r58;
	add.s64 	%rd42, %rd41, %rd8;
	st.global.u32 	[%rd42], %r58;
	add.s64 	%rd43, %rd42, %rd8;
	st.global.u32 	[%rd43], %r58;
	add.s32 	%r94, %r94, 4;
	add.s32 	%r93, %r93, -4;
	setp.ne.s32 	%p21, %r93, 0;
	@%p21 bra 	$L__BB4_14;

$L__BB4_15:
	setp.eq.s32 	%p22, %r95, 0;
	@%p22 bra 	$L__BB4_18;

	mad.lo.s32 	%r59, %r94, %r33, %r2;
	add.s32 	%r60, %r59, %r1;
	mul.wide.s32 	%rd44, %r60, 4;
	add.s64 	%rd52, %rd2, %rd44;
	mul.wide.s32 	%rd10, %r33, 4;

$L__BB4_17:
	.pragma "nounroll";
	mov.u32 	%r61, 2143289344;
	st.global.u32 	[%rd52], %r61;
	add.s64 	%rd52, %rd52, %rd10;
	add.s32 	%r95, %r95, -1;
	setp.ne.s32 	%p23, %r95, 0;
	@%p23 bra 	$L__BB4_17;

$L__BB4_18:
	cvt.rn.f32.s32 	%f47, %r35;
	add.ftz.f32 	%f48, %f47, 0f3F800000;
	mov.f32 	%f49, 0f40000000;
	div.approx.ftz.f32 	%f1, %f49, %f48;
	min.s32 	%r62, %r5, %r34;
	selp.b32 	%r25, %r97, %r62, %p13;
	cvt.ftz.f64.f32 	%fd1, %f1;
	mov.f64 	%fd17, 0d3FF0000000000000;
	sub.f64 	%fd2, %fd17, %fd1;
	cvt.rn.f64.s32 	%fd18, %r36;
	add.f64 	%fd3, %fd18, 0d3FF0000000000000;
	neg.f64 	%fd4, %fd3;
	mul.f64 	%fd19, %fd18, 0dBFB999999999999A;
	cvt.rn.ftz.f32.f64 	%f2, %fd19;
	neg.s32 	%r26, %r36;
	mul.f64 	%fd20, %fd18, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f3, %fd20;
	@%p13 bra 	$L__BB4_37;
	bra.uni 	$L__BB4_19;

$L__BB4_37:
	mad.lo.s32 	%r76, %r97, %r33, %r2;
	add.s32 	%r77, %r76, %r1;
	mul.wide.s32 	%rd48, %r77, 4;
	add.s64 	%rd56, %rd2, %rd48;
	mul.wide.s32 	%rd21, %r33, 4;
	add.s64 	%rd55, %rd1, %rd48;
	mov.f32 	%f126, 0f00000000;
	mov.u16 	%rs16, 0;
	mov.f32 	%f125, %f126;
	mov.f32 	%f123, %f126;
	mov.f32 	%f122, %f126;

$L__BB4_38:
	ld.global.nc.f32 	%f33, [%rd55];
	abs.ftz.f32 	%f86, %f33;
	setp.geu.ftz.f32 	%p47, %f86, 0f7F800000;
	@%p47 bra 	$L__BB4_40;

	sub.ftz.f32 	%f87, %f33, %f123;
	mov.f32 	%f88, 0f00000000;
	fma.rn.ftz.f32 	%f89, %f1, %f87, %f88;
	sub.ftz.f32 	%f90, %f89, %f122;
	add.ftz.f32 	%f34, %f123, %f90;
	sub.ftz.f32 	%f91, %f34, %f123;
	sub.ftz.f32 	%f122, %f91, %f90;
	mov.f32 	%f123, %f34;

$L__BB4_40:
	setp.lt.s32 	%p48, %r97, %r6;
	mov.f32 	%f124, 0f00000000;
	@%p48 bra 	$L__BB4_50;

	setp.ne.s16 	%p49, %rs8, 0;
	setp.gt.s32 	%p50, %r97, 0;
	and.pred  	%p51, %p49, %p50;
	selp.s32 	%r78, -1, 0, %p51;
	add.s32 	%r79, %r97, %r78;
	mad.lo.s32 	%r80, %r79, %r33, %r3;
	mul.wide.s32 	%rd49, %r80, 4;
	add.s64 	%rd50, %rd1, %rd49;
	and.b16  	%rs12, %rs16, 255;
	setp.eq.s16 	%p52, %rs12, 0;
	selp.f32 	%f38, 0f00000000, %f125, %p52;
	selp.f32 	%f39, 0f00000000, %f126, %p52;
	selp.b16 	%rs16, 1, %rs16, %p52;
	cvt.ftz.f64.f32 	%fd11, %f123;
	cvt.ftz.f64.f32 	%fd40, %f126;
	selp.f64 	%fd12, 0d0000000000000000, %fd40, %p52;
	ld.global.nc.f32 	%f40, [%rd50];
	cvt.ftz.f64.f32 	%fd13, %f40;
	abs.f64 	%fd41, %fd1;
	setp.geu.f64 	%p53, %fd41, 0d7FF0000000000000;
	@%p53 bra 	$L__BB4_49;

	abs.f64 	%fd42, %fd11;
	setp.geu.f64 	%p54, %fd42, 0d7FF0000000000000;
	@%p54 bra 	$L__BB4_49;

	abs.f64 	%fd43, %fd12;
	setp.geu.f64 	%p55, %fd43, 0d7FF0000000000000;
	@%p55 bra 	$L__BB4_49;

	abs.f64 	%fd44, %fd13;
	setp.geu.f64 	%p56, %fd44, 0d7FF0000000000000;
	@%p56 bra 	$L__BB4_49;

	mul.f64 	%fd45, %fd2, %fd12;
	fma.rn.f64 	%fd46, %fd1, %fd11, %fd45;
	sub.f64 	%fd14, %fd13, %fd46;
	sub.f64 	%fd47, %fd13, %fd12;
	mul.f64 	%fd48, %fd47, %fd1;
	mul.f64 	%fd15, %fd48, 0d3FB999999999999A;
	abs.f64 	%fd49, %fd15;
	setp.geu.f64 	%p57, %fd49, 0d7FF0000000000000;
	setp.le.f64 	%p58, %fd49, 0d0010000000000000;
	or.pred  	%p59, %p57, %p58;
	mov.f32 	%f124, %f2;
	@%p59 bra 	$L__BB4_49;

	div.rn.f64 	%fd16, %fd14, %fd15;
	setp.le.f64 	%p60, %fd16, %fd4;
	mov.f32 	%f124, %f2;
	@%p60 bra 	$L__BB4_49;

	setp.ge.f64 	%p61, %fd16, %fd3;
	mov.f32 	%f124, %f3;
	@%p61 bra 	$L__BB4_49;

	cvt.rmi.s32.f64 	%r81, %fd16;
	add.s32 	%r82, %r81, 1;
	setp.lt.s32 	%p62, %r81, %r26;
	min.s32 	%r83, %r81, %r36;
	selp.b32 	%r84, %r26, %r83, %p62;
	setp.lt.s32 	%p63, %r82, %r26;
	min.s32 	%r85, %r82, %r36;
	selp.b32 	%r86, %r26, %r85, %p63;
	cvt.rn.f64.s32 	%fd50, %r84;
	mul.f64 	%fd51, %fd15, %fd50;
	sub.f64 	%fd52, %fd14, %fd51;
	abs.f64 	%fd53, %fd52;
	cvt.rn.f64.s32 	%fd54, %r86;
	mul.f64 	%fd55, %fd15, %fd54;
	sub.f64 	%fd56, %fd14, %fd55;
	abs.f64 	%fd57, %fd56;
	setp.lt.f64 	%p64, %fd57, %fd53;
	selp.b32 	%r87, %r86, %r84, %p64;
	cvt.rn.f64.s32 	%fd58, %r87;
	mul.f64 	%fd59, %fd58, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f124, %fd59;

$L__BB4_49:
	sub.ftz.f32 	%f96, %f40, %f39;
	sub.ftz.f32 	%f97, %f123, %f39;
	fma.rn.ftz.f32 	%f98, %f96, %f124, %f97;
	mov.f32 	%f99, 0f00000000;
	fma.rn.ftz.f32 	%f100, %f1, %f98, %f99;
	sub.ftz.f32 	%f101, %f100, %f38;
	add.ftz.f32 	%f126, %f39, %f101;
	sub.ftz.f32 	%f102, %f126, %f39;
	sub.ftz.f32 	%f125, %f102, %f101;
	st.global.f32 	[%rd56], %f126;

$L__BB4_50:
	add.s64 	%rd56, %rd56, %rd21;
	add.s64 	%rd55, %rd55, %rd21;
	add.s32 	%r97, %r97, 1;
	setp.lt.s32 	%p65, %r97, %r34;
	@%p65 bra 	$L__BB4_38;
	bra.uni 	$L__BB4_51;

$L__BB4_5:
	add.s32 	%r47, %r34, -1;
	and.b32  	%r91, %r34, 3;
	setp.lt.u32 	%p15, %r47, 3;
	mov.u32 	%r90, 0;
	@%p15 bra 	$L__BB4_8;

	sub.s32 	%r89, %r34, %r91;
	mul.wide.s32 	%rd3, %r33, 4;
	mov.u32 	%r90, 0;

$L__BB4_7:
	mad.lo.s32 	%r49, %r90, %r33, %r3;
	mul.wide.s32 	%rd33, %r49, 4;
	add.s64 	%rd34, %rd2, %rd33;
	mov.u32 	%r50, 2143289344;
	st.global.u32 	[%rd34], %r50;
	add.s64 	%rd35, %rd34, %rd3;
	st.global.u32 	[%rd35], %r50;
	add.s64 	%rd36, %rd35, %rd3;
	st.global.u32 	[%rd36], %r50;
	add.s64 	%rd37, %rd36, %rd3;
	st.global.u32 	[%rd37], %r50;
	add.s32 	%r90, %r90, 4;
	add.s32 	%r89, %r89, -4;
	setp.ne.s32 	%p16, %r89, 0;
	@%p16 bra 	$L__BB4_7;

$L__BB4_8:
	setp.eq.s32 	%p17, %r91, 0;
	@%p17 bra 	$L__BB4_51;

	mad.lo.s32 	%r51, %r90, %r33, %r2;
	add.s32 	%r52, %r51, %r1;
	mul.wide.s32 	%rd38, %r52, 4;
	add.s64 	%rd51, %rd2, %rd38;
	mul.wide.s32 	%rd5, %r33, 4;

$L__BB4_10:
	.pragma "nounroll";
	mov.u32 	%r53, 2143289344;
	st.global.u32 	[%rd51], %r53;
	add.s64 	%rd51, %rd51, %rd5;
	add.s32 	%r91, %r91, -1;
	setp.eq.s32 	%p18, %r91, 0;
	@%p18 bra 	$L__BB4_51;
	bra.uni 	$L__BB4_10;

$L__BB4_19:
	mad.lo.s32 	%r64, %r97, %r33, %r2;
	add.s32 	%r65, %r64, %r1;
	mul.wide.s32 	%rd45, %r65, 4;
	add.s64 	%rd54, %rd2, %rd45;
	mul.wide.s32 	%rd14, %r33, 4;
	add.s64 	%rd53, %rd1, %rd45;
	mov.f32 	%f55, 0f00000000;
	mov.u16 	%rs14, 0;
	mov.u32 	%r96, 1;
	mov.f32 	%f117, %f55;
	mov.f32 	%f116, %f55;
	mov.f32 	%f107, %f55;
	mov.f32 	%f108, %f55;
	mov.f32 	%f109, %f55;
	mov.f32 	%f110, %f55;

$L__BB4_20:
	ld.global.nc.f32 	%f10, [%rd53];
	setp.eq.s32 	%p25, %r96, 1;
	mov.f32 	%f111, %f55;
	mov.f32 	%f112, %f10;
	mov.f32 	%f113, %f55;
	mov.f32 	%f114, %f10;
	@%p25 bra 	$L__BB4_26;

	setp.lt.s32 	%p26, %r97, %r25;
	abs.ftz.f32 	%f11, %f10;
	@%p26 bra 	$L__BB4_24;
	bra.uni 	$L__BB4_22;

$L__BB4_24:
	setp.geu.ftz.f32 	%p28, %f11, 0f7F800000;
	mov.f32 	%f111, %f55;
	mov.f32 	%f112, %f107;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;
	@%p28 bra 	$L__BB4_26;

	cvt.rn.f32.s32 	%f65, %r96;
	rcp.approx.ftz.f32 	%f66, %f65;
	sub.ftz.f32 	%f67, %f10, %f107;
	mul.ftz.f32 	%f68, %f66, %f67;
	sub.ftz.f32 	%f69, %f68, %f108;
	add.ftz.f32 	%f112, %f107, %f69;
	sub.ftz.f32 	%f70, %f112, %f107;
	sub.ftz.f32 	%f113, %f70, %f69;
	mov.f32 	%f111, %f55;
	mov.f32 	%f114, %f112;
	bra.uni 	$L__BB4_26;

$L__BB4_22:
	setp.geu.ftz.f32 	%p27, %f11, 0f7F800000;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, %f109;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;
	@%p27 bra 	$L__BB4_26;

	sub.ftz.f32 	%f58, %f10, %f109;
	mov.f32 	%f59, 0f00000000;
	fma.rn.ftz.f32 	%f60, %f1, %f58, %f59;
	sub.ftz.f32 	%f61, %f60, %f110;
	add.ftz.f32 	%f112, %f109, %f61;
	sub.ftz.f32 	%f62, %f112, %f109;
	sub.ftz.f32 	%f111, %f62, %f61;
	mov.f32 	%f113, %f108;
	mov.f32 	%f114, %f107;

$L__BB4_26:
	setp.lt.s32 	%p29, %r97, %r6;
	mov.f32 	%f115, 0f00000000;
	@%p29 bra 	$L__BB4_36;

	setp.ne.s16 	%p30, %rs8, 0;
	setp.gt.s32 	%p31, %r97, 0;
	and.pred  	%p32, %p30, %p31;
	selp.s32 	%r66, -1, 0, %p32;
	add.s32 	%r67, %r97, %r66;
	mad.lo.s32 	%r68, %r67, %r33, %r3;
	mul.wide.s32 	%rd46, %r68, 4;
	add.s64 	%rd47, %rd1, %rd46;
	and.b16  	%rs10, %rs14, 255;
	setp.eq.s16 	%p33, %rs10, 0;
	selp.f32 	%f20, %f112, %f117, %p33;
	selp.f32 	%f21, 0f00000000, %f116, %p33;
	selp.b16 	%rs14, 1, %rs14, %p33;
	cvt.ftz.f64.f32 	%fd5, %f112;
	cvt.ftz.f64.f32 	%fd6, %f20;
	ld.global.nc.f32 	%f22, [%rd47];
	cvt.ftz.f64.f32 	%fd7, %f22;
	abs.f64 	%fd21, %fd1;
	setp.geu.f64 	%p34, %fd21, 0d7FF0000000000000;
	@%p34 bra 	$L__BB4_35;

	abs.f64 	%fd22, %fd5;
	setp.geu.f64 	%p35, %fd22, 0d7FF0000000000000;
	@%p35 bra 	$L__BB4_35;

	abs.f64 	%fd23, %fd6;
	setp.geu.f64 	%p36, %fd23, 0d7FF0000000000000;
	@%p36 bra 	$L__BB4_35;

	abs.f64 	%fd24, %fd7;
	setp.geu.f64 	%p37, %fd24, 0d7FF0000000000000;
	@%p37 bra 	$L__BB4_35;

	mul.f64 	%fd25, %fd2, %fd6;
	fma.rn.f64 	%fd26, %fd1, %fd5, %fd25;
	sub.f64 	%fd8, %fd7, %fd26;
	sub.f64 	%fd27, %fd7, %fd6;
	mul.f64 	%fd28, %fd27, %fd1;
	mul.f64 	%fd9, %fd28, 0d3FB999999999999A;
	abs.f64 	%fd29, %fd9;
	setp.geu.f64 	%p38, %fd29, 0d7FF0000000000000;
	setp.le.f64 	%p39, %fd29, 0d0010000000000000;
	or.pred  	%p40, %p38, %p39;
	mov.f32 	%f115, %f2;
	@%p40 bra 	$L__BB4_35;

	div.rn.f64 	%fd10, %fd8, %fd9;
	setp.le.f64 	%p41, %fd10, %fd4;
	mov.f32 	%f115, %f2;
	@%p41 bra 	$L__BB4_35;

	setp.ge.f64 	%p42, %fd10, %fd3;
	mov.f32 	%f115, %f3;
	@%p42 bra 	$L__BB4_35;

	cvt.rmi.s32.f64 	%r69, %fd10;
	add.s32 	%r70, %r69, 1;
	setp.lt.s32 	%p43, %r69, %r26;
	min.s32 	%r71, %r69, %r36;
	selp.b32 	%r72, %r26, %r71, %p43;
	setp.lt.s32 	%p44, %r70, %r26;
	min.s32 	%r73, %r70, %r36;
	selp.b32 	%r74, %r26, %r73, %p44;
	cvt.rn.f64.s32 	%fd30, %r72;
	mul.f64 	%fd31, %fd9, %fd30;
	sub.f64 	%fd32, %fd8, %fd31;
	abs.f64 	%fd33, %fd32;
	cvt.rn.f64.s32 	%fd34, %r74;
	mul.f64 	%fd35, %fd9, %fd34;
	sub.f64 	%fd36, %fd8, %fd35;
	abs.f64 	%fd37, %fd36;
	setp.lt.f64 	%p45, %fd37, %fd33;
	selp.b32 	%r75, %r74, %r72, %p45;
	cvt.rn.f64.s32 	%fd38, %r75;
	mul.f64 	%fd39, %fd38, 0d3FB999999999999A;
	cvt.rn.ftz.f32.f64 	%f115, %fd39;

$L__BB4_35:
	sub.ftz.f32 	%f75, %f22, %f20;
	sub.ftz.f32 	%f76, %f112, %f20;
	fma.rn.ftz.f32 	%f77, %f75, %f115, %f76;
	mov.f32 	%f78, 0f00000000;
	fma.rn.ftz.f32 	%f79, %f1, %f77, %f78;
	sub.ftz.f32 	%f80, %f79, %f21;
	add.ftz.f32 	%f117, %f20, %f80;
	sub.ftz.f32 	%f81, %f117, %f20;
	sub.ftz.f32 	%f116, %f81, %f80;
	st.global.f32 	[%rd54], %f117;

$L__BB4_36:
	add.s32 	%r96, %r96, 1;
	add.s64 	%rd54, %rd54, %rd14;
	add.s64 	%rd53, %rd53, %rd14;
	add.s32 	%r97, %r97, 1;
	setp.lt.s32 	%p46, %r97, %r34;
	mov.f32 	%f107, %f114;
	mov.f32 	%f108, %f113;
	mov.f32 	%f109, %f112;
	mov.f32 	%f110, %f111;
	@%p46 bra 	$L__BB4_20;

$L__BB4_51:
	ret;

}

