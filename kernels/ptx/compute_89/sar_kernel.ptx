//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36424714
// Cuda compilation tools, release 13.0, V13.0.88
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_89
.address_size 64

	// .globl	sar_batch_f32

.visible .entry sar_batch_f32(
	.param .u64 sar_batch_f32_param_0,
	.param .u64 sar_batch_f32_param_1,
	.param .u32 sar_batch_f32_param_2,
	.param .u32 sar_batch_f32_param_3,
	.param .u64 sar_batch_f32_param_4,
	.param .u64 sar_batch_f32_param_5,
	.param .u32 sar_batch_f32_param_6,
	.param .u64 sar_batch_f32_param_7
)
{
	.reg .pred 	%p<61>;
	.reg .b16 	%rs<51>;
	.reg .f32 	%f<193>;
	.reg .b32 	%r<80>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd24, [sar_batch_f32_param_0];
	ld.param.u64 	%rd25, [sar_batch_f32_param_1];
	ld.param.u32 	%r33, [sar_batch_f32_param_2];
	ld.param.u32 	%r34, [sar_batch_f32_param_3];
	ld.param.u64 	%rd22, [sar_batch_f32_param_4];
	ld.param.u64 	%rd23, [sar_batch_f32_param_5];
	ld.param.u32 	%r35, [sar_batch_f32_param_6];
	ld.param.u64 	%rd26, [sar_batch_f32_param_7];
	cvta.to.global.u64 	%rd1, %rd26;
	cvta.to.global.u64 	%rd2, %rd25;
	cvta.to.global.u64 	%rd3, %rd24;
	mov.u32 	%r36, %ntid.x;
	mov.u32 	%r37, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	mad.lo.s32 	%r2, %r37, %r36, %r1;
	setp.ge.s32 	%p2, %r2, %r35;
	@%p2 bra 	$L__BB0_66;

	cvta.to.global.u64 	%rd27, %rd22;
	mul.lo.s32 	%r3, %r2, %r33;
	mul.wide.s32 	%rd28, %r2, 4;
	add.s64 	%rd29, %rd27, %rd28;
	ld.global.nc.f32 	%f1, [%rd29];
	cvta.to.global.u64 	%rd30, %rd23;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f2, [%rd31];
	add.s32 	%r78, %r34, 1;
	min.s32 	%r5, %r78, %r33;
	setp.lt.s32 	%p3, %r5, 1;
	@%p3 bra 	$L__BB0_8;

	not.b32 	%r39, %r33;
	mov.u32 	%r40, -2;
	sub.s32 	%r41, %r40, %r34;
	max.s32 	%r42, %r41, %r39;
	sub.s32 	%r43, %r40, %r42;
	and.b32  	%r72, %r5, 3;
	setp.lt.u32 	%p4, %r43, 3;
	mov.u32 	%r71, 0;
	@%p4 bra 	$L__BB0_5;

	sub.s32 	%r70, %r5, %r72;
	mov.u32 	%r71, 0;

$L__BB0_4:
	add.s32 	%r45, %r71, %r3;
	mul.wide.s32 	%rd32, %r45, 4;
	add.s64 	%rd33, %rd1, %rd32;
	mov.u32 	%r46, 2147483647;
	st.global.u32 	[%rd33], %r46;
	st.global.u32 	[%rd33+4], %r46;
	st.global.u32 	[%rd33+8], %r46;
	st.global.u32 	[%rd33+12], %r46;
	add.s32 	%r71, %r71, 4;
	add.s32 	%r70, %r70, -4;
	setp.ne.s32 	%p5, %r70, 0;
	@%p5 bra 	$L__BB0_4;

$L__BB0_5:
	setp.eq.s32 	%p6, %r72, 0;
	@%p6 bra 	$L__BB0_8;

	add.s32 	%r47, %r71, %r3;
	mul.wide.s32 	%rd34, %r47, 4;
	add.s64 	%rd44, %rd1, %rd34;

$L__BB0_7:
	.pragma "nounroll";
	mov.u32 	%r48, 2147483647;
	st.global.u32 	[%rd44], %r48;
	add.s64 	%rd44, %rd44, 4;
	add.s32 	%r72, %r72, -1;
	setp.ne.s32 	%p7, %r72, 0;
	@%p7 bra 	$L__BB0_7;

$L__BB0_8:
	setp.ge.s32 	%p8, %r78, %r33;
	@%p8 bra 	$L__BB0_66;

	setp.le.ftz.f32 	%p9, %f1, 0f00000000;
	setp.le.ftz.f32 	%p10, %f2, 0f00000000;
	or.pred  	%p11, %p9, %p10;
	@%p11 bra 	$L__BB0_60;
	bra.uni 	$L__BB0_10;

$L__BB0_60:
	not.b32 	%r59, %r34;
	add.s32 	%r60, %r59, %r33;
	and.b32  	%r77, %r60, 3;
	setp.eq.s32 	%p57, %r77, 0;
	@%p57 bra 	$L__BB0_63;

	add.s32 	%r61, %r34, %r3;
	add.s32 	%r62, %r61, 1;
	mul.wide.s32 	%rd42, %r62, 4;
	add.s64 	%rd48, %rd1, %rd42;

$L__BB0_62:
	.pragma "nounroll";
	mov.u32 	%r63, 2147483647;
	st.global.u32 	[%rd48], %r63;
	add.s32 	%r78, %r78, 1;
	add.s64 	%rd48, %rd48, 4;
	add.s32 	%r77, %r77, -1;
	setp.ne.s32 	%p58, %r77, 0;
	@%p58 bra 	$L__BB0_62;

$L__BB0_63:
	add.s32 	%r64, %r33, -2;
	sub.s32 	%r65, %r64, %r34;
	setp.lt.u32 	%p59, %r65, 3;
	@%p59 bra 	$L__BB0_66;

	add.s32 	%r66, %r78, %r3;
	mul.wide.s32 	%rd43, %r66, 4;
	add.s64 	%rd49, %rd1, %rd43;

$L__BB0_65:
	mov.u32 	%r67, 2147483647;
	st.global.u32 	[%rd49], %r67;
	st.global.u32 	[%rd49+4], %r67;
	st.global.u32 	[%rd49+8], %r67;
	st.global.u32 	[%rd49+12], %r67;
	add.s64 	%rd49, %rd49, 16;
	add.s32 	%r78, %r78, 4;
	setp.lt.s32 	%p60, %r78, %r33;
	@%p60 bra 	$L__BB0_65;
	bra.uni 	$L__BB0_66;

$L__BB0_10:
	mul.wide.s32 	%rd35, %r34, 4;
	add.s64 	%rd36, %rd3, %rd35;
	add.s64 	%rd37, %rd2, %rd35;
	ld.global.nc.f32 	%f165, [%rd36+4];
	ld.global.nc.f32 	%f166, [%rd36];
	setp.gt.ftz.f32 	%p1, %f165, %f166;
	ld.global.nc.f32 	%f168, [%rd37];
	selp.f32 	%f191, %f168, %f166, %p1;
	ld.global.nc.f32 	%f167, [%rd37+4];
	mov.f32 	%f9, 0f00000000;
	add.ftz.f32 	%f91, %f191, 0f00000000;
	add.s32 	%r49, %r34, %r3;
	mul.wide.s32 	%rd38, %r49, 4;
	add.s64 	%rd39, %rd1, %rd38;
	st.global.f32 	[%rd39+4], %f91;
	add.s32 	%r73, %r34, 2;
	setp.ge.s32 	%p12, %r73, %r33;
	@%p12 bra 	$L__BB0_66;

	selp.f32 	%f187, %f165, %f167, %p1;
	mov.f32 	%f188, 0f00000000;
	selp.u16 	%rs50, 1, 0, %p1;
	and.b32  	%r16, %r1, 31;
	mul.wide.s32 	%rd40, %r73, 4;
	add.s64 	%rd47, %rd2, %rd40;
	add.s64 	%rd46, %rd3, %rd40;
	add.s32 	%r51, %r49, 2;
	mul.wide.s32 	%rd41, %r51, 4;
	add.s64 	%rd45, %rd1, %rd41;
	mov.f32 	%f20, %f1;
	mov.f32 	%f21, %f9;
	mov.f32 	%f192, %f188;

$L__BB0_12:
	.pragma "nounroll";
	mov.f32 	%f23, %f188;
	mov.f32 	%f22, %f187;
	mov.f32 	%f19, %f168;
	mov.f32 	%f168, %f167;
	mov.f32 	%f17, %f166;
	mov.f32 	%f166, %f165;
	// begin inline asm
	activemask.b32 %r52;
	// end inline asm
	brev.b32 	%r55, %r52;
	bfind.shiftamt.u32 	%r19, %r55;
	setp.ne.s32 	%p14, %r16, %r19;
	mov.u32 	%r74, 0;
	mov.u32 	%r75, %r74;
	@%p14 bra 	$L__BB0_14;

	ld.global.nc.u32 	%r74, [%rd46];
	ld.global.nc.u32 	%r75, [%rd47];

$L__BB0_14:
	mov.u32 	%r56, 31;
	shfl.sync.idx.b32 	%r57|%p15, %r74, %r19, %r56, %r52;
	mov.b32 	%f165, %r57;
	shfl.sync.idx.b32 	%r58|%p16, %r75, %r19, %r56, %r52;
	mov.b32 	%f167, %r58;
	neg.ftz.f32 	%f92, %f191;
	sub.ftz.f32 	%f93, %f22, %f191;
	sub.ftz.f32 	%f94, %f93, %f22;
	sub.ftz.f32 	%f95, %f93, %f94;
	sub.ftz.f32 	%f96, %f22, %f95;
	sub.ftz.f32 	%f97, %f92, %f94;
	add.ftz.f32 	%f98, %f97, %f96;
	sub.ftz.f32 	%f99, %f23, %f192;
	add.ftz.f32 	%f100, %f99, %f98;
	add.ftz.f32 	%f101, %f93, %f100;
	sub.ftz.f32 	%f102, %f101, %f93;
	sub.ftz.f32 	%f103, %f101, %f102;
	sub.ftz.f32 	%f104, %f93, %f103;
	sub.ftz.f32 	%f105, %f100, %f102;
	add.ftz.f32 	%f106, %f105, %f104;
	mul.ftz.f32 	%f107, %f20, %f101;
	neg.ftz.f32 	%f108, %f107;
	fma.rn.ftz.f32 	%f109, %f20, %f101, %f108;
	mul.ftz.f32 	%f110, %f21, %f101;
	fma.rn.ftz.f32 	%f111, %f20, %f106, %f110;
	add.ftz.f32 	%f112, %f109, %f111;
	add.ftz.f32 	%f113, %f107, %f112;
	sub.ftz.f32 	%f114, %f113, %f107;
	sub.ftz.f32 	%f115, %f113, %f114;
	sub.ftz.f32 	%f116, %f107, %f115;
	sub.ftz.f32 	%f117, %f112, %f114;
	add.ftz.f32 	%f118, %f117, %f116;
	fma.rn.ftz.f32 	%f119, %f21, %f106, %f118;
	add.ftz.f32 	%f120, %f113, %f119;
	sub.ftz.f32 	%f121, %f120, %f113;
	sub.ftz.f32 	%f122, %f120, %f121;
	sub.ftz.f32 	%f123, %f113, %f122;
	sub.ftz.f32 	%f124, %f119, %f121;
	add.ftz.f32 	%f125, %f124, %f123;
	add.ftz.f32 	%f126, %f191, %f120;
	sub.ftz.f32 	%f127, %f126, %f120;
	sub.ftz.f32 	%f128, %f126, %f127;
	sub.ftz.f32 	%f129, %f120, %f128;
	sub.ftz.f32 	%f130, %f191, %f127;
	add.ftz.f32 	%f131, %f130, %f129;
	add.ftz.f32 	%f132, %f192, %f125;
	add.ftz.f32 	%f133, %f131, %f132;
	add.ftz.f32 	%f191, %f126, %f133;
	sub.ftz.f32 	%f134, %f191, %f126;
	sub.ftz.f32 	%f135, %f191, %f134;
	sub.ftz.f32 	%f136, %f126, %f135;
	sub.ftz.f32 	%f137, %f133, %f134;
	add.ftz.f32 	%f192, %f137, %f136;
	and.b16  	%rs20, %rs50, 255;
	setp.eq.s16 	%p17, %rs20, 0;
	@%p17 bra 	$L__BB0_38;

	setp.gt.ftz.f32 	%p18, %f191, %f167;
	mov.u16 	%rs42, 1;
	@%p18 bra 	$L__BB0_18;

	setp.lt.ftz.f32 	%p19, %f191, %f167;
	mov.u16 	%rs42, 0;
	@%p19 bra 	$L__BB0_18;

	setp.gt.ftz.f32 	%p20, %f192, 0f00000000;
	selp.u16 	%rs42, 1, 0, %p20;

$L__BB0_18:
	setp.eq.s16 	%p21, %rs42, 0;
	@%p21 bra 	$L__BB0_20;

	mov.f32 	%f188, 0f00000000;
	mov.u16 	%rs50, 0;
	mov.f32 	%f187, %f167;
	mov.f32 	%f20, %f1;
	mov.f32 	%f21, %f9;
	mov.f32 	%f191, %f22;
	mov.f32 	%f192, %f23;
	bra.uni 	$L__BB0_59;

$L__BB0_38:
	setp.lt.ftz.f32 	%p36, %f191, %f165;
	mov.u16 	%rs45, 1;
	@%p36 bra 	$L__BB0_41;

	setp.gt.ftz.f32 	%p37, %f191, %f165;
	mov.u16 	%rs45, 0;
	@%p37 bra 	$L__BB0_41;

	setp.lt.ftz.f32 	%p38, %f192, 0f00000000;
	selp.u16 	%rs45, 1, 0, %p38;

$L__BB0_41:
	setp.eq.s16 	%p39, %rs45, 0;
	@%p39 bra 	$L__BB0_43;

	mov.f32 	%f188, 0f00000000;
	mov.u16 	%rs50, 1;
	mov.f32 	%f187, %f165;
	mov.f32 	%f20, %f1;
	mov.f32 	%f21, %f9;
	mov.f32 	%f191, %f22;
	mov.f32 	%f192, %f23;
	bra.uni 	$L__BB0_59;

$L__BB0_20:
	setp.lt.ftz.f32 	%p22, %f22, %f165;
	mov.u16 	%rs43, 1;
	@%p22 bra 	$L__BB0_23;

	setp.gt.ftz.f32 	%p23, %f22, %f165;
	mov.u16 	%rs43, 0;
	@%p23 bra 	$L__BB0_23;

	setp.lt.ftz.f32 	%p24, %f23, 0f00000000;
	selp.u16 	%rs43, 1, 0, %p24;

$L__BB0_23:
	setp.eq.s16 	%p25, %rs43, 0;
	@%p25 bra 	$L__BB0_28;

	add.ftz.f32 	%f138, %f1, %f20;
	sub.ftz.f32 	%f139, %f138, %f20;
	sub.ftz.f32 	%f140, %f138, %f139;
	sub.ftz.f32 	%f141, %f20, %f140;
	sub.ftz.f32 	%f142, %f1, %f139;
	add.ftz.f32 	%f143, %f142, %f141;
	add.ftz.f32 	%f144, %f21, 0f00000000;
	add.ftz.f32 	%f145, %f144, %f143;
	add.ftz.f32 	%f38, %f138, %f145;
	sub.ftz.f32 	%f146, %f38, %f138;
	sub.ftz.f32 	%f147, %f38, %f146;
	sub.ftz.f32 	%f148, %f138, %f147;
	sub.ftz.f32 	%f149, %f145, %f146;
	add.ftz.f32 	%f39, %f149, %f148;
	setp.gt.ftz.f32 	%p26, %f38, %f2;
	mov.u16 	%rs44, 1;
	@%p26 bra 	$L__BB0_27;

	setp.lt.ftz.f32 	%p27, %f38, %f2;
	mov.u16 	%rs44, 0;
	@%p27 bra 	$L__BB0_27;

	setp.gt.ftz.f32 	%p28, %f39, 0f00000000;
	selp.u16 	%rs44, 1, 0, %p28;

$L__BB0_27:
	setp.eq.s16 	%p29, %rs44, 0;
	selp.f32 	%f21, %f39, %f9, %p29;
	selp.f32 	%f20, %f38, %f2, %p29;
	mov.f32 	%f23, 0f00000000;
	mov.f32 	%f22, %f165;

$L__BB0_28:
	mov.f32 	%f188, %f23;
	mov.f32 	%f187, %f22;
	setp.lt.ftz.f32 	%p30, %f191, %f168;
	@%p30 bra 	$L__BB0_33;

	setp.gt.ftz.f32 	%p31, %f191, %f168;
	mov.f32 	%f163, 0f00000000;
	@%p31 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_30;

$L__BB0_32:
	mov.f32 	%f191, %f168;
	mov.f32 	%f192, %f163;
	bra.uni 	$L__BB0_33;

$L__BB0_43:
	setp.gt.ftz.f32 	%p40, %f22, %f167;
	mov.u16 	%rs46, 1;
	@%p40 bra 	$L__BB0_46;

	setp.lt.ftz.f32 	%p41, %f22, %f167;
	mov.u16 	%rs46, 0;
	@%p41 bra 	$L__BB0_46;

	setp.gt.ftz.f32 	%p42, %f23, 0f00000000;
	selp.u16 	%rs46, 1, 0, %p42;

$L__BB0_46:
	setp.eq.s16 	%p43, %rs46, 0;
	@%p43 bra 	$L__BB0_51;

	add.ftz.f32 	%f150, %f1, %f20;
	sub.ftz.f32 	%f151, %f150, %f20;
	sub.ftz.f32 	%f152, %f150, %f151;
	sub.ftz.f32 	%f153, %f20, %f152;
	sub.ftz.f32 	%f154, %f1, %f151;
	add.ftz.f32 	%f155, %f154, %f153;
	add.ftz.f32 	%f156, %f21, 0f00000000;
	add.ftz.f32 	%f157, %f156, %f155;
	add.ftz.f32 	%f70, %f150, %f157;
	sub.ftz.f32 	%f158, %f70, %f150;
	sub.ftz.f32 	%f159, %f70, %f158;
	sub.ftz.f32 	%f160, %f150, %f159;
	sub.ftz.f32 	%f161, %f157, %f158;
	add.ftz.f32 	%f71, %f161, %f160;
	setp.gt.ftz.f32 	%p44, %f70, %f2;
	mov.u16 	%rs47, 1;
	@%p44 bra 	$L__BB0_50;

	setp.lt.ftz.f32 	%p45, %f70, %f2;
	mov.u16 	%rs47, 0;
	@%p45 bra 	$L__BB0_50;

	setp.gt.ftz.f32 	%p46, %f71, 0f00000000;
	selp.u16 	%rs47, 1, 0, %p46;

$L__BB0_50:
	setp.eq.s16 	%p47, %rs47, 0;
	selp.f32 	%f21, %f71, %f9, %p47;
	selp.f32 	%f20, %f70, %f2, %p47;
	mov.f32 	%f23, 0f00000000;
	mov.f32 	%f22, %f167;

$L__BB0_51:
	mov.f32 	%f188, %f23;
	mov.f32 	%f187, %f22;
	setp.lt.ftz.f32 	%p48, %f191, %f166;
	mov.u16 	%rs49, 1;
	mov.u16 	%rs48, %rs49;
	@%p48 bra 	$L__BB0_54;

	setp.gt.ftz.f32 	%p49, %f191, %f166;
	mov.u16 	%rs48, 0;
	@%p49 bra 	$L__BB0_54;

	setp.lt.ftz.f32 	%p50, %f192, 0f00000000;
	selp.u16 	%rs48, 1, 0, %p50;

$L__BB0_54:
	setp.eq.s16 	%p51, %rs48, 0;
	selp.f32 	%f191, %f191, %f166, %p51;
	selp.f32 	%f192, %f192, 0f00000000, %p51;
	setp.lt.ftz.f32 	%p52, %f191, %f17;
	@%p52 bra 	$L__BB0_57;

	setp.gt.ftz.f32 	%p53, %f191, %f17;
	mov.u16 	%rs49, 0;
	@%p53 bra 	$L__BB0_57;

	setp.lt.ftz.f32 	%p54, %f192, 0f00000000;
	selp.u16 	%rs49, 1, 0, %p54;

$L__BB0_57:
	setp.eq.s16 	%p55, %rs49, 0;
	mov.u16 	%rs50, 0;
	@%p55 bra 	$L__BB0_59;

	mov.f32 	%f192, 0f00000000;
	mov.f32 	%f191, %f17;
	bra.uni 	$L__BB0_59;

$L__BB0_30:
	setp.le.ftz.f32 	%p32, %f192, 0f00000000;
	@%p32 bra 	$L__BB0_33;

	mov.f32 	%f191, %f168;
	mov.f32 	%f192, %f163;

$L__BB0_33:
	setp.lt.ftz.f32 	%p33, %f191, %f19;
	@%p33 bra 	$L__BB0_59;

	setp.gt.ftz.f32 	%p34, %f191, %f19;
	mov.f32 	%f164, 0f00000000;
	@%p34 bra 	$L__BB0_37;
	bra.uni 	$L__BB0_35;

$L__BB0_37:
	mov.f32 	%f191, %f19;
	mov.f32 	%f192, %f164;
	bra.uni 	$L__BB0_59;

$L__BB0_35:
	setp.gtu.ftz.f32 	%p35, %f192, 0f00000000;
	@%p35 bra 	$L__BB0_36;
	bra.uni 	$L__BB0_59;

$L__BB0_36:
	mov.f32 	%f191, %f19;
	mov.f32 	%f192, %f164;

$L__BB0_59:
	ld.param.u32 	%r68, [sar_batch_f32_param_2];
	add.ftz.f32 	%f162, %f191, %f192;
	st.global.f32 	[%rd45], %f162;
	add.s64 	%rd47, %rd47, 4;
	add.s64 	%rd46, %rd46, 4;
	add.s64 	%rd45, %rd45, 4;
	add.s32 	%r73, %r73, 1;
	setp.lt.s32 	%p56, %r73, %r68;
	@%p56 bra 	$L__BB0_12;

$L__BB0_66:
	ret;

}
	// .globl	sar_many_series_one_param_time_major_f32
.visible .entry sar_many_series_one_param_time_major_f32(
	.param .u64 sar_many_series_one_param_time_major_f32_param_0,
	.param .u64 sar_many_series_one_param_time_major_f32_param_1,
	.param .u64 sar_many_series_one_param_time_major_f32_param_2,
	.param .u32 sar_many_series_one_param_time_major_f32_param_3,
	.param .u32 sar_many_series_one_param_time_major_f32_param_4,
	.param .f32 sar_many_series_one_param_time_major_f32_param_5,
	.param .f32 sar_many_series_one_param_time_major_f32_param_6,
	.param .u64 sar_many_series_one_param_time_major_f32_param_7
)
{
	.reg .pred 	%p<44>;
	.reg .b16 	%rs<38>;
	.reg .f32 	%f<181>;
	.reg .b32 	%r<45>;
	.reg .b64 	%rd<59>;


	ld.param.u64 	%rd33, [sar_many_series_one_param_time_major_f32_param_0];
	ld.param.u64 	%rd34, [sar_many_series_one_param_time_major_f32_param_1];
	ld.param.u64 	%rd32, [sar_many_series_one_param_time_major_f32_param_2];
	ld.param.u32 	%r22, [sar_many_series_one_param_time_major_f32_param_3];
	ld.param.u32 	%r23, [sar_many_series_one_param_time_major_f32_param_4];
	ld.param.f32 	%f98, [sar_many_series_one_param_time_major_f32_param_5];
	ld.param.f32 	%f99, [sar_many_series_one_param_time_major_f32_param_6];
	ld.param.u64 	%rd35, [sar_many_series_one_param_time_major_f32_param_7];
	cvta.to.global.u64 	%rd1, %rd35;
	cvta.to.global.u64 	%rd2, %rd34;
	cvta.to.global.u64 	%rd3, %rd33;
	mov.u32 	%r24, %ntid.y;
	mov.u32 	%r25, %ctaid.y;
	mov.u32 	%r26, %tid.y;
	mad.lo.s32 	%r1, %r25, %r24, %r26;
	setp.ge.s32 	%p1, %r1, %r22;
	@%p1 bra 	$L__BB1_61;

	cvta.to.global.u64 	%rd36, %rd32;
	mul.wide.s32 	%rd37, %r1, 4;
	add.s64 	%rd38, %rd36, %rd37;
	ld.global.nc.u32 	%r2, [%rd38];
	setp.lt.s32 	%p2, %r2, 0;
	setp.ge.s32 	%p3, %r2, %r23;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB1_58;
	bra.uni 	$L__BB1_2;

$L__BB1_58:
	mov.u32 	%r44, %tid.x;
	setp.ge.s32 	%p42, %r44, %r23;
	@%p42 bra 	$L__BB1_61;

	mov.u32 	%r19, %ntid.x;

$L__BB1_60:
	mad.lo.s32 	%r37, %r44, %r22, %r1;
	mul.wide.s32 	%rd51, %r37, 4;
	add.s64 	%rd52, %rd1, %rd51;
	mov.u32 	%r38, 2147483647;
	st.global.u32 	[%rd52], %r38;
	add.s32 	%r44, %r44, %r19;
	setp.lt.s32 	%p43, %r44, %r23;
	@%p43 bra 	$L__BB1_60;
	bra.uni 	$L__BB1_61;

$L__BB1_2:
	add.s32 	%r3, %r2, 1;
	min.s32 	%r4, %r3, %r23;
	mov.u32 	%r5, %tid.x;
	setp.ge.s32 	%p5, %r5, %r4;
	@%p5 bra 	$L__BB1_5;

	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r39, %r5;

$L__BB1_4:
	mad.lo.s32 	%r27, %r39, %r22, %r1;
	mul.wide.s32 	%rd39, %r27, 4;
	add.s64 	%rd40, %rd1, %rd39;
	mov.u32 	%r28, 2147483647;
	st.global.u32 	[%rd40], %r28;
	add.s32 	%r39, %r39, %r6;
	setp.lt.s32 	%p6, %r39, %r4;
	@%p6 bra 	$L__BB1_4;

$L__BB1_5:
	setp.ne.s32 	%p7, %r5, 0;
	setp.ge.s32 	%p8, %r3, %r23;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB1_61;

	mad.lo.s32 	%r29, %r2, %r22, %r1;
	mul.wide.s32 	%rd41, %r29, 4;
	add.s64 	%rd42, %rd3, %rd41;
	add.s32 	%r30, %r29, %r22;
	mul.wide.s32 	%rd43, %r30, 4;
	add.s64 	%rd44, %rd3, %rd43;
	add.s64 	%rd45, %rd2, %rd41;
	add.s64 	%rd46, %rd2, %rd43;
	ld.global.nc.f32 	%f146, [%rd44];
	ld.global.nc.f32 	%f147, [%rd42];
	setp.gt.ftz.f32 	%p10, %f146, %f147;
	ld.global.nc.f32 	%f142, [%rd45];
	selp.f32 	%f180, %f142, %f147, %p10;
	ld.global.nc.f32 	%f141, [%rd46];
	selp.f32 	%f178, %f146, %f141, %p10;
	add.s64 	%rd47, %rd1, %rd43;
	st.global.f32 	[%rd47], %f180;
	add.s32 	%r42, %r2, 2;
	setp.ge.s32 	%p11, %r42, %r23;
	@%p11 bra 	$L__BB1_61;

	selp.u16 	%rs31, 1, 0, %p10;
	add.s32 	%r31, %r23, 2;
	sub.s32 	%r32, %r31, %r2;
	and.b32  	%r41, %r32, 3;
	setp.eq.s32 	%p13, %r41, 0;
	mov.f32 	%f179, %f98;
	@%p13 bra 	$L__BB1_19;

	mad.lo.s32 	%r33, %r22, %r42, %r1;
	mul.wide.s32 	%rd48, %r33, 4;
	add.s64 	%rd55, %rd1, %rd48;
	mul.wide.s32 	%rd5, %r22, 4;
	add.s64 	%rd54, %rd2, %rd48;
	add.s64 	%rd53, %rd3, %rd48;
	mov.f32 	%f179, %f98;

$L__BB1_9:
	.pragma "nounroll";
	mov.u16 	%rs2, %rs31;
	mov.f32 	%f132, %f178;
	mov.f32 	%f133, %f179;
	mov.f32 	%f10, %f142;
	mov.f32 	%f142, %f141;
	mov.f32 	%f8, %f147;
	mov.f32 	%f147, %f146;
	ld.global.nc.f32 	%f146, [%rd53];
	ld.global.nc.f32 	%f141, [%rd54];
	sub.ftz.f32 	%f100, %f132, %f180;
	fma.rn.ftz.f32 	%f16, %f133, %f100, %f180;
	and.b16  	%rs10, %rs2, 255;
	setp.eq.s16 	%p14, %rs10, 0;
	@%p14 bra 	$L__BB1_14;
	bra.uni 	$L__BB1_10;

$L__BB1_14:
	setp.gt.ftz.f32 	%p17, %f146, %f16;
	mov.u16 	%rs31, 1;
	mov.f32 	%f178, %f146;
	mov.f32 	%f179, %f98;
	mov.f32 	%f180, %f132;
	@%p17 bra 	$L__BB1_18;

	setp.geu.ftz.f32 	%p18, %f141, %f132;
	@%p18 bra 	$L__BB1_17;

	add.ftz.f32 	%f103, %f133, %f98;
	min.ftz.f32 	%f133, %f103, %f99;
	mov.f32 	%f132, %f141;

$L__BB1_17:
	max.ftz.f32 	%f104, %f147, %f8;
	max.ftz.f32 	%f180, %f16, %f104;
	mov.u16 	%rs31, 0;
	mov.f32 	%f178, %f132;
	mov.f32 	%f179, %f133;
	bra.uni 	$L__BB1_18;

$L__BB1_10:
	setp.lt.ftz.f32 	%p15, %f141, %f16;
	mov.u16 	%rs31, 0;
	mov.f32 	%f178, %f141;
	mov.f32 	%f179, %f98;
	mov.f32 	%f180, %f132;
	@%p15 bra 	$L__BB1_18;

	setp.leu.ftz.f32 	%p16, %f146, %f132;
	@%p16 bra 	$L__BB1_13;

	add.ftz.f32 	%f101, %f133, %f98;
	min.ftz.f32 	%f133, %f101, %f99;
	mov.f32 	%f132, %f146;

$L__BB1_13:
	min.ftz.f32 	%f102, %f142, %f10;
	min.ftz.f32 	%f180, %f16, %f102;
	mov.u16 	%rs31, %rs2;
	mov.f32 	%f178, %f132;
	mov.f32 	%f179, %f133;

$L__BB1_18:
	st.global.f32 	[%rd55], %f180;
	add.s32 	%r42, %r42, 1;
	add.s64 	%rd55, %rd55, %rd5;
	add.s64 	%rd54, %rd54, %rd5;
	add.s64 	%rd53, %rd53, %rd5;
	add.s32 	%r41, %r41, -1;
	setp.ne.s32 	%p19, %r41, 0;
	@%p19 bra 	$L__BB1_9;

$L__BB1_19:
	add.s32 	%r34, %r23, -3;
	sub.s32 	%r35, %r34, %r2;
	setp.lt.u32 	%p20, %r35, 3;
	@%p20 bra 	$L__BB1_61;

	mad.lo.s32 	%r36, %r42, %r22, %r1;
	mul.wide.s32 	%rd49, %r36, 4;
	add.s64 	%rd56, %rd1, %rd49;
	mul.wide.s32 	%rd15, %r22, 4;
	add.s64 	%rd57, %rd3, %rd49;
	add.s64 	%rd58, %rd2, %rd49;

$L__BB1_21:
	ld.global.nc.f32 	%f42, [%rd57];
	ld.global.nc.f32 	%f43, [%rd58];
	sub.ftz.f32 	%f105, %f178, %f180;
	fma.rn.ftz.f32 	%f44, %f179, %f105, %f180;
	and.b16  	%rs14, %rs31, 255;
	setp.eq.s16 	%p21, %rs14, 0;
	@%p21 bra 	$L__BB1_26;
	bra.uni 	$L__BB1_22;

$L__BB1_26:
	setp.gt.ftz.f32 	%p24, %f42, %f44;
	mov.u16 	%rs34, 1;
	mov.f32 	%f157, %f42;
	mov.f32 	%f158, %f98;
	@%p24 bra 	$L__BB1_30;

	setp.geu.ftz.f32 	%p25, %f43, %f178;
	@%p25 bra 	$L__BB1_29;

	add.ftz.f32 	%f108, %f179, %f98;
	min.ftz.f32 	%f179, %f108, %f99;
	mov.f32 	%f178, %f43;

$L__BB1_29:
	max.ftz.f32 	%f109, %f146, %f147;
	max.ftz.f32 	%f52, %f44, %f109;
	mov.u16 	%rs34, 0;
	mov.f32 	%f157, %f178;
	mov.f32 	%f158, %f179;
	mov.f32 	%f178, %f52;
	bra.uni 	$L__BB1_30;

$L__BB1_22:
	setp.lt.ftz.f32 	%p22, %f43, %f44;
	mov.u16 	%rs34, 0;
	mov.f32 	%f157, %f43;
	mov.f32 	%f158, %f98;
	@%p22 bra 	$L__BB1_30;

	setp.leu.ftz.f32 	%p23, %f42, %f178;
	@%p23 bra 	$L__BB1_25;

	add.ftz.f32 	%f106, %f179, %f98;
	min.ftz.f32 	%f179, %f106, %f99;
	mov.f32 	%f178, %f42;

$L__BB1_25:
	min.ftz.f32 	%f107, %f141, %f142;
	min.ftz.f32 	%f48, %f44, %f107;
	mov.u16 	%rs34, %rs31;
	mov.f32 	%f157, %f178;
	mov.f32 	%f158, %f179;
	mov.f32 	%f178, %f48;

$L__BB1_30:
	st.global.f32 	[%rd56], %f178;
	add.s64 	%rd21, %rd57, %rd15;
	ld.global.nc.f32 	%f56, [%rd21];
	add.s64 	%rd22, %rd58, %rd15;
	ld.global.nc.f32 	%f57, [%rd22];
	sub.ftz.f32 	%f110, %f157, %f178;
	fma.rn.ftz.f32 	%f58, %f158, %f110, %f178;
	and.b16  	%rs18, %rs34, 255;
	setp.eq.s16 	%p26, %rs18, 0;
	@%p26 bra 	$L__BB1_35;
	bra.uni 	$L__BB1_31;

$L__BB1_35:
	setp.gt.ftz.f32 	%p29, %f56, %f58;
	mov.u16 	%rs35, 1;
	mov.f32 	%f164, %f56;
	mov.f32 	%f165, %f98;
	@%p29 bra 	$L__BB1_39;

	setp.geu.ftz.f32 	%p30, %f57, %f157;
	@%p30 bra 	$L__BB1_38;

	add.ftz.f32 	%f113, %f158, %f98;
	min.ftz.f32 	%f158, %f113, %f99;
	mov.f32 	%f157, %f57;

$L__BB1_38:
	max.ftz.f32 	%f114, %f42, %f146;
	max.ftz.f32 	%f66, %f58, %f114;
	mov.u16 	%rs35, 0;
	mov.f32 	%f164, %f157;
	mov.f32 	%f165, %f158;
	mov.f32 	%f157, %f66;
	bra.uni 	$L__BB1_39;

$L__BB1_31:
	setp.lt.ftz.f32 	%p27, %f57, %f58;
	mov.u16 	%rs35, 0;
	mov.f32 	%f164, %f57;
	mov.f32 	%f165, %f98;
	@%p27 bra 	$L__BB1_39;

	setp.leu.ftz.f32 	%p28, %f56, %f157;
	@%p28 bra 	$L__BB1_34;

	add.ftz.f32 	%f111, %f158, %f98;
	min.ftz.f32 	%f158, %f111, %f99;
	mov.f32 	%f157, %f56;

$L__BB1_34:
	min.ftz.f32 	%f112, %f43, %f141;
	min.ftz.f32 	%f62, %f58, %f112;
	mov.u16 	%rs35, %rs34;
	mov.f32 	%f164, %f157;
	mov.f32 	%f165, %f158;
	mov.f32 	%f157, %f62;

$L__BB1_39:
	add.s64 	%rd23, %rd56, %rd15;
	st.global.f32 	[%rd23], %f157;
	add.s64 	%rd24, %rd21, %rd15;
	ld.global.nc.f32 	%f147, [%rd24];
	add.s64 	%rd25, %rd22, %rd15;
	ld.global.nc.f32 	%f142, [%rd25];
	sub.ftz.f32 	%f115, %f164, %f157;
	fma.rn.ftz.f32 	%f72, %f165, %f115, %f157;
	and.b16  	%rs22, %rs35, 255;
	setp.eq.s16 	%p31, %rs22, 0;
	@%p31 bra 	$L__BB1_44;
	bra.uni 	$L__BB1_40;

$L__BB1_44:
	setp.gt.ftz.f32 	%p34, %f147, %f72;
	mov.u16 	%rs36, 1;
	mov.f32 	%f180, %f147;
	mov.f32 	%f172, %f98;
	@%p34 bra 	$L__BB1_48;

	setp.geu.ftz.f32 	%p35, %f142, %f164;
	@%p35 bra 	$L__BB1_47;

	add.ftz.f32 	%f118, %f165, %f98;
	min.ftz.f32 	%f165, %f118, %f99;
	mov.f32 	%f164, %f142;

$L__BB1_47:
	max.ftz.f32 	%f119, %f56, %f42;
	max.ftz.f32 	%f80, %f72, %f119;
	mov.u16 	%rs36, 0;
	mov.f32 	%f180, %f164;
	mov.f32 	%f172, %f165;
	mov.f32 	%f164, %f80;
	bra.uni 	$L__BB1_48;

$L__BB1_40:
	setp.lt.ftz.f32 	%p32, %f142, %f72;
	mov.u16 	%rs36, 0;
	mov.f32 	%f180, %f142;
	mov.f32 	%f172, %f98;
	@%p32 bra 	$L__BB1_48;

	setp.leu.ftz.f32 	%p33, %f147, %f164;
	@%p33 bra 	$L__BB1_43;

	add.ftz.f32 	%f116, %f165, %f98;
	min.ftz.f32 	%f165, %f116, %f99;
	mov.f32 	%f164, %f147;

$L__BB1_43:
	min.ftz.f32 	%f117, %f57, %f43;
	min.ftz.f32 	%f76, %f72, %f117;
	mov.u16 	%rs36, %rs35;
	mov.f32 	%f180, %f164;
	mov.f32 	%f172, %f165;
	mov.f32 	%f164, %f76;

$L__BB1_48:
	add.s64 	%rd26, %rd23, %rd15;
	st.global.f32 	[%rd26], %f164;
	add.s64 	%rd27, %rd24, %rd15;
	ld.global.nc.f32 	%f146, [%rd27];
	add.s64 	%rd28, %rd25, %rd15;
	ld.global.nc.f32 	%f141, [%rd28];
	sub.ftz.f32 	%f120, %f180, %f164;
	fma.rn.ftz.f32 	%f86, %f172, %f120, %f164;
	and.b16  	%rs26, %rs36, 255;
	setp.eq.s16 	%p36, %rs26, 0;
	@%p36 bra 	$L__BB1_53;
	bra.uni 	$L__BB1_49;

$L__BB1_53:
	setp.gt.ftz.f32 	%p39, %f146, %f86;
	mov.u16 	%rs31, 1;
	mov.f32 	%f178, %f146;
	mov.f32 	%f179, %f98;
	@%p39 bra 	$L__BB1_57;

	setp.geu.ftz.f32 	%p40, %f141, %f180;
	@%p40 bra 	$L__BB1_56;

	add.ftz.f32 	%f123, %f172, %f98;
	min.ftz.f32 	%f172, %f123, %f99;
	mov.f32 	%f180, %f141;

$L__BB1_56:
	max.ftz.f32 	%f124, %f147, %f56;
	max.ftz.f32 	%f94, %f86, %f124;
	mov.u16 	%rs31, 0;
	mov.f32 	%f178, %f180;
	mov.f32 	%f179, %f172;
	mov.f32 	%f180, %f94;
	bra.uni 	$L__BB1_57;

$L__BB1_49:
	setp.lt.ftz.f32 	%p37, %f141, %f86;
	mov.u16 	%rs31, 0;
	mov.f32 	%f178, %f141;
	mov.f32 	%f179, %f98;
	@%p37 bra 	$L__BB1_57;

	setp.leu.ftz.f32 	%p38, %f146, %f180;
	@%p38 bra 	$L__BB1_52;

	add.ftz.f32 	%f121, %f172, %f98;
	min.ftz.f32 	%f172, %f121, %f99;
	mov.f32 	%f180, %f146;

$L__BB1_52:
	min.ftz.f32 	%f122, %f142, %f57;
	min.ftz.f32 	%f90, %f86, %f122;
	mov.u16 	%rs31, %rs36;
	mov.f32 	%f178, %f180;
	mov.f32 	%f179, %f172;
	mov.f32 	%f180, %f90;

$L__BB1_57:
	add.s64 	%rd58, %rd28, %rd15;
	add.s64 	%rd57, %rd27, %rd15;
	add.s64 	%rd50, %rd26, %rd15;
	add.s64 	%rd56, %rd50, %rd15;
	st.global.f32 	[%rd50], %f180;
	add.s32 	%r42, %r42, 4;
	setp.lt.s32 	%p41, %r42, %r23;
	@%p41 bra 	$L__BB1_21;

$L__BB1_61:
	ret;

}

