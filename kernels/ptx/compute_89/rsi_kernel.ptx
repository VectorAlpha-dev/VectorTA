







.version 9.0
.target sm_89
.address_size 64

	

.visible .entry rsi_batch_f32(
	.param .u64 rsi_batch_f32_param_0,
	.param .u64 rsi_batch_f32_param_1,
	.param .u32 rsi_batch_f32_param_2,
	.param .u32 rsi_batch_f32_param_3,
	.param .u32 rsi_batch_f32_param_4,
	.param .u64 rsi_batch_f32_param_5
)
{
	.reg .pred 	%p<89>;
	.reg .f32 	%f<148>;
	.reg .b32 	%r<238>;
	.reg .b64 	%rd<102>;


	ld.param.u64 	%rd37, [rsi_batch_f32_param_0];
	ld.param.u64 	%rd36, [rsi_batch_f32_param_1];
	ld.param.u32 	%r118, [rsi_batch_f32_param_2];
	ld.param.u32 	%r206, [rsi_batch_f32_param_3];
	ld.param.u32 	%r120, [rsi_batch_f32_param_4];
	ld.param.u64 	%rd38, [rsi_batch_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd37;
	cvta.to.global.u64 	%rd2, %rd38;
	mov.u32 	%r1, %tid.x;
	and.b32  	%r200, %r1, 31;
	shr.u32 	%r121, %r1, 5;
	mov.u32 	%r122, %ntid.x;
	shr.u32 	%r123, %r122, 5;
	mov.u32 	%r124, %ctaid.x;
	mad.lo.s32 	%r3, %r123, %r124, %r121;
	setp.ge.s32 	%p20, %r3, %r120;
	@%p20 bra 	$L__BB0_75;

	cvta.to.global.u64 	%rd39, %rd36;
	mul.wide.s32 	%rd40, %r3, 4;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.s32 	%rd3, %r118, %r3;
	ld.global.nc.u32 	%r4, [%rd41];
	setp.lt.s32 	%p21, %r4, 1;
	setp.gt.s32 	%p22, %r4, %r118;
	or.pred  	%p23, %p21, %p22;
	setp.lt.s32 	%p24, %r206, 0;
	or.pred  	%p25, %p24, %p23;
	setp.le.s32 	%p26, %r118, %r206;
	or.pred  	%p27, %p26, %p25;
	@%p27 bra 	$L__BB0_68;
	bra.uni 	$L__BB0_2;

$L__BB0_68:
	setp.ge.s32 	%p83, %r200, %r118;
	@%p83 bra 	$L__BB0_75;

	not.b32 	%r193, %r200;
	add.s32 	%r109, %r193, %r118;
	shr.u32 	%r194, %r109, 5;
	add.s32 	%r195, %r194, 1;
	and.b32  	%r235, %r195, 3;
	setp.eq.s32 	%p84, %r235, 0;
	@%p84 bra 	$L__BB0_72;

	cvt.u64.u32 	%rd84, %r1;
	and.b64  	%rd85, %rd84, 31;
	add.s64 	%rd86, %rd3, %rd85;
	shl.b64 	%rd87, %rd86, 2;
	add.s64 	%rd100, %rd2, %rd87;

$L__BB0_71:
	.pragma "nounroll";
	mov.u32 	%r196, 2147483647;
	st.global.u32 	[%rd100], %r196;
	add.s32 	%r200, %r200, 32;
	add.s64 	%rd100, %rd100, 128;
	add.s32 	%r235, %r235, -1;
	setp.ne.s32 	%p85, %r235, 0;
	@%p85 bra 	$L__BB0_71;

$L__BB0_72:
	setp.lt.u32 	%p86, %r109, 96;
	@%p86 bra 	$L__BB0_75;

	cvt.u64.u32 	%rd88, %r200;
	add.s64 	%rd89, %rd3, %rd88;
	shl.b64 	%rd90, %rd89, 2;
	add.s64 	%rd91, %rd2, %rd90;
	add.s64 	%rd101, %rd91, 256;

$L__BB0_74:
	mov.u32 	%r197, 2147483647;
	st.global.u32 	[%rd101+-256], %r197;
	st.global.u32 	[%rd101+-128], %r197;
	st.global.u32 	[%rd101], %r197;
	st.global.u32 	[%rd101+128], %r197;
	add.s64 	%rd101, %rd101, 512;
	add.s32 	%r200, %r200, 128;
	setp.lt.s32 	%p87, %r200, %r118;
	@%p87 bra 	$L__BB0_74;
	bra.uni 	$L__BB0_75;

$L__BB0_2:
	sub.s32 	%r125, %r118, %r206;
	setp.gt.s32 	%p28, %r125, %r4;
	@%p28 bra 	$L__BB0_10;
	bra.uni 	$L__BB0_3;

$L__BB0_10:
	add.s32 	%r14, %r4, %r206;
	setp.ge.s32 	%p34, %r200, %r14;
	@%p34 bra 	$L__BB0_17;

	not.b32 	%r131, %r200;
	add.s32 	%r15, %r14, %r131;
	shr.u32 	%r132, %r15, 5;
	add.s32 	%r133, %r132, 1;
	and.b32  	%r203, %r133, 3;
	setp.eq.s32 	%p35, %r203, 0;
	mov.u32 	%r204, %r200;
	@%p35 bra 	$L__BB0_14;

	cvt.u64.u32 	%rd50, %r1;
	and.b64  	%rd51, %rd50, 31;
	add.s64 	%rd52, %rd3, %rd51;
	shl.b64 	%rd53, %rd52, 2;
	add.s64 	%rd94, %rd2, %rd53;
	mov.u32 	%r204, %r200;

$L__BB0_13:
	.pragma "nounroll";
	mov.u32 	%r134, 2147483647;
	st.global.u32 	[%rd94], %r134;
	add.s32 	%r204, %r204, 32;
	add.s64 	%rd94, %rd94, 128;
	add.s32 	%r203, %r203, -1;
	setp.ne.s32 	%p36, %r203, 0;
	@%p36 bra 	$L__BB0_13;

$L__BB0_14:
	setp.lt.u32 	%p37, %r15, 96;
	@%p37 bra 	$L__BB0_17;

	cvt.u64.u32 	%rd54, %r204;
	add.s64 	%rd55, %rd3, %rd54;
	shl.b64 	%rd56, %rd55, 2;
	add.s64 	%rd57, %rd2, %rd56;
	add.s64 	%rd95, %rd57, 256;

$L__BB0_16:
	mov.u32 	%r135, 2147483647;
	st.global.u32 	[%rd95+-256], %r135;
	st.global.u32 	[%rd95+-128], %r135;
	st.global.u32 	[%rd95], %r135;
	st.global.u32 	[%rd95+128], %r135;
	add.s64 	%rd95, %rd95, 512;
	add.s32 	%r204, %r204, 128;
	setp.lt.s32 	%p38, %r204, %r14;
	@%p38 bra 	$L__BB0_16;

$L__BB0_17:
	cvt.rn.f32.s32 	%f62, %r4;
	rcp.approx.ftz.f32 	%f1, %f62;
	setp.ne.s32 	%p39, %r200, 0;
	mov.u32 	%r138, 0;
	mov.u32 	%r207, %r138;
	mov.u32 	%r208, %r138;
	mov.u32 	%r209, %r138;
	@%p39 bra 	$L__BB0_25;

	mul.wide.s32 	%rd58, %r206, 4;
	add.s64 	%rd16, %rd1, %rd58;
	mov.f32 	%f125, 0f00000000;
	mov.f32 	%f126, %f125;
	@%p21 bra 	$L__BB0_22;

	ld.global.nc.f32 	%f124, [%rd16];
	mov.f32 	%f126, 0f00000000;
	mov.f32 	%f125, %f126;

$L__BB0_20:
	add.s32 	%r206, %r206, 1;
	mov.u32 	%r209, 1;
	mul.wide.s32 	%rd59, %r206, 4;
	add.s64 	%rd60, %rd1, %rd59;
	ld.global.nc.f32 	%f6, [%rd60];
	sub.ftz.f32 	%f7, %f6, %f124;
	abs.ftz.f32 	%f67, %f7;
	setp.geu.ftz.f32 	%p41, %f67, 0f7F800000;
	mov.u32 	%r207, %r138;
	mov.u32 	%r208, %r138;
	@%p41 bra 	$L__BB0_25;

	setp.gt.ftz.f32 	%p42, %f7, 0f00000000;
	add.ftz.f32 	%f68, %f125, %f7;
	selp.f32 	%f125, %f68, %f125, %p42;
	setp.lt.ftz.f32 	%p43, %f7, 0f00000000;
	sub.ftz.f32 	%f69, %f126, %f7;
	selp.f32 	%f126, %f69, %f126, %p43;
	setp.lt.s32 	%p44, %r206, %r14;
	mov.f32 	%f124, %f6;
	@%p44 bra 	$L__BB0_20;

$L__BB0_22:
	mul.ftz.f32 	%f12, %f1, %f126;
	mul.ftz.f32 	%f13, %f1, %f125;
	add.ftz.f32 	%f14, %f13, %f12;
	setp.eq.ftz.f32 	%p45, %f14, 0f00000000;
	mov.f32 	%f127, 0f42480000;
	@%p45 bra 	$L__BB0_24;

	mul.ftz.f32 	%f71, %f13, 0f42C80000;
	div.approx.ftz.f32 	%f127, %f71, %f14;

$L__BB0_24:
	mov.f32 	%f72, 0f42C80000;
	min.ftz.f32 	%f73, %f72, %f127;
	mov.f32 	%f74, 0f00000000;
	max.ftz.f32 	%f75, %f74, %f73;
	cvt.s64.s32 	%rd61, %r14;
	add.s64 	%rd62, %rd3, %rd61;
	shl.b64 	%rd63, %rd62, 2;
	add.s64 	%rd64, %rd2, %rd63;
	st.global.f32 	[%rd64], %f75;
	mov.b32 	%r207, %f13;
	mov.b32 	%r208, %f12;
	mov.u32 	%r209, %r138;

$L__BB0_25:
	mov.u32 	%r143, 31;
	mov.u32 	%r145, -1;
	shfl.sync.idx.b32 	%r215|%p1, %r207, %r138, %r143, %r145;
	shfl.sync.idx.b32 	%r216|%p2, %r208, %r138, %r143, %r145;
	shfl.sync.idx.b32 	%r146|%p46, %r209, %r138, %r143, %r145;
	setp.eq.s32 	%p47, %r146, 0;
	@%p47 bra 	$L__BB0_33;

	setp.ge.s32 	%p48, %r200, %r118;
	@%p48 bra 	$L__BB0_75;

	not.b32 	%r147, %r200;
	add.s32 	%r33, %r147, %r118;
	shr.u32 	%r148, %r33, 5;
	add.s32 	%r149, %r148, 1;
	and.b32  	%r211, %r149, 3;
	setp.eq.s32 	%p49, %r211, 0;
	@%p49 bra 	$L__BB0_30;

	cvt.u64.u32 	%rd65, %r1;
	and.b64  	%rd66, %rd65, 31;
	add.s64 	%rd67, %rd3, %rd66;
	shl.b64 	%rd68, %rd67, 2;
	add.s64 	%rd96, %rd2, %rd68;

$L__BB0_29:
	.pragma "nounroll";
	mov.u32 	%r150, 2147483647;
	st.global.u32 	[%rd96], %r150;
	add.s32 	%r200, %r200, 32;
	add.s64 	%rd96, %rd96, 128;
	add.s32 	%r211, %r211, -1;
	setp.ne.s32 	%p50, %r211, 0;
	@%p50 bra 	$L__BB0_29;

$L__BB0_30:
	setp.lt.u32 	%p51, %r33, 96;
	@%p51 bra 	$L__BB0_75;

	cvt.u64.u32 	%rd69, %r200;
	add.s64 	%rd70, %rd3, %rd69;
	shl.b64 	%rd71, %rd70, 2;
	add.s64 	%rd72, %rd2, %rd71;
	add.s64 	%rd97, %rd72, 256;

$L__BB0_32:
	mov.u32 	%r151, 2147483647;
	st.global.u32 	[%rd97+-256], %r151;
	st.global.u32 	[%rd97+-128], %r151;
	st.global.u32 	[%rd97], %r151;
	st.global.u32 	[%rd97+128], %r151;
	add.s64 	%rd97, %rd97, 512;
	add.s32 	%r200, %r200, 128;
	setp.lt.s32 	%p52, %r200, %r118;
	@%p52 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_75;

$L__BB0_3:
	setp.ge.s32 	%p29, %r200, %r118;
	@%p29 bra 	$L__BB0_75;

	not.b32 	%r126, %r200;
	add.s32 	%r5, %r126, %r118;
	shr.u32 	%r127, %r5, 5;
	add.s32 	%r128, %r127, 1;
	and.b32  	%r199, %r128, 3;
	setp.eq.s32 	%p30, %r199, 0;
	@%p30 bra 	$L__BB0_7;

	cvt.u64.u32 	%rd42, %r1;
	and.b64  	%rd43, %rd42, 31;
	add.s64 	%rd44, %rd3, %rd43;
	shl.b64 	%rd45, %rd44, 2;
	add.s64 	%rd92, %rd2, %rd45;

$L__BB0_6:
	.pragma "nounroll";
	mov.u32 	%r129, 2147483647;
	st.global.u32 	[%rd92], %r129;
	add.s32 	%r200, %r200, 32;
	add.s64 	%rd92, %rd92, 128;
	add.s32 	%r199, %r199, -1;
	setp.ne.s32 	%p31, %r199, 0;
	@%p31 bra 	$L__BB0_6;

$L__BB0_7:
	setp.lt.u32 	%p32, %r5, 96;
	@%p32 bra 	$L__BB0_75;

	cvt.u64.u32 	%rd46, %r200;
	add.s64 	%rd47, %rd3, %rd46;
	shl.b64 	%rd48, %rd47, 2;
	add.s64 	%rd49, %rd2, %rd48;
	add.s64 	%rd93, %rd49, 256;

$L__BB0_9:
	mov.u32 	%r130, 2147483647;
	st.global.u32 	[%rd93+-256], %r130;
	st.global.u32 	[%rd93+-128], %r130;
	st.global.u32 	[%rd93], %r130;
	st.global.u32 	[%rd93+128], %r130;
	add.s64 	%rd93, %rd93, 512;
	add.s32 	%r200, %r200, 128;
	setp.lt.s32 	%p33, %r200, %r118;
	@%p33 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_75;

$L__BB0_33:
	add.s32 	%r217, %r14, 1;
	setp.ge.s32 	%p53, %r217, %r118;
	@%p53 bra 	$L__BB0_75;

	add.s32 	%r152, %r14, %r200;
	add.s32 	%r232, %r152, 33;
	mov.f32 	%f76, 0f3F800000;
	sub.ftz.f32 	%f17, %f76, %f1;

$L__BB0_35:
	add.s32 	%r153, %r232, -32;
	setp.ge.s32 	%p55, %r153, %r118;
	mov.pred 	%p54, 0;
	mov.f32 	%f129, 0f00000000;
	mov.f32 	%f130, 0f00000000;
	mov.f32 	%f128, %f76;
	mov.pred 	%p88, %p54;
	@%p55 bra 	$L__BB0_38;

	mul.wide.s32 	%rd73, %r153, 4;
	add.s64 	%rd74, %rd1, %rd73;
	ld.global.nc.f32 	%f83, [%rd74+-4];
	ld.global.nc.f32 	%f84, [%rd74];
	sub.ftz.f32 	%f18, %f84, %f83;
	abs.ftz.f32 	%f85, %f18;
	setp.geu.ftz.f32 	%p57, %f85, 0f7F800000;
	mov.pred 	%p88, -1;
	mov.f32 	%f128, %f76;
	@%p57 bra 	$L__BB0_38;

	mov.f32 	%f86, 0f00000000;
	max.ftz.f32 	%f87, %f18, %f86;
	neg.ftz.f32 	%f88, %f18;
	max.ftz.f32 	%f89, %f88, %f86;
	mul.ftz.f32 	%f129, %f1, %f87;
	mul.ftz.f32 	%f130, %f1, %f89;
	mov.f32 	%f128, %f17;
	mov.pred 	%p88, %p54;

$L__BB0_38:
	setp.lt.s32 	%p59, %r153, %r118;
	and.pred  	%p60, %p59, %p88;
	mov.u32 	%r156, -1;
	vote.sync.ballot.b32 	%r50, %p60, %r156;
	mov.b32 	%r223, %f128;
	mov.u32 	%r157, 0;
	mov.u32 	%r158, 1;
	shfl.sync.up.b32 	%r52|%p5, %r223, %r158, %r157, %r156;
	mov.b32 	%r222, %f129;
	shfl.sync.up.b32 	%r54|%p6, %r222, %r158, %r157, %r156;
	mov.b32 	%r221, %f130;
	shfl.sync.up.b32 	%r56|%p7, %r221, %r158, %r157, %r156;
	setp.eq.s32 	%p61, %r200, 0;
	@%p61 bra 	$L__BB0_40;

	mov.b32 	%f90, %r56;
	mov.b32 	%f91, %r54;
	mov.b32 	%f92, %r52;
	mul.ftz.f32 	%f24, %f128, %f92;
	fma.rn.ftz.f32 	%f129, %f128, %f91, %f129;
	fma.rn.ftz.f32 	%f130, %f128, %f90, %f130;
	mov.b32 	%r223, %f24;
	mov.b32 	%r222, %f129;
	mov.b32 	%r221, %f130;
	mov.f32 	%f128, %f24;

$L__BB0_40:
	mov.u32 	%r160, 2;
	shfl.sync.up.b32 	%r63|%p8, %r223, %r160, %r157, %r156;
	shfl.sync.up.b32 	%r64|%p9, %r222, %r160, %r157, %r156;
	shfl.sync.up.b32 	%r65|%p10, %r221, %r160, %r157, %r156;
	setp.lt.u32 	%p62, %r200, 2;
	@%p62 bra 	$L__BB0_42;

	mov.b32 	%f93, %r65;
	mov.b32 	%f94, %r64;
	mov.b32 	%f95, %r63;
	mul.ftz.f32 	%f30, %f128, %f95;
	fma.rn.ftz.f32 	%f129, %f128, %f94, %f129;
	fma.rn.ftz.f32 	%f130, %f128, %f93, %f130;
	mov.b32 	%r223, %f30;
	mov.b32 	%r222, %f129;
	mov.b32 	%r221, %f130;
	mov.f32 	%f128, %f30;

$L__BB0_42:
	mov.u32 	%r162, 0;
	mov.u32 	%r163, 4;
	mov.u32 	%r164, -1;
	shfl.sync.up.b32 	%r72|%p11, %r223, %r163, %r162, %r164;
	shfl.sync.up.b32 	%r73|%p12, %r222, %r163, %r162, %r164;
	shfl.sync.up.b32 	%r74|%p13, %r221, %r163, %r162, %r164;
	setp.lt.u32 	%p63, %r200, 4;
	@%p63 bra 	$L__BB0_44;

	mov.b32 	%f96, %r74;
	mov.b32 	%f97, %r73;
	mov.b32 	%f98, %r72;
	mul.ftz.f32 	%f36, %f128, %f98;
	fma.rn.ftz.f32 	%f129, %f128, %f97, %f129;
	fma.rn.ftz.f32 	%f130, %f128, %f96, %f130;
	mov.b32 	%r223, %f36;
	mov.b32 	%r222, %f129;
	mov.b32 	%r221, %f130;
	mov.f32 	%f128, %f36;

$L__BB0_44:
	mov.u32 	%r166, 8;
	shfl.sync.up.b32 	%r81|%p14, %r223, %r166, %r162, %r164;
	shfl.sync.up.b32 	%r82|%p15, %r222, %r166, %r162, %r164;
	shfl.sync.up.b32 	%r83|%p16, %r221, %r166, %r162, %r164;
	setp.lt.u32 	%p64, %r200, 8;
	@%p64 bra 	$L__BB0_46;

	mov.b32 	%f99, %r83;
	mov.b32 	%f100, %r82;
	mov.b32 	%f101, %r81;
	mul.ftz.f32 	%f42, %f128, %f101;
	fma.rn.ftz.f32 	%f129, %f128, %f100, %f129;
	fma.rn.ftz.f32 	%f130, %f128, %f99, %f130;
	mov.b32 	%r223, %f42;
	mov.b32 	%r222, %f129;
	mov.b32 	%r221, %f130;
	mov.f32 	%f128, %f42;

$L__BB0_46:
	mov.u32 	%r168, 0;
	mov.u32 	%r169, 16;
	mov.u32 	%r170, -1;
	shfl.sync.up.b32 	%r90|%p17, %r223, %r169, %r168, %r170;
	shfl.sync.up.b32 	%r91|%p18, %r222, %r169, %r168, %r170;
	shfl.sync.up.b32 	%r92|%p19, %r221, %r169, %r168, %r170;
	setp.lt.u32 	%p65, %r200, 16;
	@%p65 bra 	$L__BB0_48;

	mov.b32 	%f102, %r92;
	mov.b32 	%f103, %r91;
	mov.b32 	%f104, %r90;
	mul.ftz.f32 	%f48, %f128, %f104;
	fma.rn.ftz.f32 	%f129, %f128, %f103, %f129;
	fma.rn.ftz.f32 	%f130, %f128, %f102, %f130;
	mov.f32 	%f128, %f48;

$L__BB0_48:
	mov.b32 	%f105, %r215;
	fma.rn.ftz.f32 	%f54, %f128, %f105, %f129;
	mov.b32 	%f106, %r216;
	fma.rn.ftz.f32 	%f55, %f128, %f106, %f130;
	@%p55 bra 	$L__BB0_58;

	setp.eq.s32 	%p67, %r50, 0;
	cvt.s64.s32 	%rd75, %r153;
	add.s64 	%rd76, %rd3, %rd75;
	shl.b64 	%rd77, %rd76, 2;
	add.s64 	%rd23, %rd2, %rd77;
	@%p67 bra 	$L__BB0_55;

	brev.b32 	%r173, %r50;
	bfind.shiftamt.u32 	%r174, %r173;
	setp.lt.s32 	%p68, %r200, %r174;
	@%p68 bra 	$L__BB0_52;
	bra.uni 	$L__BB0_51;

$L__BB0_52:
	add.ftz.f32 	%f56, %f54, %f55;
	setp.eq.ftz.f32 	%p69, %f56, 0f00000000;
	mov.f32 	%f146, 0f42480000;
	@%p69 bra 	$L__BB0_54;

	mul.ftz.f32 	%f108, %f54, 0f42C80000;
	div.approx.ftz.f32 	%f146, %f108, %f56;

$L__BB0_54:
	mov.f32 	%f109, 0f42C80000;
	min.ftz.f32 	%f110, %f109, %f146;
	mov.f32 	%f111, 0f00000000;
	max.ftz.f32 	%f112, %f111, %f110;
	st.global.f32 	[%rd23], %f112;
	bra.uni 	$L__BB0_58;

$L__BB0_55:
	add.ftz.f32 	%f59, %f54, %f55;
	setp.eq.ftz.f32 	%p70, %f59, 0f00000000;
	mov.f32 	%f147, 0f42480000;
	@%p70 bra 	$L__BB0_57;

	mul.ftz.f32 	%f114, %f54, 0f42C80000;
	div.approx.ftz.f32 	%f147, %f114, %f59;

$L__BB0_57:
	mov.f32 	%f115, 0f42C80000;
	min.ftz.f32 	%f116, %f115, %f147;
	mov.f32 	%f117, 0f00000000;
	max.ftz.f32 	%f118, %f117, %f116;
	st.global.f32 	[%rd23], %f118;
	bra.uni 	$L__BB0_58;

$L__BB0_51:
	mov.u32 	%r175, 2147483647;
	st.global.u32 	[%rd23], %r175;

$L__BB0_58:
	setp.eq.s32 	%p71, %r50, 0;
	sub.s32 	%r94, %r118, %r217;
	@%p71 bra 	$L__BB0_67;

	setp.gt.s32 	%p72, %r94, 31;
	add.s32 	%r176, %r94, -1;
	selp.b32 	%r177, 31, %r176, %p72;
	brev.b32 	%r178, %r50;
	bfind.shiftamt.u32 	%r179, %r178;
	setp.gt.s32 	%p73, %r179, %r177;
	@%p73 bra 	$L__BB0_67;
	bra.uni 	$L__BB0_60;

$L__BB0_67:
	not.b32 	%r186, %r217;
	mov.u32 	%r187, -1;
	add.s32 	%r188, %r186, %r118;
	setp.gt.s32 	%p79, %r94, 31;
	mov.u32 	%r189, 31;
	selp.b32 	%r190, 31, %r188, %p79;
	mov.b32 	%r191, %f54;
	shfl.sync.idx.b32 	%r215|%p80, %r191, %r190, %r189, %r187;
	mov.b32 	%r192, %f55;
	shfl.sync.idx.b32 	%r216|%p81, %r192, %r190, %r189, %r187;
	add.s32 	%r217, %r217, 32;
	setp.lt.s32 	%p82, %r217, %r118;
	add.s32 	%r232, %r232, 32;
	@%p82 bra 	$L__BB0_35;
	bra.uni 	$L__BB0_75;

$L__BB0_60:
	setp.ge.s32 	%p74, %r232, %r118;
	@%p74 bra 	$L__BB0_75;

	add.s32 	%r180, %r118, -33;
	sub.s32 	%r181, %r180, %r200;
	sub.s32 	%r96, %r181, %r217;
	shr.u32 	%r182, %r96, 5;
	add.s32 	%r183, %r182, 1;
	and.b32  	%r231, %r183, 3;
	setp.eq.s32 	%p75, %r231, 0;
	@%p75 bra 	$L__BB0_64;

	shl.b64 	%rd78, %rd3, 2;
	add.s64 	%rd79, %rd2, %rd78;
	mul.wide.s32 	%rd80, %r232, 4;
	add.s64 	%rd98, %rd79, %rd80;

$L__BB0_63:
	.pragma "nounroll";
	mov.u32 	%r184, 2147483647;
	st.global.u32 	[%rd98], %r184;
	add.s32 	%r232, %r232, 32;
	add.s64 	%rd98, %rd98, 128;
	add.s32 	%r231, %r231, -1;
	setp.ne.s32 	%p76, %r231, 0;
	@%p76 bra 	$L__BB0_63;

$L__BB0_64:
	setp.lt.u32 	%p77, %r96, 96;
	@%p77 bra 	$L__BB0_75;

	cvt.s64.s32 	%rd81, %r232;
	add.s64 	%rd82, %rd3, %rd81;
	shl.b64 	%rd83, %rd82, 2;
	add.s64 	%rd99, %rd2, %rd83;

$L__BB0_66:
	mov.u32 	%r185, 2147483647;
	st.global.u32 	[%rd99], %r185;
	st.global.u32 	[%rd99+128], %r185;
	st.global.u32 	[%rd99+256], %r185;
	st.global.u32 	[%rd99+384], %r185;
	add.s64 	%rd99, %rd99, 512;
	add.s32 	%r232, %r232, 128;
	setp.lt.s32 	%p78, %r232, %r118;
	@%p78 bra 	$L__BB0_66;

$L__BB0_75:
	ret;

}
	
.visible .entry rsi_many_series_one_param_f32(
	.param .u64 rsi_many_series_one_param_f32_param_0,
	.param .u64 rsi_many_series_one_param_f32_param_1,
	.param .u32 rsi_many_series_one_param_f32_param_2,
	.param .u32 rsi_many_series_one_param_f32_param_3,
	.param .u32 rsi_many_series_one_param_f32_param_4,
	.param .u64 rsi_many_series_one_param_f32_param_5
)
{
	.reg .pred 	%p<45>;
	.reg .f32 	%f<156>;
	.reg .b32 	%r<135>;
	.reg .b64 	%rd<101>;


	ld.param.u64 	%rd45, [rsi_many_series_one_param_f32_param_0];
	ld.param.u64 	%rd46, [rsi_many_series_one_param_f32_param_1];
	ld.param.u32 	%r50, [rsi_many_series_one_param_f32_param_2];
	ld.param.u32 	%r51, [rsi_many_series_one_param_f32_param_3];
	ld.param.u32 	%r52, [rsi_many_series_one_param_f32_param_4];
	ld.param.u64 	%rd47, [rsi_many_series_one_param_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd47;
	mov.u32 	%r53, %ntid.x;
	mov.u32 	%r54, %ctaid.x;
	mov.u32 	%r55, %tid.x;
	mad.lo.s32 	%r1, %r54, %r53, %r55;
	setp.ge.s32 	%p1, %r1, %r50;
	@%p1 bra 	$L__BB1_51;

	setp.lt.s32 	%p2, %r52, 1;
	@%p2 bra 	$L__BB1_44;

	cvt.s64.s32 	%rd2, %r1;
	cvta.to.global.u64 	%rd48, %rd46;
	mul.wide.s32 	%rd49, %r1, 4;
	add.s64 	%rd50, %rd48, %rd49;
	ld.global.nc.u32 	%r2, [%rd50];
	setp.lt.s32 	%p3, %r2, 0;
	setp.ge.s32 	%p4, %r2, %r51;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	$L__BB1_37;
	bra.uni 	$L__BB1_3;

$L__BB1_37:
	setp.lt.s32 	%p35, %r51, 1;
	@%p35 bra 	$L__BB1_51;

	add.s32 	%r104, %r51, -1;
	and.b32  	%r130, %r51, 3;
	setp.lt.u32 	%p36, %r104, 3;
	mov.u32 	%r129, 0;
	@%p36 bra 	$L__BB1_41;

	sub.s32 	%r128, %r51, %r130;
	shl.b64 	%rd81, %rd2, 2;
	add.s64 	%rd97, %rd1, %rd81;
	mul.wide.s32 	%rd30, %r50, 4;
	mov.u32 	%r129, 0;

$L__BB1_40:
	mov.u32 	%r106, 2143289344;
	st.global.u32 	[%rd97], %r106;
	add.s64 	%rd82, %rd97, %rd30;
	st.global.u32 	[%rd82], %r106;
	add.s64 	%rd83, %rd82, %rd30;
	st.global.u32 	[%rd83], %r106;
	add.s64 	%rd84, %rd83, %rd30;
	add.s64 	%rd97, %rd84, %rd30;
	st.global.u32 	[%rd84], %r106;
	add.s32 	%r129, %r129, 4;
	add.s32 	%r128, %r128, -4;
	setp.ne.s32 	%p37, %r128, 0;
	@%p37 bra 	$L__BB1_40;

$L__BB1_41:
	setp.eq.s32 	%p38, %r130, 0;
	@%p38 bra 	$L__BB1_51;

	mad.lo.s32 	%r107, %r129, %r50, %r1;
	mul.wide.s32 	%rd85, %r107, 4;
	add.s64 	%rd98, %rd1, %rd85;
	mul.wide.s32 	%rd34, %r50, 4;

$L__BB1_43:
	.pragma "nounroll";
	mov.u32 	%r108, 2143289344;
	st.global.u32 	[%rd98], %r108;
	add.s64 	%rd98, %rd98, %rd34;
	add.s32 	%r130, %r130, -1;
	setp.eq.s32 	%p39, %r130, 0;
	@%p39 bra 	$L__BB1_51;
	bra.uni 	$L__BB1_43;

$L__BB1_44:
	setp.lt.s32 	%p40, %r51, 1;
	@%p40 bra 	$L__BB1_51;

	add.s32 	%r110, %r51, -1;
	and.b32  	%r134, %r51, 3;
	setp.lt.u32 	%p41, %r110, 3;
	mov.u32 	%r133, 0;
	@%p41 bra 	$L__BB1_48;

	sub.s32 	%r132, %r51, %r134;
	mul.wide.s32 	%rd86, %r1, 4;
	add.s64 	%rd99, %rd1, %rd86;
	mul.wide.s32 	%rd38, %r50, 4;
	mov.u32 	%r133, 0;

$L__BB1_47:
	mov.u32 	%r112, 2143289344;
	st.global.u32 	[%rd99], %r112;
	add.s64 	%rd87, %rd99, %rd38;
	st.global.u32 	[%rd87], %r112;
	add.s64 	%rd88, %rd87, %rd38;
	st.global.u32 	[%rd88], %r112;
	add.s64 	%rd89, %rd88, %rd38;
	add.s64 	%rd99, %rd89, %rd38;
	st.global.u32 	[%rd89], %r112;
	add.s32 	%r133, %r133, 4;
	add.s32 	%r132, %r132, -4;
	setp.ne.s32 	%p42, %r132, 0;
	@%p42 bra 	$L__BB1_47;

$L__BB1_48:
	setp.eq.s32 	%p43, %r134, 0;
	@%p43 bra 	$L__BB1_51;

	mad.lo.s32 	%r113, %r133, %r50, %r1;
	mul.wide.s32 	%rd90, %r113, 4;
	add.s64 	%rd100, %rd1, %rd90;
	mul.wide.s32 	%rd42, %r50, 4;

$L__BB1_50:
	.pragma "nounroll";
	mov.u32 	%r114, 2143289344;
	st.global.u32 	[%rd100], %r114;
	add.s64 	%rd100, %rd100, %rd42;
	add.s32 	%r134, %r134, -1;
	setp.ne.s32 	%p44, %r134, 0;
	@%p44 bra 	$L__BB1_50;
	bra.uni 	$L__BB1_51;

$L__BB1_3:
	add.s32 	%r121, %r2, %r52;
	setp.lt.s32 	%p6, %r121, 0;
	setp.lt.s32 	%p7, %r51, 1;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB1_10;

	neg.s32 	%r57, %r51;
	mov.u32 	%r117, 0;
	not.b32 	%r58, %r121;
	max.u32 	%r4, %r57, %r58;
	neg.s32 	%r59, %r4;
	and.b32  	%r118, %r59, 3;
	setp.gt.u32 	%p9, %r4, -4;
	@%p9 bra 	$L__BB1_7;

	shl.b64 	%rd51, %rd2, 2;
	add.s64 	%rd91, %rd1, %rd51;
	add.s32 	%r61, %r4, %r118;
	neg.s32 	%r115, %r61;
	mov.u32 	%r117, 0;
	mul.wide.s32 	%rd4, %r50, 4;

$L__BB1_6:
	mov.u32 	%r62, 2143289344;
	st.global.u32 	[%rd91], %r62;
	add.s64 	%rd52, %rd91, %rd4;
	st.global.u32 	[%rd52], %r62;
	add.s64 	%rd53, %rd52, %rd4;
	st.global.u32 	[%rd53], %r62;
	add.s64 	%rd54, %rd53, %rd4;
	add.s64 	%rd91, %rd54, %rd4;
	st.global.u32 	[%rd54], %r62;
	add.s32 	%r117, %r117, 4;
	add.s32 	%r115, %r115, -4;
	setp.ne.s32 	%p10, %r115, 0;
	@%p10 bra 	$L__BB1_6;

$L__BB1_7:
	setp.eq.s32 	%p11, %r118, 0;
	@%p11 bra 	$L__BB1_10;

	mad.lo.s32 	%r63, %r117, %r50, %r1;
	mul.wide.s32 	%rd55, %r63, 4;
	add.s64 	%rd92, %rd1, %rd55;
	mul.wide.s32 	%rd8, %r50, 4;

$L__BB1_9:
	.pragma "nounroll";
	mov.u32 	%r64, 2143289344;
	st.global.u32 	[%rd92], %r64;
	add.s64 	%rd92, %rd92, %rd8;
	add.s32 	%r118, %r118, -1;
	setp.ne.s32 	%p12, %r118, 0;
	@%p12 bra 	$L__BB1_9;

$L__BB1_10:
	setp.ge.s32 	%p13, %r121, %r51;
	@%p13 bra 	$L__BB1_51;

	cvt.rn.f32.s32 	%f53, %r52;
	rcp.approx.ftz.f32 	%f1, %f53;
	mov.f32 	%f140, 0f00000000;
	mov.f32 	%f141, %f140;
	@%p2 bra 	$L__BB1_15;

	mov.f32 	%f141, 0f00000000;
	cvta.to.global.u64 	%rd56, %rd45;
	mov.u32 	%r119, %r2;
	mov.f32 	%f140, %f141;

$L__BB1_13:
	add.s32 	%r15, %r119, 1;
	mad.lo.s32 	%r69, %r15, %r50, %r1;
	mul.wide.s32 	%rd57, %r69, 4;
	add.s64 	%rd58, %rd56, %rd57;
	mad.lo.s32 	%r70, %r119, %r50, %r1;
	mul.wide.s32 	%rd59, %r70, 4;
	add.s64 	%rd60, %rd56, %rd59;
	ld.global.nc.f32 	%f56, [%rd60];
	ld.global.nc.f32 	%f57, [%rd58];
	sub.ftz.f32 	%f4, %f57, %f56;
	abs.ftz.f32 	%f58, %f4;
	setp.geu.ftz.f32 	%p15, %f58, 0f7F800000;
	@%p15 bra 	$L__BB1_18;

	setp.gt.ftz.f32 	%p16, %f4, 0f00000000;
	add.ftz.f32 	%f59, %f140, %f4;
	selp.f32 	%f140, %f59, %f140, %p16;
	setp.lt.ftz.f32 	%p17, %f4, 0f00000000;
	sub.ftz.f32 	%f60, %f141, %f4;
	selp.f32 	%f141, %f60, %f141, %p17;
	setp.lt.s32 	%p18, %r15, %r121;
	mov.u32 	%r119, %r15;
	@%p18 bra 	$L__BB1_13;

$L__BB1_15:
	mul.ftz.f32 	%f148, %f1, %f141;
	mul.ftz.f32 	%f149, %f1, %f140;
	add.ftz.f32 	%f11, %f149, %f148;
	setp.eq.ftz.f32 	%p19, %f11, 0f00000000;
	mov.f32 	%f142, 0f42480000;
	@%p19 bra 	$L__BB1_17;

	mul.ftz.f32 	%f62, %f149, 0f42C80000;
	div.approx.ftz.f32 	%f142, %f62, %f11;

$L__BB1_17:
	mov.f32 	%f63, 0f42C80000;
	min.ftz.f32 	%f64, %f63, %f142;
	mov.f32 	%f65, 0f00000000;
	max.ftz.f32 	%f66, %f65, %f64;
	mad.lo.s32 	%r75, %r121, %r50, %r1;
	mul.wide.s32 	%rd62, %r75, 4;
	add.s64 	%rd63, %rd1, %rd62;
	st.global.f32 	[%rd63], %f66;
	bra.uni 	$L__BB1_19;

$L__BB1_18:
	mad.lo.s32 	%r80, %r121, %r50, %r1;
	mul.wide.s32 	%rd65, %r80, 4;
	add.s64 	%rd66, %rd1, %rd65;
	mov.f32 	%f149, 0f7FC00000;
	mov.u32 	%r81, 2143289344;
	st.global.u32 	[%rd66], %r81;
	mov.f32 	%f148, %f149;

$L__BB1_19:
	add.s32 	%r125, %r121, 1;
	setp.ge.s32 	%p20, %r125, %r51;
	@%p20 bra 	$L__BB1_51;

	not.b32 	%r82, %r2;
	add.s32 	%r83, %r82, %r51;
	sub.s32 	%r84, %r83, %r52;
	and.b32  	%r122, %r84, 3;
	setp.eq.s32 	%p21, %r122, 0;
	@%p21 bra 	$L__BB1_26;

	mad.lo.s32 	%r89, %r50, %r125, %r1;
	mul.wide.s32 	%rd68, %r89, 4;
	add.s64 	%rd94, %rd1, %rd68;
	cvta.to.global.u64 	%rd69, %rd45;
	add.s64 	%rd93, %rd69, %rd68;
	mad.lo.s32 	%r120, %r50, %r121, %r1;

$L__BB1_22:
	.pragma "nounroll";
	mul.wide.s32 	%rd71, %r120, 4;
	add.s64 	%rd72, %rd69, %rd71;
	ld.global.nc.f32 	%f70, [%rd72];
	ld.global.nc.f32 	%f71, [%rd93];
	sub.ftz.f32 	%f72, %f71, %f70;
	max.ftz.f32 	%f73, %f72, 0f00000000;
	setp.lt.ftz.f32 	%p22, %f72, 0f00000000;
	neg.ftz.f32 	%f74, %f72;
	selp.f32 	%f75, %f74, 0f00000000, %p22;
	mul.ftz.f32 	%f76, %f1, %f73;
	mov.f32 	%f77, 0f3F800000;
	sub.ftz.f32 	%f78, %f77, %f1;
	fma.rn.ftz.f32 	%f149, %f78, %f149, %f76;
	mul.ftz.f32 	%f79, %f1, %f75;
	fma.rn.ftz.f32 	%f148, %f78, %f148, %f79;
	add.ftz.f32 	%f20, %f149, %f148;
	setp.eq.ftz.f32 	%p23, %f20, 0f00000000;
	mov.f32 	%f147, 0f42480000;
	@%p23 bra 	$L__BB1_24;

	mul.ftz.f32 	%f80, %f149, 0f42C80000;
	div.approx.ftz.f32 	%f147, %f80, %f20;

$L__BB1_24:
	mov.f32 	%f81, 0f42C80000;
	min.ftz.f32 	%f82, %f81, %f147;
	mov.f32 	%f83, 0f00000000;
	max.ftz.f32 	%f84, %f83, %f82;
	st.global.f32 	[%rd94], %f84;
	add.s32 	%r121, %r121, 1;
	mul.wide.s32 	%rd73, %r50, 4;
	add.s64 	%rd94, %rd94, %rd73;
	add.s64 	%rd93, %rd93, %rd73;
	add.s32 	%r120, %r120, %r50;
	add.s32 	%r122, %r122, -1;
	setp.ne.s32 	%p24, %r122, 0;
	@%p24 bra 	$L__BB1_22;

	add.s32 	%r125, %r121, 1;

$L__BB1_26:
	add.s32 	%r90, %r51, -2;
	sub.s32 	%r91, %r90, %r2;
	sub.s32 	%r92, %r91, %r52;
	setp.lt.u32 	%p25, %r92, 3;
	@%p25 bra 	$L__BB1_51;

	mad.lo.s32 	%r97, %r125, %r50, %r1;
	mul.wide.s32 	%rd75, %r97, 4;
	add.s64 	%rd95, %rd1, %rd75;
	cvta.to.global.u64 	%rd76, %rd45;
	add.s64 	%rd96, %rd76, %rd75;

$L__BB1_28:
	mad.lo.s32 	%r102, %r121, %r50, %r1;
	mul.wide.s32 	%rd78, %r102, 4;
	add.s64 	%rd79, %rd76, %rd78;
	ld.global.nc.f32 	%f86, [%rd79];
	ld.global.nc.f32 	%f27, [%rd96];
	sub.ftz.f32 	%f87, %f27, %f86;
	max.ftz.f32 	%f88, %f87, 0f00000000;
	setp.lt.ftz.f32 	%p26, %f87, 0f00000000;
	neg.ftz.f32 	%f89, %f87;
	selp.f32 	%f90, %f89, 0f00000000, %p26;
	mul.ftz.f32 	%f91, %f1, %f88;
	mov.f32 	%f92, 0f3F800000;
	sub.ftz.f32 	%f93, %f92, %f1;
	fma.rn.ftz.f32 	%f28, %f93, %f149, %f91;
	mul.ftz.f32 	%f94, %f1, %f90;
	fma.rn.ftz.f32 	%f29, %f93, %f148, %f94;
	add.ftz.f32 	%f30, %f28, %f29;
	setp.eq.ftz.f32 	%p27, %f30, 0f00000000;
	mov.f32 	%f153, 0f42480000;
	mov.f32 	%f152, %f153;
	@%p27 bra 	$L__BB1_30;

	mul.ftz.f32 	%f95, %f28, 0f42C80000;
	div.approx.ftz.f32 	%f152, %f95, %f30;

$L__BB1_30:
	mov.f32 	%f97, 0f42C80000;
	min.ftz.f32 	%f98, %f97, %f152;
	mov.f32 	%f99, 0f00000000;
	max.ftz.f32 	%f100, %f99, %f98;
	st.global.f32 	[%rd95], %f100;
	mul.wide.s32 	%rd21, %r50, 4;
	add.s64 	%rd22, %rd96, %rd21;
	ld.global.nc.f32 	%f33, [%rd22];
	sub.ftz.f32 	%f101, %f33, %f27;
	max.ftz.f32 	%f102, %f101, 0f00000000;
	setp.lt.ftz.f32 	%p28, %f101, 0f00000000;
	neg.ftz.f32 	%f103, %f101;
	selp.f32 	%f104, %f103, 0f00000000, %p28;
	mul.ftz.f32 	%f105, %f1, %f102;
	fma.rn.ftz.f32 	%f35, %f93, %f28, %f105;
	mul.ftz.f32 	%f107, %f1, %f104;
	fma.rn.ftz.f32 	%f36, %f93, %f29, %f107;
	add.ftz.f32 	%f37, %f35, %f36;
	setp.eq.ftz.f32 	%p29, %f37, 0f00000000;
	@%p29 bra 	$L__BB1_32;

	mul.ftz.f32 	%f108, %f35, 0f42C80000;
	div.approx.ftz.f32 	%f153, %f108, %f37;

$L__BB1_32:
	min.ftz.f32 	%f111, %f97, %f153;
	max.ftz.f32 	%f113, %f99, %f111;
	add.s64 	%rd23, %rd95, %rd21;
	st.global.f32 	[%rd23], %f113;
	add.s64 	%rd24, %rd22, %rd21;
	ld.global.nc.f32 	%f40, [%rd24];
	sub.ftz.f32 	%f114, %f40, %f33;
	max.ftz.f32 	%f115, %f114, 0f00000000;
	setp.lt.ftz.f32 	%p30, %f114, 0f00000000;
	neg.ftz.f32 	%f116, %f114;
	selp.f32 	%f117, %f116, 0f00000000, %p30;
	mul.ftz.f32 	%f118, %f1, %f115;
	fma.rn.ftz.f32 	%f41, %f93, %f35, %f118;
	mul.ftz.f32 	%f119, %f1, %f117;
	fma.rn.ftz.f32 	%f42, %f93, %f36, %f119;
	add.ftz.f32 	%f43, %f41, %f42;
	setp.eq.ftz.f32 	%p31, %f43, 0f00000000;
	mov.f32 	%f155, 0f42480000;
	mov.f32 	%f154, %f155;
	@%p31 bra 	$L__BB1_34;

	mul.ftz.f32 	%f120, %f41, 0f42C80000;
	div.approx.ftz.f32 	%f154, %f120, %f43;

$L__BB1_34:
	mov.f32 	%f122, 0f42C80000;
	min.ftz.f32 	%f123, %f122, %f154;
	mov.f32 	%f124, 0f00000000;
	max.ftz.f32 	%f125, %f124, %f123;
	add.s64 	%rd25, %rd23, %rd21;
	st.global.f32 	[%rd25], %f125;
	add.s64 	%rd26, %rd24, %rd21;
	ld.global.nc.f32 	%f126, [%rd26];
	sub.ftz.f32 	%f127, %f126, %f40;
	max.ftz.f32 	%f128, %f127, 0f00000000;
	setp.lt.ftz.f32 	%p32, %f127, 0f00000000;
	neg.ftz.f32 	%f129, %f127;
	selp.f32 	%f130, %f129, 0f00000000, %p32;
	mul.ftz.f32 	%f131, %f1, %f128;
	fma.rn.ftz.f32 	%f149, %f93, %f41, %f131;
	mul.ftz.f32 	%f132, %f1, %f130;
	fma.rn.ftz.f32 	%f148, %f93, %f42, %f132;
	add.ftz.f32 	%f48, %f149, %f148;
	setp.eq.ftz.f32 	%p33, %f48, 0f00000000;
	@%p33 bra 	$L__BB1_36;

	mul.ftz.f32 	%f133, %f149, 0f42C80000;
	div.approx.ftz.f32 	%f155, %f133, %f48;

$L__BB1_36:
	add.s64 	%rd96, %rd26, %rd21;
	min.ftz.f32 	%f135, %f122, %f155;
	max.ftz.f32 	%f137, %f124, %f135;
	add.s64 	%rd80, %rd25, %rd21;
	add.s64 	%rd95, %rd80, %rd21;
	st.global.f32 	[%rd80], %f137;
	add.s32 	%r30, %r125, 4;
	setp.lt.s32 	%p34, %r30, %r51;
	add.s32 	%r121, %r125, 3;
	mov.u32 	%r125, %r30;
	@%p34 bra 	$L__BB1_28;

$L__BB1_51:
	ret;

}

