







.version 9.0
.target sm_89
.address_size 64

	

.visible .entry kama_batch_f32(
	.param .u64 kama_batch_f32_param_0,
	.param .u64 kama_batch_f32_param_1,
	.param .u32 kama_batch_f32_param_2,
	.param .u32 kama_batch_f32_param_3,
	.param .u32 kama_batch_f32_param_4,
	.param .u64 kama_batch_f32_param_5
)
.maxntid 32, 1, 1
{
	.reg .pred 	%p<43>;
	.reg .f32 	%f<28>;
	.reg .b32 	%r<94>;
	.reg .f64 	%fd<171>;
	.reg .b64 	%rd<62>;


	ld.param.u64 	%rd28, [kama_batch_f32_param_0];
	ld.param.u64 	%rd27, [kama_batch_f32_param_1];
	ld.param.u32 	%r35, [kama_batch_f32_param_2];
	ld.param.u32 	%r37, [kama_batch_f32_param_3];
	ld.param.u32 	%r36, [kama_batch_f32_param_4];
	ld.param.u64 	%rd29, [kama_batch_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd29;
	cvta.to.global.u64 	%rd2, %rd28;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r37;
	@%p1 bra 	$L__BB0_35;

	cvta.to.global.u64 	%rd30, %rd27;
	mul.wide.s32 	%rd31, %r1, 4;
	add.s64 	%rd32, %rd30, %rd31;
	mul.lo.s32 	%r2, %r1, %r35;
	ld.global.nc.u32 	%r3, [%rd32];
	setp.lt.s32 	%p2, %r3, 1;
	setp.le.s32 	%p3, %r35, %r36;
	setp.lt.s32 	%p4, %r36, 0;
	or.pred  	%p5, %p4, %p3;
	or.pred  	%p6, %p5, %p2;
	sub.s32 	%r38, %r35, %r36;
	setp.ge.s32 	%p7, %r3, %r38;
	or.pred  	%p8, %p7, %p6;
	add.s32 	%r4, %r3, %r36;
	setp.ge.s32 	%p9, %r4, %r35;
	or.pred  	%p10, %p9, %p8;
	mov.u32 	%r93, %tid.x;
	@%p10 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_2;

$L__BB0_32:
	setp.ge.s32 	%p41, %r93, %r35;
	@%p41 bra 	$L__BB0_35;

	mov.u32 	%r32, %ntid.x;

$L__BB0_34:
	add.s32 	%r80, %r93, %r2;
	mul.wide.s32 	%rd52, %r80, 4;
	add.s64 	%rd53, %rd1, %rd52;
	mov.u32 	%r81, 2147483647;
	st.global.u32 	[%rd53], %r81;
	add.s32 	%r93, %r93, %r32;
	setp.lt.s32 	%p42, %r93, %r35;
	@%p42 bra 	$L__BB0_34;
	bra.uni 	$L__BB0_35;

$L__BB0_2:
	setp.ge.s32 	%p11, %r93, %r4;
	@%p11 bra 	$L__BB0_5;

	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r82, %r93;

$L__BB0_4:
	add.s32 	%r39, %r82, %r2;
	mul.wide.s32 	%rd33, %r39, 4;
	add.s64 	%rd34, %rd1, %rd33;
	mov.u32 	%r40, 2147483647;
	st.global.u32 	[%rd34], %r40;
	add.s32 	%r82, %r82, %r6;
	setp.lt.s32 	%p12, %r82, %r4;
	@%p12 bra 	$L__BB0_4;

$L__BB0_5:
	setp.gt.u32 	%p13, %r93, 31;
	mov.f64 	%fd162, 0d0000000000000000;
	@%p13 bra 	$L__BB0_14;

	add.s32 	%r85, %r93, %r36;
	setp.ge.s32 	%p14, %r85, %r4;
	mov.f64 	%fd152, 0d0000000000000000;
	@%p14 bra 	$L__BB0_13;

	not.b32 	%r41, %r93;
	add.s32 	%r10, %r3, %r41;
	shr.u32 	%r42, %r10, 5;
	add.s32 	%r43, %r42, 1;
	and.b32  	%r84, %r43, 3;
	setp.eq.s32 	%p15, %r84, 0;
	mov.f64 	%fd152, 0d0000000000000000;
	@%p15 bra 	$L__BB0_10;

	mul.wide.s32 	%rd35, %r85, 4;
	add.s64 	%rd36, %rd2, %rd35;
	add.s64 	%rd54, %rd36, 4;
	mov.f64 	%fd152, 0d0000000000000000;

$L__BB0_9:
	.pragma "nounroll";
	ld.global.nc.f32 	%f1, [%rd54+-4];
	cvt.ftz.f64.f32 	%fd59, %f1;
	ld.global.nc.f32 	%f2, [%rd54];
	cvt.ftz.f64.f32 	%fd60, %f2;
	sub.f64 	%fd61, %fd60, %fd59;
	abs.f64 	%fd62, %fd61;
	add.f64 	%fd152, %fd152, %fd62;
	add.s32 	%r85, %r85, 32;
	add.s64 	%rd54, %rd54, 128;
	add.s32 	%r84, %r84, -1;
	setp.ne.s32 	%p16, %r84, 0;
	@%p16 bra 	$L__BB0_9;

$L__BB0_10:
	setp.lt.u32 	%p17, %r10, 96;
	@%p17 bra 	$L__BB0_13;

	mul.wide.s32 	%rd37, %r85, 4;
	add.s64 	%rd38, %rd2, %rd37;
	add.s64 	%rd55, %rd38, 256;

$L__BB0_12:
	ld.global.nc.f32 	%f3, [%rd55+-256];
	cvt.ftz.f64.f32 	%fd63, %f3;
	ld.global.nc.f32 	%f4, [%rd55+-252];
	cvt.ftz.f64.f32 	%fd64, %f4;
	sub.f64 	%fd65, %fd64, %fd63;
	abs.f64 	%fd66, %fd65;
	add.f64 	%fd67, %fd152, %fd66;
	ld.global.nc.f32 	%f5, [%rd55+-128];
	cvt.ftz.f64.f32 	%fd68, %f5;
	ld.global.nc.f32 	%f6, [%rd55+-124];
	cvt.ftz.f64.f32 	%fd69, %f6;
	sub.f64 	%fd70, %fd69, %fd68;
	abs.f64 	%fd71, %fd70;
	add.f64 	%fd72, %fd67, %fd71;
	ld.global.nc.f32 	%f7, [%rd55];
	cvt.ftz.f64.f32 	%fd73, %f7;
	ld.global.nc.f32 	%f8, [%rd55+4];
	cvt.ftz.f64.f32 	%fd74, %f8;
	sub.f64 	%fd75, %fd74, %fd73;
	abs.f64 	%fd76, %fd75;
	add.f64 	%fd77, %fd72, %fd76;
	ld.global.nc.f32 	%f9, [%rd55+128];
	cvt.ftz.f64.f32 	%fd78, %f9;
	ld.global.nc.f32 	%f10, [%rd55+132];
	cvt.ftz.f64.f32 	%fd79, %f10;
	sub.f64 	%fd80, %fd79, %fd78;
	abs.f64 	%fd81, %fd80;
	add.f64 	%fd152, %fd77, %fd81;
	add.s64 	%rd55, %rd55, 512;
	add.s32 	%r85, %r85, 128;
	setp.lt.s32 	%p18, %r85, %r4;
	@%p18 bra 	$L__BB0_12;

$L__BB0_13:
	
	activemask.b32 %r44;
	
	
	mov.b64 {%r45,%r46}, %fd152;
	
	mov.u32 	%r65, 2;
	mov.u32 	%r66, 31;
	mov.u32 	%r67, 16;
	shfl.sync.down.b32 	%r48|%p19, %r46, %r67, %r66, %r44;
	shfl.sync.down.b32 	%r47|%p20, %r45, %r67, %r66, %r44;
	
	mov.b64 %fd83, {%r47,%r48};
	
	add.f64 	%fd84, %fd152, %fd83;
	
	mov.b64 {%r49,%r50}, %fd84;
	
	mov.u32 	%r68, 8;
	shfl.sync.down.b32 	%r52|%p21, %r50, %r68, %r66, %r44;
	shfl.sync.down.b32 	%r51|%p22, %r49, %r68, %r66, %r44;
	
	mov.b64 %fd85, {%r51,%r52};
	
	add.f64 	%fd86, %fd84, %fd85;
	
	mov.b64 {%r53,%r54}, %fd86;
	
	mov.u32 	%r69, 4;
	shfl.sync.down.b32 	%r56|%p23, %r54, %r69, %r66, %r44;
	shfl.sync.down.b32 	%r55|%p24, %r53, %r69, %r66, %r44;
	
	mov.b64 %fd87, {%r55,%r56};
	
	add.f64 	%fd88, %fd86, %fd87;
	
	mov.b64 {%r57,%r58}, %fd88;
	
	shfl.sync.down.b32 	%r60|%p25, %r58, %r65, %r66, %r44;
	shfl.sync.down.b32 	%r59|%p26, %r57, %r65, %r66, %r44;
	
	mov.b64 %fd89, {%r59,%r60};
	
	add.f64 	%fd90, %fd88, %fd89;
	
	mov.b64 {%r61,%r62}, %fd90;
	
	mov.u32 	%r70, 1;
	shfl.sync.down.b32 	%r64|%p27, %r62, %r70, %r66, %r44;
	shfl.sync.down.b32 	%r63|%p28, %r61, %r70, %r66, %r44;
	
	mov.b64 %fd91, {%r63,%r64};
	
	add.f64 	%fd92, %fd90, %fd91;
	setp.eq.s32 	%p29, %r93, 0;
	selp.f64 	%fd162, %fd92, 0d0000000000000000, %p29;

$L__BB0_14:
	setp.ne.s32 	%p30, %r93, 0;
	@%p30 bra 	$L__BB0_35;

	mul.wide.s32 	%rd39, %r4, 4;
	add.s64 	%rd40, %rd2, %rd39;
	ld.global.nc.f32 	%f11, [%rd40];
	cvt.ftz.f64.f32 	%fd160, %f11;
	add.s32 	%r19, %r4, %r2;
	mul.wide.s32 	%rd41, %r19, 4;
	add.s64 	%rd42, %rd1, %rd41;
	st.global.f32 	[%rd42], %f11;
	add.s32 	%r90, %r4, 1;
	setp.ge.s32 	%p31, %r90, %r35;
	@%p31 bra 	$L__BB0_35;

	mul.wide.s32 	%rd43, %r36, 4;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.nc.f32 	%f12, [%rd44];
	cvt.ftz.f64.f32 	%fd163, %f12;
	not.b32 	%r71, %r3;
	add.s32 	%r72, %r71, %r35;
	sub.s32 	%r73, %r72, %r36;
	and.b32  	%r89, %r73, 3;
	setp.eq.s32 	%p32, %r89, 0;
	mov.u32 	%r91, %r36;
	mov.f64 	%fd165, %fd160;
	@%p32 bra 	$L__BB0_21;

	add.s32 	%r74, %r19, 1;
	mul.wide.s32 	%rd45, %r74, 4;
	add.s64 	%rd58, %rd1, %rd45;
	mul.wide.s32 	%rd46, %r90, 4;
	add.s64 	%rd57, %rd2, %rd46;
	add.s32 	%r75, %r36, 1;
	mul.wide.s32 	%rd47, %r75, 4;
	add.s64 	%rd56, %rd2, %rd47;
	mov.f64 	%fd154, %fd163;
	mov.u32 	%r91, %r36;
	mov.f64 	%fd156, %fd160;

$L__BB0_18:
	.pragma "nounroll";
	ld.global.nc.f32 	%f13, [%rd57];
	cvt.ftz.f64.f32 	%fd165, %f13;
	add.s32 	%r91, %r91, 1;
	ld.global.nc.f32 	%f14, [%rd56];
	cvt.ftz.f64.f32 	%fd163, %f14;
	sub.f64 	%fd94, %fd165, %fd156;
	abs.f64 	%fd95, %fd94;
	sub.f64 	%fd96, %fd163, %fd154;
	abs.f64 	%fd97, %fd96;
	sub.f64 	%fd98, %fd95, %fd97;
	add.f64 	%fd162, %fd162, %fd98;
	setp.eq.f64 	%p33, %fd162, 0d0000000000000000;
	mov.f64 	%fd158, 0d0000000000000000;
	@%p33 bra 	$L__BB0_20;

	sub.f64 	%fd99, %fd165, %fd163;
	abs.f64 	%fd100, %fd99;
	div.rn.f64 	%fd158, %fd100, %fd162;

$L__BB0_20:
	fma.rn.f64 	%fd101, %fd158, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd102, %fd101, %fd101;
	sub.f64 	%fd103, %fd165, %fd160;
	fma.rn.f64 	%fd160, %fd103, %fd102, %fd160;
	cvt.rn.ftz.f32.f64 	%f15, %fd160;
	st.global.f32 	[%rd58], %f15;
	add.s32 	%r90, %r90, 1;
	add.s64 	%rd58, %rd58, 4;
	add.s64 	%rd57, %rd57, 4;
	add.s64 	%rd56, %rd56, 4;
	add.s32 	%r89, %r89, -1;
	setp.ne.s32 	%p34, %r89, 0;
	mov.f64 	%fd154, %fd163;
	mov.f64 	%fd156, %fd165;
	@%p34 bra 	$L__BB0_18;

$L__BB0_21:
	add.s32 	%r76, %r35, -2;
	sub.s32 	%r77, %r76, %r3;
	sub.s32 	%r78, %r77, %r36;
	setp.lt.u32 	%p35, %r78, 3;
	@%p35 bra 	$L__BB0_35;

	add.s32 	%r79, %r90, %r2;
	mul.wide.s32 	%rd48, %r79, 4;
	add.s64 	%rd59, %rd1, %rd48;
	mul.wide.s32 	%rd49, %r90, 4;
	add.s64 	%rd60, %rd2, %rd49;
	mul.wide.s32 	%rd50, %r91, 4;
	add.s64 	%rd51, %rd2, %rd50;
	add.s64 	%rd61, %rd51, 4;

$L__BB0_23:
	ld.global.nc.f32 	%f16, [%rd60];
	cvt.ftz.f64.f32 	%fd30, %f16;
	ld.global.nc.f32 	%f17, [%rd61];
	cvt.ftz.f64.f32 	%fd31, %f17;
	sub.f64 	%fd105, %fd30, %fd165;
	abs.f64 	%fd106, %fd105;
	sub.f64 	%fd107, %fd31, %fd163;
	abs.f64 	%fd108, %fd107;
	sub.f64 	%fd109, %fd106, %fd108;
	add.f64 	%fd32, %fd162, %fd109;
	setp.eq.f64 	%p36, %fd32, 0d0000000000000000;
	mov.f64 	%fd168, 0d0000000000000000;
	mov.f64 	%fd167, %fd168;
	@%p36 bra 	$L__BB0_25;

	sub.f64 	%fd110, %fd30, %fd31;
	abs.f64 	%fd111, %fd110;
	div.rn.f64 	%fd167, %fd111, %fd32;

$L__BB0_25:
	fma.rn.f64 	%fd113, %fd167, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd114, %fd113, %fd113;
	sub.f64 	%fd115, %fd30, %fd160;
	fma.rn.f64 	%fd35, %fd115, %fd114, %fd160;
	cvt.rn.ftz.f32.f64 	%f18, %fd35;
	st.global.f32 	[%rd59], %f18;
	ld.global.nc.f32 	%f19, [%rd60+4];
	cvt.ftz.f64.f32 	%fd36, %f19;
	ld.global.nc.f32 	%f20, [%rd61+4];
	cvt.ftz.f64.f32 	%fd37, %f20;
	sub.f64 	%fd116, %fd36, %fd30;
	abs.f64 	%fd117, %fd116;
	sub.f64 	%fd118, %fd37, %fd31;
	abs.f64 	%fd119, %fd118;
	sub.f64 	%fd120, %fd117, %fd119;
	add.f64 	%fd38, %fd32, %fd120;
	setp.eq.f64 	%p37, %fd38, 0d0000000000000000;
	@%p37 bra 	$L__BB0_27;

	sub.f64 	%fd121, %fd36, %fd37;
	abs.f64 	%fd122, %fd121;
	div.rn.f64 	%fd168, %fd122, %fd38;

$L__BB0_27:
	fma.rn.f64 	%fd124, %fd168, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd125, %fd124, %fd124;
	sub.f64 	%fd126, %fd36, %fd35;
	fma.rn.f64 	%fd41, %fd126, %fd125, %fd35;
	cvt.rn.ftz.f32.f64 	%f21, %fd41;
	st.global.f32 	[%rd59+4], %f21;
	ld.global.nc.f32 	%f22, [%rd60+8];
	cvt.ftz.f64.f32 	%fd42, %f22;
	ld.global.nc.f32 	%f23, [%rd61+8];
	cvt.ftz.f64.f32 	%fd43, %f23;
	sub.f64 	%fd127, %fd42, %fd36;
	abs.f64 	%fd128, %fd127;
	sub.f64 	%fd129, %fd43, %fd37;
	abs.f64 	%fd130, %fd129;
	sub.f64 	%fd131, %fd128, %fd130;
	add.f64 	%fd44, %fd38, %fd131;
	setp.eq.f64 	%p38, %fd44, 0d0000000000000000;
	mov.f64 	%fd170, 0d0000000000000000;
	mov.f64 	%fd169, %fd170;
	@%p38 bra 	$L__BB0_29;

	sub.f64 	%fd132, %fd42, %fd43;
	abs.f64 	%fd133, %fd132;
	div.rn.f64 	%fd169, %fd133, %fd44;

$L__BB0_29:
	fma.rn.f64 	%fd135, %fd169, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd136, %fd135, %fd135;
	sub.f64 	%fd137, %fd42, %fd41;
	fma.rn.f64 	%fd47, %fd137, %fd136, %fd41;
	cvt.rn.ftz.f32.f64 	%f24, %fd47;
	st.global.f32 	[%rd59+8], %f24;
	ld.global.nc.f32 	%f25, [%rd60+12];
	cvt.ftz.f64.f32 	%fd165, %f25;
	ld.global.nc.f32 	%f26, [%rd61+12];
	cvt.ftz.f64.f32 	%fd163, %f26;
	sub.f64 	%fd138, %fd165, %fd42;
	abs.f64 	%fd139, %fd138;
	sub.f64 	%fd140, %fd163, %fd43;
	abs.f64 	%fd141, %fd140;
	sub.f64 	%fd142, %fd139, %fd141;
	add.f64 	%fd162, %fd44, %fd142;
	setp.eq.f64 	%p39, %fd162, 0d0000000000000000;
	@%p39 bra 	$L__BB0_31;

	sub.f64 	%fd143, %fd165, %fd163;
	abs.f64 	%fd144, %fd143;
	div.rn.f64 	%fd170, %fd144, %fd162;

$L__BB0_31:
	add.s64 	%rd61, %rd61, 16;
	add.s64 	%rd60, %rd60, 16;
	fma.rn.f64 	%fd145, %fd170, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd146, %fd145, %fd145;
	sub.f64 	%fd147, %fd165, %fd47;
	fma.rn.f64 	%fd160, %fd147, %fd146, %fd47;
	cvt.rn.ftz.f32.f64 	%f27, %fd160;
	add.s64 	%rd26, %rd59, 16;
	st.global.f32 	[%rd59+12], %f27;
	add.s32 	%r90, %r90, 4;
	setp.lt.s32 	%p40, %r90, %r35;
	mov.u64 	%rd59, %rd26;
	@%p40 bra 	$L__BB0_23;

$L__BB0_35:
	ret;

}
	
.visible .entry kama_batch_prefix_f32(
	.param .u64 kama_batch_prefix_f32_param_0,
	.param .u64 kama_batch_prefix_f32_param_1,
	.param .u64 kama_batch_prefix_f32_param_2,
	.param .u32 kama_batch_prefix_f32_param_3,
	.param .u32 kama_batch_prefix_f32_param_4,
	.param .u32 kama_batch_prefix_f32_param_5,
	.param .u64 kama_batch_prefix_f32_param_6
)
.maxntid 32, 1, 1
{
	.reg .pred 	%p<48>;
	.reg .f32 	%f<158>;
	.reg .b32 	%r<108>;
	.reg .b64 	%rd<75>;


	ld.param.u64 	%rd37, [kama_batch_prefix_f32_param_0];
	ld.param.u64 	%rd38, [kama_batch_prefix_f32_param_1];
	ld.param.u64 	%rd36, [kama_batch_prefix_f32_param_2];
	ld.param.u32 	%r53, [kama_batch_prefix_f32_param_3];
	ld.param.u32 	%r55, [kama_batch_prefix_f32_param_4];
	ld.param.u32 	%r54, [kama_batch_prefix_f32_param_5];
	ld.param.u64 	%rd39, [kama_batch_prefix_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd38;
	cvta.to.global.u64 	%rd2, %rd39;
	cvta.to.global.u64 	%rd3, %rd37;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p11, %r1, %r55;
	@%p11 bra 	$L__BB1_43;

	cvta.to.global.u64 	%rd40, %rd36;
	mul.wide.s32 	%rd41, %r1, 4;
	add.s64 	%rd42, %rd40, %rd41;
	mul.lo.s32 	%r2, %r1, %r53;
	ld.global.nc.u32 	%r3, [%rd42];
	add.s32 	%r4, %r3, %r54;
	setp.lt.s32 	%p12, %r3, 1;
	setp.le.s32 	%p13, %r53, %r54;
	setp.lt.s32 	%p14, %r54, 0;
	or.pred  	%p15, %p14, %p13;
	or.pred  	%p16, %p15, %p12;
	sub.s32 	%r56, %r53, %r54;
	setp.ge.s32 	%p17, %r3, %r56;
	or.pred  	%p18, %p17, %p16;
	setp.ge.s32 	%p19, %r4, %r53;
	or.pred  	%p20, %p19, %p18;
	mov.u32 	%r107, %tid.x;
	@%p20 bra 	$L__BB1_40;
	bra.uni 	$L__BB1_2;

$L__BB1_40:
	setp.ge.s32 	%p46, %r107, %r53;
	@%p46 bra 	$L__BB1_43;

	mov.u32 	%r50, %ntid.x;

$L__BB1_42:
	add.s32 	%r90, %r107, %r2;
	mul.wide.s32 	%rd63, %r90, 4;
	add.s64 	%rd64, %rd2, %rd63;
	mov.u32 	%r91, 2147483647;
	st.global.u32 	[%rd64], %r91;
	add.s32 	%r107, %r107, %r50;
	setp.lt.s32 	%p47, %r107, %r53;
	@%p47 bra 	$L__BB1_42;
	bra.uni 	$L__BB1_43;

$L__BB1_2:
	setp.ge.s32 	%p21, %r107, %r4;
	@%p21 bra 	$L__BB1_5;

	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r92, %r107;

$L__BB1_4:
	add.s32 	%r57, %r92, %r2;
	mul.wide.s32 	%rd43, %r57, 4;
	add.s64 	%rd44, %rd2, %rd43;
	mov.u32 	%r58, 2147483647;
	st.global.u32 	[%rd44], %r58;
	add.s32 	%r92, %r92, %r6;
	setp.lt.s32 	%p22, %r92, %r4;
	@%p22 bra 	$L__BB1_4;

$L__BB1_5:
	setp.ne.s32 	%p23, %r107, 0;
	mul.wide.s32 	%rd45, %r4, 4;
	add.s64 	%rd4, %rd3, %rd45;
	@%p23 bra 	$L__BB1_7;

	ld.global.nc.f32 	%f59, [%rd4];
	add.s32 	%r59, %r4, %r2;
	mul.wide.s32 	%rd46, %r59, 4;
	add.s64 	%rd47, %rd2, %rd46;
	st.global.f32 	[%rd47], %f59;

$L__BB1_7:
	setp.gt.s32 	%p24, %r107, 31;
	@%p24 bra 	$L__BB1_43;

	ld.global.nc.f32 	%f152, [%rd4];
	add.s32 	%r102, %r4, 1;
	add.s32 	%r60, %r4, 32;
	setp.ge.s32 	%p25, %r60, %r53;
	@%p25 bra 	$L__BB1_23;

	mov.u32 	%r93, %r102;

$L__BB1_10:
	add.s32 	%r11, %r93, %r107;
	mul.wide.s32 	%rd48, %r11, 4;
	add.s64 	%rd49, %rd3, %rd48;
	add.s64 	%rd50, %rd1, %rd48;
	sub.s32 	%r61, %r11, %r3;
	cvt.s64.s32 	%rd5, %r61;
	mul.wide.s32 	%rd51, %r61, 4;
	add.s64 	%rd52, %rd1, %rd51;
	ld.global.nc.f32 	%f61, [%rd52];
	ld.global.nc.f32 	%f62, [%rd50];
	sub.ftz.f32 	%f3, %f62, %f61;
	ld.global.nc.f32 	%f4, [%rd49];
	setp.eq.ftz.f32 	%p26, %f3, 0f00000000;
	mov.f32 	%f138, 0f00000000;
	@%p26 bra 	$L__BB1_12;

	shl.b64 	%rd53, %rd5, 2;
	add.s64 	%rd54, %rd3, %rd53;
	ld.global.nc.f32 	%f63, [%rd54];
	sub.ftz.f32 	%f64, %f4, %f63;
	abs.ftz.f32 	%f65, %f64;
	div.approx.ftz.f32 	%f138, %f65, %f3;

$L__BB1_12:
	mov.f32 	%f66, 0f3D842108;
	mov.f32 	%f67, 0f3F1A268A;
	fma.rn.ftz.f32 	%f68, %f138, %f67, %f66;
	mul.ftz.f32 	%f69, %f68, %f68;
	mov.f32 	%f70, 0f3F800000;
	sub.ftz.f32 	%f141, %f70, %f69;
	mul.ftz.f32 	%f142, %f4, %f69;
	mov.b32 	%r97, %f141;
	mov.u32 	%r62, 0;
	mov.u32 	%r63, 1;
	mov.u32 	%r64, -1;
	shfl.sync.up.b32 	%r13|%p1, %r97, %r63, %r62, %r64;
	mov.b32 	%r96, %f142;
	shfl.sync.up.b32 	%r15|%p2, %r96, %r63, %r62, %r64;
	setp.lt.s32 	%p27, %r107, 1;
	@%p27 bra 	$L__BB1_14;

	mov.b32 	%f71, %r15;
	mov.b32 	%f72, %r13;
	fma.rn.ftz.f32 	%f142, %f141, %f71, %f142;
	mul.ftz.f32 	%f141, %f141, %f72;
	mov.b32 	%r97, %f141;
	mov.b32 	%r96, %f142;

$L__BB1_14:
	mov.u32 	%r66, 2;
	shfl.sync.up.b32 	%r20|%p3, %r97, %r66, %r62, %r64;
	shfl.sync.up.b32 	%r21|%p4, %r96, %r66, %r62, %r64;
	setp.lt.s32 	%p28, %r107, 2;
	@%p28 bra 	$L__BB1_16;

	mov.b32 	%f73, %r21;
	mov.b32 	%f74, %r20;
	fma.rn.ftz.f32 	%f142, %f141, %f73, %f142;
	mul.ftz.f32 	%f141, %f141, %f74;
	mov.b32 	%r97, %f141;
	mov.b32 	%r96, %f142;

$L__BB1_16:
	mov.u32 	%r68, 0;
	mov.u32 	%r69, 4;
	mov.u32 	%r70, -1;
	shfl.sync.up.b32 	%r26|%p5, %r97, %r69, %r68, %r70;
	shfl.sync.up.b32 	%r27|%p6, %r96, %r69, %r68, %r70;
	setp.lt.s32 	%p29, %r107, 4;
	@%p29 bra 	$L__BB1_18;

	mov.b32 	%f75, %r27;
	mov.b32 	%f76, %r26;
	fma.rn.ftz.f32 	%f142, %f141, %f75, %f142;
	mul.ftz.f32 	%f141, %f141, %f76;
	mov.b32 	%r97, %f141;
	mov.b32 	%r96, %f142;

$L__BB1_18:
	mov.u32 	%r72, 8;
	shfl.sync.up.b32 	%r32|%p7, %r97, %r72, %r68, %r70;
	shfl.sync.up.b32 	%r33|%p8, %r96, %r72, %r68, %r70;
	setp.lt.s32 	%p30, %r107, 8;
	@%p30 bra 	$L__BB1_20;

	mov.b32 	%f77, %r33;
	mov.b32 	%f78, %r32;
	fma.rn.ftz.f32 	%f142, %f141, %f77, %f142;
	mul.ftz.f32 	%f141, %f141, %f78;
	mov.b32 	%r97, %f141;
	mov.b32 	%r96, %f142;

$L__BB1_20:
	mov.u32 	%r74, 0;
	mov.u32 	%r75, 16;
	mov.u32 	%r76, -1;
	shfl.sync.up.b32 	%r38|%p9, %r97, %r75, %r74, %r76;
	shfl.sync.up.b32 	%r39|%p10, %r96, %r75, %r74, %r76;
	setp.lt.s32 	%p31, %r107, 16;
	@%p31 bra 	$L__BB1_22;

	mov.b32 	%f79, %r39;
	mov.b32 	%f80, %r38;
	fma.rn.ftz.f32 	%f142, %f141, %f79, %f142;
	mul.ftz.f32 	%f141, %f141, %f80;

$L__BB1_22:
	add.s32 	%r77, %r11, %r2;
	mul.wide.s32 	%rd55, %r77, 4;
	add.s64 	%rd56, %rd2, %rd55;
	fma.rn.ftz.f32 	%f81, %f141, %f152, %f142;
	st.global.f32 	[%rd56], %f81;
	mov.b32 	%r78, %f81;
	mov.u32 	%r79, 31;
	shfl.sync.idx.b32 	%r81|%p32, %r78, %r79, %r79, %r76;
	mov.b32 	%f152, %r81;
	add.s32 	%r102, %r93, 32;
	add.s32 	%r82, %r93, 63;
	setp.lt.s32 	%p33, %r82, %r53;
	mov.u32 	%r93, %r102;
	@%p33 bra 	$L__BB1_10;

$L__BB1_23:
	setp.ge.s32 	%p34, %r102, %r53;
	or.pred  	%p36, %p23, %p34;
	@%p36 bra 	$L__BB1_43;

	sub.s32 	%r83, %r53, %r102;
	and.b32  	%r104, %r83, 3;
	setp.eq.s32 	%p37, %r104, 0;
	mov.u32 	%r105, %r102;
	@%p37 bra 	$L__BB1_29;

	add.s32 	%r84, %r102, %r2;
	mul.wide.s32 	%rd57, %r84, 4;
	add.s64 	%rd69, %rd2, %rd57;
	sub.s32 	%r85, %r3, %r102;
	mul.wide.s32 	%rd58, %r85, 4;
	sub.s64 	%rd68, %rd3, %rd58;
	sub.s64 	%rd67, %rd1, %rd58;
	mul.wide.s32 	%rd59, %r102, 4;
	add.s64 	%rd66, %rd1, %rd59;
	add.s64 	%rd65, %rd3, %rd59;
	mov.u32 	%r105, %r102;

$L__BB1_26:
	.pragma "nounroll";
	ld.global.nc.f32 	%f83, [%rd67];
	ld.global.nc.f32 	%f84, [%rd66];
	sub.ftz.f32 	%f32, %f84, %f83;
	ld.global.nc.f32 	%f33, [%rd65];
	setp.eq.ftz.f32 	%p38, %f32, 0f00000000;
	mov.f32 	%f151, 0f00000000;
	@%p38 bra 	$L__BB1_28;

	ld.global.nc.f32 	%f85, [%rd68];
	sub.ftz.f32 	%f86, %f33, %f85;
	abs.ftz.f32 	%f87, %f86;
	div.approx.ftz.f32 	%f151, %f87, %f32;

$L__BB1_28:
	mov.f32 	%f88, 0f3D842108;
	mov.f32 	%f89, 0f3F1A268A;
	fma.rn.ftz.f32 	%f90, %f151, %f89, %f88;
	mul.ftz.f32 	%f91, %f90, %f90;
	sub.ftz.f32 	%f92, %f33, %f152;
	fma.rn.ftz.f32 	%f152, %f92, %f91, %f152;
	st.global.f32 	[%rd69], %f152;
	add.s32 	%r105, %r105, 1;
	add.s64 	%rd69, %rd69, 4;
	add.s64 	%rd68, %rd68, 4;
	add.s64 	%rd67, %rd67, 4;
	add.s64 	%rd66, %rd66, 4;
	add.s64 	%rd65, %rd65, 4;
	add.s32 	%r104, %r104, -1;
	setp.ne.s32 	%p39, %r104, 0;
	@%p39 bra 	$L__BB1_26;

$L__BB1_29:
	not.b32 	%r86, %r102;
	add.s32 	%r87, %r86, %r53;
	setp.lt.u32 	%p40, %r87, 3;
	@%p40 bra 	$L__BB1_43;

	add.s32 	%r88, %r105, %r2;
	sub.s32 	%r89, %r3, %r105;
	mul.wide.s32 	%rd60, %r88, 4;
	add.s64 	%rd70, %rd2, %rd60;
	mul.wide.s32 	%rd61, %r105, 4;
	add.s64 	%rd71, %rd3, %rd61;
	mul.wide.s32 	%rd62, %r89, 4;
	sub.s64 	%rd72, %rd3, %rd62;
	add.s64 	%rd73, %rd1, %rd61;
	sub.s64 	%rd74, %rd1, %rd62;

$L__BB1_31:
	ld.global.nc.f32 	%f94, [%rd74];
	ld.global.nc.f32 	%f95, [%rd73];
	sub.ftz.f32 	%f39, %f95, %f94;
	ld.global.nc.f32 	%f40, [%rd71];
	setp.eq.ftz.f32 	%p41, %f39, 0f00000000;
	mov.f32 	%f155, 0f00000000;
	mov.f32 	%f154, %f155;
	@%p41 bra 	$L__BB1_33;

	ld.global.nc.f32 	%f96, [%rd72];
	sub.ftz.f32 	%f97, %f40, %f96;
	abs.ftz.f32 	%f98, %f97;
	div.approx.ftz.f32 	%f154, %f98, %f39;

$L__BB1_33:
	mov.f32 	%f100, 0f3D842108;
	mov.f32 	%f101, 0f3F1A268A;
	fma.rn.ftz.f32 	%f102, %f154, %f101, %f100;
	mul.ftz.f32 	%f103, %f102, %f102;
	sub.ftz.f32 	%f104, %f40, %f152;
	fma.rn.ftz.f32 	%f43, %f104, %f103, %f152;
	st.global.f32 	[%rd70], %f43;
	ld.global.nc.f32 	%f105, [%rd74+4];
	ld.global.nc.f32 	%f106, [%rd73+4];
	sub.ftz.f32 	%f44, %f106, %f105;
	ld.global.nc.f32 	%f45, [%rd71+4];
	setp.eq.ftz.f32 	%p42, %f44, 0f00000000;
	@%p42 bra 	$L__BB1_35;

	ld.global.nc.f32 	%f107, [%rd72+4];
	sub.ftz.f32 	%f108, %f45, %f107;
	abs.ftz.f32 	%f109, %f108;
	div.approx.ftz.f32 	%f155, %f109, %f44;

$L__BB1_35:
	fma.rn.ftz.f32 	%f113, %f155, %f101, %f100;
	mul.ftz.f32 	%f114, %f113, %f113;
	sub.ftz.f32 	%f115, %f45, %f43;
	fma.rn.ftz.f32 	%f48, %f115, %f114, %f43;
	st.global.f32 	[%rd70+4], %f48;
	ld.global.nc.f32 	%f116, [%rd74+8];
	ld.global.nc.f32 	%f117, [%rd73+8];
	sub.ftz.f32 	%f49, %f117, %f116;
	ld.global.nc.f32 	%f50, [%rd71+8];
	setp.eq.ftz.f32 	%p43, %f49, 0f00000000;
	mov.f32 	%f157, 0f00000000;
	mov.f32 	%f156, %f157;
	@%p43 bra 	$L__BB1_37;

	ld.global.nc.f32 	%f118, [%rd72+8];
	sub.ftz.f32 	%f119, %f50, %f118;
	abs.ftz.f32 	%f120, %f119;
	div.approx.ftz.f32 	%f156, %f120, %f49;

$L__BB1_37:
	mov.f32 	%f122, 0f3D842108;
	mov.f32 	%f123, 0f3F1A268A;
	fma.rn.ftz.f32 	%f124, %f156, %f123, %f122;
	mul.ftz.f32 	%f125, %f124, %f124;
	sub.ftz.f32 	%f126, %f50, %f48;
	fma.rn.ftz.f32 	%f53, %f126, %f125, %f48;
	st.global.f32 	[%rd70+8], %f53;
	ld.global.nc.f32 	%f127, [%rd74+12];
	ld.global.nc.f32 	%f128, [%rd73+12];
	sub.ftz.f32 	%f54, %f128, %f127;
	ld.global.nc.f32 	%f55, [%rd71+12];
	setp.eq.ftz.f32 	%p44, %f54, 0f00000000;
	@%p44 bra 	$L__BB1_39;

	ld.global.nc.f32 	%f129, [%rd72+12];
	sub.ftz.f32 	%f130, %f55, %f129;
	abs.ftz.f32 	%f131, %f130;
	div.approx.ftz.f32 	%f157, %f131, %f54;

$L__BB1_39:
	add.s64 	%rd74, %rd74, 16;
	add.s64 	%rd73, %rd73, 16;
	add.s64 	%rd72, %rd72, 16;
	add.s64 	%rd71, %rd71, 16;
	fma.rn.ftz.f32 	%f134, %f157, %f123, %f122;
	mul.ftz.f32 	%f135, %f134, %f134;
	sub.ftz.f32 	%f136, %f55, %f53;
	fma.rn.ftz.f32 	%f152, %f136, %f135, %f53;
	add.s64 	%rd35, %rd70, 16;
	st.global.f32 	[%rd70+12], %f152;
	add.s32 	%r105, %r105, 4;
	setp.lt.s32 	%p45, %r105, %r53;
	mov.u64 	%rd70, %rd35;
	@%p45 bra 	$L__BB1_31;

$L__BB1_43:
	ret;

}
	
.visible .entry kama_many_series_one_param_time_major_f32(
	.param .u64 kama_many_series_one_param_time_major_f32_param_0,
	.param .u32 kama_many_series_one_param_time_major_f32_param_1,
	.param .u32 kama_many_series_one_param_time_major_f32_param_2,
	.param .u32 kama_many_series_one_param_time_major_f32_param_3,
	.param .u64 kama_many_series_one_param_time_major_f32_param_4,
	.param .u64 kama_many_series_one_param_time_major_f32_param_5
)
.maxntid 32, 1, 1
{
	.reg .pred 	%p<43>;
	.reg .f32 	%f<28>;
	.reg .b32 	%r<105>;
	.reg .f64 	%fd<171>;
	.reg .b64 	%rd<85>;


	ld.param.u64 	%rd46, [kama_many_series_one_param_time_major_f32_param_0];
	ld.param.u32 	%r33, [kama_many_series_one_param_time_major_f32_param_1];
	ld.param.u32 	%r34, [kama_many_series_one_param_time_major_f32_param_2];
	ld.param.u32 	%r35, [kama_many_series_one_param_time_major_f32_param_3];
	ld.param.u64 	%rd45, [kama_many_series_one_param_time_major_f32_param_4];
	ld.param.u64 	%rd47, [kama_many_series_one_param_time_major_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd47;
	cvta.to.global.u64 	%rd2, %rd46;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r34;
	@%p1 bra 	$L__BB2_35;

	cvta.to.global.u64 	%rd48, %rd45;
	mul.wide.s32 	%rd49, %r1, 4;
	add.s64 	%rd50, %rd48, %rd49;
	ld.global.nc.u32 	%r2, [%rd50];
	setp.lt.s32 	%p2, %r2, 0;
	setp.ge.s32 	%p3, %r2, %r35;
	or.pred  	%p4, %p2, %p3;
	setp.lt.s32 	%p5, %r33, 1;
	or.pred  	%p6, %p5, %p4;
	sub.s32 	%r36, %r35, %r2;
	setp.le.s32 	%p7, %r36, %r33;
	or.pred  	%p8, %p7, %p6;
	add.s32 	%r3, %r2, %r33;
	setp.ge.s32 	%p9, %r3, %r35;
	or.pred  	%p10, %p9, %p8;
	mov.u32 	%r104, %tid.x;
	@%p10 bra 	$L__BB2_32;
	bra.uni 	$L__BB2_2;

$L__BB2_32:
	setp.ge.s32 	%p41, %r104, %r35;
	@%p41 bra 	$L__BB2_35;

	mov.u32 	%r30, %ntid.x;

$L__BB2_34:
	mad.lo.s32 	%r91, %r104, %r34, %r1;
	mul.wide.s32 	%rd73, %r91, 4;
	add.s64 	%rd74, %rd1, %rd73;
	mov.u32 	%r92, 2147483647;
	st.global.u32 	[%rd74], %r92;
	add.s32 	%r104, %r104, %r30;
	setp.lt.s32 	%p42, %r104, %r35;
	@%p42 bra 	$L__BB2_34;
	bra.uni 	$L__BB2_35;

$L__BB2_2:
	setp.ge.s32 	%p11, %r104, %r3;
	@%p11 bra 	$L__BB2_5;

	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r93, %r104;

$L__BB2_4:
	mad.lo.s32 	%r37, %r93, %r34, %r1;
	mul.wide.s32 	%rd51, %r37, 4;
	add.s64 	%rd52, %rd1, %rd51;
	mov.u32 	%r38, 2147483647;
	st.global.u32 	[%rd52], %r38;
	add.s32 	%r93, %r93, %r5;
	setp.lt.s32 	%p12, %r93, %r3;
	@%p12 bra 	$L__BB2_4;

$L__BB2_5:
	setp.gt.u32 	%p13, %r104, 31;
	mov.f64 	%fd162, 0d0000000000000000;
	@%p13 bra 	$L__BB2_14;

	add.s32 	%r96, %r2, %r104;
	setp.ge.s32 	%p14, %r96, %r3;
	mov.f64 	%fd152, 0d0000000000000000;
	@%p14 bra 	$L__BB2_13;

	not.b32 	%r39, %r104;
	add.s32 	%r9, %r39, %r33;
	shr.u32 	%r40, %r9, 5;
	add.s32 	%r41, %r40, 1;
	and.b32  	%r95, %r41, 3;
	setp.eq.s32 	%p15, %r95, 0;
	mov.f64 	%fd152, 0d0000000000000000;
	@%p15 bra 	$L__BB2_10;

	add.s32 	%r42, %r96, 1;
	mad.lo.s32 	%r43, %r34, %r42, %r1;
	mul.wide.s32 	%rd53, %r43, 4;
	add.s64 	%rd76, %rd2, %rd53;
	shl.b32 	%r44, %r34, 5;
	mul.wide.s32 	%rd4, %r44, 4;
	mad.lo.s32 	%r45, %r34, %r96, %r1;
	mul.wide.s32 	%rd54, %r45, 4;
	add.s64 	%rd75, %rd2, %rd54;
	mov.f64 	%fd152, 0d0000000000000000;

$L__BB2_9:
	.pragma "nounroll";
	ld.global.nc.f32 	%f1, [%rd75];
	cvt.ftz.f64.f32 	%fd59, %f1;
	ld.global.nc.f32 	%f2, [%rd76];
	cvt.ftz.f64.f32 	%fd60, %f2;
	sub.f64 	%fd61, %fd60, %fd59;
	abs.f64 	%fd62, %fd61;
	add.f64 	%fd152, %fd152, %fd62;
	add.s32 	%r96, %r96, 32;
	add.s64 	%rd76, %rd76, %rd4;
	add.s64 	%rd75, %rd75, %rd4;
	add.s32 	%r95, %r95, -1;
	setp.ne.s32 	%p16, %r95, 0;
	@%p16 bra 	$L__BB2_9;

$L__BB2_10:
	setp.lt.u32 	%p17, %r9, 96;
	@%p17 bra 	$L__BB2_13;

	add.s32 	%r46, %r96, 1;
	mad.lo.s32 	%r47, %r34, %r46, %r1;
	mad.lo.s32 	%r48, %r96, %r34, %r1;
	mul.wide.s32 	%rd55, %r48, 4;
	add.s64 	%rd77, %rd2, %rd55;
	shl.b32 	%r49, %r34, 5;
	mul.wide.s32 	%rd11, %r49, 4;
	mul.wide.s32 	%rd56, %r47, 4;
	add.s64 	%rd78, %rd2, %rd56;

$L__BB2_12:
	ld.global.nc.f32 	%f3, [%rd77];
	cvt.ftz.f64.f32 	%fd63, %f3;
	ld.global.nc.f32 	%f4, [%rd78];
	cvt.ftz.f64.f32 	%fd64, %f4;
	sub.f64 	%fd65, %fd64, %fd63;
	abs.f64 	%fd66, %fd65;
	add.f64 	%fd67, %fd152, %fd66;
	add.s64 	%rd57, %rd77, %rd11;
	ld.global.nc.f32 	%f5, [%rd57];
	cvt.ftz.f64.f32 	%fd68, %f5;
	add.s64 	%rd58, %rd78, %rd11;
	ld.global.nc.f32 	%f6, [%rd58];
	cvt.ftz.f64.f32 	%fd69, %f6;
	sub.f64 	%fd70, %fd69, %fd68;
	abs.f64 	%fd71, %fd70;
	add.f64 	%fd72, %fd67, %fd71;
	add.s64 	%rd59, %rd57, %rd11;
	ld.global.nc.f32 	%f7, [%rd59];
	cvt.ftz.f64.f32 	%fd73, %f7;
	add.s64 	%rd60, %rd58, %rd11;
	ld.global.nc.f32 	%f8, [%rd60];
	cvt.ftz.f64.f32 	%fd74, %f8;
	sub.f64 	%fd75, %fd74, %fd73;
	abs.f64 	%fd76, %fd75;
	add.f64 	%fd77, %fd72, %fd76;
	add.s64 	%rd61, %rd59, %rd11;
	add.s64 	%rd77, %rd61, %rd11;
	ld.global.nc.f32 	%f9, [%rd61];
	cvt.ftz.f64.f32 	%fd78, %f9;
	add.s64 	%rd62, %rd60, %rd11;
	add.s64 	%rd78, %rd62, %rd11;
	ld.global.nc.f32 	%f10, [%rd62];
	cvt.ftz.f64.f32 	%fd79, %f10;
	sub.f64 	%fd80, %fd79, %fd78;
	abs.f64 	%fd81, %fd80;
	add.f64 	%fd152, %fd77, %fd81;
	add.s32 	%r96, %r96, 128;
	setp.lt.s32 	%p18, %r96, %r3;
	@%p18 bra 	$L__BB2_12;

$L__BB2_13:
	
	activemask.b32 %r50;
	
	
	mov.b64 {%r51,%r52}, %fd152;
	
	mov.u32 	%r71, 2;
	mov.u32 	%r72, 31;
	mov.u32 	%r73, 16;
	shfl.sync.down.b32 	%r54|%p19, %r52, %r73, %r72, %r50;
	shfl.sync.down.b32 	%r53|%p20, %r51, %r73, %r72, %r50;
	
	mov.b64 %fd83, {%r53,%r54};
	
	add.f64 	%fd84, %fd152, %fd83;
	
	mov.b64 {%r55,%r56}, %fd84;
	
	mov.u32 	%r74, 8;
	shfl.sync.down.b32 	%r58|%p21, %r56, %r74, %r72, %r50;
	shfl.sync.down.b32 	%r57|%p22, %r55, %r74, %r72, %r50;
	
	mov.b64 %fd85, {%r57,%r58};
	
	add.f64 	%fd86, %fd84, %fd85;
	
	mov.b64 {%r59,%r60}, %fd86;
	
	mov.u32 	%r75, 4;
	shfl.sync.down.b32 	%r62|%p23, %r60, %r75, %r72, %r50;
	shfl.sync.down.b32 	%r61|%p24, %r59, %r75, %r72, %r50;
	
	mov.b64 %fd87, {%r61,%r62};
	
	add.f64 	%fd88, %fd86, %fd87;
	
	mov.b64 {%r63,%r64}, %fd88;
	
	shfl.sync.down.b32 	%r66|%p25, %r64, %r71, %r72, %r50;
	shfl.sync.down.b32 	%r65|%p26, %r63, %r71, %r72, %r50;
	
	mov.b64 %fd89, {%r65,%r66};
	
	add.f64 	%fd90, %fd88, %fd89;
	
	mov.b64 {%r67,%r68}, %fd90;
	
	mov.u32 	%r76, 1;
	shfl.sync.down.b32 	%r70|%p27, %r68, %r76, %r72, %r50;
	shfl.sync.down.b32 	%r69|%p28, %r67, %r76, %r72, %r50;
	
	mov.b64 %fd91, {%r69,%r70};
	
	add.f64 	%fd92, %fd90, %fd91;
	setp.eq.s32 	%p29, %r104, 0;
	selp.f64 	%fd162, %fd92, 0d0000000000000000, %p29;

$L__BB2_14:
	setp.ne.s32 	%p30, %r104, 0;
	@%p30 bra 	$L__BB2_35;

	mad.lo.s32 	%r77, %r3, %r34, %r1;
	mul.wide.s32 	%rd63, %r77, 4;
	add.s64 	%rd64, %rd2, %rd63;
	ld.global.nc.f32 	%f11, [%rd64];
	cvt.ftz.f64.f32 	%fd160, %f11;
	add.s64 	%rd65, %rd1, %rd63;
	st.global.f32 	[%rd65], %f11;
	add.s32 	%r101, %r3, 1;
	setp.ge.s32 	%p31, %r101, %r35;
	@%p31 bra 	$L__BB2_35;

	mad.lo.s32 	%r78, %r2, %r34, %r1;
	mul.wide.s32 	%rd66, %r78, 4;
	add.s64 	%rd67, %rd2, %rd66;
	ld.global.nc.f32 	%f12, [%rd67];
	cvt.ftz.f64.f32 	%fd163, %f12;
	not.b32 	%r79, %r2;
	add.s32 	%r80, %r79, %r35;
	sub.s32 	%r81, %r80, %r33;
	and.b32  	%r100, %r81, 3;
	setp.eq.s32 	%p32, %r100, 0;
	mov.u32 	%r102, %r2;
	mov.f64 	%fd165, %fd160;
	@%p32 bra 	$L__BB2_21;

	mad.lo.s32 	%r82, %r34, %r101, %r1;
	mul.wide.s32 	%rd68, %r82, 4;
	add.s64 	%rd81, %rd1, %rd68;
	mul.wide.s32 	%rd18, %r34, 4;
	add.s64 	%rd80, %rd2, %rd68;
	add.s32 	%r83, %r2, 1;
	mad.lo.s32 	%r84, %r34, %r83, %r1;
	mul.wide.s32 	%rd69, %r84, 4;
	add.s64 	%rd79, %rd2, %rd69;
	mov.f64 	%fd154, %fd163;
	mov.u32 	%r102, %r2;
	mov.f64 	%fd156, %fd160;

$L__BB2_18:
	.pragma "nounroll";
	ld.global.nc.f32 	%f13, [%rd80];
	cvt.ftz.f64.f32 	%fd165, %f13;
	add.s32 	%r102, %r102, 1;
	ld.global.nc.f32 	%f14, [%rd79];
	cvt.ftz.f64.f32 	%fd163, %f14;
	sub.f64 	%fd94, %fd165, %fd156;
	abs.f64 	%fd95, %fd94;
	sub.f64 	%fd96, %fd163, %fd154;
	abs.f64 	%fd97, %fd96;
	sub.f64 	%fd98, %fd95, %fd97;
	add.f64 	%fd162, %fd162, %fd98;
	setp.eq.f64 	%p33, %fd162, 0d0000000000000000;
	mov.f64 	%fd158, 0d0000000000000000;
	@%p33 bra 	$L__BB2_20;

	sub.f64 	%fd99, %fd165, %fd163;
	abs.f64 	%fd100, %fd99;
	div.rn.f64 	%fd158, %fd100, %fd162;

$L__BB2_20:
	fma.rn.f64 	%fd101, %fd158, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd102, %fd101, %fd101;
	sub.f64 	%fd103, %fd165, %fd160;
	fma.rn.f64 	%fd160, %fd103, %fd102, %fd160;
	cvt.rn.ftz.f32.f64 	%f15, %fd160;
	st.global.f32 	[%rd81], %f15;
	add.s32 	%r101, %r101, 1;
	add.s64 	%rd81, %rd81, %rd18;
	add.s64 	%rd80, %rd80, %rd18;
	add.s64 	%rd79, %rd79, %rd18;
	add.s32 	%r100, %r100, -1;
	setp.ne.s32 	%p34, %r100, 0;
	mov.f64 	%fd154, %fd163;
	mov.f64 	%fd156, %fd165;
	@%p34 bra 	$L__BB2_18;

$L__BB2_21:
	add.s32 	%r85, %r35, -2;
	sub.s32 	%r86, %r85, %r2;
	sub.s32 	%r87, %r86, %r33;
	setp.lt.u32 	%p35, %r87, 3;
	@%p35 bra 	$L__BB2_35;

	mad.lo.s32 	%r88, %r101, %r34, %r1;
	add.s32 	%r89, %r102, 1;
	mad.lo.s32 	%r90, %r34, %r89, %r1;
	mul.wide.s32 	%rd70, %r88, 4;
	add.s64 	%rd82, %rd1, %rd70;
	mul.wide.s32 	%rd28, %r34, 4;
	add.s64 	%rd83, %rd2, %rd70;
	mul.wide.s32 	%rd71, %r90, 4;
	add.s64 	%rd84, %rd2, %rd71;

$L__BB2_23:
	ld.global.nc.f32 	%f16, [%rd83];
	cvt.ftz.f64.f32 	%fd30, %f16;
	ld.global.nc.f32 	%f17, [%rd84];
	cvt.ftz.f64.f32 	%fd31, %f17;
	sub.f64 	%fd105, %fd30, %fd165;
	abs.f64 	%fd106, %fd105;
	sub.f64 	%fd107, %fd31, %fd163;
	abs.f64 	%fd108, %fd107;
	sub.f64 	%fd109, %fd106, %fd108;
	add.f64 	%fd32, %fd162, %fd109;
	setp.eq.f64 	%p36, %fd32, 0d0000000000000000;
	mov.f64 	%fd168, 0d0000000000000000;
	mov.f64 	%fd167, %fd168;
	@%p36 bra 	$L__BB2_25;

	sub.f64 	%fd110, %fd30, %fd31;
	abs.f64 	%fd111, %fd110;
	div.rn.f64 	%fd167, %fd111, %fd32;

$L__BB2_25:
	fma.rn.f64 	%fd113, %fd167, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd114, %fd113, %fd113;
	sub.f64 	%fd115, %fd30, %fd160;
	fma.rn.f64 	%fd35, %fd115, %fd114, %fd160;
	cvt.rn.ftz.f32.f64 	%f18, %fd35;
	st.global.f32 	[%rd82], %f18;
	add.s64 	%rd34, %rd83, %rd28;
	ld.global.nc.f32 	%f19, [%rd34];
	cvt.ftz.f64.f32 	%fd36, %f19;
	add.s64 	%rd35, %rd84, %rd28;
	ld.global.nc.f32 	%f20, [%rd35];
	cvt.ftz.f64.f32 	%fd37, %f20;
	sub.f64 	%fd116, %fd36, %fd30;
	abs.f64 	%fd117, %fd116;
	sub.f64 	%fd118, %fd37, %fd31;
	abs.f64 	%fd119, %fd118;
	sub.f64 	%fd120, %fd117, %fd119;
	add.f64 	%fd38, %fd32, %fd120;
	setp.eq.f64 	%p37, %fd38, 0d0000000000000000;
	@%p37 bra 	$L__BB2_27;

	sub.f64 	%fd121, %fd36, %fd37;
	abs.f64 	%fd122, %fd121;
	div.rn.f64 	%fd168, %fd122, %fd38;

$L__BB2_27:
	fma.rn.f64 	%fd124, %fd168, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd125, %fd124, %fd124;
	sub.f64 	%fd126, %fd36, %fd35;
	fma.rn.f64 	%fd41, %fd126, %fd125, %fd35;
	cvt.rn.ftz.f32.f64 	%f21, %fd41;
	add.s64 	%rd36, %rd82, %rd28;
	st.global.f32 	[%rd36], %f21;
	add.s64 	%rd37, %rd34, %rd28;
	ld.global.nc.f32 	%f22, [%rd37];
	cvt.ftz.f64.f32 	%fd42, %f22;
	add.s64 	%rd38, %rd35, %rd28;
	ld.global.nc.f32 	%f23, [%rd38];
	cvt.ftz.f64.f32 	%fd43, %f23;
	sub.f64 	%fd127, %fd42, %fd36;
	abs.f64 	%fd128, %fd127;
	sub.f64 	%fd129, %fd43, %fd37;
	abs.f64 	%fd130, %fd129;
	sub.f64 	%fd131, %fd128, %fd130;
	add.f64 	%fd44, %fd38, %fd131;
	setp.eq.f64 	%p38, %fd44, 0d0000000000000000;
	mov.f64 	%fd170, 0d0000000000000000;
	mov.f64 	%fd169, %fd170;
	@%p38 bra 	$L__BB2_29;

	sub.f64 	%fd132, %fd42, %fd43;
	abs.f64 	%fd133, %fd132;
	div.rn.f64 	%fd169, %fd133, %fd44;

$L__BB2_29:
	fma.rn.f64 	%fd135, %fd169, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd136, %fd135, %fd135;
	sub.f64 	%fd137, %fd42, %fd41;
	fma.rn.f64 	%fd47, %fd137, %fd136, %fd41;
	cvt.rn.ftz.f32.f64 	%f24, %fd47;
	add.s64 	%rd39, %rd36, %rd28;
	st.global.f32 	[%rd39], %f24;
	add.s64 	%rd40, %rd37, %rd28;
	ld.global.nc.f32 	%f25, [%rd40];
	cvt.ftz.f64.f32 	%fd165, %f25;
	add.s64 	%rd41, %rd38, %rd28;
	ld.global.nc.f32 	%f26, [%rd41];
	cvt.ftz.f64.f32 	%fd163, %f26;
	sub.f64 	%fd138, %fd165, %fd42;
	abs.f64 	%fd139, %fd138;
	sub.f64 	%fd140, %fd163, %fd43;
	abs.f64 	%fd141, %fd140;
	sub.f64 	%fd142, %fd139, %fd141;
	add.f64 	%fd162, %fd44, %fd142;
	setp.eq.f64 	%p39, %fd162, 0d0000000000000000;
	@%p39 bra 	$L__BB2_31;

	sub.f64 	%fd143, %fd165, %fd163;
	abs.f64 	%fd144, %fd143;
	div.rn.f64 	%fd170, %fd144, %fd162;

$L__BB2_31:
	add.s64 	%rd84, %rd41, %rd28;
	add.s64 	%rd83, %rd40, %rd28;
	fma.rn.f64 	%fd145, %fd170, 0d3FE344D1344D1344, 0d3FB0842108421084;
	mul.f64 	%fd146, %fd145, %fd145;
	sub.f64 	%fd147, %fd165, %fd47;
	fma.rn.f64 	%fd160, %fd147, %fd146, %fd47;
	cvt.rn.ftz.f32.f64 	%f27, %fd160;
	add.s64 	%rd72, %rd39, %rd28;
	add.s64 	%rd82, %rd72, %rd28;
	st.global.f32 	[%rd72], %f27;
	add.s32 	%r101, %r101, 4;
	setp.lt.s32 	%p40, %r101, %r35;
	@%p40 bra 	$L__BB2_23;

$L__BB2_35:
	ret;

}

