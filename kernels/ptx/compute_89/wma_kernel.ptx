







.version 9.0
.target sm_89
.address_size 64


.const .align 16 .b8 C_WMA_RAMP[32768];
.extern .shared .align 16 .b8 shmem[];

.visible .entry wma_batch_f32(
	.param .u64 wma_batch_f32_param_0,
	.param .u64 wma_batch_f32_param_1,
	.param .u32 wma_batch_f32_param_2,
	.param .u32 wma_batch_f32_param_3,
	.param .u32 wma_batch_f32_param_4,
	.param .u64 wma_batch_f32_param_5
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<81>;
	.reg .b32 	%r<69>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd17, [wma_batch_f32_param_0];
	ld.param.u64 	%rd16, [wma_batch_f32_param_1];
	ld.param.u32 	%r35, [wma_batch_f32_param_2];
	ld.param.u32 	%r37, [wma_batch_f32_param_3];
	ld.param.u32 	%r36, [wma_batch_f32_param_4];
	ld.param.u64 	%rd18, [wma_batch_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd17;
	cvta.to.global.u64 	%rd2, %rd18;
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r37;
	@%p1 bra 	$L__BB0_41;

	cvta.to.global.u64 	%rd19, %rd16;
	mul.wide.s32 	%rd20, %r1, 4;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.nc.u32 	%r2, [%rd21];
	setp.lt.s32 	%p2, %r2, 2;
	@%p2 bra 	$L__BB0_41;

	setp.lt.s32 	%p3, %r2, 8193;
	mov.u32 	%r3, %tid.x;
	@%p3 bra 	$L__BB0_7;

	setp.ge.s32 	%p4, %r3, %r2;
	@%p4 bra 	$L__BB0_6;

	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r40, shmem;
	mov.u32 	%r60, %r3;

$L__BB0_5:
	add.s32 	%r38, %r60, 1;
	cvt.rn.f32.s32 	%f21, %r38;
	shl.b32 	%r39, %r60, 2;
	add.s32 	%r41, %r40, %r39;
	st.shared.f32 	[%r41], %f21;
	add.s32 	%r60, %r60, %r4;
	setp.lt.s32 	%p5, %r60, %r2;
	@%p5 bra 	$L__BB0_5;

$L__BB0_6:
	bar.sync 	0;

$L__BB0_7:
	mov.u32 	%r42, shmem;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r42;
	  cvta.shared.u64 	%rd22, %tmp; }
	mov.u64 	%rd23, C_WMA_RAMP;
	cvta.const.u64 	%rd24, %rd23;
	selp.b64 	%rd3, %rd24, %rd22, %p3;
	cvt.rn.f32.s32 	%f22, %r2;
	add.ftz.f32 	%f23, %f22, 0f3F800000;
	mul.ftz.f32 	%f24, %f23, %f22;
	mov.f32 	%f25, 0f40000000;
	div.approx.ftz.f32 	%f1, %f25, %f24;
	add.s32 	%r43, %r36, %r2;
	add.s32 	%r7, %r43, -1;
	mul.lo.s32 	%r8, %r1, %r35;
	mov.u32 	%r44, %ntid.x;
	mov.u32 	%r45, %ctaid.x;
	mad.lo.s32 	%r63, %r45, %r44, %r3;
	mov.u32 	%r46, %nctaid.x;
	mul.lo.s32 	%r10, %r46, %r44;
	setp.ge.s32 	%p7, %r63, %r35;
	@%p7 bra 	$L__BB0_41;

	setp.gt.s32 	%p8, %r2, 0;
	@%p8 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_9;

$L__BB0_25:
	add.s32 	%r23, %r2, -1;
	and.b32  	%r24, %r2, 7;
	sub.s32 	%r25, %r2, %r24;
	mov.u32 	%r54, 1;
	sub.s32 	%r26, %r54, %r2;

$L__BB0_26:
	add.s32 	%r55, %r63, %r8;
	mul.wide.s32 	%rd29, %r55, 4;
	add.s64 	%rd8, %rd2, %rd29;
	setp.lt.s32 	%p18, %r63, %r7;
	@%p18 bra 	$L__BB0_39;
	bra.uni 	$L__BB0_27;

$L__BB0_39:
	mov.u32 	%r59, 2147483647;
	st.global.u32 	[%rd8], %r59;
	bra.uni 	$L__BB0_40;

$L__BB0_27:
	setp.lt.u32 	%p19, %r23, 7;
	add.s32 	%r28, %r26, %r63;
	mov.f32 	%f80, 0f00000000;
	mov.u32 	%r68, 0;
	@%p19 bra 	$L__BB0_30;

	mul.wide.s32 	%rd9, %r28, 4;
	mov.f32 	%f80, 0f00000000;
	mov.u32 	%r68, 0;
	mov.u64 	%rd33, %rd3;
	mov.u64 	%rd34, %rd1;
	mov.u32 	%r67, %r25;

$L__BB0_29:
	.pragma "nounroll";
	add.s64 	%rd30, %rd34, %rd9;
	ld.f32 	%f34, [%rd33];
	ld.global.nc.f32 	%f35, [%rd30];
	fma.rn.ftz.f32 	%f36, %f35, %f34, %f80;
	ld.f32 	%f37, [%rd33+4];
	ld.global.nc.f32 	%f38, [%rd30+4];
	fma.rn.ftz.f32 	%f39, %f38, %f37, %f36;
	ld.f32 	%f40, [%rd33+8];
	ld.global.nc.f32 	%f41, [%rd30+8];
	fma.rn.ftz.f32 	%f42, %f41, %f40, %f39;
	ld.f32 	%f43, [%rd33+12];
	ld.global.nc.f32 	%f44, [%rd30+12];
	fma.rn.ftz.f32 	%f45, %f44, %f43, %f42;
	ld.f32 	%f46, [%rd33+16];
	ld.global.nc.f32 	%f47, [%rd30+16];
	fma.rn.ftz.f32 	%f48, %f47, %f46, %f45;
	ld.f32 	%f49, [%rd33+20];
	ld.global.nc.f32 	%f50, [%rd30+20];
	fma.rn.ftz.f32 	%f51, %f50, %f49, %f48;
	ld.f32 	%f52, [%rd33+24];
	ld.global.nc.f32 	%f53, [%rd30+24];
	fma.rn.ftz.f32 	%f54, %f53, %f52, %f51;
	ld.f32 	%f55, [%rd33+28];
	ld.global.nc.f32 	%f56, [%rd30+28];
	fma.rn.ftz.f32 	%f80, %f56, %f55, %f54;
	add.s32 	%r68, %r68, 8;
	add.s64 	%rd34, %rd34, 32;
	add.s64 	%rd33, %rd33, 32;
	add.s32 	%r67, %r67, -8;
	setp.ne.s32 	%p20, %r67, 0;
	@%p20 bra 	$L__BB0_29;

$L__BB0_30:
	setp.eq.s32 	%p21, %r24, 0;
	@%p21 bra 	$L__BB0_38;

	setp.eq.s32 	%p22, %r24, 1;
	add.s32 	%r58, %r28, %r68;
	mul.wide.s32 	%rd31, %r58, 4;
	add.s64 	%rd14, %rd1, %rd31;
	mul.wide.s32 	%rd32, %r68, 4;
	add.s64 	%rd15, %rd3, %rd32;
	ld.f32 	%f57, [%rd15];
	ld.global.nc.f32 	%f58, [%rd14];
	fma.rn.ftz.f32 	%f80, %f58, %f57, %f80;
	@%p22 bra 	$L__BB0_38;

	setp.eq.s32 	%p23, %r24, 2;
	ld.f32 	%f59, [%rd15+4];
	ld.global.nc.f32 	%f60, [%rd14+4];
	fma.rn.ftz.f32 	%f80, %f60, %f59, %f80;
	@%p23 bra 	$L__BB0_38;

	setp.eq.s32 	%p24, %r24, 3;
	ld.f32 	%f61, [%rd15+8];
	ld.global.nc.f32 	%f62, [%rd14+8];
	fma.rn.ftz.f32 	%f80, %f62, %f61, %f80;
	@%p24 bra 	$L__BB0_38;

	setp.eq.s32 	%p25, %r24, 4;
	ld.f32 	%f63, [%rd15+12];
	ld.global.nc.f32 	%f64, [%rd14+12];
	fma.rn.ftz.f32 	%f80, %f64, %f63, %f80;
	@%p25 bra 	$L__BB0_38;

	setp.eq.s32 	%p26, %r24, 5;
	ld.f32 	%f65, [%rd15+16];
	ld.global.nc.f32 	%f66, [%rd14+16];
	fma.rn.ftz.f32 	%f80, %f66, %f65, %f80;
	@%p26 bra 	$L__BB0_38;

	setp.eq.s32 	%p27, %r24, 6;
	ld.f32 	%f67, [%rd15+20];
	ld.global.nc.f32 	%f68, [%rd14+20];
	fma.rn.ftz.f32 	%f80, %f68, %f67, %f80;
	@%p27 bra 	$L__BB0_38;

	ld.f32 	%f69, [%rd15+24];
	ld.global.nc.f32 	%f70, [%rd14+24];
	fma.rn.ftz.f32 	%f80, %f70, %f69, %f80;

$L__BB0_38:
	mul.ftz.f32 	%f71, %f1, %f80;
	st.global.f32 	[%rd8], %f71;

$L__BB0_40:
	add.s32 	%r63, %r63, %r10;
	setp.lt.s32 	%p28, %r63, %r35;
	@%p28 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_41;

$L__BB0_9:
	add.s32 	%r47, %r10, %r35;
	add.s32 	%r48, %r63, %r10;
	not.b32 	%r49, %r48;
	add.s32 	%r50, %r47, %r49;
	div.u32 	%r11, %r50, %r10;
	add.s32 	%r51, %r11, 1;
	and.b32  	%r62, %r51, 3;
	setp.eq.s32 	%p9, %r62, 0;
	@%p9 bra 	$L__BB0_14;

	mul.ftz.f32 	%f2, %f1, 0f00000000;

$L__BB0_11:
	.pragma "nounroll";
	setp.ge.s32 	%p10, %r63, %r7;
	mov.f32 	%f72, %f2;
	@%p10 bra 	$L__BB0_13;

	mov.f32 	%f72, 0f7FFFFFFF;

$L__BB0_13:
	add.s32 	%r52, %r63, %r8;
	mul.wide.s32 	%rd25, %r52, 4;
	add.s64 	%rd26, %rd2, %rd25;
	st.global.f32 	[%rd26], %f72;
	add.s32 	%r63, %r63, %r10;
	add.s32 	%r62, %r62, -1;
	setp.ne.s32 	%p11, %r62, 0;
	@%p11 bra 	$L__BB0_11;

$L__BB0_14:
	setp.lt.u32 	%p12, %r11, 3;
	@%p12 bra 	$L__BB0_41;

	mul.ftz.f32 	%f4, %f1, 0f00000000;
	mul.wide.s32 	%rd4, %r10, 4;

$L__BB0_16:
	setp.lt.s32 	%p13, %r63, %r7;
	mov.f32 	%f73, 0f7FFFFFFF;
	@%p13 bra 	$L__BB0_18;

	mov.f32 	%f73, %f4;

$L__BB0_18:
	add.s32 	%r53, %r63, %r8;
	mul.wide.s32 	%rd27, %r53, 4;
	add.s64 	%rd5, %rd2, %rd27;
	st.global.f32 	[%rd5], %f73;
	add.s32 	%r19, %r63, %r10;
	setp.ge.s32 	%p14, %r19, %r7;
	mov.f32 	%f74, %f4;
	@%p14 bra 	$L__BB0_20;

	mov.f32 	%f74, 0f7FFFFFFF;

$L__BB0_20:
	add.s64 	%rd6, %rd5, %rd4;
	st.global.f32 	[%rd6], %f74;
	add.s32 	%r20, %r19, %r10;
	setp.ge.s32 	%p15, %r20, %r7;
	mov.f32 	%f75, %f4;
	@%p15 bra 	$L__BB0_22;

	mov.f32 	%f75, 0f7FFFFFFF;

$L__BB0_22:
	add.s64 	%rd7, %rd6, %rd4;
	st.global.f32 	[%rd7], %f75;
	add.s32 	%r21, %r20, %r10;
	setp.ge.s32 	%p16, %r21, %r7;
	mov.f32 	%f76, %f4;
	@%p16 bra 	$L__BB0_24;

	mov.f32 	%f76, 0f7FFFFFFF;

$L__BB0_24:
	add.s64 	%rd28, %rd7, %rd4;
	st.global.f32 	[%rd28], %f76;
	add.s32 	%r63, %r21, %r10;
	setp.lt.s32 	%p17, %r63, %r35;
	@%p17 bra 	$L__BB0_16;

$L__BB0_41:
	ret;

}

.visible .entry wma_batch_rolling_f32(
	.param .u64 wma_batch_rolling_f32_param_0,
	.param .u64 wma_batch_rolling_f32_param_1,
	.param .u32 wma_batch_rolling_f32_param_2,
	.param .u32 wma_batch_rolling_f32_param_3,
	.param .u32 wma_batch_rolling_f32_param_4,
	.param .u64 wma_batch_rolling_f32_param_5
)
{
	.reg .pred 	%p<19>;
	.reg .f32 	%f<117>;
	.reg .b32 	%r<111>;
	.reg .b64 	%rd<65>;


	ld.param.u64 	%rd32, [wma_batch_rolling_f32_param_0];
	ld.param.u64 	%rd31, [wma_batch_rolling_f32_param_1];
	ld.param.u32 	%r41, [wma_batch_rolling_f32_param_2];
	ld.param.u32 	%r43, [wma_batch_rolling_f32_param_3];
	ld.param.u32 	%r42, [wma_batch_rolling_f32_param_4];
	ld.param.u64 	%rd33, [wma_batch_rolling_f32_param_5];
	cvta.to.global.u64 	%rd64, %rd32;
	cvta.to.global.u64 	%rd2, %rd33;
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r43;
	@%p1 bra 	$L__BB1_24;

	cvta.to.global.u64 	%rd34, %rd31;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.u32 	%r2, [%rd36];
	setp.lt.s32 	%p2, %r2, 2;
	@%p2 bra 	$L__BB1_24;

	cvt.rn.f32.s32 	%f1, %r2;
	add.ftz.f32 	%f27, %f1, 0f3F800000;
	mul.ftz.f32 	%f28, %f27, %f1;
	mov.f32 	%f29, 0f40000000;
	div.approx.ftz.f32 	%f2, %f29, %f28;
	add.s32 	%r3, %r2, %r42;
	add.s32 	%r4, %r3, -1;
	mul.lo.s32 	%r5, %r1, %r41;
	mov.u32 	%r44, %ntid.x;
	mov.u32 	%r45, %ctaid.x;
	mov.u32 	%r46, %tid.x;
	mad.lo.s32 	%r6, %r45, %r44, %r46;
	mov.u32 	%r47, %nctaid.x;
	mul.lo.s32 	%r7, %r47, %r44;
	min.s32 	%r8, %r4, %r41;
	setp.ge.s32 	%p3, %r6, %r8;
	@%p3 bra 	$L__BB1_9;

	add.s32 	%r48, %r7, -2;
	neg.s32 	%r49, %r2;
	sub.s32 	%r50, %r49, %r42;
	not.b32 	%r51, %r41;
	max.s32 	%r52, %r50, %r51;
	sub.s32 	%r53, %r48, %r52;
	add.s32 	%r54, %r6, %r7;
	sub.s32 	%r55, %r53, %r54;
	div.u32 	%r9, %r55, %r7;
	add.s32 	%r56, %r9, 1;
	and.b32  	%r100, %r56, 3;
	setp.eq.s32 	%p4, %r100, 0;
	mov.u32 	%r101, %r6;
	@%p4 bra 	$L__BB1_6;

	add.s32 	%r57, %r6, %r5;
	mul.wide.s32 	%rd37, %r57, 4;
	add.s64 	%rd57, %rd2, %rd37;
	mul.wide.s32 	%rd4, %r7, 4;
	mov.u32 	%r101, %r6;

$L__BB1_5:
	.pragma "nounroll";
	mov.u32 	%r58, 2147483647;
	st.global.u32 	[%rd57], %r58;
	add.s32 	%r101, %r101, %r7;
	add.s64 	%rd57, %rd57, %rd4;
	add.s32 	%r100, %r100, -1;
	setp.ne.s32 	%p5, %r100, 0;
	@%p5 bra 	$L__BB1_5;

$L__BB1_6:
	setp.lt.u32 	%p6, %r9, 3;
	@%p6 bra 	$L__BB1_9;

	mul.wide.s32 	%rd7, %r7, 4;

$L__BB1_8:
	add.s32 	%r59, %r101, %r5;
	mul.wide.s32 	%rd38, %r59, 4;
	add.s64 	%rd39, %rd2, %rd38;
	mov.u32 	%r60, 2147483647;
	st.global.u32 	[%rd39], %r60;
	add.s64 	%rd40, %rd39, %rd7;
	st.global.u32 	[%rd40], %r60;
	add.s32 	%r61, %r101, %r7;
	add.s32 	%r62, %r61, %r7;
	add.s64 	%rd41, %rd40, %rd7;
	st.global.u32 	[%rd41], %r60;
	add.s32 	%r63, %r62, %r7;
	add.s64 	%rd42, %rd41, %rd7;
	st.global.u32 	[%rd42], %r60;
	add.s32 	%r101, %r63, %r7;
	setp.lt.s32 	%p7, %r101, %r8;
	@%p7 bra 	$L__BB1_8;

$L__BB1_9:
	bar.sync 	0;
	shl.b32 	%r18, %r6, 8;
	add.s32 	%r19, %r4, %r18;
	setp.ge.s32 	%p8, %r19, %r41;
	@%p8 bra 	$L__BB1_24;

	add.s32 	%r64, %r19, 256;
	min.s32 	%r20, %r64, %r41;
	mov.u32 	%r65, 1;
	sub.s32 	%r66, %r65, %r2;
	add.s32 	%r67, %r66, %r19;
	cvt.s64.s32 	%rd8, %r67;
	setp.lt.s32 	%p9, %r2, 1;
	mov.f32 	%f109, 0f00000000;
	mov.f32 	%f110, %f109;
	@%p9 bra 	$L__BB1_17;

	add.s32 	%r69, %r2, -1;
	and.b32  	%r106, %r2, 7;
	setp.lt.u32 	%p10, %r69, 7;
	mov.f32 	%f110, 0f00000000;
	mov.u32 	%r104, 0;
	mov.f32 	%f109, %f110;
	@%p10 bra 	$L__BB1_14;

	sub.s32 	%r22, %r106, %r2;
	shl.b64 	%rd43, %rd8, 2;
	add.s64 	%rd44, %rd64, %rd43;
	add.s64 	%rd58, %rd44, 16;
	mov.f32 	%f110, 0f00000000;
	mov.u32 	%r104, 0;

$L__BB1_13:
	.pragma "nounroll";
	ld.global.nc.f32 	%f37, [%rd58+-16];
	add.ftz.f32 	%f38, %f109, %f37;
	add.s32 	%r71, %r104, 1;
	cvt.rn.f32.s32 	%f39, %r71;
	fma.rn.ftz.f32 	%f40, %f39, %f37, %f110;
	ld.global.nc.f32 	%f41, [%rd58+-12];
	add.ftz.f32 	%f42, %f38, %f41;
	add.s32 	%r72, %r104, 2;
	cvt.rn.f32.s32 	%f43, %r72;
	fma.rn.ftz.f32 	%f44, %f43, %f41, %f40;
	ld.global.nc.f32 	%f45, [%rd58+-8];
	add.ftz.f32 	%f46, %f42, %f45;
	add.s32 	%r73, %r104, 3;
	cvt.rn.f32.s32 	%f47, %r73;
	fma.rn.ftz.f32 	%f48, %f47, %f45, %f44;
	ld.global.nc.f32 	%f49, [%rd58+-4];
	add.ftz.f32 	%f50, %f46, %f49;
	add.s32 	%r74, %r104, 4;
	cvt.rn.f32.s32 	%f51, %r74;
	fma.rn.ftz.f32 	%f52, %f51, %f49, %f48;
	ld.global.nc.f32 	%f53, [%rd58];
	add.ftz.f32 	%f54, %f50, %f53;
	add.s32 	%r75, %r104, 5;
	cvt.rn.f32.s32 	%f55, %r75;
	fma.rn.ftz.f32 	%f56, %f55, %f53, %f52;
	ld.global.nc.f32 	%f57, [%rd58+4];
	add.ftz.f32 	%f58, %f54, %f57;
	add.s32 	%r76, %r104, 6;
	cvt.rn.f32.s32 	%f59, %r76;
	fma.rn.ftz.f32 	%f60, %f59, %f57, %f56;
	ld.global.nc.f32 	%f61, [%rd58+8];
	add.ftz.f32 	%f62, %f58, %f61;
	add.s32 	%r77, %r104, 7;
	cvt.rn.f32.s32 	%f63, %r77;
	fma.rn.ftz.f32 	%f64, %f63, %f61, %f60;
	ld.global.nc.f32 	%f65, [%rd58+12];
	add.ftz.f32 	%f109, %f62, %f65;
	add.s32 	%r104, %r104, 8;
	cvt.rn.f32.s32 	%f66, %r104;
	fma.rn.ftz.f32 	%f110, %f66, %f65, %f64;
	add.s32 	%r78, %r22, %r104;
	add.s64 	%rd58, %rd58, 32;
	setp.ne.s32 	%p11, %r78, 0;
	@%p11 bra 	$L__BB1_13;

$L__BB1_14:
	setp.eq.s32 	%p12, %r106, 0;
	@%p12 bra 	$L__BB1_17;

	add.s32 	%r105, %r104, 1;
	cvt.s64.s32 	%rd45, %r104;
	add.s64 	%rd46, %rd45, %rd8;
	shl.b64 	%rd47, %rd46, 2;
	add.s64 	%rd59, %rd64, %rd47;

$L__BB1_16:
	.pragma "nounroll";
	ld.global.nc.f32 	%f67, [%rd59];
	add.ftz.f32 	%f109, %f109, %f67;
	cvt.rn.f32.s32 	%f68, %r105;
	fma.rn.ftz.f32 	%f110, %f68, %f67, %f110;
	add.s32 	%r105, %r105, 1;
	add.s64 	%rd59, %rd59, 4;
	add.s32 	%r106, %r106, -1;
	setp.ne.s32 	%p13, %r106, 0;
	@%p13 bra 	$L__BB1_16;

$L__BB1_17:
	add.s32 	%r79, %r19, %r5;
	mul.wide.s32 	%rd48, %r79, 4;
	add.s64 	%rd49, %rd2, %rd48;
	mul.ftz.f32 	%f69, %f2, %f110;
	st.global.f32 	[%rd49], %f69;
	add.s32 	%r109, %r18, %r3;
	setp.ge.s32 	%p14, %r109, %r20;
	@%p14 bra 	$L__BB1_24;

	not.b32 	%r80, %r2;
	sub.s32 	%r81, %r80, %r42;
	mov.u32 	%r82, -256;
	sub.s32 	%r83, %r82, %r2;
	sub.s32 	%r84, %r83, %r42;
	sub.s32 	%r85, %r84, %r18;
	not.b32 	%r86, %r41;
	max.s32 	%r32, %r85, %r86;
	sub.s32 	%r87, %r81, %r32;
	and.b32  	%r108, %r87, 3;
	setp.eq.s32 	%p15, %r108, 0;
	@%p15 bra 	$L__BB1_21;

	add.s32 	%r88, %r3, %r5;
	add.s32 	%r89, %r88, %r18;
	mul.wide.s32 	%rd50, %r89, 4;
	add.s64 	%rd62, %rd2, %rd50;
	neg.s32 	%r90, %r42;
	sub.s32 	%r91, %r90, %r18;
	mul.wide.s32 	%rd51, %r91, 4;
	sub.s64 	%rd61, %rd64, %rd51;
	mul.wide.s32 	%rd52, %r109, 4;
	add.s64 	%rd60, %rd64, %rd52;
	mov.f32 	%f112, %f109;

$L__BB1_20:
	.pragma "nounroll";
	ld.global.nc.f32 	%f70, [%rd61];
	sub.ftz.f32 	%f71, %f112, %f70;
	ld.global.nc.f32 	%f72, [%rd60];
	add.ftz.f32 	%f109, %f72, %f71;
	sub.ftz.f32 	%f73, %f110, %f112;
	fma.rn.ftz.f32 	%f110, %f72, %f1, %f73;
	mul.ftz.f32 	%f74, %f2, %f110;
	st.global.f32 	[%rd62], %f74;
	add.s32 	%r109, %r109, 1;
	add.s64 	%rd62, %rd62, 4;
	add.s64 	%rd61, %rd61, 4;
	add.s64 	%rd60, %rd60, 4;
	add.s32 	%r108, %r108, -1;
	setp.ne.s32 	%p16, %r108, 0;
	mov.f32 	%f112, %f109;
	@%p16 bra 	$L__BB1_20;

$L__BB1_21:
	mov.u32 	%r92, -2;
	sub.s32 	%r93, %r92, %r2;
	sub.s32 	%r94, %r93, %r42;
	sub.s32 	%r95, %r94, %r32;
	sub.s32 	%r96, %r95, %r18;
	setp.lt.u32 	%p17, %r96, 3;
	@%p17 bra 	$L__BB1_24;

	add.s32 	%r97, %r109, %r5;
	mul.wide.s32 	%rd53, %r97, 4;
	add.s64 	%rd63, %rd2, %rd53;
	sub.s32 	%r98, %r2, %r109;
	mul.wide.s32 	%rd54, %r98, 4;
	neg.s64 	%rd25, %rd54;
	mul.wide.s32 	%rd26, %r109, 4;

$L__BB1_23:
	add.s64 	%rd55, %rd64, %rd26;
	add.s64 	%rd56, %rd64, %rd25;
	ld.global.nc.f32 	%f75, [%rd56];
	sub.ftz.f32 	%f76, %f109, %f75;
	ld.global.nc.f32 	%f77, [%rd55];
	add.ftz.f32 	%f78, %f77, %f76;
	sub.ftz.f32 	%f79, %f110, %f109;
	fma.rn.ftz.f32 	%f80, %f77, %f1, %f79;
	mul.ftz.f32 	%f81, %f2, %f80;
	st.global.f32 	[%rd63], %f81;
	ld.global.nc.f32 	%f82, [%rd56+4];
	sub.ftz.f32 	%f83, %f78, %f82;
	ld.global.nc.f32 	%f84, [%rd55+4];
	add.ftz.f32 	%f85, %f84, %f83;
	sub.ftz.f32 	%f86, %f80, %f78;
	fma.rn.ftz.f32 	%f87, %f84, %f1, %f86;
	mul.ftz.f32 	%f88, %f2, %f87;
	st.global.f32 	[%rd63+4], %f88;
	ld.global.nc.f32 	%f89, [%rd56+8];
	sub.ftz.f32 	%f90, %f85, %f89;
	ld.global.nc.f32 	%f91, [%rd55+8];
	add.ftz.f32 	%f92, %f91, %f90;
	sub.ftz.f32 	%f93, %f87, %f85;
	fma.rn.ftz.f32 	%f94, %f91, %f1, %f93;
	mul.ftz.f32 	%f95, %f2, %f94;
	st.global.f32 	[%rd63+8], %f95;
	ld.global.nc.f32 	%f96, [%rd56+12];
	sub.ftz.f32 	%f97, %f92, %f96;
	ld.global.nc.f32 	%f98, [%rd55+12];
	add.ftz.f32 	%f109, %f98, %f97;
	sub.ftz.f32 	%f99, %f94, %f92;
	fma.rn.ftz.f32 	%f110, %f98, %f1, %f99;
	mul.ftz.f32 	%f100, %f2, %f110;
	st.global.f32 	[%rd63+12], %f100;
	add.s64 	%rd64, %rd64, 16;
	add.s64 	%rd63, %rd63, 16;
	add.s32 	%r109, %r109, 4;
	setp.lt.s32 	%p18, %r109, %r20;
	@%p18 bra 	$L__BB1_23;

$L__BB1_24:
	ret;

}

.visible .entry wma_batch_prefix_f32(
	.param .u64 wma_batch_prefix_f32_param_0,
	.param .u64 wma_batch_prefix_f32_param_1,
	.param .u64 wma_batch_prefix_f32_param_2,
	.param .u32 wma_batch_prefix_f32_param_3,
	.param .u32 wma_batch_prefix_f32_param_4,
	.param .u32 wma_batch_prefix_f32_param_5,
	.param .u64 wma_batch_prefix_f32_param_6
)
{
	.reg .pred 	%p<13>;
	.reg .f32 	%f<71>;
	.reg .b32 	%r<60>;
	.reg .b64 	%rd<67>;


	ld.param.u64 	%rd26, [wma_batch_prefix_f32_param_0];
	ld.param.u64 	%rd27, [wma_batch_prefix_f32_param_1];
	ld.param.u64 	%rd25, [wma_batch_prefix_f32_param_2];
	ld.param.u32 	%r24, [wma_batch_prefix_f32_param_3];
	ld.param.u32 	%r26, [wma_batch_prefix_f32_param_4];
	ld.param.u32 	%r25, [wma_batch_prefix_f32_param_5];
	ld.param.u64 	%rd28, [wma_batch_prefix_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd27;
	cvta.to.global.u64 	%rd3, %rd26;
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r26;
	@%p1 bra 	$L__BB2_19;

	cvta.to.global.u64 	%rd29, %rd25;
	mul.wide.s32 	%rd30, %r1, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.u32 	%r2, [%rd31];
	setp.lt.s32 	%p2, %r2, 2;
	@%p2 bra 	$L__BB2_19;

	cvt.rn.f32.s32 	%f12, %r2;
	add.ftz.f32 	%f13, %f12, 0f3F800000;
	mul.ftz.f32 	%f14, %f13, %f12;
	mov.f32 	%f15, 0f40000000;
	div.approx.ftz.f32 	%f1, %f15, %f14;
	add.s32 	%r27, %r25, %r2;
	add.s32 	%r3, %r27, -1;
	mul.lo.s32 	%r4, %r1, %r24;
	mov.u32 	%r28, %ntid.x;
	mov.u32 	%r29, %ctaid.x;
	mul.lo.s32 	%r5, %r29, %r28;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r58, %r5, %r6;
	mov.u32 	%r30, %nctaid.x;
	mul.lo.s32 	%r8, %r30, %r28;
	setp.ge.s32 	%p3, %r58, %r24;
	@%p3 bra 	$L__BB2_19;

	add.s32 	%r31, %r8, %r24;
	add.s32 	%r32, %r58, %r8;
	not.b32 	%r33, %r32;
	add.s32 	%r34, %r31, %r33;
	div.u32 	%r9, %r34, %r8;
	add.s32 	%r35, %r9, 1;
	and.b32  	%r57, %r35, 3;
	setp.eq.s32 	%p4, %r57, 0;
	@%p4 bra 	$L__BB2_8;

	sub.s32 	%r55, %r58, %r2;
	add.s32 	%r36, %r58, 1;
	mul.wide.s32 	%rd32, %r36, 4;
	add.s64 	%rd66, %rd2, %rd32;
	mul.wide.s32 	%rd5, %r8, 4;
	add.s64 	%rd65, %rd3, %rd32;
	add.s32 	%r37, %r2, -1;
	sub.s32 	%r38, %r37, %r5;
	sub.s32 	%r39, %r38, %r6;
	mul.wide.s32 	%rd33, %r39, 4;
	sub.s64 	%rd64, %rd2, %rd33;
	neg.s32 	%r40, %r8;
	mul.wide.s32 	%rd34, %r40, 4;
	neg.s64 	%rd8, %rd34;
	sub.s64 	%rd63, %rd3, %rd33;
	add.s32 	%r41, %r58, %r4;
	mul.wide.s32 	%rd35, %r41, 4;
	add.s64 	%rd62, %rd1, %rd35;

$L__BB2_5:
	.pragma "nounroll";
	setp.lt.s32 	%p5, %r58, %r3;
	mov.f32 	%f66, 0f7FFFFFFF;
	@%p5 bra 	$L__BB2_7;

	ld.global.nc.f32 	%f17, [%rd65];
	ld.global.nc.f32 	%f18, [%rd63];
	sub.ftz.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd64];
	ld.global.nc.f32 	%f21, [%rd66];
	sub.ftz.f32 	%f22, %f21, %f20;
	cvt.rn.f32.s32 	%f23, %r55;
	neg.ftz.f32 	%f24, %f23;
	fma.rn.ftz.f32 	%f25, %f24, %f19, %f22;
	mul.ftz.f32 	%f66, %f1, %f25;

$L__BB2_7:
	st.global.f32 	[%rd62], %f66;
	add.s32 	%r58, %r58, %r8;
	add.s32 	%r55, %r55, %r8;
	add.s64 	%rd66, %rd66, %rd5;
	add.s64 	%rd65, %rd65, %rd5;
	add.s64 	%rd64, %rd64, %rd8;
	add.s64 	%rd63, %rd63, %rd8;
	add.s64 	%rd62, %rd62, %rd5;
	add.s32 	%r57, %r57, -1;
	setp.ne.s32 	%p6, %r57, 0;
	@%p6 bra 	$L__BB2_5;

$L__BB2_8:
	setp.lt.u32 	%p7, %r9, 3;
	@%p7 bra 	$L__BB2_19;

	mul.wide.s32 	%rd21, %r8, 4;

$L__BB2_10:
	setp.lt.s32 	%p8, %r58, %r3;
	mov.f32 	%f68, 0f7FFFFFFF;
	mov.f32 	%f67, %f68;
	@%p8 bra 	$L__BB2_12;

	add.s32 	%r42, %r58, 1;
	sub.s32 	%r43, %r42, %r2;
	mul.wide.s32 	%rd36, %r42, 4;
	add.s64 	%rd37, %rd3, %rd36;
	mul.wide.s32 	%rd38, %r43, 4;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.nc.f32 	%f27, [%rd39];
	ld.global.nc.f32 	%f28, [%rd37];
	sub.ftz.f32 	%f29, %f28, %f27;
	add.s64 	%rd40, %rd2, %rd36;
	add.s64 	%rd41, %rd2, %rd38;
	ld.global.nc.f32 	%f30, [%rd41];
	ld.global.nc.f32 	%f31, [%rd40];
	sub.ftz.f32 	%f32, %f31, %f30;
	sub.s32 	%r44, %r58, %r2;
	cvt.rn.f32.s32 	%f33, %r44;
	neg.ftz.f32 	%f34, %f33;
	fma.rn.ftz.f32 	%f35, %f34, %f29, %f32;
	mul.ftz.f32 	%f67, %f1, %f35;

$L__BB2_12:
	add.s32 	%r45, %r58, %r4;
	mul.wide.s32 	%rd42, %r45, 4;
	add.s64 	%rd22, %rd1, %rd42;
	st.global.f32 	[%rd22], %f67;
	add.s32 	%r20, %r58, %r8;
	setp.lt.s32 	%p9, %r20, %r3;
	@%p9 bra 	$L__BB2_14;

	add.s32 	%r46, %r20, 1;
	sub.s32 	%r47, %r46, %r2;
	mul.wide.s32 	%rd43, %r46, 4;
	add.s64 	%rd44, %rd3, %rd43;
	mul.wide.s32 	%rd45, %r47, 4;
	add.s64 	%rd46, %rd3, %rd45;
	ld.global.nc.f32 	%f37, [%rd46];
	ld.global.nc.f32 	%f38, [%rd44];
	sub.ftz.f32 	%f39, %f38, %f37;
	add.s64 	%rd47, %rd2, %rd43;
	add.s64 	%rd48, %rd2, %rd45;
	ld.global.nc.f32 	%f40, [%rd48];
	ld.global.nc.f32 	%f41, [%rd47];
	sub.ftz.f32 	%f42, %f41, %f40;
	sub.s32 	%r48, %r20, %r2;
	cvt.rn.f32.s32 	%f43, %r48;
	neg.ftz.f32 	%f44, %f43;
	fma.rn.ftz.f32 	%f45, %f44, %f39, %f42;
	mul.ftz.f32 	%f68, %f1, %f45;

$L__BB2_14:
	add.s64 	%rd23, %rd22, %rd21;
	st.global.f32 	[%rd23], %f68;
	add.s32 	%r21, %r20, %r8;
	setp.lt.s32 	%p10, %r21, %r3;
	mov.f32 	%f70, 0f7FFFFFFF;
	mov.f32 	%f69, %f70;
	@%p10 bra 	$L__BB2_16;

	add.s32 	%r49, %r21, 1;
	sub.s32 	%r50, %r49, %r2;
	mul.wide.s32 	%rd49, %r49, 4;
	add.s64 	%rd50, %rd3, %rd49;
	mul.wide.s32 	%rd51, %r50, 4;
	add.s64 	%rd52, %rd3, %rd51;
	ld.global.nc.f32 	%f47, [%rd52];
	ld.global.nc.f32 	%f48, [%rd50];
	sub.ftz.f32 	%f49, %f48, %f47;
	add.s64 	%rd53, %rd2, %rd49;
	add.s64 	%rd54, %rd2, %rd51;
	ld.global.nc.f32 	%f50, [%rd54];
	ld.global.nc.f32 	%f51, [%rd53];
	sub.ftz.f32 	%f52, %f51, %f50;
	sub.s32 	%r51, %r21, %r2;
	cvt.rn.f32.s32 	%f53, %r51;
	neg.ftz.f32 	%f54, %f53;
	fma.rn.ftz.f32 	%f55, %f54, %f49, %f52;
	mul.ftz.f32 	%f69, %f1, %f55;

$L__BB2_16:
	add.s64 	%rd24, %rd23, %rd21;
	st.global.f32 	[%rd24], %f69;
	add.s32 	%r22, %r21, %r8;
	setp.lt.s32 	%p11, %r22, %r3;
	@%p11 bra 	$L__BB2_18;

	add.s32 	%r52, %r22, 1;
	sub.s32 	%r53, %r52, %r2;
	mul.wide.s32 	%rd55, %r52, 4;
	add.s64 	%rd56, %rd3, %rd55;
	mul.wide.s32 	%rd57, %r53, 4;
	add.s64 	%rd58, %rd3, %rd57;
	ld.global.nc.f32 	%f57, [%rd58];
	ld.global.nc.f32 	%f58, [%rd56];
	sub.ftz.f32 	%f59, %f58, %f57;
	add.s64 	%rd59, %rd2, %rd55;
	add.s64 	%rd60, %rd2, %rd57;
	ld.global.nc.f32 	%f60, [%rd60];
	ld.global.nc.f32 	%f61, [%rd59];
	sub.ftz.f32 	%f62, %f61, %f60;
	sub.s32 	%r54, %r22, %r2;
	cvt.rn.f32.s32 	%f63, %r54;
	neg.ftz.f32 	%f64, %f63;
	fma.rn.ftz.f32 	%f65, %f64, %f59, %f62;
	mul.ftz.f32 	%f70, %f1, %f65;

$L__BB2_18:
	add.s64 	%rd61, %rd24, %rd21;
	st.global.f32 	[%rd61], %f70;
	add.s32 	%r58, %r22, %r8;
	setp.lt.s32 	%p12, %r58, %r24;
	@%p12 bra 	$L__BB2_10;

$L__BB2_19:
	ret;

}

.visible .entry wma_multi_series_one_param_time_major_f32(
	.param .u64 wma_multi_series_one_param_time_major_f32_param_0,
	.param .u32 wma_multi_series_one_param_time_major_f32_param_1,
	.param .u32 wma_multi_series_one_param_time_major_f32_param_2,
	.param .u32 wma_multi_series_one_param_time_major_f32_param_3,
	.param .u64 wma_multi_series_one_param_time_major_f32_param_4,
	.param .u64 wma_multi_series_one_param_time_major_f32_param_5
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<81>;
	.reg .b32 	%r<74>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd20, [wma_multi_series_one_param_time_major_f32_param_0];
	ld.param.u32 	%r37, [wma_multi_series_one_param_time_major_f32_param_1];
	ld.param.u32 	%r38, [wma_multi_series_one_param_time_major_f32_param_2];
	ld.param.u32 	%r39, [wma_multi_series_one_param_time_major_f32_param_3];
	ld.param.u64 	%rd19, [wma_multi_series_one_param_time_major_f32_param_4];
	ld.param.u64 	%rd21, [wma_multi_series_one_param_time_major_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd20;
	cvta.to.global.u64 	%rd2, %rd21;
	setp.lt.s32 	%p1, %r37, 2;
	@%p1 bra 	$L__BB3_41;

	setp.lt.s32 	%p2, %r37, 8193;
	@%p2 bra 	$L__BB3_6;

	mov.u32 	%r65, %tid.x;
	setp.ge.s32 	%p3, %r65, %r37;
	@%p3 bra 	$L__BB3_5;

	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r42, shmem;

$L__BB3_4:
	add.s32 	%r40, %r65, 1;
	cvt.rn.f32.s32 	%f21, %r40;
	shl.b32 	%r41, %r65, 2;
	add.s32 	%r43, %r42, %r41;
	st.shared.f32 	[%r43], %f21;
	add.s32 	%r65, %r65, %r2;
	setp.lt.s32 	%p4, %r65, %r37;
	@%p4 bra 	$L__BB3_4;

$L__BB3_5:
	bar.sync 	0;

$L__BB3_6:
	mov.u32 	%r44, shmem;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r44;
	  cvta.shared.u64 	%rd22, %tmp; }
	mov.u64 	%rd23, C_WMA_RAMP;
	cvta.const.u64 	%rd24, %rd23;
	selp.b64 	%rd3, %rd24, %rd22, %p2;
	cvt.rn.f32.s32 	%f22, %r37;
	add.ftz.f32 	%f23, %f22, 0f3F800000;
	mul.ftz.f32 	%f24, %f23, %f22;
	mov.f32 	%f25, 0f40000000;
	div.approx.ftz.f32 	%f1, %f25, %f24;
	mov.u32 	%r5, %ctaid.y;
	setp.ge.s32 	%p6, %r5, %r38;
	@%p6 bra 	$L__BB3_41;

	cvta.to.global.u64 	%rd25, %rd19;
	mul.wide.s32 	%rd26, %r5, 4;
	add.s64 	%rd27, %rd25, %rd26;
	add.s32 	%r6, %r37, -1;
	ld.global.nc.u32 	%r45, [%rd27];
	add.s32 	%r7, %r6, %r45;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r46, %ctaid.x;
	mov.u32 	%r47, %tid.x;
	mad.lo.s32 	%r68, %r46, %r8, %r47;
	mov.u32 	%r10, %nctaid.x;
	mul.lo.s32 	%r11, %r10, %r8;
	setp.ge.s32 	%p7, %r68, %r39;
	@%p7 bra 	$L__BB3_41;

	setp.gt.s32 	%p8, %r37, 0;
	@%p8 bra 	$L__BB3_25;
	bra.uni 	$L__BB3_9;

$L__BB3_25:
	and.b32  	%r24, %r37, 7;
	sub.s32 	%r25, %r24, %r37;
	shl.b32 	%r26, %r38, 3;
	mul.wide.s32 	%rd8, %r38, 4;
	mov.u32 	%r57, 1;
	sub.s32 	%r27, %r57, %r37;

$L__BB3_26:
	mad.lo.s32 	%r58, %r68, %r38, %r5;
	mul.wide.s32 	%rd32, %r58, 4;
	add.s64 	%rd9, %rd2, %rd32;
	setp.lt.s32 	%p18, %r68, %r7;
	@%p18 bra 	$L__BB3_39;
	bra.uni 	$L__BB3_27;

$L__BB3_39:
	mov.u32 	%r64, 2147483647;
	st.global.u32 	[%rd9], %r64;
	bra.uni 	$L__BB3_40;

$L__BB3_27:
	setp.lt.u32 	%p19, %r6, 7;
	add.s32 	%r29, %r27, %r68;
	mov.f32 	%f80, 0f00000000;
	mov.u32 	%r73, 0;
	@%p19 bra 	$L__BB3_30;

	mad.lo.s32 	%r71, %r38, %r29, %r5;
	mov.f32 	%f80, 0f00000000;
	mov.u32 	%r73, 0;
	mov.u64 	%rd45, %rd3;

$L__BB3_29:
	.pragma "nounroll";
	mul.wide.s32 	%rd33, %r71, 4;
	add.s64 	%rd34, %rd1, %rd33;
	ld.f32 	%f34, [%rd45];
	ld.global.nc.f32 	%f35, [%rd34];
	fma.rn.ftz.f32 	%f36, %f35, %f34, %f80;
	add.s64 	%rd35, %rd34, %rd8;
	ld.f32 	%f37, [%rd45+4];
	ld.global.nc.f32 	%f38, [%rd35];
	fma.rn.ftz.f32 	%f39, %f38, %f37, %f36;
	add.s64 	%rd36, %rd35, %rd8;
	ld.f32 	%f40, [%rd45+8];
	ld.global.nc.f32 	%f41, [%rd36];
	fma.rn.ftz.f32 	%f42, %f41, %f40, %f39;
	add.s64 	%rd37, %rd36, %rd8;
	ld.f32 	%f43, [%rd45+12];
	ld.global.nc.f32 	%f44, [%rd37];
	fma.rn.ftz.f32 	%f45, %f44, %f43, %f42;
	add.s64 	%rd38, %rd37, %rd8;
	ld.f32 	%f46, [%rd45+16];
	ld.global.nc.f32 	%f47, [%rd38];
	fma.rn.ftz.f32 	%f48, %f47, %f46, %f45;
	add.s64 	%rd39, %rd38, %rd8;
	ld.f32 	%f49, [%rd45+20];
	ld.global.nc.f32 	%f50, [%rd39];
	fma.rn.ftz.f32 	%f51, %f50, %f49, %f48;
	add.s64 	%rd40, %rd39, %rd8;
	ld.f32 	%f52, [%rd45+24];
	ld.global.nc.f32 	%f53, [%rd40];
	fma.rn.ftz.f32 	%f54, %f53, %f52, %f51;
	add.s64 	%rd41, %rd40, %rd8;
	ld.f32 	%f55, [%rd45+28];
	ld.global.nc.f32 	%f56, [%rd41];
	fma.rn.ftz.f32 	%f80, %f56, %f55, %f54;
	add.s32 	%r73, %r73, 8;
	add.s32 	%r61, %r25, %r73;
	add.s32 	%r71, %r71, %r26;
	add.s64 	%rd45, %rd45, 32;
	setp.ne.s32 	%p20, %r61, 0;
	@%p20 bra 	$L__BB3_29;

$L__BB3_30:
	setp.eq.s32 	%p21, %r24, 0;
	@%p21 bra 	$L__BB3_38;

	setp.eq.s32 	%p22, %r24, 1;
	add.s32 	%r62, %r29, %r73;
	mad.lo.s32 	%r63, %r62, %r38, %r5;
	mul.wide.s32 	%rd42, %r63, 4;
	add.s64 	%rd12, %rd1, %rd42;
	mul.wide.s32 	%rd43, %r73, 4;
	add.s64 	%rd13, %rd3, %rd43;
	ld.f32 	%f57, [%rd13];
	ld.global.nc.f32 	%f58, [%rd12];
	fma.rn.ftz.f32 	%f80, %f58, %f57, %f80;
	@%p22 bra 	$L__BB3_38;

	setp.eq.s32 	%p23, %r24, 2;
	add.s64 	%rd14, %rd12, %rd8;
	ld.f32 	%f59, [%rd13+4];
	ld.global.nc.f32 	%f60, [%rd14];
	fma.rn.ftz.f32 	%f80, %f60, %f59, %f80;
	@%p23 bra 	$L__BB3_38;

	setp.eq.s32 	%p24, %r24, 3;
	add.s64 	%rd15, %rd14, %rd8;
	ld.f32 	%f61, [%rd13+8];
	ld.global.nc.f32 	%f62, [%rd15];
	fma.rn.ftz.f32 	%f80, %f62, %f61, %f80;
	@%p24 bra 	$L__BB3_38;

	setp.eq.s32 	%p25, %r24, 4;
	add.s64 	%rd16, %rd15, %rd8;
	ld.f32 	%f63, [%rd13+12];
	ld.global.nc.f32 	%f64, [%rd16];
	fma.rn.ftz.f32 	%f80, %f64, %f63, %f80;
	@%p25 bra 	$L__BB3_38;

	setp.eq.s32 	%p26, %r24, 5;
	add.s64 	%rd17, %rd16, %rd8;
	ld.f32 	%f65, [%rd13+16];
	ld.global.nc.f32 	%f66, [%rd17];
	fma.rn.ftz.f32 	%f80, %f66, %f65, %f80;
	@%p26 bra 	$L__BB3_38;

	setp.eq.s32 	%p27, %r24, 6;
	add.s64 	%rd18, %rd17, %rd8;
	ld.f32 	%f67, [%rd13+20];
	ld.global.nc.f32 	%f68, [%rd18];
	fma.rn.ftz.f32 	%f80, %f68, %f67, %f80;
	@%p27 bra 	$L__BB3_38;

	add.s64 	%rd44, %rd18, %rd8;
	ld.f32 	%f69, [%rd13+24];
	ld.global.nc.f32 	%f70, [%rd44];
	fma.rn.ftz.f32 	%f80, %f70, %f69, %f80;

$L__BB3_38:
	mul.ftz.f32 	%f71, %f1, %f80;
	st.global.f32 	[%rd9], %f71;

$L__BB3_40:
	add.s32 	%r68, %r68, %r11;
	setp.lt.s32 	%p28, %r68, %r39;
	@%p28 bra 	$L__BB3_26;
	bra.uni 	$L__BB3_41;

$L__BB3_9:
	add.s32 	%r48, %r11, %r39;
	add.s32 	%r49, %r68, %r11;
	not.b32 	%r50, %r49;
	add.s32 	%r51, %r48, %r50;
	div.u32 	%r12, %r51, %r11;
	add.s32 	%r52, %r12, 1;
	and.b32  	%r67, %r52, 3;
	setp.eq.s32 	%p9, %r67, 0;
	@%p9 bra 	$L__BB3_14;

	mul.ftz.f32 	%f2, %f1, 0f00000000;

$L__BB3_11:
	.pragma "nounroll";
	setp.ge.s32 	%p10, %r68, %r7;
	mov.f32 	%f72, %f2;
	@%p10 bra 	$L__BB3_13;

	mov.f32 	%f72, 0f7FFFFFFF;

$L__BB3_13:
	mad.lo.s32 	%r53, %r68, %r38, %r5;
	mul.wide.s32 	%rd28, %r53, 4;
	add.s64 	%rd29, %rd2, %rd28;
	st.global.f32 	[%rd29], %f72;
	add.s32 	%r68, %r68, %r11;
	add.s32 	%r67, %r67, -1;
	setp.ne.s32 	%p11, %r67, 0;
	@%p11 bra 	$L__BB3_11;

$L__BB3_14:
	setp.lt.u32 	%p12, %r12, 3;
	@%p12 bra 	$L__BB3_41;

	mul.ftz.f32 	%f4, %f1, 0f00000000;
	mul.lo.s32 	%r54, %r8, %r10;
	mul.lo.s32 	%r55, %r54, %r38;
	mul.wide.s32 	%rd4, %r55, 4;

$L__BB3_16:
	setp.lt.s32 	%p13, %r68, %r7;
	mov.f32 	%f73, 0f7FFFFFFF;
	@%p13 bra 	$L__BB3_18;

	mov.f32 	%f73, %f4;

$L__BB3_18:
	mad.lo.s32 	%r56, %r68, %r38, %r5;
	mul.wide.s32 	%rd30, %r56, 4;
	add.s64 	%rd5, %rd2, %rd30;
	st.global.f32 	[%rd5], %f73;
	add.s32 	%r20, %r68, %r11;
	setp.ge.s32 	%p14, %r20, %r7;
	mov.f32 	%f74, %f4;
	@%p14 bra 	$L__BB3_20;

	mov.f32 	%f74, 0f7FFFFFFF;

$L__BB3_20:
	add.s64 	%rd6, %rd5, %rd4;
	st.global.f32 	[%rd6], %f74;
	add.s32 	%r21, %r20, %r11;
	setp.ge.s32 	%p15, %r21, %r7;
	mov.f32 	%f75, %f4;
	@%p15 bra 	$L__BB3_22;

	mov.f32 	%f75, 0f7FFFFFFF;

$L__BB3_22:
	add.s64 	%rd7, %rd6, %rd4;
	st.global.f32 	[%rd7], %f75;
	add.s32 	%r22, %r21, %r11;
	setp.ge.s32 	%p16, %r22, %r7;
	mov.f32 	%f76, %f4;
	@%p16 bra 	$L__BB3_24;

	mov.f32 	%f76, 0f7FFFFFFF;

$L__BB3_24:
	add.s64 	%rd31, %rd7, %rd4;
	st.global.f32 	[%rd31], %f76;
	add.s32 	%r68, %r22, %r11;
	setp.lt.s32 	%p17, %r68, %r39;
	@%p17 bra 	$L__BB3_16;

$L__BB3_41:
	ret;

}

