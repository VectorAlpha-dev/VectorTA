







.version 9.0
.target sm_89
.address_size 64



.visible .entry vidya_batch_f32(
	.param .u64 vidya_batch_f32_param_0,
	.param .u64 vidya_batch_f32_param_1,
	.param .u64 vidya_batch_f32_param_2,
	.param .u64 vidya_batch_f32_param_3,
	.param .u32 vidya_batch_f32_param_4,
	.param .u32 vidya_batch_f32_param_5,
	.param .u32 vidya_batch_f32_param_6,
	.param .u64 vidya_batch_f32_param_7
)
{
	.reg .pred 	%p<46>;
	.reg .f32 	%f<41>;
	.reg .b32 	%r<77>;
	.reg .f64 	%fd<252>;
	.reg .b64 	%rd<71>;


	ld.param.u64 	%rd33, [vidya_batch_f32_param_0];
	ld.param.u64 	%rd30, [vidya_batch_f32_param_1];
	ld.param.u64 	%rd31, [vidya_batch_f32_param_2];
	ld.param.u64 	%rd32, [vidya_batch_f32_param_3];
	ld.param.u32 	%r37, [vidya_batch_f32_param_4];
	ld.param.u32 	%r38, [vidya_batch_f32_param_5];
	ld.param.u32 	%r39, [vidya_batch_f32_param_6];
	ld.param.u64 	%rd34, [vidya_batch_f32_param_7];
	cvta.to.global.u64 	%rd1, %rd34;
	cvta.to.global.u64 	%rd2, %rd33;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r39;
	setp.lt.s32 	%p2, %r37, 1;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB0_39;

	cvta.to.global.u64 	%rd35, %rd30;
	mul.wide.s32 	%rd36, %r1, 4;
	add.s64 	%rd37, %rd35, %rd36;
	cvta.to.global.u64 	%rd38, %rd31;
	add.s64 	%rd39, %rd38, %rd36;
	cvta.to.global.u64 	%rd40, %rd32;
	add.s64 	%rd41, %rd40, %rd36;
	mul.lo.s32 	%r2, %r1, %r37;
	ld.global.nc.u32 	%r3, [%rd37];
	setp.lt.s32 	%p4, %r3, 2;
	ld.global.nc.u32 	%r4, [%rd39];
	setp.lt.s32 	%p5, %r4, %r3;
	or.pred  	%p6, %p4, %p5;
	setp.lt.s32 	%p7, %r4, 2;
	or.pred  	%p8, %p7, %p6;
	ld.global.nc.f32 	%f1, [%rd41];
	setp.lt.ftz.f32 	%p9, %f1, 0f00000000;
	or.pred  	%p10, %p9, %p8;
	setp.gt.ftz.f32 	%p11, %f1, 0f3F800000;
	or.pred  	%p12, %p11, %p10;
	setp.lt.s32 	%p13, %r38, 0;
	or.pred  	%p14, %p13, %p12;
	setp.le.s32 	%p15, %r37, %r38;
	or.pred  	%p16, %p15, %p14;
	sub.s32 	%r40, %r37, %r38;
	setp.gt.s32 	%p17, %r4, %r40;
	or.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB0_36;
	bra.uni 	$L__BB0_2;

$L__BB0_36:
	mov.u32 	%r76, %tid.x;
	setp.ge.s32 	%p44, %r76, %r37;
	@%p44 bra 	$L__BB0_39;

	mov.u32 	%r34, %ntid.x;

$L__BB0_38:
	add.s32 	%r63, %r76, %r2;
	mul.wide.s32 	%rd61, %r63, 4;
	add.s64 	%rd62, %rd1, %rd61;
	mov.u32 	%r64, 2147483647;
	st.global.u32 	[%rd62], %r64;
	add.s32 	%r76, %r76, %r34;
	setp.lt.s32 	%p45, %r76, %r37;
	@%p45 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_39;

$L__BB0_2:
	add.s32 	%r75, %r4, %r38;
	add.s32 	%r6, %r75, -2;
	mov.u32 	%r7, %tid.x;
	setp.ge.s32 	%p19, %r7, %r6;
	@%p19 bra 	$L__BB0_5;

	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r65, %r7;

$L__BB0_4:
	add.s32 	%r41, %r65, %r2;
	mul.wide.s32 	%rd42, %r41, 4;
	add.s64 	%rd43, %rd1, %rd42;
	mov.u32 	%r42, 2147483647;
	st.global.u32 	[%rd43], %r42;
	add.s32 	%r65, %r65, %r8;
	setp.lt.s32 	%p20, %r65, %r6;
	@%p20 bra 	$L__BB0_4;

$L__BB0_5:
	setp.ne.s32 	%p21, %r7, 0;
	@%p21 bra 	$L__BB0_39;

	sub.s32 	%r11, %r75, %r3;
	setp.le.s32 	%p22, %r11, %r38;
	mov.f64 	%fd238, 0d0000000000000000;
	mov.f64 	%fd236, %fd238;
	mov.f64 	%fd237, %fd238;
	@%p22 bra 	$L__BB0_13;

	sub.s32 	%r43, %r4, %r3;
	and.b32  	%r67, %r43, 3;
	setp.eq.s32 	%p23, %r67, 0;
	mov.f64 	%fd237, 0d0000000000000000;
	mov.u32 	%r68, %r38;
	mov.f64 	%fd236, %fd237;
	@%p23 bra 	$L__BB0_10;

	mul.wide.s32 	%rd44, %r38, 4;
	add.s64 	%rd63, %rd2, %rd44;
	mov.f64 	%fd237, 0d0000000000000000;
	mov.u32 	%r68, %r38;

$L__BB0_9:
	.pragma "nounroll";
	ld.global.nc.f32 	%f13, [%rd63];
	cvt.ftz.f64.f32 	%fd85, %f13;
	add.f64 	%fd236, %fd236, %fd85;
	fma.rn.f64 	%fd237, %fd85, %fd85, %fd237;
	add.s32 	%r68, %r68, 1;
	add.s64 	%rd63, %rd63, 4;
	add.s32 	%r67, %r67, -1;
	setp.ne.s32 	%p24, %r67, 0;
	@%p24 bra 	$L__BB0_9;

$L__BB0_10:
	not.b32 	%r44, %r3;
	add.s32 	%r45, %r4, %r44;
	setp.lt.u32 	%p25, %r45, 3;
	@%p25 bra 	$L__BB0_13;

	mul.wide.s32 	%rd45, %r68, 4;
	add.s64 	%rd46, %rd2, %rd45;
	add.s64 	%rd64, %rd46, 8;

$L__BB0_12:
	ld.global.nc.f32 	%f14, [%rd64+-8];
	cvt.ftz.f64.f32 	%fd86, %f14;
	add.f64 	%fd87, %fd236, %fd86;
	fma.rn.f64 	%fd88, %fd86, %fd86, %fd237;
	ld.global.nc.f32 	%f15, [%rd64+-4];
	cvt.ftz.f64.f32 	%fd89, %f15;
	add.f64 	%fd90, %fd87, %fd89;
	fma.rn.f64 	%fd91, %fd89, %fd89, %fd88;
	ld.global.nc.f32 	%f16, [%rd64];
	cvt.ftz.f64.f32 	%fd92, %f16;
	add.f64 	%fd93, %fd90, %fd92;
	fma.rn.f64 	%fd94, %fd92, %fd92, %fd91;
	ld.global.nc.f32 	%f17, [%rd64+4];
	cvt.ftz.f64.f32 	%fd95, %f17;
	add.f64 	%fd236, %fd93, %fd95;
	fma.rn.f64 	%fd237, %fd95, %fd95, %fd94;
	add.s64 	%rd64, %rd64, 16;
	add.s32 	%r68, %r68, 4;
	setp.lt.s32 	%p26, %r68, %r11;
	@%p26 bra 	$L__BB0_12;

$L__BB0_13:
	setp.lt.s32 	%p27, %r3, 1;
	mov.f64 	%fd239, %fd238;
	@%p27 bra 	$L__BB0_20;

	add.s32 	%r46, %r75, 1;
	sub.s32 	%r47, %r46, %r3;
	max.s32 	%r48, %r47, %r75;
	add.s32 	%r20, %r3, %r48;
	sub.s32 	%r49, %r20, %r4;
	sub.s32 	%r50, %r49, %r38;
	and.b32  	%r71, %r50, 3;
	setp.eq.s32 	%p28, %r71, 0;
	mov.f64 	%fd239, 0d0000000000000000;
	mov.u32 	%r72, %r11;
	mov.f64 	%fd238, %fd239;
	@%p28 bra 	$L__BB0_17;

	mul.wide.s32 	%rd47, %r11, 4;
	add.s64 	%rd65, %rd2, %rd47;
	mov.f64 	%fd239, 0d0000000000000000;
	mov.u32 	%r72, %r11;

$L__BB0_16:
	.pragma "nounroll";
	ld.global.nc.f32 	%f18, [%rd65];
	cvt.ftz.f64.f32 	%fd103, %f18;
	add.f64 	%fd236, %fd236, %fd103;
	fma.rn.f64 	%fd237, %fd103, %fd103, %fd237;
	add.f64 	%fd238, %fd238, %fd103;
	fma.rn.f64 	%fd239, %fd103, %fd103, %fd239;
	add.s32 	%r72, %r72, 1;
	add.s64 	%rd65, %rd65, 4;
	add.s32 	%r71, %r71, -1;
	setp.ne.s32 	%p29, %r71, 0;
	@%p29 bra 	$L__BB0_16;

$L__BB0_17:
	not.b32 	%r51, %r4;
	add.s32 	%r52, %r20, %r51;
	sub.s32 	%r53, %r52, %r38;
	setp.lt.u32 	%p30, %r53, 3;
	@%p30 bra 	$L__BB0_20;

	mul.wide.s32 	%rd48, %r72, 4;
	add.s64 	%rd49, %rd2, %rd48;
	add.s64 	%rd66, %rd49, 8;

$L__BB0_19:
	ld.global.nc.f32 	%f19, [%rd66+-8];
	cvt.ftz.f64.f32 	%fd104, %f19;
	add.f64 	%fd105, %fd236, %fd104;
	fma.rn.f64 	%fd106, %fd104, %fd104, %fd237;
	add.f64 	%fd107, %fd238, %fd104;
	fma.rn.f64 	%fd108, %fd104, %fd104, %fd239;
	ld.global.nc.f32 	%f20, [%rd66+-4];
	cvt.ftz.f64.f32 	%fd109, %f20;
	add.f64 	%fd110, %fd105, %fd109;
	fma.rn.f64 	%fd111, %fd109, %fd109, %fd106;
	add.f64 	%fd112, %fd107, %fd109;
	fma.rn.f64 	%fd113, %fd109, %fd109, %fd108;
	ld.global.nc.f32 	%f21, [%rd66];
	cvt.ftz.f64.f32 	%fd114, %f21;
	add.f64 	%fd115, %fd110, %fd114;
	fma.rn.f64 	%fd116, %fd114, %fd114, %fd111;
	add.f64 	%fd117, %fd112, %fd114;
	fma.rn.f64 	%fd118, %fd114, %fd114, %fd113;
	ld.global.nc.f32 	%f22, [%rd66+4];
	cvt.ftz.f64.f32 	%fd119, %f22;
	add.f64 	%fd236, %fd115, %fd119;
	fma.rn.f64 	%fd237, %fd119, %fd119, %fd116;
	add.f64 	%fd238, %fd117, %fd119;
	fma.rn.f64 	%fd239, %fd119, %fd119, %fd118;
	add.s64 	%rd66, %rd66, 16;
	add.s32 	%r72, %r72, 4;
	setp.lt.s32 	%p31, %r72, %r75;
	@%p31 bra 	$L__BB0_19;

$L__BB0_20:
	mul.wide.s32 	%rd50, %r6, 4;
	add.s64 	%rd15, %rd2, %rd50;
	ld.global.nc.f32 	%f39, [%rd15];
	add.s32 	%r54, %r75, %r2;
	mul.wide.s32 	%rd51, %r54, 4;
	add.s64 	%rd16, %rd1, %rd51;
	st.global.f32 	[%rd16+-8], %f39;
	setp.gt.s32 	%p32, %r75, %r37;
	@%p32 bra 	$L__BB0_24;

	cvt.rn.f64.s32 	%fd121, %r4;
	rcp.rn.f64 	%fd122, %fd121;
	mul.f64 	%fd123, %fd122, %fd236;
	mul.f64 	%fd124, %fd122, %fd237;
	mul.f64 	%fd125, %fd123, %fd123;
	sub.f64 	%fd126, %fd124, %fd125;
	mov.f64 	%fd240, 0d0000000000000000;
	max.f64 	%fd127, %fd240, %fd126;
	sqrt.rn.f64 	%fd43, %fd127;
	setp.eq.f64 	%p33, %fd43, 0d0000000000000000;
	@%p33 bra 	$L__BB0_23;

	cvt.rn.f64.s32 	%fd128, %r3;
	rcp.rn.f64 	%fd129, %fd128;
	mul.f64 	%fd130, %fd129, %fd238;
	mul.f64 	%fd131, %fd130, %fd130;
	mul.f64 	%fd132, %fd129, %fd239;
	sub.f64 	%fd133, %fd132, %fd131;
	mov.f64 	%fd134, 0d0000000000000000;
	max.f64 	%fd135, %fd134, %fd133;
	sqrt.rn.f64 	%fd136, %fd135;
	div.rn.f64 	%fd240, %fd136, %fd43;

$L__BB0_23:
	cvt.ftz.f64.f32 	%fd137, %f1;
	mul.f64 	%fd138, %fd240, %fd137;
	ld.global.nc.f32 	%f23, [%rd15+4];
	sub.ftz.f32 	%f24, %f23, %f39;
	cvt.rn.ftz.f32.f64 	%f25, %fd138;
	fma.rn.ftz.f32 	%f39, %f24, %f25, %f39;
	st.global.f32 	[%rd16+-4], %f39;

$L__BB0_24:
	setp.ge.s32 	%p34, %r75, %r37;
	@%p34 bra 	$L__BB0_39;

	cvt.rn.f64.s32 	%fd139, %r3;
	rcp.rn.f64 	%fd46, %fd139;
	cvt.rn.f64.s32 	%fd140, %r4;
	rcp.rn.f64 	%fd47, %fd140;
	cvt.ftz.f64.f32 	%fd48, %f1;
	sub.s32 	%r55, %r37, %r4;
	sub.s32 	%r56, %r55, %r38;
	and.b32  	%r57, %r56, 1;
	setp.eq.b32 	%p35, %r57, 1;
	mov.pred 	%p36, 0;
	xor.pred  	%p37, %p35, %p36;
	not.pred 	%p38, %p37;
	@%p38 bra 	$L__BB0_29;

	ld.global.nc.f32 	%f5, [%rd15+8];
	cvt.ftz.f64.f32 	%fd142, %f5;
	add.f64 	%fd143, %fd236, %fd142;
	fma.rn.f64 	%fd144, %fd142, %fd142, %fd237;
	add.f64 	%fd145, %fd238, %fd142;
	fma.rn.f64 	%fd146, %fd142, %fd142, %fd239;
	mul.wide.s32 	%rd52, %r38, 4;
	add.s64 	%rd53, %rd2, %rd52;
	ld.global.nc.f32 	%f26, [%rd53];
	cvt.ftz.f64.f32 	%fd147, %f26;
	mul.wide.s32 	%rd54, %r11, 4;
	add.s64 	%rd55, %rd2, %rd54;
	ld.global.nc.f32 	%f27, [%rd55];
	cvt.ftz.f64.f32 	%fd148, %f27;
	sub.f64 	%fd236, %fd143, %fd147;
	mul.f64 	%fd149, %fd147, %fd147;
	sub.f64 	%fd237, %fd144, %fd149;
	sub.f64 	%fd238, %fd145, %fd148;
	mul.f64 	%fd150, %fd148, %fd148;
	sub.f64 	%fd239, %fd146, %fd150;
	mul.f64 	%fd151, %fd47, %fd236;
	mul.f64 	%fd152, %fd47, %fd237;
	mul.f64 	%fd153, %fd151, %fd151;
	sub.f64 	%fd154, %fd152, %fd153;
	mov.f64 	%fd241, 0d0000000000000000;
	max.f64 	%fd155, %fd241, %fd154;
	sqrt.rn.f64 	%fd53, %fd155;
	setp.eq.f64 	%p39, %fd53, 0d0000000000000000;
	@%p39 bra 	$L__BB0_28;

	mul.f64 	%fd156, %fd46, %fd238;
	mul.f64 	%fd157, %fd156, %fd156;
	mul.f64 	%fd158, %fd46, %fd239;
	sub.f64 	%fd159, %fd158, %fd157;
	mov.f64 	%fd160, 0d0000000000000000;
	max.f64 	%fd161, %fd160, %fd159;
	sqrt.rn.f64 	%fd162, %fd161;
	div.rn.f64 	%fd241, %fd162, %fd53;

$L__BB0_28:
	mul.f64 	%fd163, %fd241, %fd48;
	cvt.rn.ftz.f32.f64 	%f28, %fd163;
	sub.ftz.f32 	%f29, %f5, %f39;
	fma.rn.ftz.f32 	%f39, %f29, %f28, %f39;
	st.global.f32 	[%rd16], %f39;
	add.s32 	%r75, %r75, 1;

$L__BB0_29:
	not.b32 	%r58, %r4;
	add.s32 	%r59, %r58, %r37;
	setp.eq.s32 	%p40, %r59, %r38;
	@%p40 bra 	$L__BB0_39;

	sub.s32 	%r60, %r4, %r75;
	mul.wide.s32 	%rd56, %r60, 4;
	sub.s64 	%rd70, %rd2, %rd56;
	sub.s32 	%r61, %r3, %r75;
	mul.wide.s32 	%rd57, %r61, 4;
	sub.s64 	%rd69, %rd2, %rd57;
	add.s32 	%r62, %r75, %r2;
	mul.wide.s32 	%rd58, %r62, 4;
	add.s64 	%rd68, %rd1, %rd58;
	mul.wide.s32 	%rd59, %r75, 4;
	add.s64 	%rd60, %rd2, %rd59;
	add.s64 	%rd67, %rd60, 4;

$L__BB0_31:
	add.s64 	%rd25, %rd67, -4;
	ld.global.nc.f32 	%f9, [%rd67+-4];
	cvt.ftz.f64.f32 	%fd165, %f9;
	add.f64 	%fd166, %fd236, %fd165;
	fma.rn.f64 	%fd167, %fd165, %fd165, %fd237;
	add.f64 	%fd168, %fd238, %fd165;
	fma.rn.f64 	%fd169, %fd165, %fd165, %fd239;
	ld.global.nc.f32 	%f30, [%rd70];
	cvt.ftz.f64.f32 	%fd170, %f30;
	ld.global.nc.f32 	%f31, [%rd69];
	cvt.ftz.f64.f32 	%fd171, %f31;
	sub.f64 	%fd64, %fd166, %fd170;
	mul.f64 	%fd172, %fd170, %fd170;
	sub.f64 	%fd65, %fd167, %fd172;
	sub.f64 	%fd66, %fd168, %fd171;
	mul.f64 	%fd173, %fd171, %fd171;
	sub.f64 	%fd67, %fd169, %fd173;
	mul.f64 	%fd174, %fd47, %fd64;
	mul.f64 	%fd175, %fd47, %fd65;
	mul.f64 	%fd176, %fd174, %fd174;
	sub.f64 	%fd177, %fd175, %fd176;
	mov.f64 	%fd251, 0d0000000000000000;
	max.f64 	%fd178, %fd251, %fd177;
	sqrt.rn.f64 	%fd68, %fd178;
	setp.eq.f64 	%p41, %fd68, 0d0000000000000000;
	mov.f64 	%fd250, %fd251;
	@%p41 bra 	$L__BB0_33;

	mul.f64 	%fd179, %fd46, %fd66;
	mul.f64 	%fd180, %fd179, %fd179;
	mul.f64 	%fd181, %fd46, %fd67;
	sub.f64 	%fd182, %fd181, %fd180;
	mov.f64 	%fd183, 0d0000000000000000;
	max.f64 	%fd184, %fd183, %fd182;
	sqrt.rn.f64 	%fd185, %fd184;
	div.rn.f64 	%fd250, %fd185, %fd68;

$L__BB0_33:
	mul.f64 	%fd187, %fd250, %fd48;
	cvt.rn.ftz.f32.f64 	%f32, %fd187;
	sub.ftz.f32 	%f33, %f9, %f39;
	fma.rn.ftz.f32 	%f10, %f33, %f32, %f39;
	st.global.f32 	[%rd68], %f10;
	ld.global.nc.f32 	%f11, [%rd25+4];
	cvt.ftz.f64.f32 	%fd188, %f11;
	add.f64 	%fd189, %fd64, %fd188;
	fma.rn.f64 	%fd190, %fd188, %fd188, %fd65;
	add.f64 	%fd191, %fd66, %fd188;
	fma.rn.f64 	%fd192, %fd188, %fd188, %fd67;
	ld.global.nc.f32 	%f34, [%rd70+4];
	cvt.ftz.f64.f32 	%fd193, %f34;
	ld.global.nc.f32 	%f35, [%rd69+4];
	cvt.ftz.f64.f32 	%fd194, %f35;
	sub.f64 	%fd236, %fd189, %fd193;
	mul.f64 	%fd195, %fd193, %fd193;
	sub.f64 	%fd237, %fd190, %fd195;
	sub.f64 	%fd238, %fd191, %fd194;
	mul.f64 	%fd196, %fd194, %fd194;
	sub.f64 	%fd239, %fd192, %fd196;
	mul.f64 	%fd197, %fd47, %fd236;
	mul.f64 	%fd198, %fd47, %fd237;
	mul.f64 	%fd199, %fd197, %fd197;
	sub.f64 	%fd200, %fd198, %fd199;
	max.f64 	%fd201, %fd251, %fd200;
	sqrt.rn.f64 	%fd75, %fd201;
	setp.eq.f64 	%p42, %fd75, 0d0000000000000000;
	@%p42 bra 	$L__BB0_35;

	mul.f64 	%fd202, %fd46, %fd238;
	mul.f64 	%fd203, %fd202, %fd202;
	mul.f64 	%fd204, %fd46, %fd239;
	sub.f64 	%fd205, %fd204, %fd203;
	mov.f64 	%fd206, 0d0000000000000000;
	max.f64 	%fd207, %fd206, %fd205;
	sqrt.rn.f64 	%fd208, %fd207;
	div.rn.f64 	%fd251, %fd208, %fd75;

$L__BB0_35:
	mul.f64 	%fd209, %fd251, %fd48;
	cvt.rn.ftz.f32.f64 	%f36, %fd209;
	sub.ftz.f32 	%f37, %f11, %f10;
	fma.rn.ftz.f32 	%f39, %f37, %f36, %f10;
	st.global.f32 	[%rd68+4], %f39;
	add.s64 	%rd70, %rd70, 8;
	add.s64 	%rd69, %rd69, 8;
	add.s64 	%rd68, %rd68, 8;
	add.s64 	%rd67, %rd67, 8;
	add.s32 	%r75, %r75, 2;
	setp.lt.s32 	%p43, %r75, %r37;
	@%p43 bra 	$L__BB0_31;

$L__BB0_39:
	ret;

}

.visible .entry vidya_batch_prefix_f32(
	.param .u64 vidya_batch_prefix_f32_param_0,
	.param .u64 vidya_batch_prefix_f32_param_1,
	.param .u64 vidya_batch_prefix_f32_param_2,
	.param .u64 vidya_batch_prefix_f32_param_3,
	.param .u64 vidya_batch_prefix_f32_param_4,
	.param .u64 vidya_batch_prefix_f32_param_5,
	.param .u32 vidya_batch_prefix_f32_param_6,
	.param .u32 vidya_batch_prefix_f32_param_7,
	.param .u32 vidya_batch_prefix_f32_param_8,
	.param .u64 vidya_batch_prefix_f32_param_9
)
.maxntid 32, 1, 1
{
	.reg .pred 	%p<64>;
	.reg .f32 	%f<91>;
	.reg .b32 	%r<113>;
	.reg .f64 	%fd<93>;
	.reg .b64 	%rd<82>;


	ld.param.u64 	%rd29, [vidya_batch_prefix_f32_param_0];
	ld.param.u64 	%rd30, [vidya_batch_prefix_f32_param_1];
	ld.param.u64 	%rd31, [vidya_batch_prefix_f32_param_2];
	ld.param.u64 	%rd26, [vidya_batch_prefix_f32_param_3];
	ld.param.u64 	%rd27, [vidya_batch_prefix_f32_param_4];
	ld.param.u64 	%rd28, [vidya_batch_prefix_f32_param_5];
	ld.param.u32 	%r52, [vidya_batch_prefix_f32_param_6];
	ld.param.u32 	%r53, [vidya_batch_prefix_f32_param_7];
	ld.param.u32 	%r54, [vidya_batch_prefix_f32_param_8];
	ld.param.u64 	%rd32, [vidya_batch_prefix_f32_param_9];
	cvta.to.global.u64 	%rd81, %rd31;
	cvta.to.global.u64 	%rd80, %rd30;
	cvta.to.global.u64 	%rd3, %rd32;
	cvta.to.global.u64 	%rd4, %rd29;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p11, %r1, %r54;
	setp.lt.s32 	%p12, %r52, 1;
	or.pred  	%p13, %p12, %p11;
	@%p13 bra 	$L__BB1_38;

	cvta.to.global.u64 	%rd33, %rd26;
	mul.wide.s32 	%rd34, %r1, 4;
	add.s64 	%rd35, %rd33, %rd34;
	cvta.to.global.u64 	%rd36, %rd27;
	add.s64 	%rd37, %rd36, %rd34;
	cvta.to.global.u64 	%rd38, %rd28;
	add.s64 	%rd39, %rd38, %rd34;
	mul.lo.s32 	%r2, %r1, %r52;
	ld.global.nc.u32 	%r3, [%rd35];
	setp.lt.s32 	%p14, %r3, 2;
	ld.global.nc.u32 	%r4, [%rd37];
	setp.lt.s32 	%p15, %r4, %r3;
	or.pred  	%p16, %p14, %p15;
	setp.lt.s32 	%p17, %r4, 2;
	or.pred  	%p18, %p17, %p16;
	ld.global.nc.f32 	%f1, [%rd39];
	setp.lt.ftz.f32 	%p19, %f1, 0f00000000;
	or.pred  	%p20, %p19, %p18;
	setp.gt.ftz.f32 	%p21, %f1, 0f3F800000;
	or.pred  	%p22, %p21, %p20;
	setp.lt.s32 	%p23, %r53, 0;
	or.pred  	%p24, %p23, %p22;
	setp.le.s32 	%p25, %r52, %r53;
	or.pred  	%p26, %p25, %p24;
	sub.s32 	%r55, %r52, %r53;
	setp.gt.s32 	%p27, %r4, %r55;
	or.pred  	%p28, %p27, %p26;
	@%p28 bra 	$L__BB1_35;
	bra.uni 	$L__BB1_2;

$L__BB1_35:
	mov.u32 	%r112, %tid.x;
	setp.ge.s32 	%p62, %r112, %r52;
	@%p62 bra 	$L__BB1_38;

	mov.u32 	%r49, %ntid.x;

$L__BB1_37:
	add.s32 	%r97, %r112, %r2;
	mul.wide.s32 	%rd76, %r97, 4;
	add.s64 	%rd77, %rd3, %rd76;
	mov.u32 	%r98, 2147483647;
	st.global.u32 	[%rd77], %r98;
	add.s32 	%r112, %r112, %r49;
	setp.lt.s32 	%p63, %r112, %r52;
	@%p63 bra 	$L__BB1_37;
	bra.uni 	$L__BB1_38;

$L__BB1_2:
	add.s32 	%r5, %r4, %r53;
	add.s32 	%r6, %r5, -2;
	add.s32 	%r109, %r5, -1;
	mov.u32 	%r8, %tid.x;
	setp.ge.s32 	%p29, %r8, %r6;
	@%p29 bra 	$L__BB1_5;

	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r99, %r8;

$L__BB1_4:
	add.s32 	%r56, %r99, %r2;
	mul.wide.s32 	%rd40, %r56, 4;
	add.s64 	%rd41, %rd3, %rd40;
	mov.u32 	%r57, 2147483647;
	st.global.u32 	[%rd41], %r57;
	add.s32 	%r99, %r99, %r9;
	setp.lt.s32 	%p30, %r99, %r6;
	@%p30 bra 	$L__BB1_4;

$L__BB1_5:
	setp.ne.s32 	%p31, %r8, 0;
	mul.wide.s32 	%rd42, %r6, 4;
	add.s64 	%rd5, %rd4, %rd42;
	@%p31 bra 	$L__BB1_7;

	ld.global.nc.f32 	%f41, [%rd5];
	add.s32 	%r58, %r6, %r2;
	mul.wide.s32 	%rd43, %r58, 4;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.f32 	[%rd44], %f41;

$L__BB1_7:
	setp.gt.s32 	%p32, %r8, 31;
	@%p32 bra 	$L__BB1_38;

	ld.global.nc.f32 	%f85, [%rd5];
	cvt.rn.f64.s32 	%fd11, %r3;
	rcp.rn.f64 	%fd1, %fd11;
	cvt.rn.f64.s32 	%fd12, %r4;
	rcp.rn.f64 	%fd2, %fd12;
	add.s32 	%r59, %r5, 30;
	setp.ge.s32 	%p33, %r59, %r52;
	@%p33 bra 	$L__BB1_23;

	mov.u32 	%r100, %r109;

$L__BB1_10:
	add.s32 	%r13, %r100, %r8;
	add.s32 	%r60, %r13, 1;
	mul.wide.s32 	%rd45, %r60, 8;
	add.s64 	%rd46, %rd80, %rd45;
	sub.s32 	%r61, %r60, %r4;
	mul.wide.s32 	%rd47, %r61, 8;
	add.s64 	%rd48, %rd80, %rd47;
	ld.global.nc.f64 	%fd13, [%rd48];
	ld.global.nc.f64 	%fd14, [%rd46];
	sub.f64 	%fd15, %fd14, %fd13;
	add.s64 	%rd49, %rd81, %rd45;
	add.s64 	%rd50, %rd81, %rd47;
	ld.global.nc.f64 	%fd16, [%rd50];
	ld.global.nc.f64 	%fd17, [%rd49];
	sub.f64 	%fd18, %fd17, %fd16;
	sub.s32 	%r62, %r60, %r3;
	mul.wide.s32 	%rd51, %r62, 8;
	add.s64 	%rd52, %rd80, %rd51;
	ld.global.nc.f64 	%fd19, [%rd52];
	sub.f64 	%fd20, %fd14, %fd19;
	add.s64 	%rd53, %rd81, %rd51;
	ld.global.nc.f64 	%fd21, [%rd53];
	sub.f64 	%fd22, %fd17, %fd21;
	mul.f64 	%fd23, %fd1, %fd20;
	mul.f64 	%fd24, %fd2, %fd15;
	neg.f64 	%fd25, %fd23;
	mul.f64 	%fd26, %fd1, %fd22;
	fma.rn.f64 	%fd27, %fd25, %fd23, %fd26;
	neg.f64 	%fd28, %fd24;
	mul.f64 	%fd29, %fd2, %fd18;
	fma.rn.f64 	%fd30, %fd28, %fd24, %fd29;
	mov.f64 	%fd31, 0d0000000000000000;
	max.f64 	%fd3, %fd31, %fd27;
	max.f64 	%fd4, %fd31, %fd30;
	setp.leu.f64 	%p34, %fd4, 0d0000000000000000;
	setp.leu.f64 	%p35, %fd3, 0d0000000000000000;
	mov.f32 	%f74, 0f00000000;
	or.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB1_12;

	div.rn.f64 	%fd32, %fd3, %fd4;
	cvt.rn.ftz.f32.f64 	%f43, %fd32;
	sqrt.approx.ftz.f32 	%f44, %f43;
	mul.ftz.f32 	%f74, %f1, %f44;

$L__BB1_12:
	mul.wide.s32 	%rd54, %r13, 4;
	add.s64 	%rd55, %rd4, %rd54;
	ld.global.nc.f32 	%f45, [%rd55];
	mul.ftz.f32 	%f78, %f74, %f45;
	mov.f32 	%f46, 0f3F800000;
	sub.ftz.f32 	%f77, %f46, %f74;
	mov.b32 	%r104, %f77;
	mov.u32 	%r63, 0;
	mov.u32 	%r64, 1;
	mov.u32 	%r65, -1;
	shfl.sync.up.b32 	%r15|%p1, %r104, %r64, %r63, %r65;
	mov.b32 	%r103, %f78;
	shfl.sync.up.b32 	%r17|%p2, %r103, %r64, %r63, %r65;
	setp.lt.s32 	%p37, %r8, 1;
	@%p37 bra 	$L__BB1_14;

	mov.b32 	%f47, %r17;
	mov.b32 	%f48, %r15;
	fma.rn.ftz.f32 	%f78, %f77, %f47, %f78;
	mul.ftz.f32 	%f77, %f77, %f48;
	mov.b32 	%r104, %f77;
	mov.b32 	%r103, %f78;

$L__BB1_14:
	mov.u32 	%r67, 2;
	shfl.sync.up.b32 	%r22|%p3, %r104, %r67, %r63, %r65;
	shfl.sync.up.b32 	%r23|%p4, %r103, %r67, %r63, %r65;
	setp.lt.s32 	%p38, %r8, 2;
	@%p38 bra 	$L__BB1_16;

	mov.b32 	%f49, %r23;
	mov.b32 	%f50, %r22;
	fma.rn.ftz.f32 	%f78, %f77, %f49, %f78;
	mul.ftz.f32 	%f77, %f77, %f50;
	mov.b32 	%r104, %f77;
	mov.b32 	%r103, %f78;

$L__BB1_16:
	mov.u32 	%r69, 0;
	mov.u32 	%r70, 4;
	mov.u32 	%r71, -1;
	shfl.sync.up.b32 	%r28|%p5, %r104, %r70, %r69, %r71;
	shfl.sync.up.b32 	%r29|%p6, %r103, %r70, %r69, %r71;
	setp.lt.s32 	%p39, %r8, 4;
	@%p39 bra 	$L__BB1_18;

	mov.b32 	%f51, %r29;
	mov.b32 	%f52, %r28;
	fma.rn.ftz.f32 	%f78, %f77, %f51, %f78;
	mul.ftz.f32 	%f77, %f77, %f52;
	mov.b32 	%r104, %f77;
	mov.b32 	%r103, %f78;

$L__BB1_18:
	mov.u32 	%r73, 8;
	shfl.sync.up.b32 	%r34|%p7, %r104, %r73, %r69, %r71;
	shfl.sync.up.b32 	%r35|%p8, %r103, %r73, %r69, %r71;
	setp.lt.s32 	%p40, %r8, 8;
	@%p40 bra 	$L__BB1_20;

	mov.b32 	%f53, %r35;
	mov.b32 	%f54, %r34;
	fma.rn.ftz.f32 	%f78, %f77, %f53, %f78;
	mul.ftz.f32 	%f77, %f77, %f54;
	mov.b32 	%r104, %f77;
	mov.b32 	%r103, %f78;

$L__BB1_20:
	mov.u32 	%r75, 0;
	mov.u32 	%r76, 16;
	mov.u32 	%r77, -1;
	shfl.sync.up.b32 	%r40|%p9, %r104, %r76, %r75, %r77;
	shfl.sync.up.b32 	%r41|%p10, %r103, %r76, %r75, %r77;
	setp.lt.s32 	%p41, %r8, 16;
	@%p41 bra 	$L__BB1_22;

	mov.b32 	%f55, %r41;
	mov.b32 	%f56, %r40;
	fma.rn.ftz.f32 	%f78, %f77, %f55, %f78;
	mul.ftz.f32 	%f77, %f77, %f56;

$L__BB1_22:
	add.s32 	%r78, %r13, %r2;
	mul.wide.s32 	%rd56, %r78, 4;
	add.s64 	%rd57, %rd3, %rd56;
	fma.rn.ftz.f32 	%f57, %f77, %f85, %f78;
	st.global.f32 	[%rd57], %f57;
	mov.b32 	%r79, %f57;
	mov.u32 	%r80, 31;
	shfl.sync.idx.b32 	%r82|%p42, %r79, %r80, %r80, %r77;
	mov.b32 	%f85, %r82;
	add.s32 	%r109, %r100, 32;
	add.s32 	%r83, %r100, 63;
	setp.lt.s32 	%p43, %r83, %r52;
	mov.u32 	%r100, %r109;
	@%p43 bra 	$L__BB1_10;

$L__BB1_23:
	setp.ge.s32 	%p44, %r109, %r52;
	or.pred  	%p46, %p31, %p44;
	@%p46 bra 	$L__BB1_38;

	sub.s32 	%r84, %r52, %r109;
	and.b32  	%r85, %r84, 1;
	setp.eq.b32 	%p47, %r85, 1;
	mov.pred 	%p48, 0;
	xor.pred  	%p49, %p47, %p48;
	not.pred 	%p50, %p49;
	mov.u32 	%r111, %r109;
	@%p50 bra 	$L__BB1_28;

	add.s32 	%r111, %r109, 1;
	mul.wide.s32 	%rd58, %r111, 8;
	add.s64 	%rd59, %rd80, %rd58;
	sub.s32 	%r86, %r111, %r4;
	mul.wide.s32 	%rd60, %r86, 8;
	add.s64 	%rd61, %rd80, %rd60;
	ld.global.nc.f64 	%fd33, [%rd61];
	ld.global.nc.f64 	%fd34, [%rd59];
	sub.f64 	%fd35, %fd34, %fd33;
	add.s64 	%rd62, %rd81, %rd58;
	add.s64 	%rd63, %rd81, %rd60;
	ld.global.nc.f64 	%fd36, [%rd63];
	ld.global.nc.f64 	%fd37, [%rd62];
	sub.f64 	%fd38, %fd37, %fd36;
	sub.s32 	%r87, %r111, %r3;
	mul.wide.s32 	%rd64, %r87, 8;
	add.s64 	%rd65, %rd80, %rd64;
	ld.global.nc.f64 	%fd39, [%rd65];
	sub.f64 	%fd40, %fd34, %fd39;
	add.s64 	%rd66, %rd81, %rd64;
	ld.global.nc.f64 	%fd41, [%rd66];
	sub.f64 	%fd42, %fd37, %fd41;
	mul.f64 	%fd43, %fd1, %fd40;
	mul.f64 	%fd44, %fd2, %fd35;
	neg.f64 	%fd45, %fd43;
	mul.f64 	%fd46, %fd1, %fd42;
	fma.rn.f64 	%fd47, %fd45, %fd43, %fd46;
	neg.f64 	%fd48, %fd44;
	mul.f64 	%fd49, %fd2, %fd38;
	fma.rn.f64 	%fd50, %fd48, %fd44, %fd49;
	mov.f64 	%fd51, 0d0000000000000000;
	max.f64 	%fd5, %fd51, %fd47;
	max.f64 	%fd6, %fd51, %fd50;
	setp.leu.f64 	%p51, %fd6, 0d0000000000000000;
	setp.leu.f64 	%p52, %fd5, 0d0000000000000000;
	mov.f32 	%f86, 0f00000000;
	or.pred  	%p53, %p52, %p51;
	@%p53 bra 	$L__BB1_27;

	div.rn.f64 	%fd52, %fd5, %fd6;
	cvt.rn.ftz.f32.f64 	%f59, %fd52;
	sqrt.approx.ftz.f32 	%f60, %f59;
	mul.ftz.f32 	%f86, %f1, %f60;

$L__BB1_27:
	mul.wide.s32 	%rd67, %r109, 4;
	add.s64 	%rd68, %rd4, %rd67;
	ld.global.nc.f32 	%f61, [%rd68];
	sub.ftz.f32 	%f62, %f61, %f85;
	fma.rn.ftz.f32 	%f85, %f62, %f86, %f85;
	add.s32 	%r88, %r109, %r2;
	mul.wide.s32 	%rd69, %r88, 4;
	add.s64 	%rd70, %rd3, %rd69;
	st.global.f32 	[%rd70], %f85;

$L__BB1_28:
	neg.s32 	%r89, %r52;
	not.b32 	%r90, %r109;
	setp.eq.s32 	%p54, %r90, %r89;
	@%p54 bra 	$L__BB1_38;

	add.s32 	%r91, %r111, %r2;
	add.s32 	%r92, %r111, 1;
	mul.wide.s32 	%rd6, %r92, 8;
	add.s32 	%r93, %r4, -1;
	sub.s32 	%r94, %r93, %r111;
	mul.wide.s32 	%rd71, %r94, 8;
	neg.s64 	%rd7, %rd71;
	add.s32 	%r95, %r3, -1;
	sub.s32 	%r96, %r95, %r111;
	mul.wide.s32 	%rd72, %r96, 8;
	neg.s64 	%rd8, %rd72;
	mul.wide.s32 	%rd73, %r91, 4;
	add.s64 	%rd79, %rd3, %rd73;
	mul.wide.s32 	%rd74, %r111, 4;
	add.s64 	%rd75, %rd4, %rd74;
	add.s64 	%rd78, %rd75, 4;

$L__BB1_30:
	add.s64 	%rd15, %rd80, %rd6;
	add.s64 	%rd16, %rd80, %rd7;
	ld.global.nc.f64 	%fd53, [%rd16];
	ld.global.nc.f64 	%fd54, [%rd15];
	sub.f64 	%fd55, %fd54, %fd53;
	add.s64 	%rd17, %rd81, %rd6;
	add.s64 	%rd18, %rd81, %rd7;
	ld.global.nc.f64 	%fd56, [%rd18];
	ld.global.nc.f64 	%fd57, [%rd17];
	sub.f64 	%fd58, %fd57, %fd56;
	add.s64 	%rd19, %rd80, %rd8;
	ld.global.nc.f64 	%fd59, [%rd19];
	sub.f64 	%fd60, %fd54, %fd59;
	add.s64 	%rd20, %rd81, %rd8;
	ld.global.nc.f64 	%fd61, [%rd20];
	sub.f64 	%fd62, %fd57, %fd61;
	mul.f64 	%fd63, %fd1, %fd60;
	mul.f64 	%fd64, %fd2, %fd55;
	neg.f64 	%fd65, %fd63;
	mul.f64 	%fd66, %fd1, %fd62;
	fma.rn.f64 	%fd67, %fd65, %fd63, %fd66;
	neg.f64 	%fd68, %fd64;
	mul.f64 	%fd69, %fd2, %fd58;
	fma.rn.f64 	%fd70, %fd68, %fd64, %fd69;
	mov.f64 	%fd71, 0d0000000000000000;
	max.f64 	%fd7, %fd71, %fd67;
	max.f64 	%fd8, %fd71, %fd70;
	setp.leu.f64 	%p55, %fd8, 0d0000000000000000;
	setp.leu.f64 	%p56, %fd7, 0d0000000000000000;
	mov.f32 	%f90, 0f00000000;
	or.pred  	%p57, %p56, %p55;
	mov.f32 	%f89, %f90;
	@%p57 bra 	$L__BB1_32;

	div.rn.f64 	%fd72, %fd7, %fd8;
	cvt.rn.ftz.f32.f64 	%f64, %fd72;
	sqrt.approx.ftz.f32 	%f65, %f64;
	mul.ftz.f32 	%f89, %f1, %f65;

$L__BB1_32:
	add.s64 	%rd21, %rd78, -4;
	ld.global.nc.f32 	%f67, [%rd78+-4];
	sub.ftz.f32 	%f68, %f67, %f85;
	fma.rn.ftz.f32 	%f37, %f68, %f89, %f85;
	st.global.f32 	[%rd79], %f37;
	add.s32 	%r111, %r111, 2;
	ld.global.nc.f64 	%fd73, [%rd16+8];
	ld.global.nc.f64 	%fd74, [%rd15+8];
	sub.f64 	%fd75, %fd74, %fd73;
	ld.global.nc.f64 	%fd76, [%rd18+8];
	ld.global.nc.f64 	%fd77, [%rd17+8];
	sub.f64 	%fd78, %fd77, %fd76;
	ld.global.nc.f64 	%fd79, [%rd19+8];
	sub.f64 	%fd80, %fd74, %fd79;
	ld.global.nc.f64 	%fd81, [%rd20+8];
	sub.f64 	%fd82, %fd77, %fd81;
	mul.f64 	%fd83, %fd1, %fd80;
	mul.f64 	%fd84, %fd2, %fd75;
	neg.f64 	%fd85, %fd83;
	mul.f64 	%fd86, %fd1, %fd82;
	fma.rn.f64 	%fd87, %fd85, %fd83, %fd86;
	neg.f64 	%fd88, %fd84;
	mul.f64 	%fd89, %fd2, %fd78;
	fma.rn.f64 	%fd90, %fd88, %fd84, %fd89;
	max.f64 	%fd9, %fd71, %fd87;
	max.f64 	%fd10, %fd71, %fd90;
	setp.leu.f64 	%p58, %fd10, 0d0000000000000000;
	setp.leu.f64 	%p59, %fd9, 0d0000000000000000;
	or.pred  	%p60, %p59, %p58;
	@%p60 bra 	$L__BB1_34;

	div.rn.f64 	%fd92, %fd9, %fd10;
	cvt.rn.ftz.f32.f64 	%f69, %fd92;
	sqrt.approx.ftz.f32 	%f70, %f69;
	mul.ftz.f32 	%f90, %f1, %f70;

$L__BB1_34:
	ld.global.nc.f32 	%f71, [%rd21+4];
	sub.ftz.f32 	%f72, %f71, %f37;
	fma.rn.ftz.f32 	%f85, %f72, %f90, %f37;
	st.global.f32 	[%rd79+4], %f85;
	add.s64 	%rd81, %rd81, 16;
	add.s64 	%rd80, %rd80, 16;
	add.s64 	%rd79, %rd79, 8;
	add.s64 	%rd78, %rd78, 8;
	setp.lt.s32 	%p61, %r111, %r52;
	@%p61 bra 	$L__BB1_30;

$L__BB1_38:
	ret;

}

.visible .entry vidya_many_series_one_param_f32(
	.param .u64 vidya_many_series_one_param_f32_param_0,
	.param .u64 vidya_many_series_one_param_f32_param_1,
	.param .u32 vidya_many_series_one_param_f32_param_2,
	.param .u32 vidya_many_series_one_param_f32_param_3,
	.param .f32 vidya_many_series_one_param_f32_param_4,
	.param .u32 vidya_many_series_one_param_f32_param_5,
	.param .u32 vidya_many_series_one_param_f32_param_6,
	.param .u64 vidya_many_series_one_param_f32_param_7
)
{
	.reg .pred 	%p<43>;
	.reg .f32 	%f<41>;
	.reg .b32 	%r<106>;
	.reg .f64 	%fd<252>;
	.reg .b64 	%rd<85>;


	ld.param.u64 	%rd34, [vidya_many_series_one_param_f32_param_0];
	ld.param.u64 	%rd33, [vidya_many_series_one_param_f32_param_1];
	ld.param.u32 	%r49, [vidya_many_series_one_param_f32_param_2];
	ld.param.u32 	%r50, [vidya_many_series_one_param_f32_param_3];
	ld.param.f32 	%f12, [vidya_many_series_one_param_f32_param_4];
	ld.param.u32 	%r51, [vidya_many_series_one_param_f32_param_5];
	ld.param.u32 	%r52, [vidya_many_series_one_param_f32_param_6];
	ld.param.u64 	%rd35, [vidya_many_series_one_param_f32_param_7];
	cvta.to.global.u64 	%rd1, %rd35;
	cvta.to.global.u64 	%rd2, %rd34;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r51;
	setp.lt.s32 	%p2, %r52, 1;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB2_40;

	cvta.to.global.u64 	%rd36, %rd33;
	mul.wide.s32 	%rd37, %r1, 4;
	add.s64 	%rd38, %rd36, %rd37;
	ld.global.nc.u32 	%r53, [%rd38];
	max.s32 	%r2, %r53, 0;
	setp.ge.s32 	%p4, %r2, %r52;
	@%p4 bra 	$L__BB2_40;

	setp.lt.s32 	%p5, %r49, 2;
	setp.lt.s32 	%p6, %r50, %r49;
	or.pred  	%p7, %p5, %p6;
	setp.lt.s32 	%p8, %r50, 2;
	or.pred  	%p9, %p8, %p7;
	setp.lt.ftz.f32 	%p10, %f12, 0f00000000;
	or.pred  	%p11, %p10, %p9;
	setp.gt.ftz.f32 	%p12, %f12, 0f3F800000;
	or.pred  	%p13, %p12, %p11;
	sub.s32 	%r3, %r52, %r2;
	setp.lt.s32 	%p14, %r3, %r50;
	or.pred  	%p15, %p13, %p14;
	@%p15 bra 	$L__BB2_37;
	bra.uni 	$L__BB2_3;

$L__BB2_37:
	mov.u32 	%r105, %tid.x;
	setp.ge.s32 	%p41, %r105, %r52;
	@%p41 bra 	$L__BB2_40;

	mov.u32 	%r46, %ntid.x;

$L__BB2_39:
	mad.lo.s32 	%r88, %r105, %r51, %r1;
	mul.wide.s32 	%rd75, %r88, 4;
	add.s64 	%rd76, %rd1, %rd75;
	mov.u32 	%r89, 2147483647;
	st.global.u32 	[%rd76], %r89;
	add.s32 	%r105, %r105, %r46;
	setp.lt.s32 	%p42, %r105, %r52;
	@%p42 bra 	$L__BB2_39;
	bra.uni 	$L__BB2_40;

$L__BB2_3:
	add.s32 	%r104, %r2, %r50;
	add.s32 	%r5, %r104, -2;
	mov.u32 	%r6, %tid.x;
	setp.ge.s32 	%p16, %r6, %r5;
	@%p16 bra 	$L__BB2_6;

	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r90, %r6;

$L__BB2_5:
	mad.lo.s32 	%r54, %r90, %r51, %r1;
	mul.wide.s32 	%rd39, %r54, 4;
	add.s64 	%rd40, %rd1, %rd39;
	mov.u32 	%r55, 2147483647;
	st.global.u32 	[%rd40], %r55;
	add.s32 	%r90, %r90, %r7;
	setp.lt.s32 	%p17, %r90, %r5;
	@%p17 bra 	$L__BB2_5;

$L__BB2_6:
	setp.ne.s32 	%p18, %r6, 0;
	@%p18 bra 	$L__BB2_40;

	sub.s32 	%r10, %r104, %r49;
	setp.ge.s32 	%p19, %r2, %r10;
	mov.f64 	%fd238, 0d0000000000000000;
	mov.f64 	%fd236, %fd238;
	mov.f64 	%fd237, %fd238;
	@%p19 bra 	$L__BB2_14;

	sub.s32 	%r56, %r50, %r49;
	and.b32  	%r92, %r56, 3;
	setp.eq.s32 	%p20, %r92, 0;
	mov.f64 	%fd237, 0d0000000000000000;
	mov.u32 	%r93, %r2;
	mov.f64 	%fd236, %fd237;
	@%p20 bra 	$L__BB2_11;

	mad.lo.s32 	%r57, %r51, %r2, %r1;
	mul.wide.s32 	%rd41, %r57, 4;
	add.s64 	%rd77, %rd2, %rd41;
	mul.wide.s32 	%rd4, %r51, 4;
	mov.f64 	%fd237, 0d0000000000000000;
	mov.u32 	%r93, %r2;

$L__BB2_10:
	.pragma "nounroll";
	ld.global.nc.f32 	%f13, [%rd77];
	cvt.ftz.f64.f32 	%fd85, %f13;
	add.f64 	%fd236, %fd236, %fd85;
	fma.rn.f64 	%fd237, %fd85, %fd85, %fd237;
	add.s32 	%r93, %r93, 1;
	add.s64 	%rd77, %rd77, %rd4;
	add.s32 	%r92, %r92, -1;
	setp.ne.s32 	%p21, %r92, 0;
	@%p21 bra 	$L__BB2_10;

$L__BB2_11:
	not.b32 	%r58, %r49;
	add.s32 	%r59, %r58, %r50;
	setp.lt.u32 	%p22, %r59, 3;
	@%p22 bra 	$L__BB2_14;

	mad.lo.s32 	%r60, %r93, %r51, %r1;
	mul.wide.s32 	%rd42, %r60, 4;
	add.s64 	%rd78, %rd2, %rd42;
	mul.wide.s32 	%rd8, %r51, 4;

$L__BB2_13:
	ld.global.nc.f32 	%f14, [%rd78];
	cvt.ftz.f64.f32 	%fd86, %f14;
	add.f64 	%fd87, %fd236, %fd86;
	fma.rn.f64 	%fd88, %fd86, %fd86, %fd237;
	add.s64 	%rd43, %rd78, %rd8;
	ld.global.nc.f32 	%f15, [%rd43];
	cvt.ftz.f64.f32 	%fd89, %f15;
	add.f64 	%fd90, %fd87, %fd89;
	fma.rn.f64 	%fd91, %fd89, %fd89, %fd88;
	add.s64 	%rd44, %rd43, %rd8;
	ld.global.nc.f32 	%f16, [%rd44];
	cvt.ftz.f64.f32 	%fd92, %f16;
	add.f64 	%fd93, %fd90, %fd92;
	fma.rn.f64 	%fd94, %fd92, %fd92, %fd91;
	add.s64 	%rd45, %rd44, %rd8;
	add.s64 	%rd78, %rd45, %rd8;
	ld.global.nc.f32 	%f17, [%rd45];
	cvt.ftz.f64.f32 	%fd95, %f17;
	add.f64 	%fd236, %fd93, %fd95;
	fma.rn.f64 	%fd237, %fd95, %fd95, %fd94;
	add.s32 	%r93, %r93, 4;
	setp.lt.s32 	%p23, %r93, %r10;
	@%p23 bra 	$L__BB2_13;

$L__BB2_14:
	setp.lt.s32 	%p24, %r49, 1;
	mov.f64 	%fd239, %fd238;
	@%p24 bra 	$L__BB2_21;

	add.s32 	%r61, %r104, 1;
	sub.s32 	%r62, %r61, %r49;
	max.s32 	%r63, %r62, %r104;
	add.s32 	%r19, %r63, %r49;
	sub.s32 	%r64, %r19, %r2;
	sub.s32 	%r65, %r64, %r50;
	and.b32  	%r96, %r65, 3;
	setp.eq.s32 	%p25, %r96, 0;
	mov.f64 	%fd239, 0d0000000000000000;
	mov.u32 	%r97, %r10;
	mov.f64 	%fd238, %fd239;
	@%p25 bra 	$L__BB2_18;

	mad.lo.s32 	%r66, %r51, %r10, %r1;
	mul.wide.s32 	%rd46, %r66, 4;
	add.s64 	%rd79, %rd2, %rd46;
	mul.wide.s32 	%rd12, %r51, 4;
	mov.f64 	%fd239, 0d0000000000000000;
	mov.u32 	%r97, %r10;

$L__BB2_17:
	.pragma "nounroll";
	ld.global.nc.f32 	%f18, [%rd79];
	cvt.ftz.f64.f32 	%fd103, %f18;
	add.f64 	%fd236, %fd236, %fd103;
	fma.rn.f64 	%fd237, %fd103, %fd103, %fd237;
	add.f64 	%fd238, %fd238, %fd103;
	fma.rn.f64 	%fd239, %fd103, %fd103, %fd239;
	add.s32 	%r97, %r97, 1;
	add.s64 	%rd79, %rd79, %rd12;
	add.s32 	%r96, %r96, -1;
	setp.ne.s32 	%p26, %r96, 0;
	@%p26 bra 	$L__BB2_17;

$L__BB2_18:
	not.b32 	%r67, %r2;
	add.s32 	%r68, %r19, %r67;
	sub.s32 	%r69, %r68, %r50;
	setp.lt.u32 	%p27, %r69, 3;
	@%p27 bra 	$L__BB2_21;

	mad.lo.s32 	%r70, %r97, %r51, %r1;
	mul.wide.s32 	%rd47, %r70, 4;
	add.s64 	%rd80, %rd2, %rd47;
	mul.wide.s32 	%rd16, %r51, 4;

$L__BB2_20:
	ld.global.nc.f32 	%f19, [%rd80];
	cvt.ftz.f64.f32 	%fd104, %f19;
	add.f64 	%fd105, %fd236, %fd104;
	fma.rn.f64 	%fd106, %fd104, %fd104, %fd237;
	add.f64 	%fd107, %fd238, %fd104;
	fma.rn.f64 	%fd108, %fd104, %fd104, %fd239;
	add.s64 	%rd48, %rd80, %rd16;
	ld.global.nc.f32 	%f20, [%rd48];
	cvt.ftz.f64.f32 	%fd109, %f20;
	add.f64 	%fd110, %fd105, %fd109;
	fma.rn.f64 	%fd111, %fd109, %fd109, %fd106;
	add.f64 	%fd112, %fd107, %fd109;
	fma.rn.f64 	%fd113, %fd109, %fd109, %fd108;
	add.s64 	%rd49, %rd48, %rd16;
	ld.global.nc.f32 	%f21, [%rd49];
	cvt.ftz.f64.f32 	%fd114, %f21;
	add.f64 	%fd115, %fd110, %fd114;
	fma.rn.f64 	%fd116, %fd114, %fd114, %fd111;
	add.f64 	%fd117, %fd112, %fd114;
	fma.rn.f64 	%fd118, %fd114, %fd114, %fd113;
	add.s64 	%rd50, %rd49, %rd16;
	add.s64 	%rd80, %rd50, %rd16;
	ld.global.nc.f32 	%f22, [%rd50];
	cvt.ftz.f64.f32 	%fd119, %f22;
	add.f64 	%fd236, %fd115, %fd119;
	fma.rn.f64 	%fd237, %fd119, %fd119, %fd116;
	add.f64 	%fd238, %fd117, %fd119;
	fma.rn.f64 	%fd239, %fd119, %fd119, %fd118;
	add.s32 	%r97, %r97, 4;
	setp.lt.s32 	%p28, %r97, %r104;
	@%p28 bra 	$L__BB2_20;

$L__BB2_21:
	mad.lo.s32 	%r71, %r5, %r51, %r1;
	mul.wide.s32 	%rd51, %r71, 4;
	add.s64 	%rd52, %rd2, %rd51;
	ld.global.nc.f32 	%f39, [%rd52];
	add.s64 	%rd53, %rd1, %rd51;
	st.global.f32 	[%rd53], %f39;
	setp.gt.s32 	%p29, %r104, %r52;
	@%p29 bra 	$L__BB2_25;

	cvt.rn.f64.s32 	%fd121, %r50;
	rcp.rn.f64 	%fd122, %fd121;
	mul.f64 	%fd123, %fd122, %fd236;
	mul.f64 	%fd124, %fd122, %fd237;
	mul.f64 	%fd125, %fd123, %fd123;
	sub.f64 	%fd126, %fd124, %fd125;
	mov.f64 	%fd240, 0d0000000000000000;
	max.f64 	%fd127, %fd240, %fd126;
	sqrt.rn.f64 	%fd43, %fd127;
	setp.eq.f64 	%p30, %fd43, 0d0000000000000000;
	@%p30 bra 	$L__BB2_24;

	cvt.rn.f64.s32 	%fd128, %r49;
	rcp.rn.f64 	%fd129, %fd128;
	mul.f64 	%fd130, %fd129, %fd238;
	mul.f64 	%fd131, %fd130, %fd130;
	mul.f64 	%fd132, %fd129, %fd239;
	sub.f64 	%fd133, %fd132, %fd131;
	mov.f64 	%fd134, 0d0000000000000000;
	max.f64 	%fd135, %fd134, %fd133;
	sqrt.rn.f64 	%fd136, %fd135;
	div.rn.f64 	%fd240, %fd136, %fd43;

$L__BB2_24:
	cvt.ftz.f64.f32 	%fd137, %f12;
	mul.f64 	%fd138, %fd240, %fd137;
	add.s32 	%r72, %r104, -1;
	mad.lo.s32 	%r73, %r72, %r51, %r1;
	mul.wide.s32 	%rd54, %r73, 4;
	add.s64 	%rd55, %rd2, %rd54;
	ld.global.nc.f32 	%f23, [%rd55];
	sub.ftz.f32 	%f24, %f23, %f39;
	cvt.rn.ftz.f32.f64 	%f25, %fd138;
	fma.rn.ftz.f32 	%f39, %f24, %f25, %f39;
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f39;

$L__BB2_25:
	setp.ge.s32 	%p31, %r104, %r52;
	@%p31 bra 	$L__BB2_40;

	cvt.rn.f64.s32 	%fd139, %r49;
	rcp.rn.f64 	%fd46, %fd139;
	cvt.rn.f64.s32 	%fd140, %r50;
	rcp.rn.f64 	%fd47, %fd140;
	cvt.ftz.f64.f32 	%fd48, %f12;
	sub.s32 	%r74, %r3, %r50;
	and.b32  	%r75, %r74, 1;
	setp.eq.b32 	%p32, %r75, 1;
	mov.pred 	%p33, 0;
	xor.pred  	%p34, %p32, %p33;
	not.pred 	%p35, %p34;
	@%p35 bra 	$L__BB2_30;

	mad.lo.s32 	%r76, %r104, %r51, %r1;
	cvt.s64.s32 	%rd19, %r76;
	mul.wide.s32 	%rd57, %r76, 4;
	add.s64 	%rd58, %rd2, %rd57;
	ld.global.nc.f32 	%f4, [%rd58];
	cvt.ftz.f64.f32 	%fd142, %f4;
	add.f64 	%fd143, %fd236, %fd142;
	fma.rn.f64 	%fd144, %fd142, %fd142, %fd237;
	add.f64 	%fd145, %fd238, %fd142;
	fma.rn.f64 	%fd146, %fd142, %fd142, %fd239;
	mad.lo.s32 	%r77, %r2, %r51, %r1;
	mul.wide.s32 	%rd59, %r77, 4;
	add.s64 	%rd60, %rd2, %rd59;
	ld.global.nc.f32 	%f26, [%rd60];
	cvt.ftz.f64.f32 	%fd147, %f26;
	mad.lo.s32 	%r78, %r10, %r51, %r1;
	mul.wide.s32 	%rd61, %r78, 4;
	add.s64 	%rd62, %rd2, %rd61;
	ld.global.nc.f32 	%f27, [%rd62];
	cvt.ftz.f64.f32 	%fd148, %f27;
	sub.f64 	%fd236, %fd143, %fd147;
	mul.f64 	%fd149, %fd147, %fd147;
	sub.f64 	%fd237, %fd144, %fd149;
	sub.f64 	%fd238, %fd145, %fd148;
	mul.f64 	%fd150, %fd148, %fd148;
	sub.f64 	%fd239, %fd146, %fd150;
	mul.f64 	%fd151, %fd47, %fd236;
	mul.f64 	%fd152, %fd47, %fd237;
	mul.f64 	%fd153, %fd151, %fd151;
	sub.f64 	%fd154, %fd152, %fd153;
	mov.f64 	%fd241, 0d0000000000000000;
	max.f64 	%fd155, %fd241, %fd154;
	sqrt.rn.f64 	%fd53, %fd155;
	setp.eq.f64 	%p36, %fd53, 0d0000000000000000;
	@%p36 bra 	$L__BB2_29;

	mul.f64 	%fd156, %fd46, %fd238;
	mul.f64 	%fd157, %fd156, %fd156;
	mul.f64 	%fd158, %fd46, %fd239;
	sub.f64 	%fd159, %fd158, %fd157;
	mov.f64 	%fd160, 0d0000000000000000;
	max.f64 	%fd161, %fd160, %fd159;
	sqrt.rn.f64 	%fd162, %fd161;
	div.rn.f64 	%fd241, %fd162, %fd53;

$L__BB2_29:
	mul.f64 	%fd163, %fd241, %fd48;
	cvt.rn.ftz.f32.f64 	%f28, %fd163;
	sub.ftz.f32 	%f29, %f4, %f39;
	fma.rn.ftz.f32 	%f39, %f29, %f28, %f39;
	shl.b64 	%rd63, %rd19, 2;
	add.s64 	%rd64, %rd1, %rd63;
	st.global.f32 	[%rd64], %f39;
	add.s32 	%r104, %r104, 1;

$L__BB2_30:
	not.b32 	%r79, %r2;
	add.s32 	%r80, %r79, %r52;
	setp.eq.s32 	%p37, %r80, %r50;
	@%p37 bra 	$L__BB2_40;

	sub.s32 	%r81, %r104, %r50;
	mad.lo.s32 	%r103, %r51, %r81, %r1;
	sub.s32 	%r82, %r104, %r49;
	mad.lo.s32 	%r102, %r51, %r82, %r1;
	add.s32 	%r83, %r104, 1;
	sub.s32 	%r84, %r83, %r49;
	mad.lo.s32 	%r101, %r51, %r84, %r1;
	sub.s32 	%r85, %r83, %r50;
	mad.lo.s32 	%r100, %r51, %r85, %r1;
	mad.lo.s32 	%r86, %r51, %r83, %r1;
	mul.wide.s32 	%rd65, %r86, 4;
	add.s64 	%rd84, %rd1, %rd65;
	shl.b32 	%r34, %r51, 1;
	mul.wide.s32 	%rd21, %r34, 4;
	add.s64 	%rd83, %rd2, %rd65;
	mad.lo.s32 	%r87, %r104, %r51, %r1;
	mul.wide.s32 	%rd66, %r87, 4;
	add.s64 	%rd82, %rd1, %rd66;
	add.s64 	%rd81, %rd2, %rd66;

$L__BB2_32:
	ld.global.nc.f32 	%f8, [%rd81];
	cvt.ftz.f64.f32 	%fd165, %f8;
	add.f64 	%fd166, %fd236, %fd165;
	fma.rn.f64 	%fd167, %fd165, %fd165, %fd237;
	add.f64 	%fd168, %fd238, %fd165;
	fma.rn.f64 	%fd169, %fd165, %fd165, %fd239;
	mul.wide.s32 	%rd67, %r103, 4;
	add.s64 	%rd68, %rd2, %rd67;
	ld.global.nc.f32 	%f30, [%rd68];
	cvt.ftz.f64.f32 	%fd170, %f30;
	mul.wide.s32 	%rd69, %r102, 4;
	add.s64 	%rd70, %rd2, %rd69;
	ld.global.nc.f32 	%f31, [%rd70];
	cvt.ftz.f64.f32 	%fd171, %f31;
	sub.f64 	%fd64, %fd166, %fd170;
	mul.f64 	%fd172, %fd170, %fd170;
	sub.f64 	%fd65, %fd167, %fd172;
	sub.f64 	%fd66, %fd168, %fd171;
	mul.f64 	%fd173, %fd171, %fd171;
	sub.f64 	%fd67, %fd169, %fd173;
	mul.f64 	%fd174, %fd47, %fd64;
	mul.f64 	%fd175, %fd47, %fd65;
	mul.f64 	%fd176, %fd174, %fd174;
	sub.f64 	%fd177, %fd175, %fd176;
	mov.f64 	%fd251, 0d0000000000000000;
	max.f64 	%fd178, %fd251, %fd177;
	sqrt.rn.f64 	%fd68, %fd178;
	setp.eq.f64 	%p38, %fd68, 0d0000000000000000;
	mov.f64 	%fd250, %fd251;
	@%p38 bra 	$L__BB2_34;

	mul.f64 	%fd179, %fd46, %fd66;
	mul.f64 	%fd180, %fd179, %fd179;
	mul.f64 	%fd181, %fd46, %fd67;
	sub.f64 	%fd182, %fd181, %fd180;
	mov.f64 	%fd183, 0d0000000000000000;
	max.f64 	%fd184, %fd183, %fd182;
	sqrt.rn.f64 	%fd185, %fd184;
	div.rn.f64 	%fd250, %fd185, %fd68;

$L__BB2_34:
	mul.f64 	%fd187, %fd250, %fd48;
	cvt.rn.ftz.f32.f64 	%f32, %fd187;
	sub.ftz.f32 	%f33, %f8, %f39;
	fma.rn.ftz.f32 	%f9, %f33, %f32, %f39;
	st.global.f32 	[%rd82], %f9;
	ld.global.nc.f32 	%f10, [%rd83];
	cvt.ftz.f64.f32 	%fd188, %f10;
	add.f64 	%fd189, %fd64, %fd188;
	fma.rn.f64 	%fd190, %fd188, %fd188, %fd65;
	add.f64 	%fd191, %fd66, %fd188;
	fma.rn.f64 	%fd192, %fd188, %fd188, %fd67;
	mul.wide.s32 	%rd71, %r100, 4;
	add.s64 	%rd72, %rd2, %rd71;
	ld.global.nc.f32 	%f34, [%rd72];
	cvt.ftz.f64.f32 	%fd193, %f34;
	mul.wide.s32 	%rd73, %r101, 4;
	add.s64 	%rd74, %rd2, %rd73;
	ld.global.nc.f32 	%f35, [%rd74];
	cvt.ftz.f64.f32 	%fd194, %f35;
	sub.f64 	%fd236, %fd189, %fd193;
	mul.f64 	%fd195, %fd193, %fd193;
	sub.f64 	%fd237, %fd190, %fd195;
	sub.f64 	%fd238, %fd191, %fd194;
	mul.f64 	%fd196, %fd194, %fd194;
	sub.f64 	%fd239, %fd192, %fd196;
	mul.f64 	%fd197, %fd47, %fd236;
	mul.f64 	%fd198, %fd47, %fd237;
	mul.f64 	%fd199, %fd197, %fd197;
	sub.f64 	%fd200, %fd198, %fd199;
	max.f64 	%fd201, %fd251, %fd200;
	sqrt.rn.f64 	%fd75, %fd201;
	setp.eq.f64 	%p39, %fd75, 0d0000000000000000;
	@%p39 bra 	$L__BB2_36;

	mul.f64 	%fd202, %fd46, %fd238;
	mul.f64 	%fd203, %fd202, %fd202;
	mul.f64 	%fd204, %fd46, %fd239;
	sub.f64 	%fd205, %fd204, %fd203;
	mov.f64 	%fd206, 0d0000000000000000;
	max.f64 	%fd207, %fd206, %fd205;
	sqrt.rn.f64 	%fd208, %fd207;
	div.rn.f64 	%fd251, %fd208, %fd75;

$L__BB2_36:
	mul.f64 	%fd209, %fd251, %fd48;
	cvt.rn.ftz.f32.f64 	%f36, %fd209;
	sub.ftz.f32 	%f37, %f10, %f9;
	fma.rn.ftz.f32 	%f39, %f37, %f36, %f9;
	st.global.f32 	[%rd84], %f39;
	add.s32 	%r103, %r103, %r34;
	add.s32 	%r102, %r102, %r34;
	add.s32 	%r101, %r101, %r34;
	add.s32 	%r100, %r100, %r34;
	add.s64 	%rd84, %rd84, %rd21;
	add.s64 	%rd83, %rd83, %rd21;
	add.s64 	%rd82, %rd82, %rd21;
	add.s64 	%rd81, %rd81, %rd21;
	add.s32 	%r104, %r104, 2;
	setp.lt.s32 	%p40, %r104, %r52;
	@%p40 bra 	$L__BB2_32;

$L__BB2_40:
	ret;

}

