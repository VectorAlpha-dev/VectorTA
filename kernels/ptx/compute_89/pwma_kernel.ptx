







.version 9.0
.target sm_89
.address_size 64

	

.const .align 4 .b8 pwma_const_w[16384];
.extern .shared .align 16 .b8 shraw[];
.extern .shared .align 16 .b8 shared_weights[];
.extern .shared .align 16 .b8 shraw$1[];

.visible .entry pwma_batch_f32(
	.param .u64 pwma_batch_f32_param_0,
	.param .u64 pwma_batch_f32_param_1,
	.param .u64 pwma_batch_f32_param_2,
	.param .u64 pwma_batch_f32_param_3,
	.param .u32 pwma_batch_f32_param_4,
	.param .u32 pwma_batch_f32_param_5,
	.param .u32 pwma_batch_f32_param_6,
	.param .u64 pwma_batch_f32_param_7
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<71>;
	.reg .b32 	%r<75>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd14, [pwma_batch_f32_param_0];
	ld.param.u64 	%rd11, [pwma_batch_f32_param_1];
	ld.param.u64 	%rd12, [pwma_batch_f32_param_2];
	ld.param.u64 	%rd13, [pwma_batch_f32_param_3];
	ld.param.u32 	%r36, [pwma_batch_f32_param_4];
	ld.param.u32 	%r38, [pwma_batch_f32_param_5];
	ld.param.u32 	%r37, [pwma_batch_f32_param_6];
	ld.param.u64 	%rd15, [pwma_batch_f32_param_7];
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r38;
	@%p1 bra 	$L__BB0_28;

	cvta.to.global.u64 	%rd16, %rd12;
	cvt.s64.s32 	%rd3, %r1;
	mul.wide.s32 	%rd17, %r1, 4;
	add.s64 	%rd18, %rd16, %rd17;
	ld.global.nc.u32 	%r2, [%rd18];
	setp.lt.s32 	%p2, %r2, 1;
	setp.gt.s32 	%p3, %r2, %r37;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_28;

	mov.u32 	%r3, %tid.x;
	setp.lt.s32 	%p5, %r3, %r2;
	@%p5 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_5;

$L__BB0_3:
	mul.lo.s32 	%r4, %r1, %r37;
	mov.u32 	%r5, %ntid.x;
	cvta.to.global.u64 	%rd4, %rd11;
	mov.u32 	%r65, %r3;

$L__BB0_4:
	add.s32 	%r39, %r65, %r4;
	mul.wide.s32 	%rd19, %r39, 4;
	add.s64 	%rd20, %rd4, %rd19;
	ld.global.nc.f32 	%f13, [%rd20];
	shl.b32 	%r40, %r65, 2;
	mov.u32 	%r41, shared_weights;
	add.s32 	%r42, %r41, %r40;
	st.shared.f32 	[%r42], %f13;
	add.s32 	%r65, %r65, %r5;
	setp.lt.s32 	%p6, %r65, %r2;
	@%p6 bra 	$L__BB0_4;

$L__BB0_5:
	mov.u32 	%r43, %ntid.x;
	bar.sync 	0;
	cvta.to.global.u64 	%rd21, %rd13;
	shl.b64 	%rd22, %rd3, 2;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.nc.u32 	%r8, [%rd23];
	mul.lo.s32 	%r9, %r1, %r36;
	mov.u32 	%r44, %ctaid.x;
	mad.lo.s32 	%r68, %r44, %r43, %r3;
	mov.u32 	%r45, %nctaid.x;
	mul.lo.s32 	%r11, %r45, %r43;
	setp.ge.s32 	%p7, %r68, %r36;
	@%p7 bra 	$L__BB0_28;

	setp.gt.s32 	%p8, %r2, 0;
	@%p8 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_7;

$L__BB0_12:
	add.s32 	%r21, %r2, -1;
	and.b32  	%r22, %r2, 7;
	sub.s32 	%r23, %r2, %r22;
	mov.u32 	%r56, 1;
	sub.s32 	%r24, %r56, %r2;

$L__BB0_13:
	add.s32 	%r57, %r68, %r9;
	mul.wide.s32 	%rd31, %r57, 4;
	add.s64 	%rd6, %rd2, %rd31;
	setp.lt.s32 	%p18, %r68, %r8;
	@%p18 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_14;

$L__BB0_26:
	mov.u32 	%r64, 2147483647;
	st.global.u32 	[%rd6], %r64;
	bra.uni 	$L__BB0_27;

$L__BB0_14:
	setp.lt.u32 	%p19, %r21, 7;
	add.s32 	%r26, %r24, %r68;
	mov.f32 	%f70, 0f00000000;
	mov.u32 	%r74, 0;
	@%p19 bra 	$L__BB0_17;

	mul.wide.s32 	%rd7, %r26, 4;
	mov.f32 	%f70, 0f00000000;
	mov.u32 	%r74, 0;
	mov.u32 	%r71, shared_weights;
	mov.u64 	%rd34, %rd1;
	mov.u32 	%r73, %r23;

$L__BB0_16:
	.pragma "nounroll";
	add.s64 	%rd32, %rd34, %rd7;
	ld.shared.v4.f32 	{%f22, %f23, %f24, %f25}, [%r71];
	ld.global.nc.f32 	%f30, [%rd32];
	fma.rn.ftz.f32 	%f31, %f30, %f22, %f70;
	ld.global.nc.f32 	%f32, [%rd32+4];
	fma.rn.ftz.f32 	%f33, %f32, %f23, %f31;
	ld.global.nc.f32 	%f34, [%rd32+8];
	fma.rn.ftz.f32 	%f35, %f34, %f24, %f33;
	ld.global.nc.f32 	%f36, [%rd32+12];
	fma.rn.ftz.f32 	%f37, %f36, %f25, %f35;
	ld.shared.v4.f32 	{%f38, %f39, %f40, %f41}, [%r71+16];
	ld.global.nc.f32 	%f46, [%rd32+16];
	fma.rn.ftz.f32 	%f47, %f46, %f38, %f37;
	ld.global.nc.f32 	%f48, [%rd32+20];
	fma.rn.ftz.f32 	%f49, %f48, %f39, %f47;
	ld.global.nc.f32 	%f50, [%rd32+24];
	fma.rn.ftz.f32 	%f51, %f50, %f40, %f49;
	ld.global.nc.f32 	%f52, [%rd32+28];
	fma.rn.ftz.f32 	%f70, %f52, %f41, %f51;
	add.s32 	%r74, %r74, 8;
	add.s32 	%r71, %r71, 32;
	add.s64 	%rd34, %rd34, 32;
	add.s32 	%r73, %r73, -8;
	setp.ne.s32 	%p20, %r73, 0;
	@%p20 bra 	$L__BB0_16;

$L__BB0_17:
	setp.eq.s32 	%p21, %r22, 0;
	@%p21 bra 	$L__BB0_25;

	setp.eq.s32 	%p22, %r22, 1;
	add.s32 	%r61, %r26, %r74;
	mul.wide.s32 	%rd33, %r61, 4;
	add.s64 	%rd10, %rd1, %rd33;
	shl.b32 	%r62, %r74, 2;
	mov.u32 	%r63, shared_weights;
	add.s32 	%r34, %r63, %r62;
	ld.shared.f32 	%f53, [%r34];
	ld.global.nc.f32 	%f54, [%rd10];
	fma.rn.ftz.f32 	%f70, %f54, %f53, %f70;
	@%p22 bra 	$L__BB0_25;

	setp.eq.s32 	%p23, %r22, 2;
	ld.shared.f32 	%f55, [%r34+4];
	ld.global.nc.f32 	%f56, [%rd10+4];
	fma.rn.ftz.f32 	%f70, %f56, %f55, %f70;
	@%p23 bra 	$L__BB0_25;

	setp.eq.s32 	%p24, %r22, 3;
	ld.shared.f32 	%f57, [%r34+8];
	ld.global.nc.f32 	%f58, [%rd10+8];
	fma.rn.ftz.f32 	%f70, %f58, %f57, %f70;
	@%p24 bra 	$L__BB0_25;

	setp.eq.s32 	%p25, %r22, 4;
	ld.shared.f32 	%f59, [%r34+12];
	ld.global.nc.f32 	%f60, [%rd10+12];
	fma.rn.ftz.f32 	%f70, %f60, %f59, %f70;
	@%p25 bra 	$L__BB0_25;

	setp.eq.s32 	%p26, %r22, 5;
	ld.shared.f32 	%f61, [%r34+16];
	ld.global.nc.f32 	%f62, [%rd10+16];
	fma.rn.ftz.f32 	%f70, %f62, %f61, %f70;
	@%p26 bra 	$L__BB0_25;

	setp.eq.s32 	%p27, %r22, 6;
	ld.shared.f32 	%f63, [%r34+20];
	ld.global.nc.f32 	%f64, [%rd10+20];
	fma.rn.ftz.f32 	%f70, %f64, %f63, %f70;
	@%p27 bra 	$L__BB0_25;

	ld.shared.f32 	%f65, [%r34+24];
	ld.global.nc.f32 	%f66, [%rd10+24];
	fma.rn.ftz.f32 	%f70, %f66, %f65, %f70;

$L__BB0_25:
	st.global.f32 	[%rd6], %f70;

$L__BB0_27:
	add.s32 	%r68, %r68, %r11;
	setp.lt.s32 	%p28, %r68, %r36;
	@%p28 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_28;

$L__BB0_7:
	add.s32 	%r46, %r11, %r36;
	add.s32 	%r47, %r68, %r11;
	not.b32 	%r48, %r47;
	add.s32 	%r49, %r46, %r48;
	div.u32 	%r12, %r49, %r11;
	add.s32 	%r50, %r12, 1;
	and.b32  	%r67, %r50, 3;
	setp.eq.s32 	%p9, %r67, 0;
	@%p9 bra 	$L__BB0_9;

$L__BB0_8:
	.pragma "nounroll";
	add.s32 	%r51, %r68, %r9;
	mul.wide.s32 	%rd24, %r51, 4;
	add.s64 	%rd25, %rd2, %rd24;
	setp.lt.s32 	%p10, %r68, %r8;
	selp.f32 	%f14, 0f7FFFFFFF, 0f00000000, %p10;
	st.global.f32 	[%rd25], %f14;
	add.s32 	%r68, %r68, %r11;
	add.s32 	%r67, %r67, -1;
	setp.ne.s32 	%p11, %r67, 0;
	@%p11 bra 	$L__BB0_8;

$L__BB0_9:
	setp.lt.u32 	%p12, %r12, 3;
	@%p12 bra 	$L__BB0_28;

	mul.wide.s32 	%rd5, %r11, 4;

$L__BB0_11:
	add.s32 	%r52, %r68, %r9;
	mul.wide.s32 	%rd26, %r52, 4;
	add.s64 	%rd27, %rd2, %rd26;
	setp.lt.s32 	%p13, %r68, %r8;
	selp.f32 	%f15, 0f7FFFFFFF, 0f00000000, %p13;
	st.global.f32 	[%rd27], %f15;
	add.s32 	%r53, %r68, %r11;
	setp.lt.s32 	%p14, %r53, %r8;
	selp.f32 	%f16, 0f7FFFFFFF, 0f00000000, %p14;
	add.s64 	%rd28, %rd27, %rd5;
	st.global.f32 	[%rd28], %f16;
	add.s32 	%r54, %r53, %r11;
	setp.lt.s32 	%p15, %r54, %r8;
	selp.f32 	%f17, 0f7FFFFFFF, 0f00000000, %p15;
	add.s64 	%rd29, %rd28, %rd5;
	st.global.f32 	[%rd29], %f17;
	add.s32 	%r55, %r54, %r11;
	setp.lt.s32 	%p16, %r55, %r8;
	selp.f32 	%f18, 0f7FFFFFFF, 0f00000000, %p16;
	add.s64 	%rd30, %rd29, %rd5;
	st.global.f32 	[%rd30], %f18;
	add.s32 	%r68, %r55, %r11;
	setp.lt.s32 	%p17, %r68, %r36;
	@%p17 bra 	$L__BB0_11;

$L__BB0_28:
	ret;

}
	
.visible .entry pwma_multi_series_one_param_f32(
	.param .u64 pwma_multi_series_one_param_f32_param_0,
	.param .u64 pwma_multi_series_one_param_f32_param_1,
	.param .u32 pwma_multi_series_one_param_f32_param_2,
	.param .f32 pwma_multi_series_one_param_f32_param_3,
	.param .u32 pwma_multi_series_one_param_f32_param_4,
	.param .u32 pwma_multi_series_one_param_f32_param_5,
	.param .u64 pwma_multi_series_one_param_f32_param_6,
	.param .u64 pwma_multi_series_one_param_f32_param_7
)
{
	.reg .pred 	%p<26>;
	.reg .f32 	%f<71>;
	.reg .b32 	%r<78>;
	.reg .b64 	%rd<41>;


	ld.param.u64 	%rd15, [pwma_multi_series_one_param_f32_param_0];
	ld.param.u64 	%rd13, [pwma_multi_series_one_param_f32_param_1];
	ld.param.u32 	%r37, [pwma_multi_series_one_param_f32_param_2];
	ld.param.u32 	%r38, [pwma_multi_series_one_param_f32_param_4];
	ld.param.u32 	%r39, [pwma_multi_series_one_param_f32_param_5];
	ld.param.u64 	%rd14, [pwma_multi_series_one_param_f32_param_6];
	ld.param.u64 	%rd16, [pwma_multi_series_one_param_f32_param_7];
	cvta.to.global.u64 	%rd1, %rd15;
	cvta.to.global.u64 	%rd2, %rd16;
	mov.u32 	%r1, %tid.x;
	setp.ge.s32 	%p1, %r1, %r37;
	@%p1 bra 	$L__BB1_3;

	mov.u32 	%r2, %ntid.x;
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r68, %r1;

$L__BB1_2:
	mul.wide.s32 	%rd17, %r68, 4;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.nc.f32 	%f13, [%rd18];
	shl.b32 	%r40, %r68, 2;
	mov.u32 	%r41, shared_weights;
	add.s32 	%r42, %r41, %r40;
	st.shared.f32 	[%r42], %f13;
	add.s32 	%r68, %r68, %r2;
	setp.lt.s32 	%p2, %r68, %r37;
	@%p2 bra 	$L__BB1_2;

$L__BB1_3:
	bar.sync 	0;
	mov.u32 	%r5, %ctaid.y;
	setp.ge.s32 	%p3, %r5, %r38;
	@%p3 bra 	$L__BB1_27;

	cvta.to.global.u64 	%rd19, %rd14;
	mul.wide.s32 	%rd20, %r5, 4;
	add.s64 	%rd21, %rd19, %rd20;
	add.s32 	%r6, %r37, -1;
	ld.global.nc.u32 	%r43, [%rd21];
	add.s32 	%r7, %r6, %r43;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r44, %ctaid.x;
	mad.lo.s32 	%r71, %r44, %r8, %r1;
	mov.u32 	%r10, %nctaid.x;
	mul.lo.s32 	%r11, %r10, %r8;
	setp.ge.s32 	%p4, %r71, %r39;
	@%p4 bra 	$L__BB1_27;

	setp.gt.s32 	%p5, %r37, 0;
	@%p5 bra 	$L__BB1_11;
	bra.uni 	$L__BB1_6;

$L__BB1_11:
	and.b32  	%r21, %r37, 7;
	shl.b32 	%r22, %r38, 3;
	sub.s32 	%r23, %r21, %r37;
	mul.wide.s32 	%rd5, %r38, 4;
	mov.u32 	%r57, 1;
	sub.s32 	%r24, %r57, %r37;

$L__BB1_12:
	mad.lo.s32 	%r58, %r71, %r38, %r5;
	mul.wide.s32 	%rd29, %r58, 4;
	add.s64 	%rd6, %rd2, %rd29;
	setp.lt.s32 	%p15, %r71, %r7;
	@%p15 bra 	$L__BB1_25;
	bra.uni 	$L__BB1_13;

$L__BB1_25:
	mov.u32 	%r67, 2147483647;
	st.global.u32 	[%rd6], %r67;
	bra.uni 	$L__BB1_26;

$L__BB1_13:
	setp.lt.u32 	%p16, %r6, 7;
	add.s32 	%r26, %r24, %r71;
	mov.f32 	%f70, 0f00000000;
	mov.u32 	%r77, 0;
	@%p16 bra 	$L__BB1_16;

	mad.lo.s32 	%r74, %r38, %r26, %r5;
	mov.f32 	%f70, 0f00000000;
	mov.u32 	%r77, 0;
	mov.u32 	%r75, shared_weights;

$L__BB1_15:
	.pragma "nounroll";
	mul.wide.s32 	%rd30, %r74, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.shared.v4.f32 	{%f22, %f23, %f24, %f25}, [%r75];
	ld.global.nc.f32 	%f30, [%rd31];
	fma.rn.ftz.f32 	%f31, %f30, %f22, %f70;
	add.s64 	%rd32, %rd31, %rd5;
	ld.global.nc.f32 	%f32, [%rd32];
	fma.rn.ftz.f32 	%f33, %f32, %f23, %f31;
	add.s64 	%rd33, %rd32, %rd5;
	ld.global.nc.f32 	%f34, [%rd33];
	fma.rn.ftz.f32 	%f35, %f34, %f24, %f33;
	add.s64 	%rd34, %rd33, %rd5;
	ld.global.nc.f32 	%f36, [%rd34];
	fma.rn.ftz.f32 	%f37, %f36, %f25, %f35;
	add.s64 	%rd35, %rd34, %rd5;
	ld.shared.v4.f32 	{%f38, %f39, %f40, %f41}, [%r75+16];
	ld.global.nc.f32 	%f46, [%rd35];
	fma.rn.ftz.f32 	%f47, %f46, %f38, %f37;
	add.s64 	%rd36, %rd35, %rd5;
	ld.global.nc.f32 	%f48, [%rd36];
	fma.rn.ftz.f32 	%f49, %f48, %f39, %f47;
	add.s64 	%rd37, %rd36, %rd5;
	ld.global.nc.f32 	%f50, [%rd37];
	fma.rn.ftz.f32 	%f51, %f50, %f40, %f49;
	add.s64 	%rd38, %rd37, %rd5;
	ld.global.nc.f32 	%f52, [%rd38];
	fma.rn.ftz.f32 	%f70, %f52, %f41, %f51;
	add.s32 	%r75, %r75, 32;
	add.s32 	%r74, %r74, %r22;
	add.s32 	%r77, %r77, 8;
	add.s32 	%r62, %r23, %r77;
	setp.ne.s32 	%p17, %r62, 0;
	@%p17 bra 	$L__BB1_15;

$L__BB1_16:
	setp.eq.s32 	%p18, %r21, 0;
	@%p18 bra 	$L__BB1_24;

	setp.eq.s32 	%p19, %r21, 1;
	add.s32 	%r63, %r26, %r77;
	mad.lo.s32 	%r64, %r63, %r38, %r5;
	mul.wide.s32 	%rd39, %r64, 4;
	add.s64 	%rd7, %rd1, %rd39;
	shl.b32 	%r65, %r77, 2;
	mov.u32 	%r66, shared_weights;
	add.s32 	%r35, %r66, %r65;
	ld.shared.f32 	%f53, [%r35];
	ld.global.nc.f32 	%f54, [%rd7];
	fma.rn.ftz.f32 	%f70, %f54, %f53, %f70;
	@%p19 bra 	$L__BB1_24;

	setp.eq.s32 	%p20, %r21, 2;
	add.s64 	%rd8, %rd7, %rd5;
	ld.shared.f32 	%f55, [%r35+4];
	ld.global.nc.f32 	%f56, [%rd8];
	fma.rn.ftz.f32 	%f70, %f56, %f55, %f70;
	@%p20 bra 	$L__BB1_24;

	setp.eq.s32 	%p21, %r21, 3;
	add.s64 	%rd9, %rd8, %rd5;
	ld.shared.f32 	%f57, [%r35+8];
	ld.global.nc.f32 	%f58, [%rd9];
	fma.rn.ftz.f32 	%f70, %f58, %f57, %f70;
	@%p21 bra 	$L__BB1_24;

	setp.eq.s32 	%p22, %r21, 4;
	add.s64 	%rd10, %rd9, %rd5;
	ld.shared.f32 	%f59, [%r35+12];
	ld.global.nc.f32 	%f60, [%rd10];
	fma.rn.ftz.f32 	%f70, %f60, %f59, %f70;
	@%p22 bra 	$L__BB1_24;

	setp.eq.s32 	%p23, %r21, 5;
	add.s64 	%rd11, %rd10, %rd5;
	ld.shared.f32 	%f61, [%r35+16];
	ld.global.nc.f32 	%f62, [%rd11];
	fma.rn.ftz.f32 	%f70, %f62, %f61, %f70;
	@%p23 bra 	$L__BB1_24;

	setp.eq.s32 	%p24, %r21, 6;
	add.s64 	%rd12, %rd11, %rd5;
	ld.shared.f32 	%f63, [%r35+20];
	ld.global.nc.f32 	%f64, [%rd12];
	fma.rn.ftz.f32 	%f70, %f64, %f63, %f70;
	@%p24 bra 	$L__BB1_24;

	add.s64 	%rd40, %rd12, %rd5;
	ld.shared.f32 	%f65, [%r35+24];
	ld.global.nc.f32 	%f66, [%rd40];
	fma.rn.ftz.f32 	%f70, %f66, %f65, %f70;

$L__BB1_24:
	st.global.f32 	[%rd6], %f70;

$L__BB1_26:
	add.s32 	%r71, %r71, %r11;
	setp.lt.s32 	%p25, %r71, %r39;
	@%p25 bra 	$L__BB1_12;
	bra.uni 	$L__BB1_27;

$L__BB1_6:
	add.s32 	%r45, %r11, %r39;
	add.s32 	%r46, %r71, %r11;
	not.b32 	%r47, %r46;
	add.s32 	%r48, %r45, %r47;
	div.u32 	%r12, %r48, %r11;
	add.s32 	%r49, %r12, 1;
	and.b32  	%r70, %r49, 3;
	setp.eq.s32 	%p6, %r70, 0;
	@%p6 bra 	$L__BB1_8;

$L__BB1_7:
	.pragma "nounroll";
	mad.lo.s32 	%r50, %r71, %r38, %r5;
	mul.wide.s32 	%rd22, %r50, 4;
	add.s64 	%rd23, %rd2, %rd22;
	setp.lt.s32 	%p7, %r71, %r7;
	selp.f32 	%f14, 0f7FFFFFFF, 0f00000000, %p7;
	st.global.f32 	[%rd23], %f14;
	add.s32 	%r71, %r71, %r11;
	add.s32 	%r70, %r70, -1;
	setp.ne.s32 	%p8, %r70, 0;
	@%p8 bra 	$L__BB1_7;

$L__BB1_8:
	setp.lt.u32 	%p9, %r12, 3;
	@%p9 bra 	$L__BB1_27;

	mul.lo.s32 	%r51, %r8, %r10;
	mul.lo.s32 	%r52, %r51, %r38;
	mul.wide.s32 	%rd4, %r52, 4;

$L__BB1_10:
	mad.lo.s32 	%r53, %r71, %r38, %r5;
	mul.wide.s32 	%rd24, %r53, 4;
	add.s64 	%rd25, %rd2, %rd24;
	setp.lt.s32 	%p10, %r71, %r7;
	selp.f32 	%f15, 0f7FFFFFFF, 0f00000000, %p10;
	st.global.f32 	[%rd25], %f15;
	add.s32 	%r54, %r71, %r11;
	setp.lt.s32 	%p11, %r54, %r7;
	selp.f32 	%f16, 0f7FFFFFFF, 0f00000000, %p11;
	add.s64 	%rd26, %rd25, %rd4;
	st.global.f32 	[%rd26], %f16;
	add.s32 	%r55, %r54, %r11;
	setp.lt.s32 	%p12, %r55, %r7;
	selp.f32 	%f17, 0f7FFFFFFF, 0f00000000, %p12;
	add.s64 	%rd27, %rd26, %rd4;
	st.global.f32 	[%rd27], %f17;
	add.s32 	%r56, %r55, %r11;
	setp.lt.s32 	%p13, %r56, %r7;
	selp.f32 	%f18, 0f7FFFFFFF, 0f00000000, %p13;
	add.s64 	%rd28, %rd27, %rd4;
	st.global.f32 	[%rd28], %f18;
	add.s32 	%r71, %r56, %r11;
	setp.lt.s32 	%p14, %r71, %r39;
	@%p14 bra 	$L__BB1_10;

$L__BB1_27:
	ret;

}
	
.visible .entry pwma_batch_tiled_async_f32(
	.param .u64 pwma_batch_tiled_async_f32_param_0,
	.param .u64 pwma_batch_tiled_async_f32_param_1,
	.param .u64 pwma_batch_tiled_async_f32_param_2,
	.param .u64 pwma_batch_tiled_async_f32_param_3,
	.param .u32 pwma_batch_tiled_async_f32_param_4,
	.param .u32 pwma_batch_tiled_async_f32_param_5,
	.param .u32 pwma_batch_tiled_async_f32_param_6,
	.param .u64 pwma_batch_tiled_async_f32_param_7
)
{
	.reg .pred 	%p<60>;
	.reg .b16 	%rs<35>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<185>;
	.reg .b64 	%rd<71>;
	
	.shared .align 8 .b8 _ZZ26pwma_batch_tiled_async_f32E3pss[40];

	ld.param.u64 	%rd15, [pwma_batch_tiled_async_f32_param_0];
	ld.param.u64 	%rd16, [pwma_batch_tiled_async_f32_param_1];
	ld.param.u64 	%rd17, [pwma_batch_tiled_async_f32_param_2];
	ld.param.u64 	%rd18, [pwma_batch_tiled_async_f32_param_3];
	ld.param.u32 	%r63, [pwma_batch_tiled_async_f32_param_4];
	ld.param.u32 	%r65, [pwma_batch_tiled_async_f32_param_5];
	ld.param.u32 	%r64, [pwma_batch_tiled_async_f32_param_6];
	ld.param.u64 	%rd19, [pwma_batch_tiled_async_f32_param_7];
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r65;
	@%p1 bra 	$L__BB2_56;

	cvta.to.global.u64 	%rd20, %rd17;
	cvt.s64.s32 	%rd1, %r1;
	mul.wide.s32 	%rd21, %r1, 4;
	add.s64 	%rd22, %rd20, %rd21;
	ld.global.nc.u32 	%r2, [%rd22];
	setp.lt.s32 	%p2, %r2, 1;
	setp.gt.s32 	%p3, %r2, %r64;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB2_56;

	add.s32 	%r3, %r2, 127;
	cvta.to.global.u64 	%rd23, %rd18;
	shl.b64 	%rd24, %rd1, 2;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.u32 	%r4, [%rd25];
	mov.u32 	%r5, %tid.x;
	setp.lt.s32 	%p5, %r5, %r2;
	@%p5 bra 	$L__BB2_3;
	bra.uni 	$L__BB2_5;

$L__BB2_3:
	mov.u32 	%r6, %ntid.x;
	cvta.to.global.u64 	%rd2, %rd16;
	mul.lo.s32 	%r66, %r1, %r64;
	cvt.s64.s32 	%rd3, %r66;
	mov.u32 	%r172, %r5;

$L__BB2_4:
	cvt.s64.s32 	%rd26, %r172;
	add.s64 	%rd27, %rd26, %rd3;
	shl.b64 	%rd28, %rd27, 2;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.nc.f32 	%f13, [%rd29];
	shl.b32 	%r67, %r172, 2;
	mov.u32 	%r68, shraw$1;
	add.s32 	%r69, %r68, %r67;
	st.shared.f32 	[%r69], %f13;
	add.s32 	%r172, %r172, %r6;
	setp.lt.s32 	%p6, %r172, %r2;
	@%p6 bra 	$L__BB2_4;

$L__BB2_5:
	mov.u32 	%r9, %ntid.x;
	bar.sync 	0;
	mov.u32 	%r10, %ntid.y;
	mov.u32 	%r70, %tid.z;
	mov.u32 	%r71, %tid.y;
	mad.lo.s32 	%r72, %r10, %r70, %r71;
	mul.lo.s32 	%r73, %r72, %r9;
	neg.s32 	%r74, %r5;
	setp.ne.s32 	%p7, %r73, %r74;
	@%p7 bra 	$L__BB2_7;

	mov.u32 	%r84, %ntid.z;
	mul.lo.s32 	%r85, %r9, %r10;
	mul.lo.s32 	%r83, %r85, %r84;
	mov.u32 	%r77, _ZZ26pwma_batch_tiled_async_f32E3pss;
	add.s32 	%r75, %r77, 8;
	
	mbarrier.init.shared.b64 [%r75], %r83;
	
	
	mbarrier.init.shared.b64 [%r77], %r83;
	
	add.s32 	%r81, %r77, 16;
	add.s32 	%r79, %r77, 24;
	
	mbarrier.init.shared.b64 [%r79], %r83;
	
	
	mbarrier.init.shared.b64 [%r81], %r83;
	
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r77;
	  cvta.shared.u64 	%rd31, %tmp; }
	add.s64 	%rd30, %rd31, 32;
	
	st.relaxed.cta.b32 [%rd30],%r83;
	

$L__BB2_7:
	shl.b32 	%r87, %r64, 2;
	add.s32 	%r88, %r87, 15;
	and.b32  	%r89, %r88, -16;
	mov.u32 	%r90, shraw$1;
	add.s32 	%r11, %r90, %r89;
	mov.u32 	%r173, 0;
	barrier.sync 	0;
	mov.u32 	%r12, %nctaid.x;
	shl.b32 	%r13, %r12, 7;
	mov.u32 	%r91, %ctaid.x;
	shl.b32 	%r178, %r91, 7;
	or.b32  	%r92, %r178, 1;
	sub.s32 	%r15, %r92, %r2;
	cvta.to.global.u64 	%rd4, %rd15;
	
	mov.u64 %rd32, %globaltimer;
	
	mul.lo.s32 	%r16, %r1, %r63;
	cvta.to.global.u64 	%rd6, %rd19;
	bra.uni 	$L__BB2_8;

$L__BB2_80:
	add.s32 	%r173, %r173, 1;

$L__BB2_8:
	mov.u32 	%r95, _ZZ26pwma_batch_tiled_async_f32E3pss;
	add.s32 	%r93, %r95, 8;
	mov.u32 	%r94, 1;
	
	{.reg .pred %p;mbarrier.test_wait.parity.shared.b64 %p, [%r93], %r94;selp.u16 %rs10, 1, 0, %p;}
	
	setp.eq.s16 	%p8, %rs10, 0;
	@%p8 bra 	$L__BB2_75;
	bra.uni 	$L__BB2_9;

$L__BB2_75:
	setp.lt.s32 	%p57, %r173, 16;
	@%p57 bra 	$L__BB2_80;

	
	mov.u64 %rd66, %globaltimer;
	
	sub.s64 	%rd14, %rd66, %rd32;
	setp.lt.s64 	%p58, %rd14, 4000000;
	@%p58 bra 	$L__BB2_78;
	bra.uni 	$L__BB2_77;

$L__BB2_78:
	setp.lt.s64 	%p59, %rd14, 40000;
	@%p59 bra 	$L__BB2_8;

	shr.s64 	%rd67, %rd14, 63;
	shr.u64 	%rd68, %rd67, 62;
	add.s64 	%rd69, %rd14, %rd68;
	shr.u64 	%rd70, %rd69, 2;
	cvt.u32.u64 	%r171, %rd70;
	
	nanosleep.u32 %r171;
	
	bra.uni 	$L__BB2_8;

$L__BB2_77:
	mov.u32 	%r170, 1000000;
	
	nanosleep.u32 %r170;
	
	bra.uni 	$L__BB2_8;

$L__BB2_9:
	setp.ge.s32 	%p9, %r5, %r3;
	@%p9 bra 	$L__BB2_15;

	mov.u32 	%r174, %r5;

$L__BB2_11:
	add.s32 	%r19, %r15, %r174;
	setp.gt.s32 	%p10, %r19, -1;
	setp.lt.s32 	%p11, %r19, %r63;
	and.pred  	%p12, %p10, %p11;
	shl.b32 	%r96, %r174, 2;
	add.s32 	%r20, %r11, %r96;
	@%p12 bra 	$L__BB2_13;
	bra.uni 	$L__BB2_12;

$L__BB2_13:
	mul.wide.s32 	%rd34, %r19, 4;
	add.s64 	%rd33, %rd4, %rd34;
	
	cp.async.ca.shared.global [%r20], [%rd33], 4, 4;
	
	bra.uni 	$L__BB2_14;

$L__BB2_12:
	mov.u32 	%r97, 0;
	st.shared.u32 	[%r20], %r97;

$L__BB2_14:
	add.s32 	%r174, %r174, %r9;
	setp.lt.s32 	%p13, %r174, %r3;
	@%p13 bra 	$L__BB2_11;

$L__BB2_15:
	
	cp.async.mbarrier.arrive.shared.b64 [%r95];
	
	
	mbarrier.arrive.shared.b64                                  %rd35,  [%r95];           
	
	
	mov.u64 %rd36, %globaltimer;
	
	mov.u32 	%r175, 0;
	add.s32 	%r102, %r95, 24;
	bra.uni 	$L__BB2_16;

$L__BB2_74:
	add.s32 	%r175, %r175, 1;

$L__BB2_16:
	mov.u32 	%r103, 1;
	
	{.reg .pred %p;mbarrier.test_wait.parity.shared.b64 %p, [%r102], %r103;selp.u16 %rs11, 1, 0, %p;}
	
	setp.eq.s16 	%p14, %rs11, 0;
	@%p14 bra 	$L__BB2_69;
	bra.uni 	$L__BB2_17;

$L__BB2_69:
	setp.lt.s32 	%p54, %r175, 16;
	@%p54 bra 	$L__BB2_74;

	
	mov.u64 %rd61, %globaltimer;
	
	sub.s64 	%rd13, %rd61, %rd36;
	setp.lt.s64 	%p55, %rd13, 4000000;
	@%p55 bra 	$L__BB2_72;
	bra.uni 	$L__BB2_71;

$L__BB2_72:
	setp.lt.s64 	%p56, %rd13, 40000;
	@%p56 bra 	$L__BB2_16;

	shr.s64 	%rd62, %rd13, 63;
	shr.u64 	%rd63, %rd62, 62;
	add.s64 	%rd64, %rd13, %rd63;
	shr.u64 	%rd65, %rd64, 2;
	cvt.u32.u64 	%r169, %rd65;
	
	nanosleep.u32 %r169;
	
	bra.uni 	$L__BB2_16;

$L__BB2_71:
	mov.u32 	%r168, 1000000;
	
	nanosleep.u32 %r168;
	
	bra.uni 	$L__BB2_16;

$L__BB2_17:
	@%p9 bra 	$L__BB2_23;

	add.s32 	%r23, %r15, %r13;
	mov.u32 	%r176, %r5;

$L__BB2_19:
	add.s32 	%r25, %r23, %r176;
	setp.gt.s32 	%p16, %r25, -1;
	setp.lt.s32 	%p17, %r25, %r63;
	and.pred  	%p18, %p16, %p17;
	add.s32 	%r105, %r176, %r3;
	shl.b32 	%r106, %r105, 2;
	add.s32 	%r26, %r11, %r106;
	@%p18 bra 	$L__BB2_21;
	bra.uni 	$L__BB2_20;

$L__BB2_21:
	mul.wide.s32 	%rd38, %r25, 4;
	add.s64 	%rd37, %rd4, %rd38;
	
	cp.async.ca.shared.global [%r26], [%rd37], 4, 4;
	
	bra.uni 	$L__BB2_22;

$L__BB2_20:
	mov.u32 	%r107, 0;
	st.shared.u32 	[%r26], %r107;

$L__BB2_22:
	add.s32 	%r176, %r176, %r9;
	setp.lt.s32 	%p19, %r176, %r3;
	@%p19 bra 	$L__BB2_19;

$L__BB2_23:
	add.s32 	%r110, %r95, 16;
	
	cp.async.mbarrier.arrive.shared.b64 [%r110];
	
	
	mbarrier.arrive.shared.b64                                  %rd39,  [%r110];           
	
	setp.ge.s32 	%p20, %r178, %r63;
	@%p20 bra 	$L__BB2_53;

	shl.b32 	%r113, %r12, 8;
	or.b32  	%r114, %r113, 1;
	sub.s32 	%r28, %r114, %r2;
	add.s32 	%r29, %r2, -1;
	and.b32  	%r30, %r2, 7;
	sub.s32 	%r31, %r2, %r30;
	mov.u16 	%rs34, 244;
	mov.u16 	%rs32, 0;
	mov.u32 	%r112, 0;
	mov.u32 	%r177, %r112;
	mov.u16 	%rs33, %rs32;

$L__BB2_25:
	and.b16  	%rs15, %rs33, 255;
	mul.wide.u16 	%r116, %rs15, 16;
	and.b16  	%rs4, %rs34, 2;
	shr.u16 	%rs16, %rs4, 1;
	
	mov.u64 %rd40, %globaltimer;
	
	add.s32 	%r34, %r95, %r116;
	cvt.u32.u16 	%r35, %rs16;
	mov.u32 	%r179, %r112;
	bra.uni 	$L__BB2_26;

$L__BB2_68:
	add.s32 	%r179, %r179, 1;

$L__BB2_26:
	
	{.reg .pred %p;mbarrier.test_wait.parity.shared.b64 %p, [%r34], %r35;selp.u16 %rs17, 1, 0, %p;}
	
	setp.eq.s16 	%p21, %rs17, 0;
	@%p21 bra 	$L__BB2_63;
	bra.uni 	$L__BB2_27;

$L__BB2_63:
	setp.lt.s32 	%p51, %r179, 16;
	@%p51 bra 	$L__BB2_68;

	
	mov.u64 %rd56, %globaltimer;
	
	sub.s64 	%rd12, %rd56, %rd40;
	setp.lt.s64 	%p52, %rd12, 4000000;
	@%p52 bra 	$L__BB2_66;
	bra.uni 	$L__BB2_65;

$L__BB2_66:
	setp.lt.s64 	%p53, %rd12, 40000;
	@%p53 bra 	$L__BB2_26;

	shr.s64 	%rd57, %rd12, 63;
	shr.u64 	%rd58, %rd57, 62;
	add.s64 	%rd59, %rd12, %rd58;
	shr.u64 	%rd60, %rd59, 2;
	cvt.u32.u64 	%r167, %rd60;
	
	nanosleep.u32 %r167;
	
	bra.uni 	$L__BB2_26;

$L__BB2_65:
	mov.u32 	%r166, 1000000;
	
	nanosleep.u32 %r166;
	
	bra.uni 	$L__BB2_26;

$L__BB2_27:
	bar.sync 	0;
	mul.lo.s32 	%r37, %r177, %r3;
	add.s32 	%r38, %r178, %r5;
	setp.ge.s32 	%p22, %r38, %r63;
	@%p22 bra 	$L__BB2_43;

	setp.lt.s32 	%p23, %r38, %r4;
	add.s32 	%r120, %r38, %r16;
	mul.wide.s32 	%rd41, %r120, 4;
	add.s64 	%rd9, %rd6, %rd41;
	@%p23 bra 	$L__BB2_42;
	bra.uni 	$L__BB2_29;

$L__BB2_42:
	mov.u32 	%r133, 2147483647;
	st.global.u32 	[%rd9], %r133;
	bra.uni 	$L__BB2_43;

$L__BB2_29:
	add.s32 	%r39, %r37, %r5;
	mov.f32 	%f66, 0f00000000;
	@%p2 bra 	$L__BB2_41;

	setp.lt.u32 	%p25, %r29, 7;
	mov.f32 	%f66, 0f00000000;
	mov.u32 	%r182, 0;
	@%p25 bra 	$L__BB2_33;

	mov.f32 	%f66, 0f00000000;
	mov.u32 	%r182, 0;
	mov.u32 	%r181, %r31;

$L__BB2_32:
	.pragma "nounroll";
	add.s32 	%r123, %r39, %r182;
	shl.b32 	%r124, %r123, 2;
	add.s32 	%r125, %r11, %r124;
	shl.b32 	%r126, %r182, 2;
	add.s32 	%r128, %r90, %r126;
	ld.shared.v4.f32 	{%f18, %f19, %f20, %f21}, [%r128];
	ld.shared.f32 	%f26, [%r125];
	fma.rn.ftz.f32 	%f27, %f26, %f18, %f66;
	ld.shared.f32 	%f28, [%r125+4];
	fma.rn.ftz.f32 	%f29, %f28, %f19, %f27;
	ld.shared.f32 	%f30, [%r125+8];
	fma.rn.ftz.f32 	%f31, %f30, %f20, %f29;
	ld.shared.f32 	%f32, [%r125+12];
	fma.rn.ftz.f32 	%f33, %f32, %f21, %f31;
	ld.shared.v4.f32 	{%f34, %f35, %f36, %f37}, [%r128+16];
	ld.shared.f32 	%f42, [%r125+16];
	fma.rn.ftz.f32 	%f43, %f42, %f34, %f33;
	ld.shared.f32 	%f44, [%r125+20];
	fma.rn.ftz.f32 	%f45, %f44, %f35, %f43;
	ld.shared.f32 	%f46, [%r125+24];
	fma.rn.ftz.f32 	%f47, %f46, %f36, %f45;
	ld.shared.f32 	%f48, [%r125+28];
	fma.rn.ftz.f32 	%f66, %f48, %f37, %f47;
	add.s32 	%r182, %r182, 8;
	add.s32 	%r181, %r181, -8;
	setp.ne.s32 	%p26, %r181, 0;
	@%p26 bra 	$L__BB2_32;

$L__BB2_33:
	setp.eq.s32 	%p27, %r30, 0;
	@%p27 bra 	$L__BB2_41;

	setp.eq.s32 	%p28, %r30, 1;
	add.s32 	%r129, %r39, %r182;
	shl.b32 	%r130, %r129, 2;
	add.s32 	%r45, %r11, %r130;
	shl.b32 	%r131, %r182, 2;
	add.s32 	%r46, %r90, %r131;
	ld.shared.f32 	%f49, [%r46];
	ld.shared.f32 	%f50, [%r45];
	fma.rn.ftz.f32 	%f66, %f50, %f49, %f66;
	@%p28 bra 	$L__BB2_41;

	setp.eq.s32 	%p29, %r30, 2;
	ld.shared.f32 	%f51, [%r46+4];
	ld.shared.f32 	%f52, [%r45+4];
	fma.rn.ftz.f32 	%f66, %f52, %f51, %f66;
	@%p29 bra 	$L__BB2_41;

	setp.eq.s32 	%p30, %r30, 3;
	ld.shared.f32 	%f53, [%r46+8];
	ld.shared.f32 	%f54, [%r45+8];
	fma.rn.ftz.f32 	%f66, %f54, %f53, %f66;
	@%p30 bra 	$L__BB2_41;

	setp.eq.s32 	%p31, %r30, 4;
	ld.shared.f32 	%f55, [%r46+12];
	ld.shared.f32 	%f56, [%r45+12];
	fma.rn.ftz.f32 	%f66, %f56, %f55, %f66;
	@%p31 bra 	$L__BB2_41;

	setp.eq.s32 	%p32, %r30, 5;
	ld.shared.f32 	%f57, [%r46+16];
	ld.shared.f32 	%f58, [%r45+16];
	fma.rn.ftz.f32 	%f66, %f58, %f57, %f66;
	@%p32 bra 	$L__BB2_41;

	setp.eq.s32 	%p33, %r30, 6;
	ld.shared.f32 	%f59, [%r46+20];
	ld.shared.f32 	%f60, [%r45+20];
	fma.rn.ftz.f32 	%f66, %f60, %f59, %f66;
	@%p33 bra 	$L__BB2_41;

	ld.shared.f32 	%f61, [%r46+24];
	ld.shared.f32 	%f62, [%r45+24];
	fma.rn.ftz.f32 	%f66, %f62, %f61, %f66;

$L__BB2_41:
	st.global.f32 	[%rd9], %f66;

$L__BB2_43:
	bar.sync 	0;
	add.s32 	%r134, %r34, 8;
	
	mbarrier.arrive.shared.b64                                  %rd42,  [%r134];           
	
	add.s16 	%rs18, %rs33, 1;
	and.b16  	%rs19, %rs18, 255;
	setp.eq.s16 	%p34, %rs19, 2;
	setp.eq.s16 	%p35, %rs4, 0;
	selp.u16 	%rs20, 1, 0, %p35;
	shl.b16 	%rs21, %rs20, 1;
	and.b16  	%rs22, %rs34, -3;
	or.b16  	%rs23, %rs21, %rs22;
	selp.b16 	%rs5, %rs23, %rs34, %p34;
	selp.b16 	%rs33, 0, %rs18, %p34;
	and.b16  	%rs24, %rs32, 255;
	mul.wide.u16 	%r47, %rs24, 16;
	and.b16  	%rs7, %rs5, 1;
	
	mov.u64 %rd43, %globaltimer;
	
	add.s32 	%r137, %r95, %r47;
	add.s32 	%r48, %r137, 8;
	cvt.u32.u16 	%r49, %rs7;
	mov.u32 	%r183, 0;
	bra.uni 	$L__BB2_44;

$L__BB2_62:
	add.s32 	%r183, %r183, 1;

$L__BB2_44:
	
	{.reg .pred %p;mbarrier.test_wait.parity.shared.b64 %p, [%r48], %r49;selp.u16 %rs25, 1, 0, %p;}
	
	setp.eq.s16 	%p36, %rs25, 0;
	@%p36 bra 	$L__BB2_57;
	bra.uni 	$L__BB2_45;

$L__BB2_57:
	setp.lt.s32 	%p48, %r183, 16;
	@%p48 bra 	$L__BB2_62;

	
	mov.u64 %rd51, %globaltimer;
	
	sub.s64 	%rd11, %rd51, %rd43;
	setp.lt.s64 	%p49, %rd11, 4000000;
	@%p49 bra 	$L__BB2_60;
	bra.uni 	$L__BB2_59;

$L__BB2_60:
	setp.lt.s64 	%p50, %rd11, 40000;
	@%p50 bra 	$L__BB2_44;

	shr.s64 	%rd52, %rd11, 63;
	shr.u64 	%rd53, %rd52, 62;
	add.s64 	%rd54, %rd11, %rd53;
	shr.u64 	%rd55, %rd54, 2;
	cvt.u32.u64 	%r165, %rd55;
	
	nanosleep.u32 %r165;
	
	bra.uni 	$L__BB2_44;

$L__BB2_59:
	mov.u32 	%r164, 1000000;
	
	nanosleep.u32 %r164;
	
	bra.uni 	$L__BB2_44;

$L__BB2_45:
	@%p9 bra 	$L__BB2_51;

	add.s32 	%r51, %r28, %r178;
	mov.u32 	%r184, %r5;

$L__BB2_47:
	add.s32 	%r53, %r51, %r184;
	setp.gt.s32 	%p38, %r53, -1;
	setp.lt.s32 	%p39, %r53, %r63;
	and.pred  	%p40, %p38, %p39;
	add.s32 	%r140, %r184, %r37;
	shl.b32 	%r141, %r140, 2;
	add.s32 	%r54, %r11, %r141;
	@%p40 bra 	$L__BB2_49;
	bra.uni 	$L__BB2_48;

$L__BB2_49:
	mul.wide.s32 	%rd45, %r53, 4;
	add.s64 	%rd44, %rd4, %rd45;
	
	cp.async.ca.shared.global [%r54], [%rd44], 4, 4;
	
	bra.uni 	$L__BB2_50;

$L__BB2_48:
	mov.u32 	%r142, 0;
	st.shared.u32 	[%r54], %r142;

$L__BB2_50:
	add.s32 	%r184, %r184, %r9;
	setp.lt.s32 	%p41, %r184, %r3;
	@%p41 bra 	$L__BB2_47;

$L__BB2_51:
	
	cp.async.mbarrier.arrive.shared.b64 [%r137];
	
	
	mbarrier.arrive.shared.b64                                  %rd46,  [%r137];           
	
	add.s16 	%rs26, %rs32, 1;
	and.b16  	%rs27, %rs26, 255;
	setp.eq.s16 	%p42, %rs27, 2;
	setp.eq.s16 	%p43, %rs7, 0;
	selp.u16 	%rs28, 1, 0, %p43;
	and.b16  	%rs29, %rs5, -2;
	or.b16  	%rs30, %rs29, %rs28;
	selp.b16 	%rs34, %rs30, %rs5, %p42;
	selp.b16 	%rs32, 0, %rs26, %p42;
	add.s32 	%r147, %r177, 1;
	shr.u32 	%r148, %r147, 31;
	add.s32 	%r149, %r147, %r148;
	and.b32  	%r150, %r149, -2;
	sub.s32 	%r177, %r147, %r150;
	add.s32 	%r178, %r178, %r13;
	setp.lt.s32 	%p44, %r178, %r63;
	@%p44 bra 	$L__BB2_25;

	and.b16  	%rs31, %rs34, 4;
	setp.eq.s16 	%p45, %rs31, 0;
	@%p45 bra 	$L__BB2_56;

$L__BB2_53:
	
	activemask.b32 %r151;
	
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r95;
	  cvta.shared.u64 	%rd47, %tmp; }
	add.s64 	%rd48, %rd47, 32;
	match.any.sync.b64 	%r58, %rd48, %r151;
	brev.b32 	%r154, %r58;
	bfind.shiftamt.u32 	%r155, %r154;
	
	mov.u32 %r152, %laneid;
	
	setp.ne.s32 	%p46, %r152, %r155;
	@%p46 bra 	$L__BB2_56;

	popc.b32 	%r158, %r58;
	neg.s32 	%r157, %r158;
	
	fence.sc.cta;
	
	
	atom.add.acquire.cta.u32 %r156,[%rd48],%r157;
	
	setp.ne.s32 	%p47, %r156, %r158;
	@%p47 bra 	$L__BB2_56;

	
	mbarrier.inval.shared.b64 [%r95];
	
	
	mbarrier.inval.shared.b64 [%r93];
	
	
	mbarrier.inval.shared.b64 [%r110];
	
	
	mbarrier.inval.shared.b64 [%r102];
	

$L__BB2_56:
	ret;

}
	
.visible .entry pwma_ms1p_tiled_f32_tx128_ty2(
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty2_param_0,
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty2_param_1,
	.param .u32 pwma_ms1p_tiled_f32_tx128_ty2_param_2,
	.param .f32 pwma_ms1p_tiled_f32_tx128_ty2_param_3,
	.param .u32 pwma_ms1p_tiled_f32_tx128_ty2_param_4,
	.param .u32 pwma_ms1p_tiled_f32_tx128_ty2_param_5,
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty2_param_6,
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty2_param_7
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<56>;
	.reg .b32 	%r<128>;
	.reg .b64 	%rd<26>;


	ld.param.u64 	%rd7, [pwma_ms1p_tiled_f32_tx128_ty2_param_0];
	ld.param.u64 	%rd8, [pwma_ms1p_tiled_f32_tx128_ty2_param_1];
	ld.param.u32 	%r59, [pwma_ms1p_tiled_f32_tx128_ty2_param_2];
	ld.param.u32 	%r60, [pwma_ms1p_tiled_f32_tx128_ty2_param_4];
	ld.param.u32 	%r61, [pwma_ms1p_tiled_f32_tx128_ty2_param_5];
	ld.param.u64 	%rd9, [pwma_ms1p_tiled_f32_tx128_ty2_param_6];
	ld.param.u64 	%rd10, [pwma_ms1p_tiled_f32_tx128_ty2_param_7];
	cvta.to.global.u64 	%rd1, %rd8;
	mov.u32 	%r62, %ctaid.x;
	shl.b32 	%r1, %r62, 7;
	mov.u32 	%r63, %ctaid.y;
	shl.b32 	%r2, %r63, 1;
	setp.ge.s32 	%p1, %r1, %r61;
	setp.ge.s32 	%p2, %r2, %r60;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB3_31;

	add.s32 	%r3, %r59, 127;
	shl.b32 	%r64, %r59, 2;
	add.s32 	%r65, %r64, 15;
	and.b32  	%r4, %r65, -16;
	and.b64  	%rd11, %rd8, 15;
	setp.eq.s64 	%p4, %rd11, 0;
	@%p4 bra 	$L__BB3_5;

	mov.u32 	%r66, %tid.y;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r67, %tid.x;
	mad.lo.s32 	%r115, %r66, %r5, %r67;
	setp.ge.s32 	%p5, %r115, %r59;
	@%p5 bra 	$L__BB3_11;

	mov.u32 	%r68, %ntid.y;
	mul.lo.s32 	%r7, %r5, %r68;

$L__BB3_4:
	mul.wide.s32 	%rd12, %r115, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.nc.f32 	%f10, [%rd13];
	shl.b32 	%r69, %r115, 2;
	mov.u32 	%r70, shraw;
	add.s32 	%r71, %r70, %r69;
	st.shared.f32 	[%r71], %f10;
	add.s32 	%r115, %r115, %r7;
	setp.lt.s32 	%p6, %r115, %r59;
	@%p6 bra 	$L__BB3_4;
	bra.uni 	$L__BB3_11;

$L__BB3_5:
	shr.s32 	%r10, %r59, 2;
	mov.u32 	%r11, %ntid.x;
	mov.u32 	%r12, %tid.y;
	mov.u32 	%r13, %tid.x;
	mad.lo.s32 	%r116, %r12, %r11, %r13;
	setp.ge.s32 	%p7, %r116, %r10;
	@%p7 bra 	$L__BB3_8;

	mov.u32 	%r72, %ntid.y;
	mul.lo.s32 	%r15, %r11, %r72;

$L__BB3_7:
	mul.wide.s32 	%rd14, %r116, 16;
	add.s64 	%rd15, %rd1, %rd14;
	shl.b32 	%r73, %r116, 4;
	mov.u32 	%r74, shraw;
	add.s32 	%r75, %r74, %r73;
	ld.global.nc.v4.u32 	{%r76, %r77, %r78, %r79}, [%rd15];
	st.shared.v4.u32 	[%r75], {%r76, %r77, %r78, %r79};
	add.s32 	%r116, %r116, %r15;
	setp.lt.s32 	%p8, %r116, %r10;
	@%p8 bra 	$L__BB3_7;

$L__BB3_8:
	or.b32  	%r84, %r13, %r12;
	setp.ne.s32 	%p9, %r84, 0;
	and.b32  	%r18, %r59, 3;
	setp.eq.s32 	%p10, %r18, 0;
	or.pred  	%p11, %p9, %p10;
	@%p11 bra 	$L__BB3_11;

	and.b32  	%r87, %r64, -16;
	mov.u32 	%r88, shraw;
	add.s32 	%r117, %r88, %r87;
	mul.wide.s32 	%rd16, %r59, 4;
	and.b64  	%rd17, %rd16, -16;
	add.s64 	%rd25, %rd1, %rd17;
	mov.u32 	%r118, 0;

$L__BB3_10:
	ld.global.nc.f32 	%f11, [%rd25];
	st.shared.f32 	[%r117], %f11;
	add.s32 	%r117, %r117, 4;
	add.s64 	%rd25, %rd25, 4;
	add.s32 	%r118, %r118, 1;
	setp.lt.u32 	%p12, %r118, %r18;
	@%p12 bra 	$L__BB3_10;

$L__BB3_11:
	mov.u32 	%r24, %tid.x;
	bar.sync 	0;
	setp.lt.s32 	%p13, %r24, %r3;
	@%p13 bra 	$L__BB3_12;
	bra.uni 	$L__BB3_20;

$L__BB3_12:
	add.s32 	%r89, %r1, 1;
	sub.s32 	%r25, %r89, %r59;
	mov.u32 	%r26, %tid.y;
	add.s32 	%r27, %r2, %r26;
	mov.u32 	%r28, %ntid.x;
	mul.lo.s32 	%r29, %r3, 3;
	mov.u32 	%r90, shraw;
	add.s32 	%r30, %r90, %r4;
	cvta.to.global.u64 	%rd5, %rd7;
	mov.u32 	%r119, %r24;

$L__BB3_13:
	add.s32 	%r32, %r25, %r119;
	setp.gt.s32 	%p14, %r32, -1;
	setp.lt.s32 	%p15, %r32, %r61;
	and.pred  	%p16, %p14, %p15;
	mad.lo.s32 	%r91, %r119, 3, %r26;
	shl.b32 	%r92, %r91, 2;
	add.s32 	%r33, %r30, %r92;
	@%p16 bra 	$L__BB3_16;
	bra.uni 	$L__BB3_14;

$L__BB3_16:
	setp.ge.s32 	%p18, %r27, %r60;
	mov.f32 	%f50, 0f00000000;
	@%p18 bra 	$L__BB3_18;

	mad.lo.s32 	%r95, %r32, %r60, %r27;
	mul.wide.s32 	%rd18, %r95, 4;
	add.s64 	%rd19, %rd5, %rd18;
	ld.global.nc.f32 	%f50, [%rd19];

$L__BB3_18:
	st.shared.f32 	[%r33], %f50;
	bra.uni 	$L__BB3_19;

$L__BB3_14:
	setp.ge.s32 	%p17, %r91, %r29;
	@%p17 bra 	$L__BB3_19;

	mov.u32 	%r94, 0;
	st.shared.u32 	[%r33], %r94;

$L__BB3_19:
	add.s32 	%r119, %r119, %r28;
	setp.lt.s32 	%p19, %r119, %r3;
	@%p19 bra 	$L__BB3_13;

$L__BB3_20:
	mov.u32 	%r35, %tid.y;
	add.s32 	%r36, %r2, %r35;
	bar.sync 	0;
	add.s32 	%r37, %r1, %r24;
	setp.ge.s32 	%p20, %r36, %r60;
	setp.ge.s32 	%p21, %r37, %r61;
	or.pred  	%p22, %p20, %p21;
	@%p22 bra 	$L__BB3_31;

	cvta.to.global.u64 	%rd20, %rd9;
	mul.wide.s32 	%rd21, %r36, 4;
	add.s64 	%rd22, %rd20, %rd21;
	add.s32 	%r38, %r59, -1;
	ld.global.nc.u32 	%r98, [%rd22];
	add.s32 	%r99, %r38, %r98;
	mad.lo.s32 	%r100, %r37, %r60, %r36;
	setp.lt.s32 	%p23, %r37, %r99;
	cvta.to.global.u64 	%rd23, %rd10;
	mul.wide.s32 	%rd24, %r100, 4;
	add.s64 	%rd6, %rd23, %rd24;
	@%p23 bra 	$L__BB3_30;
	bra.uni 	$L__BB3_22;

$L__BB3_30:
	mov.u32 	%r114, 2147483647;
	st.global.u32 	[%rd6], %r114;
	bra.uni 	$L__BB3_31;

$L__BB3_22:
	setp.lt.s32 	%p24, %r59, 1;
	mov.f32 	%f55, 0f00000000;
	@%p24 bra 	$L__BB3_29;

	and.b32  	%r127, %r59, 7;
	setp.lt.u32 	%p25, %r38, 7;
	mov.f32 	%f55, 0f00000000;
	mov.u32 	%r124, 0;
	@%p25 bra 	$L__BB3_26;

	sub.s32 	%r123, %r59, %r127;
	mad.lo.s32 	%r104, %r24, 12, %r4;
	shl.b32 	%r105, %r35, 2;
	add.s32 	%r106, %r104, %r105;
	mov.u32 	%r121, shraw;
	add.s32 	%r107, %r121, %r106;
	add.s32 	%r120, %r107, 48;
	mov.f32 	%f55, 0f00000000;
	mov.u32 	%r124, 0;

$L__BB3_25:
	.pragma "nounroll";
	ld.shared.v4.f32 	{%f17, %f18, %f19, %f20}, [%r121];
	ld.shared.f32 	%f25, [%r120+-48];
	fma.rn.ftz.f32 	%f26, %f25, %f17, %f55;
	ld.shared.f32 	%f27, [%r120+-36];
	fma.rn.ftz.f32 	%f28, %f27, %f18, %f26;
	ld.shared.f32 	%f29, [%r120+-24];
	fma.rn.ftz.f32 	%f30, %f29, %f19, %f28;
	ld.shared.f32 	%f31, [%r120+-12];
	fma.rn.ftz.f32 	%f32, %f31, %f20, %f30;
	ld.shared.v4.f32 	{%f33, %f34, %f35, %f36}, [%r121+16];
	ld.shared.f32 	%f41, [%r120];
	fma.rn.ftz.f32 	%f42, %f41, %f33, %f32;
	ld.shared.f32 	%f43, [%r120+12];
	fma.rn.ftz.f32 	%f44, %f43, %f34, %f42;
	ld.shared.f32 	%f45, [%r120+24];
	fma.rn.ftz.f32 	%f46, %f45, %f35, %f44;
	ld.shared.f32 	%f47, [%r120+36];
	fma.rn.ftz.f32 	%f55, %f47, %f36, %f46;
	add.s32 	%r124, %r124, 8;
	add.s32 	%r121, %r121, 32;
	add.s32 	%r120, %r120, 96;
	add.s32 	%r123, %r123, -8;
	setp.ne.s32 	%p26, %r123, 0;
	@%p26 bra 	$L__BB3_25;

$L__BB3_26:
	setp.eq.s32 	%p27, %r127, 0;
	@%p27 bra 	$L__BB3_29;

	shl.b32 	%r108, %r124, 2;
	mov.u32 	%r109, shraw;
	add.s32 	%r126, %r109, %r108;
	add.s32 	%r110, %r24, %r124;
	mad.lo.s32 	%r111, %r110, 12, %r4;
	shl.b32 	%r112, %r35, 2;
	add.s32 	%r113, %r111, %r112;
	add.s32 	%r125, %r109, %r113;

$L__BB3_28:
	.pragma "nounroll";
	ld.shared.f32 	%f48, [%r126];
	ld.shared.f32 	%f49, [%r125];
	fma.rn.ftz.f32 	%f55, %f49, %f48, %f55;
	add.s32 	%r126, %r126, 4;
	add.s32 	%r125, %r125, 12;
	add.s32 	%r127, %r127, -1;
	setp.ne.s32 	%p28, %r127, 0;
	@%p28 bra 	$L__BB3_28;

$L__BB3_29:
	st.global.f32 	[%rd6], %f55;

$L__BB3_31:
	ret;

}
	
.visible .entry pwma_ms1p_tiled_f32_tx128_ty4(
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty4_param_0,
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty4_param_1,
	.param .u32 pwma_ms1p_tiled_f32_tx128_ty4_param_2,
	.param .f32 pwma_ms1p_tiled_f32_tx128_ty4_param_3,
	.param .u32 pwma_ms1p_tiled_f32_tx128_ty4_param_4,
	.param .u32 pwma_ms1p_tiled_f32_tx128_ty4_param_5,
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty4_param_6,
	.param .u64 pwma_ms1p_tiled_f32_tx128_ty4_param_7
)
{
	.reg .pred 	%p<30>;
	.reg .f32 	%f<64>;
	.reg .b32 	%r<130>;
	.reg .b64 	%rd<28>;


	ld.param.u64 	%rd10, [pwma_ms1p_tiled_f32_tx128_ty4_param_0];
	ld.param.u64 	%rd7, [pwma_ms1p_tiled_f32_tx128_ty4_param_1];
	ld.param.u32 	%r60, [pwma_ms1p_tiled_f32_tx128_ty4_param_2];
	ld.param.u32 	%r61, [pwma_ms1p_tiled_f32_tx128_ty4_param_4];
	ld.param.u32 	%r62, [pwma_ms1p_tiled_f32_tx128_ty4_param_5];
	ld.param.u64 	%rd8, [pwma_ms1p_tiled_f32_tx128_ty4_param_6];
	ld.param.u64 	%rd9, [pwma_ms1p_tiled_f32_tx128_ty4_param_7];
	cvta.to.global.u64 	%rd1, %rd10;
	cvta.to.global.u64 	%rd2, %rd7;
	mov.u32 	%r63, %ctaid.x;
	shl.b32 	%r1, %r63, 7;
	mov.u32 	%r64, %ctaid.y;
	shl.b32 	%r2, %r64, 2;
	setp.ge.s32 	%p1, %r1, %r62;
	setp.ge.s32 	%p2, %r2, %r61;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB4_33;

	add.s32 	%r3, %r60, 127;
	shl.b32 	%r65, %r60, 2;
	add.s32 	%r66, %r65, 15;
	and.b32  	%r4, %r66, -16;
	and.b64  	%rd11, %rd7, 15;
	setp.eq.s64 	%p4, %rd11, 0;
	@%p4 bra 	$L__BB4_5;

	mov.u32 	%r67, %tid.y;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r68, %tid.x;
	mad.lo.s32 	%r117, %r67, %r5, %r68;
	setp.ge.s32 	%p5, %r117, %r60;
	@%p5 bra 	$L__BB4_11;

	mov.u32 	%r69, %ntid.y;
	mul.lo.s32 	%r7, %r5, %r69;

$L__BB4_4:
	mul.wide.s32 	%rd12, %r117, 4;
	add.s64 	%rd13, %rd2, %rd12;
	ld.global.nc.f32 	%f10, [%rd13];
	shl.b32 	%r70, %r117, 2;
	mov.u32 	%r71, shraw;
	add.s32 	%r72, %r71, %r70;
	st.shared.f32 	[%r72], %f10;
	add.s32 	%r117, %r117, %r7;
	setp.lt.s32 	%p6, %r117, %r60;
	@%p6 bra 	$L__BB4_4;
	bra.uni 	$L__BB4_11;

$L__BB4_5:
	shr.s32 	%r10, %r60, 2;
	mov.u32 	%r11, %ntid.x;
	mov.u32 	%r12, %tid.y;
	mov.u32 	%r13, %tid.x;
	mad.lo.s32 	%r118, %r12, %r11, %r13;
	setp.ge.s32 	%p7, %r118, %r10;
	@%p7 bra 	$L__BB4_8;

	mov.u32 	%r73, %ntid.y;
	mul.lo.s32 	%r15, %r11, %r73;

$L__BB4_7:
	mul.wide.s32 	%rd14, %r118, 16;
	add.s64 	%rd15, %rd2, %rd14;
	shl.b32 	%r74, %r118, 4;
	mov.u32 	%r75, shraw;
	add.s32 	%r76, %r75, %r74;
	ld.global.nc.v4.u32 	{%r77, %r78, %r79, %r80}, [%rd15];
	st.shared.v4.u32 	[%r76], {%r77, %r78, %r79, %r80};
	add.s32 	%r118, %r118, %r15;
	setp.lt.s32 	%p8, %r118, %r10;
	@%p8 bra 	$L__BB4_7;

$L__BB4_8:
	or.b32  	%r85, %r13, %r12;
	setp.ne.s32 	%p9, %r85, 0;
	and.b32  	%r18, %r60, 3;
	setp.eq.s32 	%p10, %r18, 0;
	or.pred  	%p11, %p9, %p10;
	@%p11 bra 	$L__BB4_11;

	and.b32  	%r88, %r65, -16;
	mov.u32 	%r89, shraw;
	add.s32 	%r119, %r89, %r88;
	mul.wide.s32 	%rd16, %r60, 4;
	and.b64  	%rd17, %rd16, -16;
	add.s64 	%rd27, %rd2, %rd17;
	mov.u32 	%r120, 0;

$L__BB4_10:
	ld.global.nc.f32 	%f11, [%rd27];
	st.shared.f32 	[%r119], %f11;
	add.s32 	%r119, %r119, 4;
	add.s64 	%rd27, %rd27, 4;
	add.s32 	%r120, %r120, 1;
	setp.lt.u32 	%p12, %r120, %r18;
	@%p12 bra 	$L__BB4_10;

$L__BB4_11:
	mov.u32 	%r24, %tid.x;
	bar.sync 	0;
	setp.lt.s32 	%p13, %r24, %r3;
	@%p13 bra 	$L__BB4_12;
	bra.uni 	$L__BB4_22;

$L__BB4_12:
	mov.u32 	%r90, shraw;
	add.s32 	%r25, %r90, %r4;
	and.b32  	%r91, %r61, 3;
	add.s32 	%r92, %r1, 1;
	sub.s32 	%r26, %r92, %r60;
	mov.u32 	%r27, %tid.y;
	or.b32  	%r28, %r91, %r27;
	mov.u32 	%r29, %ntid.x;
	mul.lo.s32 	%r30, %r3, 5;
	add.s32 	%r31, %r2, %r27;
	mov.u32 	%r121, %r24;

$L__BB4_13:
	add.s32 	%r33, %r26, %r121;
	setp.gt.s32 	%p14, %r33, -1;
	setp.lt.s32 	%p15, %r33, %r62;
	and.pred  	%p16, %p14, %p15;
	mad.lo.s32 	%r93, %r121, 5, %r27;
	shl.b32 	%r94, %r93, 2;
	add.s32 	%r34, %r25, %r94;
	@%p16 bra 	$L__BB4_16;
	bra.uni 	$L__BB4_14;

$L__BB4_16:
	setp.eq.s32 	%p18, %r28, 0;
	@%p18 bra 	$L__BB4_20;

	setp.ge.s32 	%p19, %r31, %r61;
	mov.f32 	%f58, 0f00000000;
	@%p19 bra 	$L__BB4_19;

	mad.lo.s32 	%r97, %r33, %r61, %r31;
	mul.wide.s32 	%rd18, %r97, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.nc.f32 	%f58, [%rd19];

$L__BB4_19:
	st.shared.f32 	[%r34], %f58;
	bra.uni 	$L__BB4_21;

$L__BB4_14:
	setp.ge.s32 	%p17, %r93, %r30;
	@%p17 bra 	$L__BB4_21;

	mov.u32 	%r96, 0;
	st.shared.u32 	[%r34], %r96;
	bra.uni 	$L__BB4_21;

$L__BB4_20:
	mad.lo.s32 	%r98, %r33, %r61, %r2;
	mul.wide.s32 	%rd20, %r98, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.nc.v4.f32 	{%f13, %f14, %f15, %f16}, [%rd21];
	mad.lo.s32 	%r99, %r121, 20, %r25;
	st.shared.f32 	[%r99], %f13;
	st.shared.f32 	[%r99+4], %f14;
	st.shared.f32 	[%r99+8], %f15;
	st.shared.f32 	[%r99+12], %f16;

$L__BB4_21:
	add.s32 	%r121, %r121, %r29;
	setp.lt.s32 	%p20, %r121, %r3;
	@%p20 bra 	$L__BB4_13;

$L__BB4_22:
	mov.u32 	%r36, %tid.y;
	add.s32 	%r37, %r2, %r36;
	bar.sync 	0;
	setp.ge.s32 	%p21, %r37, %r61;
	add.s32 	%r38, %r1, %r24;
	setp.ge.s32 	%p22, %r38, %r62;
	or.pred  	%p23, %p21, %p22;
	@%p23 bra 	$L__BB4_33;

	cvta.to.global.u64 	%rd22, %rd8;
	mul.wide.s32 	%rd23, %r37, 4;
	add.s64 	%rd24, %rd22, %rd23;
	add.s32 	%r39, %r60, -1;
	ld.global.nc.u32 	%r100, [%rd24];
	add.s32 	%r101, %r39, %r100;
	mad.lo.s32 	%r102, %r38, %r61, %r37;
	setp.lt.s32 	%p24, %r38, %r101;
	cvta.to.global.u64 	%rd25, %rd9;
	mul.wide.s32 	%rd26, %r102, 4;
	add.s64 	%rd6, %rd25, %rd26;
	@%p24 bra 	$L__BB4_32;
	bra.uni 	$L__BB4_24;

$L__BB4_32:
	mov.u32 	%r116, 2147483647;
	st.global.u32 	[%rd6], %r116;
	bra.uni 	$L__BB4_33;

$L__BB4_24:
	setp.lt.s32 	%p25, %r60, 1;
	mov.f32 	%f63, 0f00000000;
	@%p25 bra 	$L__BB4_31;

	and.b32  	%r129, %r60, 7;
	setp.lt.u32 	%p26, %r39, 7;
	mov.f32 	%f63, 0f00000000;
	mov.u32 	%r126, 0;
	@%p26 bra 	$L__BB4_28;

	sub.s32 	%r125, %r60, %r129;
	mad.lo.s32 	%r106, %r24, 20, %r4;
	shl.b32 	%r107, %r36, 2;
	add.s32 	%r108, %r106, %r107;
	mov.u32 	%r123, shraw;
	add.s32 	%r109, %r123, %r108;
	add.s32 	%r122, %r109, 80;
	mov.f32 	%f63, 0f00000000;
	mov.u32 	%r126, 0;

$L__BB4_27:
	.pragma "nounroll";
	ld.shared.v4.f32 	{%f25, %f26, %f27, %f28}, [%r123];
	ld.shared.f32 	%f33, [%r122+-80];
	fma.rn.ftz.f32 	%f34, %f33, %f25, %f63;
	ld.shared.f32 	%f35, [%r122+-60];
	fma.rn.ftz.f32 	%f36, %f35, %f26, %f34;
	ld.shared.f32 	%f37, [%r122+-40];
	fma.rn.ftz.f32 	%f38, %f37, %f27, %f36;
	ld.shared.f32 	%f39, [%r122+-20];
	fma.rn.ftz.f32 	%f40, %f39, %f28, %f38;
	ld.shared.v4.f32 	{%f41, %f42, %f43, %f44}, [%r123+16];
	ld.shared.f32 	%f49, [%r122];
	fma.rn.ftz.f32 	%f50, %f49, %f41, %f40;
	ld.shared.f32 	%f51, [%r122+20];
	fma.rn.ftz.f32 	%f52, %f51, %f42, %f50;
	ld.shared.f32 	%f53, [%r122+40];
	fma.rn.ftz.f32 	%f54, %f53, %f43, %f52;
	ld.shared.f32 	%f55, [%r122+60];
	fma.rn.ftz.f32 	%f63, %f55, %f44, %f54;
	add.s32 	%r126, %r126, 8;
	add.s32 	%r123, %r123, 32;
	add.s32 	%r122, %r122, 160;
	add.s32 	%r125, %r125, -8;
	setp.ne.s32 	%p27, %r125, 0;
	@%p27 bra 	$L__BB4_27;

$L__BB4_28:
	setp.eq.s32 	%p28, %r129, 0;
	@%p28 bra 	$L__BB4_31;

	shl.b32 	%r110, %r126, 2;
	mov.u32 	%r111, shraw;
	add.s32 	%r128, %r111, %r110;
	add.s32 	%r112, %r24, %r126;
	mad.lo.s32 	%r113, %r112, 20, %r4;
	shl.b32 	%r114, %r36, 2;
	add.s32 	%r115, %r113, %r114;
	add.s32 	%r127, %r111, %r115;

$L__BB4_30:
	.pragma "nounroll";
	ld.shared.f32 	%f56, [%r128];
	ld.shared.f32 	%f57, [%r127];
	fma.rn.ftz.f32 	%f63, %f57, %f56, %f63;
	add.s32 	%r128, %r128, 4;
	add.s32 	%r127, %r127, 20;
	add.s32 	%r129, %r129, -1;
	setp.ne.s32 	%p29, %r129, 0;
	@%p29 bra 	$L__BB4_30;

$L__BB4_31:
	st.global.f32 	[%rd6], %f63;

$L__BB4_33:
	ret;

}
	
.visible .entry pwma_ms1p_const_f32(
	.param .u64 pwma_ms1p_const_f32_param_0,
	.param .u32 pwma_ms1p_const_f32_param_1,
	.param .u32 pwma_ms1p_const_f32_param_2,
	.param .u32 pwma_ms1p_const_f32_param_3,
	.param .u64 pwma_ms1p_const_f32_param_4,
	.param .u64 pwma_ms1p_const_f32_param_5
)
{
	.reg .pred 	%p<24>;
	.reg .f32 	%f<62>;
	.reg .b32 	%r<64>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd16, [pwma_ms1p_const_f32_param_0];
	ld.param.u32 	%r30, [pwma_ms1p_const_f32_param_1];
	ld.param.u32 	%r31, [pwma_ms1p_const_f32_param_2];
	ld.param.u32 	%r32, [pwma_ms1p_const_f32_param_3];
	ld.param.u64 	%rd15, [pwma_ms1p_const_f32_param_4];
	ld.param.u64 	%rd17, [pwma_ms1p_const_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd17;
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r31;
	@%p1 bra 	$L__BB5_24;

	cvta.to.global.u64 	%rd18, %rd15;
	mul.wide.s32 	%rd19, %r1, 4;
	add.s64 	%rd20, %rd18, %rd19;
	add.s32 	%r2, %r30, -1;
	ld.global.nc.u32 	%r33, [%rd20];
	add.s32 	%r3, %r2, %r33;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r34, %ctaid.x;
	mov.u32 	%r35, %tid.x;
	mad.lo.s32 	%r58, %r34, %r4, %r35;
	mov.u32 	%r6, %nctaid.x;
	mul.lo.s32 	%r7, %r6, %r4;
	setp.ge.s32 	%p2, %r58, %r32;
	@%p2 bra 	$L__BB5_24;

	setp.gt.s32 	%p3, %r30, 0;
	@%p3 bra 	$L__BB5_8;
	bra.uni 	$L__BB5_3;

$L__BB5_8:
	and.b32  	%r17, %r30, 7;
	sub.s32 	%r18, %r17, %r30;
	shl.b32 	%r19, %r31, 3;
	mul.wide.s32 	%rd4, %r31, 4;
	mov.u32 	%r48, 1;
	sub.s32 	%r20, %r48, %r30;
	mov.u64 	%rd29, pwma_const_w;

$L__BB5_9:
	mad.lo.s32 	%r49, %r58, %r31, %r1;
	mul.wide.s32 	%rd28, %r49, 4;
	add.s64 	%rd5, %rd2, %rd28;
	setp.lt.s32 	%p13, %r58, %r3;
	@%p13 bra 	$L__BB5_22;
	bra.uni 	$L__BB5_10;

$L__BB5_22:
	mov.u32 	%r55, 2147483647;
	st.global.u32 	[%rd5], %r55;
	bra.uni 	$L__BB5_23;

$L__BB5_10:
	setp.lt.u32 	%p14, %r2, 7;
	add.s32 	%r22, %r20, %r58;
	mov.f32 	%f61, 0f00000000;
	mov.u32 	%r63, 0;
	@%p14 bra 	$L__BB5_13;

	mad.lo.s32 	%r61, %r31, %r22, %r1;
	mov.f32 	%f61, 0f00000000;
	mov.u32 	%r63, 0;
	mov.u64 	%rd43, %rd29;

$L__BB5_12:
	.pragma "nounroll";
	mul.wide.s32 	%rd30, %r61, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.const.f32 	%f21, [%rd43];
	ld.global.nc.f32 	%f22, [%rd31];
	fma.rn.ftz.f32 	%f23, %f22, %f21, %f61;
	add.s64 	%rd32, %rd31, %rd4;
	ld.const.f32 	%f24, [%rd43+4];
	ld.global.nc.f32 	%f25, [%rd32];
	fma.rn.ftz.f32 	%f26, %f25, %f24, %f23;
	add.s64 	%rd33, %rd32, %rd4;
	ld.const.f32 	%f27, [%rd43+8];
	ld.global.nc.f32 	%f28, [%rd33];
	fma.rn.ftz.f32 	%f29, %f28, %f27, %f26;
	add.s64 	%rd34, %rd33, %rd4;
	ld.const.f32 	%f30, [%rd43+12];
	ld.global.nc.f32 	%f31, [%rd34];
	fma.rn.ftz.f32 	%f32, %f31, %f30, %f29;
	add.s64 	%rd35, %rd34, %rd4;
	ld.const.f32 	%f33, [%rd43+16];
	ld.global.nc.f32 	%f34, [%rd35];
	fma.rn.ftz.f32 	%f35, %f34, %f33, %f32;
	add.s64 	%rd36, %rd35, %rd4;
	ld.const.f32 	%f36, [%rd43+20];
	ld.global.nc.f32 	%f37, [%rd36];
	fma.rn.ftz.f32 	%f38, %f37, %f36, %f35;
	add.s64 	%rd37, %rd36, %rd4;
	ld.const.f32 	%f39, [%rd43+24];
	ld.global.nc.f32 	%f40, [%rd37];
	fma.rn.ftz.f32 	%f41, %f40, %f39, %f38;
	add.s64 	%rd38, %rd37, %rd4;
	ld.const.f32 	%f42, [%rd43+28];
	ld.global.nc.f32 	%f43, [%rd38];
	fma.rn.ftz.f32 	%f61, %f43, %f42, %f41;
	add.s32 	%r63, %r63, 8;
	add.s32 	%r52, %r18, %r63;
	add.s32 	%r61, %r61, %r19;
	add.s64 	%rd43, %rd43, 32;
	setp.ne.s32 	%p15, %r52, 0;
	@%p15 bra 	$L__BB5_12;

$L__BB5_13:
	setp.eq.s32 	%p16, %r17, 0;
	@%p16 bra 	$L__BB5_21;

	setp.eq.s32 	%p17, %r17, 1;
	add.s32 	%r53, %r22, %r63;
	mad.lo.s32 	%r54, %r53, %r31, %r1;
	mul.wide.s32 	%rd39, %r54, 4;
	add.s64 	%rd8, %rd1, %rd39;
	mul.wide.s32 	%rd40, %r63, 4;
	mov.u64 	%rd41, pwma_const_w;
	add.s64 	%rd9, %rd41, %rd40;
	ld.const.f32 	%f44, [%rd9];
	ld.global.nc.f32 	%f45, [%rd8];
	fma.rn.ftz.f32 	%f61, %f45, %f44, %f61;
	@%p17 bra 	$L__BB5_21;

	setp.eq.s32 	%p18, %r17, 2;
	add.s64 	%rd10, %rd8, %rd4;
	ld.const.f32 	%f46, [%rd9+4];
	ld.global.nc.f32 	%f47, [%rd10];
	fma.rn.ftz.f32 	%f61, %f47, %f46, %f61;
	@%p18 bra 	$L__BB5_21;

	setp.eq.s32 	%p19, %r17, 3;
	add.s64 	%rd11, %rd10, %rd4;
	ld.const.f32 	%f48, [%rd9+8];
	ld.global.nc.f32 	%f49, [%rd11];
	fma.rn.ftz.f32 	%f61, %f49, %f48, %f61;
	@%p19 bra 	$L__BB5_21;

	setp.eq.s32 	%p20, %r17, 4;
	add.s64 	%rd12, %rd11, %rd4;
	ld.const.f32 	%f50, [%rd9+12];
	ld.global.nc.f32 	%f51, [%rd12];
	fma.rn.ftz.f32 	%f61, %f51, %f50, %f61;
	@%p20 bra 	$L__BB5_21;

	setp.eq.s32 	%p21, %r17, 5;
	add.s64 	%rd13, %rd12, %rd4;
	ld.const.f32 	%f52, [%rd9+16];
	ld.global.nc.f32 	%f53, [%rd13];
	fma.rn.ftz.f32 	%f61, %f53, %f52, %f61;
	@%p21 bra 	$L__BB5_21;

	setp.eq.s32 	%p22, %r17, 6;
	add.s64 	%rd14, %rd13, %rd4;
	ld.const.f32 	%f54, [%rd9+20];
	ld.global.nc.f32 	%f55, [%rd14];
	fma.rn.ftz.f32 	%f61, %f55, %f54, %f61;
	@%p22 bra 	$L__BB5_21;

	add.s64 	%rd42, %rd14, %rd4;
	ld.const.f32 	%f56, [%rd9+24];
	ld.global.nc.f32 	%f57, [%rd42];
	fma.rn.ftz.f32 	%f61, %f57, %f56, %f61;

$L__BB5_21:
	st.global.f32 	[%rd5], %f61;

$L__BB5_23:
	add.s32 	%r58, %r58, %r7;
	setp.lt.s32 	%p23, %r58, %r32;
	@%p23 bra 	$L__BB5_9;
	bra.uni 	$L__BB5_24;

$L__BB5_3:
	add.s32 	%r36, %r7, %r32;
	add.s32 	%r37, %r58, %r7;
	not.b32 	%r38, %r37;
	add.s32 	%r39, %r36, %r38;
	div.u32 	%r8, %r39, %r7;
	add.s32 	%r40, %r8, 1;
	and.b32  	%r57, %r40, 3;
	setp.eq.s32 	%p4, %r57, 0;
	@%p4 bra 	$L__BB5_5;

$L__BB5_4:
	.pragma "nounroll";
	mad.lo.s32 	%r41, %r58, %r31, %r1;
	mul.wide.s32 	%rd21, %r41, 4;
	add.s64 	%rd22, %rd2, %rd21;
	setp.lt.s32 	%p5, %r58, %r3;
	selp.f32 	%f13, 0f7FFFFFFF, 0f00000000, %p5;
	st.global.f32 	[%rd22], %f13;
	add.s32 	%r58, %r58, %r7;
	add.s32 	%r57, %r57, -1;
	setp.ne.s32 	%p6, %r57, 0;
	@%p6 bra 	$L__BB5_4;

$L__BB5_5:
	setp.lt.u32 	%p7, %r8, 3;
	@%p7 bra 	$L__BB5_24;

	mul.lo.s32 	%r42, %r4, %r6;
	mul.lo.s32 	%r43, %r42, %r31;
	mul.wide.s32 	%rd3, %r43, 4;

$L__BB5_7:
	mad.lo.s32 	%r44, %r58, %r31, %r1;
	mul.wide.s32 	%rd23, %r44, 4;
	add.s64 	%rd24, %rd2, %rd23;
	setp.lt.s32 	%p8, %r58, %r3;
	selp.f32 	%f14, 0f7FFFFFFF, 0f00000000, %p8;
	st.global.f32 	[%rd24], %f14;
	add.s32 	%r45, %r58, %r7;
	setp.lt.s32 	%p9, %r45, %r3;
	selp.f32 	%f15, 0f7FFFFFFF, 0f00000000, %p9;
	add.s64 	%rd25, %rd24, %rd3;
	st.global.f32 	[%rd25], %f15;
	add.s32 	%r46, %r45, %r7;
	setp.lt.s32 	%p10, %r46, %r3;
	selp.f32 	%f16, 0f7FFFFFFF, 0f00000000, %p10;
	add.s64 	%rd26, %rd25, %rd3;
	st.global.f32 	[%rd26], %f16;
	add.s32 	%r47, %r46, %r7;
	setp.lt.s32 	%p11, %r47, %r3;
	selp.f32 	%f17, 0f7FFFFFFF, 0f00000000, %p11;
	add.s64 	%rd27, %rd26, %rd3;
	st.global.f32 	[%rd27], %f17;
	add.s32 	%r58, %r47, %r7;
	setp.lt.s32 	%p12, %r58, %r32;
	@%p12 bra 	$L__BB5_7;

$L__BB5_24:
	ret;

}

