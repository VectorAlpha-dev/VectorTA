







.version 9.0
.target sm_89
.address_size 64


.func  (.param .align 8 .b8 func_retval0[16]) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0
)
;
.extern .shared .align 16 .b8 sdata[];
.global .align 16 .b8 __cudart_sin_cos_coeffs[128] = {70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};
.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry reflex_batch_f32(
	.param .u64 reflex_batch_f32_param_0,
	.param .u64 reflex_batch_f32_param_1,
	.param .u32 reflex_batch_f32_param_2,
	.param .u32 reflex_batch_f32_param_3,
	.param .u32 reflex_batch_f32_param_4,
	.param .u64 reflex_batch_f32_param_5
)
{
	.reg .pred 	%p<83>;
	.reg .f32 	%f<69>;
	.reg .b32 	%r<312>;
	.reg .f64 	%fd<356>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd11, [reflex_batch_f32_param_0];
	ld.param.u64 	%rd12, [reflex_batch_f32_param_1];
	ld.param.u32 	%r90, [reflex_batch_f32_param_2];
	ld.param.u32 	%r91, [reflex_batch_f32_param_3];
	ld.param.u64 	%rd13, [reflex_batch_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd13;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r91;
	mov.u32 	%r92, %tid.x;
	setp.ne.s32 	%p2, %r92, 0;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB0_76;

	mul.wide.s32 	%rd15, %r1, 4;
	add.s64 	%rd14, %rd12, %rd15;

	ld.global.nc.s32 %r93, [%rd14];

	setp.lt.s32 	%p4, %r93, 2;
	setp.lt.s32 	%p5, %r90, 1;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB0_76;

	mul.lo.s32 	%r94, %r1, %r90;
	cvt.s64.s32 	%rd2, %r94;
	min.s32 	%r3, %r93, %r90;
	setp.lt.s32 	%p7, %r3, 1;
	@%p7 bra 	$L__BB0_9;

	add.s32 	%r96, %r3, -1;
	and.b32  	%r277, %r3, 3;
	setp.lt.u32 	%p8, %r96, 3;
	mov.u32 	%r276, 0;
	@%p8 bra 	$L__BB0_6;

	sub.s32 	%r275, %r3, %r277;
	mov.u32 	%r97, 0;
	mov.u32 	%r276, %r97;

$L__BB0_5:
	cvt.s64.s32 	%rd16, %r276;
	add.s64 	%rd17, %rd16, %rd2;
	shl.b64 	%rd18, %rd17, 2;
	add.s64 	%rd19, %rd1, %rd18;
	st.global.u32 	[%rd19], %r97;
	st.global.u32 	[%rd19+4], %r97;
	st.global.u32 	[%rd19+8], %r97;
	st.global.u32 	[%rd19+12], %r97;
	add.s32 	%r276, %r276, 4;
	add.s32 	%r275, %r275, -4;
	setp.ne.s32 	%p9, %r275, 0;
	@%p9 bra 	$L__BB0_5;

$L__BB0_6:
	setp.eq.s32 	%p10, %r277, 0;
	@%p10 bra 	$L__BB0_9;

	cvt.s64.s32 	%rd20, %r276;
	add.s64 	%rd21, %rd20, %rd2;
	shl.b64 	%rd22, %rd21, 2;
	add.s64 	%rd47, %rd1, %rd22;

$L__BB0_8:
	.pragma "nounroll";
	mov.u32 	%r99, 0;
	st.global.u32 	[%rd47], %r99;
	add.s64 	%rd47, %rd47, 4;
	add.s32 	%r277, %r277, -1;
	setp.ne.s32 	%p11, %r277, 0;
	@%p11 bra 	$L__BB0_8;

$L__BB0_9:
	shr.u32 	%r100, %r93, 31;
	add.s32 	%r101, %r93, %r100;
	shr.s32 	%r102, %r101, 1;
	max.s32 	%r103, %r102, 1;
	cvt.rn.f64.s32 	%fd1, %r103;
	mov.f64 	%fd112, 0dC011C4D339C8C6CB;
	div.rn.f64 	%fd2, %fd112, %fd1;
	mov.f64 	%fd113, 0d4338000000000000;
	mov.f64 	%fd114, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd115, %fd2, %fd114, %fd113;
	{
	.reg .b32 %temp;
	mov.b64 	{%r13, %temp}, %fd115;
	}
	mov.f64 	%fd116, 0dC338000000000000;
	add.rn.f64 	%fd117, %fd115, %fd116;
	mov.f64 	%fd118, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd119, %fd117, %fd118, %fd2;
	mov.f64 	%fd120, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd121, %fd117, %fd120, %fd119;
	mov.f64 	%fd122, 0d3E928AF3FCA213EA;
	mov.f64 	%fd123, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd124, %fd123, %fd121, %fd122;
	mov.f64 	%fd125, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd126, %fd124, %fd121, %fd125;
	mov.f64 	%fd127, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd128, %fd126, %fd121, %fd127;
	mov.f64 	%fd129, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd130, %fd128, %fd121, %fd129;
	mov.f64 	%fd131, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd132, %fd130, %fd121, %fd131;
	mov.f64 	%fd133, 0d3F81111111122322;
	fma.rn.f64 	%fd134, %fd132, %fd121, %fd133;
	mov.f64 	%fd135, 0d3FA55555555502A1;
	fma.rn.f64 	%fd136, %fd134, %fd121, %fd135;
	mov.f64 	%fd137, 0d3FC5555555555511;
	fma.rn.f64 	%fd138, %fd136, %fd121, %fd137;
	mov.f64 	%fd139, 0d3FE000000000000B;
	fma.rn.f64 	%fd140, %fd138, %fd121, %fd139;
	mov.f64 	%fd141, 0d3FF0000000000000;
	fma.rn.f64 	%fd142, %fd140, %fd121, %fd141;
	fma.rn.f64 	%fd143, %fd142, %fd121, %fd141;
	{
	.reg .b32 %temp;
	mov.b64 	{%r14, %temp}, %fd143;
	}
	{
	.reg .b32 %temp;
	mov.b64 	{%temp, %r15}, %fd143;
	}
	shl.b32 	%r104, %r13, 20;
	add.s32 	%r105, %r15, %r104;
	mov.b64 	%fd320, {%r14, %r105};
	{
	.reg .b32 %temp;
	mov.b64 	{%temp, %r106}, %fd2;
	}
	mov.b32 	%f16, %r106;
	abs.ftz.f32 	%f1, %f16;
	setp.lt.ftz.f32 	%p12, %f1, 0f4086232B;
	@%p12 bra 	$L__BB0_12;

	setp.lt.f64 	%p13, %fd2, 0d0000000000000000;
	add.f64 	%fd144, %fd2, 0d7FF0000000000000;
	selp.f64 	%fd320, 0d0000000000000000, %fd144, %p13;
	setp.geu.ftz.f32 	%p14, %f1, 0f40874800;
	@%p14 bra 	$L__BB0_12;

	mov.f64 	%fd295, 0d4338000000000000;
	mov.f64 	%fd294, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd293, %fd2, %fd294, %fd295;
	{
	.reg .b32 %temp;
	mov.b64 	{%r268, %temp}, %fd293;
	}
	shr.u32 	%r107, %r268, 31;
	add.s32 	%r108, %r268, %r107;
	shr.s32 	%r109, %r108, 1;
	shl.b32 	%r110, %r109, 20;
	add.s32 	%r111, %r15, %r110;
	mov.b64 	%fd145, {%r14, %r111};
	sub.s32 	%r112, %r268, %r109;
	shl.b32 	%r113, %r112, 20;
	add.s32 	%r114, %r113, 1072693248;
	mov.u32 	%r115, 0;
	mov.b64 	%fd146, {%r115, %r114};
	mul.f64 	%fd320, %fd145, %fd146;

$L__BB0_12:
	mul.f64 	%fd7, %fd320, %fd320;
	mov.f64 	%fd147, 0d4011C4D339C8C6CB;
	div.rn.f64 	%fd8, %fd147, %fd1;
	abs.f64 	%fd9, %fd8;
	setp.eq.f64 	%p15, %fd9, 0d7FF0000000000000;
	@%p15 bra 	$L__BB0_15;
	bra.uni 	$L__BB0_13;

$L__BB0_15:
	mov.f64 	%fd156, 0d0000000000000000;
	mul.rn.f64 	%fd321, %fd8, %fd156;
	mov.u32 	%r278, 0;
	bra.uni 	$L__BB0_16;

$L__BB0_13:
	mul.f64 	%fd148, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r278, %fd148;
	cvt.rn.f64.s32 	%fd149, %r278;
	neg.f64 	%fd150, %fd149;
	mov.f64 	%fd151, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd152, %fd150, %fd151, %fd8;
	mov.f64 	%fd153, 0d3C91A62633145C00;
	fma.rn.f64 	%fd154, %fd150, %fd153, %fd152;
	mov.f64 	%fd155, 0d397B839A252049C0;
	fma.rn.f64 	%fd321, %fd150, %fd155, %fd154;
	setp.ltu.f64 	%p16, %fd9, 0d41E0000000000000;
	@%p16 bra 	$L__BB0_16;

	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .align 8 .b8 retval0[16];
	call.uni (retval0),
	__internal_trig_reduction_slowpathd,
	(
	param0
	);
	ld.param.f64 	%fd321, [retval0+0];
	ld.param.b32 	%r278, [retval0+8];
	}

$L__BB0_16:
	add.s32 	%r19, %r278, 1;
	and.b32  	%r117, %r19, 1;
	shl.b32 	%r118, %r19, 3;
	and.b32  	%r119, %r118, 8;
	mul.wide.u32 	%rd23, %r119, 8;
	mov.u64 	%rd24, __cudart_sin_cos_coeffs;
	add.s64 	%rd25, %rd24, %rd23;
	setp.eq.s32 	%p17, %r117, 0;
	selp.f64 	%fd157, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	ld.global.nc.v2.f64 	{%fd158, %fd159}, [%rd25];
	mul.rn.f64 	%fd14, %fd321, %fd321;
	fma.rn.f64 	%fd162, %fd157, %fd14, %fd158;
	fma.rn.f64 	%fd163, %fd162, %fd14, %fd159;
	ld.global.nc.v2.f64 	{%fd164, %fd165}, [%rd25+16];
	fma.rn.f64 	%fd168, %fd163, %fd14, %fd164;
	fma.rn.f64 	%fd169, %fd168, %fd14, %fd165;
	ld.global.nc.v2.f64 	{%fd170, %fd171}, [%rd25+32];
	fma.rn.f64 	%fd174, %fd169, %fd14, %fd170;
	fma.rn.f64 	%fd15, %fd174, %fd14, %fd171;
	fma.rn.f64 	%fd323, %fd15, %fd321, %fd321;
	@%p17 bra 	$L__BB0_18;

	mov.f64 	%fd175, 0d3FF0000000000000;
	fma.rn.f64 	%fd323, %fd15, %fd14, %fd175;

$L__BB0_18:
	and.b32  	%r120, %r19, 2;
	setp.eq.s32 	%p18, %r120, 0;
	@%p18 bra 	$L__BB0_20;

	mov.f64 	%fd176, 0d0000000000000000;
	mov.f64 	%fd177, 0dBFF0000000000000;
	fma.rn.f64 	%fd323, %fd323, %fd177, %fd176;

$L__BB0_20:
	setp.lt.s32 	%p81, %r90, 1;
	add.f64 	%fd178, %fd7, 0d3FF0000000000000;
	add.f64 	%fd179, %fd320, %fd320;
	mul.f64 	%fd21, %fd179, %fd323;
	sub.f64 	%fd180, %fd178, %fd21;
	mul.f64 	%fd22, %fd180, 0d3FE0000000000000;
	add.s32 	%r20, %r93, 1;
	@%p81 bra 	$L__BB0_22;


	ld.global.nc.f32 %f17, [%rd11];

	cvt.ftz.f64.f32 	%fd181, %f17;
	st.shared.f64 	[sdata], %fd181;

$L__BB0_22:
	setp.lt.s32 	%p20, %r90, 2;
	@%p20 bra 	$L__BB0_24;

	add.s64 	%rd27, %rd11, 4;

	ld.global.nc.f32 %f18, [%rd27];

	cvt.ftz.f64.f32 	%fd182, %f18;
	st.shared.f64 	[sdata+8], %fd182;

$L__BB0_24:
	setp.lt.s32 	%p82, %r90, 1;
	mov.f64 	%fd325, 0d0000000000000000;
	mov.f64 	%fd324, %fd325;
	@%p82 bra 	$L__BB0_26;

	ld.shared.f64 	%fd324, [sdata];

$L__BB0_26:
	@%p20 bra 	$L__BB0_28;

	ld.shared.f64 	%fd325, [sdata+8];

$L__BB0_28:
	add.f64 	%fd353, %fd324, %fd325;
	cvt.rn.f64.s32 	%fd186, %r93;
	rcp.rn.f64 	%fd28, %fd186;
	mov.f64 	%fd187, 0d3FF0000000000000;
	add.f64 	%fd188, %fd28, 0d3FF0000000000000;
	mul.f64 	%fd29, %fd188, 0d3FE0000000000000;
	sub.f64 	%fd30, %fd187, %fd29;
	mov.f64 	%fd355, 0d0000000000000000;
	@%p20 bra 	$L__BB0_30;

	add.s64 	%rd28, %rd11, 4;

	ld.global.nc.f32 %f19, [%rd28];

	cvt.ftz.f64.f32 	%fd355, %f19;

$L__BB0_30:
	setp.lt.s32 	%p24, %r90, 3;
	@%p24 bra 	$L__BB0_76;

	neg.f64 	%fd33, %fd7;
	mov.f64 	%fd334, 0d0000000000000000;
	mov.u32 	%r311, 2;
	mov.u32 	%r308, 1;
	mov.u32 	%r290, 0;
	mov.u32 	%r309, %r290;
	mov.u32 	%r307, %r311;

$L__BB0_32:
	setp.ge.s32 	%p25, %r311, %r90;
	@%p25 bra 	$L__BB0_75;

	sub.s32 	%r127, %r311, %r90;
	setp.gt.u32 	%p26, %r127, -4;
	neg.s32 	%r128, %r127;
	selp.b32 	%r26, %r128, 4, %p26;
	and.b32  	%r27, %r26, 3;
	mov.u32 	%r298, %r311;
	@%p26 bra 	$L__BB0_56;

	sub.s32 	%r289, %r26, %r27;
	mov.u32 	%r298, %r311;

$L__BB0_35:
	.pragma "nounroll";
	cvt.s64.s32 	%rd6, %r298;
	mul.wide.s32 	%rd30, %r298, 4;
	add.s64 	%rd29, %rd11, %rd30;

	ld.global.nc.f32 %f20, [%rd29];

	cvt.ftz.f64.f32 	%fd40, %f20;
	add.f64 	%fd191, %fd355, %fd40;
	mul.f64 	%fd192, %fd22, %fd191;
	shl.b32 	%r129, %r309, 3;
	mov.u32 	%r130, sdata;
	add.s32 	%r131, %r130, %r129;
	ld.shared.f64 	%fd193, [%r131];
	fma.rn.f64 	%fd194, %fd33, %fd193, %fd192;
	shl.b32 	%r132, %r308, 3;
	add.s32 	%r133, %r130, %r132;
	ld.shared.f64 	%fd195, [%r133];
	fma.rn.f64 	%fd333, %fd21, %fd195, %fd194;
	shl.b32 	%r134, %r307, 3;
	add.s32 	%r135, %r130, %r134;
	st.shared.f64 	[%r135], %fd333;
	add.s64 	%rd31, %rd6, %rd2;
	shl.b64 	%rd32, %rd31, 2;
	add.s64 	%rd8, %rd1, %rd32;
	setp.lt.s32 	%p27, %r298, %r93;
	@%p27 bra 	$L__BB0_40;

	mov.f32 	%f62, 0f00000000;
	shl.b32 	%r136, %r290, 3;
	add.s32 	%r138, %r130, %r136;
	ld.shared.f64 	%fd42, [%r138];
	mul.f64 	%fd196, %fd29, %fd42;
	fma.rn.f64 	%fd197, %fd30, %fd333, %fd196;
	mul.f64 	%fd198, %fd28, %fd353;
	sub.f64 	%fd43, %fd197, %fd198;
	mul.f64 	%fd199, %fd43, 0d3FA47AE147AE147B;
	mul.f64 	%fd200, %fd43, %fd199;
	mov.f64 	%fd201, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd334, %fd201, %fd334, %fd200;
	setp.leu.f64 	%p28, %fd334, 0d0000000000000000;
	@%p28 bra 	$L__BB0_39;

	mov.f32 	%f62, 0f00000000;
	abs.f64 	%fd202, %fd334;
	setp.geu.f64 	%p29, %fd202, 0d7FF0000000000000;
	@%p29 bra 	$L__BB0_39;

	mul.f64 	%fd292, %fd29, %fd42;
	mul.f64 	%fd291, %fd28, %fd353;
	fma.rn.f64 	%fd290, %fd30, %fd333, %fd292;
	sub.f64 	%fd289, %fd290, %fd291;
	sqrt.rn.f64 	%fd203, %fd334;
	div.rn.f64 	%fd204, %fd289, %fd203;
	cvt.rn.ftz.f32.f64 	%f62, %fd204;

$L__BB0_39:
	st.global.f32 	[%rd8], %f62;
	sub.f64 	%fd333, %fd333, %fd42;
	add.s32 	%r139, %r290, 1;
	setp.eq.s32 	%p30, %r139, %r20;
	selp.b32 	%r140, %r20, 0, %p30;
	sub.s32 	%r290, %r139, %r140;

$L__BB0_40:
	mov.u32 	%r262, sdata;
	add.f64 	%fd48, %fd353, %fd333;
	add.s32 	%r141, %r307, 1;
	setp.eq.s32 	%p31, %r141, %r20;
	selp.b32 	%r142, %r20, 0, %p31;
	sub.s32 	%r37, %r141, %r142;
	add.s32 	%r143, %r308, 1;
	setp.eq.s32 	%p32, %r143, %r20;
	selp.b32 	%r144, %r20, 0, %p32;
	sub.s32 	%r38, %r143, %r144;
	add.s32 	%r145, %r309, 1;
	setp.eq.s32 	%p33, %r145, %r20;
	selp.b32 	%r146, %r20, 0, %p33;
	sub.s32 	%r39, %r145, %r146;
	cvt.u32.u64 	%r147, %rd6;
	add.s32 	%r148, %r147, 1;
	add.s64 	%rd33, %rd29, 4;

	ld.global.nc.f32 %f23, [%rd33];

	cvt.ftz.f64.f32 	%fd49, %f23;
	shl.b32 	%r149, %r38, 3;
	add.s32 	%r151, %r262, %r149;
	shl.b32 	%r152, %r39, 3;
	add.s32 	%r153, %r262, %r152;
	add.f64 	%fd205, %fd40, %fd49;
	mul.f64 	%fd206, %fd22, %fd205;
	ld.shared.f64 	%fd207, [%r153];
	fma.rn.f64 	%fd208, %fd33, %fd207, %fd206;
	ld.shared.f64 	%fd209, [%r151];
	fma.rn.f64 	%fd335, %fd21, %fd209, %fd208;
	shl.b32 	%r154, %r37, 3;
	add.s32 	%r155, %r262, %r154;
	st.shared.f64 	[%r155], %fd335;
	setp.lt.s32 	%p34, %r148, %r93;
	@%p34 bra 	$L__BB0_45;

	mov.f32 	%f63, 0f00000000;
	mov.u32 	%r263, sdata;
	shl.b32 	%r156, %r290, 3;
	add.s32 	%r158, %r263, %r156;
	ld.shared.f64 	%fd51, [%r158];
	mul.f64 	%fd210, %fd29, %fd51;
	fma.rn.f64 	%fd211, %fd30, %fd335, %fd210;
	mul.f64 	%fd212, %fd28, %fd48;
	sub.f64 	%fd52, %fd211, %fd212;
	mul.f64 	%fd213, %fd52, 0d3FA47AE147AE147B;
	mul.f64 	%fd214, %fd52, %fd213;
	mov.f64 	%fd215, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd334, %fd215, %fd334, %fd214;
	setp.leu.f64 	%p35, %fd334, 0d0000000000000000;
	@%p35 bra 	$L__BB0_44;

	mov.f32 	%f63, 0f00000000;
	abs.f64 	%fd216, %fd334;
	setp.geu.f64 	%p36, %fd216, 0d7FF0000000000000;
	@%p36 bra 	$L__BB0_44;

	mul.f64 	%fd299, %fd29, %fd51;
	mul.f64 	%fd298, %fd28, %fd48;
	fma.rn.f64 	%fd297, %fd30, %fd335, %fd299;
	sub.f64 	%fd296, %fd297, %fd298;
	sqrt.rn.f64 	%fd217, %fd334;
	div.rn.f64 	%fd218, %fd296, %fd217;
	cvt.rn.ftz.f32.f64 	%f63, %fd218;

$L__BB0_44:
	st.global.f32 	[%rd8+4], %f63;
	sub.f64 	%fd335, %fd335, %fd51;
	add.s32 	%r159, %r290, 1;
	setp.eq.s32 	%p37, %r159, %r20;
	selp.b32 	%r160, %r20, 0, %p37;
	sub.s32 	%r290, %r159, %r160;

$L__BB0_45:
	mov.u32 	%r264, sdata;
	add.f64 	%fd57, %fd48, %fd335;
	add.s32 	%r161, %r37, 1;
	setp.eq.s32 	%p38, %r161, %r20;
	selp.b32 	%r162, %r20, 0, %p38;
	sub.s32 	%r42, %r161, %r162;
	add.s32 	%r163, %r38, 1;
	setp.eq.s32 	%p39, %r163, %r20;
	selp.b32 	%r164, %r20, 0, %p39;
	sub.s32 	%r43, %r163, %r164;
	add.s32 	%r165, %r39, 1;
	setp.eq.s32 	%p40, %r165, %r20;
	selp.b32 	%r166, %r20, 0, %p40;
	sub.s32 	%r44, %r165, %r166;
	add.s32 	%r168, %r147, 2;
	add.s64 	%rd34, %rd29, 8;

	ld.global.nc.f32 %f26, [%rd34];

	cvt.ftz.f64.f32 	%fd58, %f26;
	shl.b32 	%r169, %r43, 3;
	add.s32 	%r171, %r264, %r169;
	shl.b32 	%r172, %r44, 3;
	add.s32 	%r173, %r264, %r172;
	add.f64 	%fd219, %fd49, %fd58;
	mul.f64 	%fd220, %fd22, %fd219;
	ld.shared.f64 	%fd221, [%r173];
	fma.rn.f64 	%fd222, %fd33, %fd221, %fd220;
	ld.shared.f64 	%fd223, [%r171];
	fma.rn.f64 	%fd337, %fd21, %fd223, %fd222;
	shl.b32 	%r174, %r42, 3;
	add.s32 	%r175, %r264, %r174;
	st.shared.f64 	[%r175], %fd337;
	setp.lt.s32 	%p41, %r168, %r93;
	@%p41 bra 	$L__BB0_50;

	mov.f32 	%f64, 0f00000000;
	mov.u32 	%r265, sdata;
	shl.b32 	%r176, %r290, 3;
	add.s32 	%r178, %r265, %r176;
	ld.shared.f64 	%fd60, [%r178];
	mul.f64 	%fd224, %fd29, %fd60;
	fma.rn.f64 	%fd225, %fd30, %fd337, %fd224;
	mul.f64 	%fd226, %fd28, %fd57;
	sub.f64 	%fd61, %fd225, %fd226;
	mul.f64 	%fd227, %fd61, 0d3FA47AE147AE147B;
	mul.f64 	%fd228, %fd61, %fd227;
	mov.f64 	%fd229, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd334, %fd229, %fd334, %fd228;
	setp.leu.f64 	%p42, %fd334, 0d0000000000000000;
	@%p42 bra 	$L__BB0_49;

	mov.f32 	%f64, 0f00000000;
	abs.f64 	%fd230, %fd334;
	setp.geu.f64 	%p43, %fd230, 0d7FF0000000000000;
	@%p43 bra 	$L__BB0_49;

	mul.f64 	%fd303, %fd29, %fd60;
	mul.f64 	%fd302, %fd28, %fd57;
	fma.rn.f64 	%fd301, %fd30, %fd337, %fd303;
	sub.f64 	%fd300, %fd301, %fd302;
	sqrt.rn.f64 	%fd231, %fd334;
	div.rn.f64 	%fd232, %fd300, %fd231;
	cvt.rn.ftz.f32.f64 	%f64, %fd232;

$L__BB0_49:
	st.global.f32 	[%rd8+8], %f64;
	sub.f64 	%fd337, %fd337, %fd60;
	add.s32 	%r179, %r290, 1;
	setp.eq.s32 	%p44, %r179, %r20;
	selp.b32 	%r180, %r20, 0, %p44;
	sub.s32 	%r290, %r179, %r180;

$L__BB0_50:
	mov.u32 	%r266, sdata;
	add.f64 	%fd66, %fd57, %fd337;
	add.s32 	%r181, %r42, 1;
	setp.eq.s32 	%p45, %r181, %r20;
	selp.b32 	%r182, %r20, 0, %p45;
	sub.s32 	%r47, %r181, %r182;
	add.s32 	%r183, %r43, 1;
	setp.eq.s32 	%p46, %r183, %r20;
	selp.b32 	%r184, %r20, 0, %p46;
	sub.s32 	%r48, %r183, %r184;
	add.s32 	%r185, %r44, 1;
	setp.eq.s32 	%p47, %r185, %r20;
	selp.b32 	%r186, %r20, 0, %p47;
	sub.s32 	%r49, %r185, %r186;
	add.s32 	%r188, %r147, 3;
	add.s64 	%rd35, %rd29, 12;

	ld.global.nc.f32 %f29, [%rd35];

	cvt.ftz.f64.f32 	%fd355, %f29;
	shl.b32 	%r189, %r48, 3;
	add.s32 	%r191, %r266, %r189;
	shl.b32 	%r192, %r49, 3;
	add.s32 	%r193, %r266, %r192;
	add.f64 	%fd233, %fd58, %fd355;
	mul.f64 	%fd234, %fd22, %fd233;
	ld.shared.f64 	%fd235, [%r193];
	fma.rn.f64 	%fd236, %fd33, %fd235, %fd234;
	ld.shared.f64 	%fd237, [%r191];
	fma.rn.f64 	%fd339, %fd21, %fd237, %fd236;
	shl.b32 	%r194, %r47, 3;
	add.s32 	%r195, %r266, %r194;
	st.shared.f64 	[%r195], %fd339;
	setp.lt.s32 	%p48, %r188, %r93;
	@%p48 bra 	$L__BB0_55;

	mov.f32 	%f65, 0f00000000;
	mov.u32 	%r267, sdata;
	shl.b32 	%r196, %r290, 3;
	add.s32 	%r198, %r267, %r196;
	ld.shared.f64 	%fd69, [%r198];
	mul.f64 	%fd238, %fd29, %fd69;
	fma.rn.f64 	%fd239, %fd30, %fd339, %fd238;
	mul.f64 	%fd240, %fd28, %fd66;
	sub.f64 	%fd70, %fd239, %fd240;
	mul.f64 	%fd241, %fd70, 0d3FA47AE147AE147B;
	mul.f64 	%fd242, %fd70, %fd241;
	mov.f64 	%fd243, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd334, %fd243, %fd334, %fd242;
	setp.leu.f64 	%p49, %fd334, 0d0000000000000000;
	@%p49 bra 	$L__BB0_54;

	mov.f32 	%f65, 0f00000000;
	abs.f64 	%fd244, %fd334;
	setp.geu.f64 	%p50, %fd244, 0d7FF0000000000000;
	@%p50 bra 	$L__BB0_54;

	mul.f64 	%fd307, %fd29, %fd69;
	mul.f64 	%fd306, %fd28, %fd66;
	fma.rn.f64 	%fd305, %fd30, %fd339, %fd307;
	sub.f64 	%fd304, %fd305, %fd306;
	sqrt.rn.f64 	%fd245, %fd334;
	div.rn.f64 	%fd246, %fd304, %fd245;
	cvt.rn.ftz.f32.f64 	%f65, %fd246;

$L__BB0_54:
	st.global.f32 	[%rd8+12], %f65;
	sub.f64 	%fd339, %fd339, %fd69;
	add.s32 	%r199, %r290, 1;
	setp.eq.s32 	%p51, %r199, %r20;
	selp.b32 	%r200, %r20, 0, %p51;
	sub.s32 	%r290, %r199, %r200;

$L__BB0_55:
	add.f64 	%fd353, %fd66, %fd339;
	add.s32 	%r201, %r47, 1;
	setp.eq.s32 	%p52, %r201, %r20;
	selp.b32 	%r202, %r20, 0, %p52;
	sub.s32 	%r307, %r201, %r202;
	add.s32 	%r203, %r48, 1;
	setp.eq.s32 	%p53, %r203, %r20;
	selp.b32 	%r204, %r20, 0, %p53;
	sub.s32 	%r308, %r203, %r204;
	add.s32 	%r205, %r49, 1;
	setp.eq.s32 	%p54, %r205, %r20;
	selp.b32 	%r206, %r20, 0, %p54;
	sub.s32 	%r309, %r205, %r206;
	add.s32 	%r298, %r147, 4;
	add.s32 	%r289, %r289, -4;
	setp.ne.s32 	%p55, %r289, 0;
	@%p55 bra 	$L__BB0_35;

$L__BB0_56:
	setp.eq.s32 	%p56, %r27, 0;
	mov.u32 	%r311, %r298;
	@%p56 bra 	$L__BB0_75;

	cvt.s64.s32 	%rd37, %r298;
	mul.wide.s32 	%rd38, %r298, 4;
	add.s64 	%rd36, %rd11, %rd38;

	ld.global.nc.f32 %f32, [%rd36];

	cvt.ftz.f64.f32 	%fd82, %f32;
	add.f64 	%fd247, %fd355, %fd82;
	mul.f64 	%fd248, %fd22, %fd247;
	shl.b32 	%r208, %r309, 3;
	mov.u32 	%r209, sdata;
	add.s32 	%r210, %r209, %r208;
	ld.shared.f64 	%fd249, [%r210];
	fma.rn.f64 	%fd250, %fd33, %fd249, %fd248;
	shl.b32 	%r211, %r308, 3;
	add.s32 	%r212, %r209, %r211;
	ld.shared.f64 	%fd251, [%r212];
	fma.rn.f64 	%fd347, %fd21, %fd251, %fd250;
	shl.b32 	%r213, %r307, 3;
	add.s32 	%r214, %r209, %r213;
	st.shared.f64 	[%r214], %fd347;
	add.s64 	%rd39, %rd37, %rd2;
	shl.b64 	%rd40, %rd39, 2;
	add.s64 	%rd10, %rd1, %rd40;
	setp.lt.s32 	%p57, %r298, %r93;
	@%p57 bra 	$L__BB0_62;

	mov.f32 	%f66, 0f00000000;
	mov.u32 	%r269, sdata;
	shl.b32 	%r215, %r290, 3;
	add.s32 	%r217, %r269, %r215;
	ld.shared.f64 	%fd84, [%r217];
	mul.f64 	%fd252, %fd29, %fd84;
	fma.rn.f64 	%fd253, %fd30, %fd347, %fd252;
	mul.f64 	%fd254, %fd28, %fd353;
	sub.f64 	%fd85, %fd253, %fd254;
	mul.f64 	%fd255, %fd85, 0d3FA47AE147AE147B;
	mul.f64 	%fd256, %fd85, %fd255;
	mov.f64 	%fd257, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd334, %fd257, %fd334, %fd256;
	setp.leu.f64 	%p58, %fd334, 0d0000000000000000;
	@%p58 bra 	$L__BB0_61;

	mov.f32 	%f66, 0f00000000;
	abs.f64 	%fd258, %fd334;
	setp.geu.f64 	%p59, %fd258, 0d7FF0000000000000;
	@%p59 bra 	$L__BB0_61;

	mul.f64 	%fd311, %fd29, %fd84;
	mul.f64 	%fd310, %fd28, %fd353;
	fma.rn.f64 	%fd309, %fd30, %fd347, %fd311;
	sub.f64 	%fd308, %fd309, %fd310;
	sqrt.rn.f64 	%fd259, %fd334;
	div.rn.f64 	%fd260, %fd308, %fd259;
	cvt.rn.ftz.f32.f64 	%f66, %fd260;

$L__BB0_61:
	st.global.f32 	[%rd10], %f66;
	sub.f64 	%fd347, %fd347, %fd84;
	add.s32 	%r218, %r290, 1;
	setp.eq.s32 	%p60, %r218, %r20;
	selp.b32 	%r219, %r20, 0, %p60;
	sub.s32 	%r290, %r218, %r219;

$L__BB0_62:
	add.f64 	%fd353, %fd353, %fd347;
	add.s32 	%r220, %r307, 1;
	setp.eq.s32 	%p61, %r220, %r20;
	selp.b32 	%r221, %r20, 0, %p61;
	sub.s32 	%r307, %r220, %r221;
	add.s32 	%r222, %r308, 1;
	setp.eq.s32 	%p62, %r222, %r20;
	selp.b32 	%r223, %r20, 0, %p62;
	sub.s32 	%r308, %r222, %r223;
	add.s32 	%r224, %r309, 1;
	setp.eq.s32 	%p63, %r224, %r20;
	selp.b32 	%r225, %r20, 0, %p63;
	sub.s32 	%r309, %r224, %r225;
	add.s32 	%r311, %r298, 1;
	setp.eq.s32 	%p64, %r27, 1;
	mov.f64 	%fd355, %fd82;
	@%p64 bra 	$L__BB0_75;

	mul.wide.s32 	%rd44, %r298, 4;
	add.s64 	%rd43, %rd11, %rd44;
	mov.u32 	%r270, sdata;
	add.s64 	%rd41, %rd43, 4;

	ld.global.nc.f32 %f35, [%rd41];

	cvt.ftz.f64.f32 	%fd355, %f35;
	add.f64 	%fd261, %fd82, %fd355;
	mul.f64 	%fd262, %fd22, %fd261;
	shl.b32 	%r226, %r309, 3;
	add.s32 	%r228, %r270, %r226;
	ld.shared.f64 	%fd263, [%r228];
	fma.rn.f64 	%fd264, %fd33, %fd263, %fd262;
	shl.b32 	%r229, %r308, 3;
	add.s32 	%r230, %r270, %r229;
	ld.shared.f64 	%fd265, [%r230];
	fma.rn.f64 	%fd349, %fd21, %fd265, %fd264;
	shl.b32 	%r231, %r307, 3;
	add.s32 	%r232, %r270, %r231;
	st.shared.f64 	[%r232], %fd349;
	setp.lt.s32 	%p65, %r311, %r93;
	@%p65 bra 	$L__BB0_68;

	mov.f32 	%f67, 0f00000000;
	mov.u32 	%r271, sdata;
	shl.b32 	%r233, %r290, 3;
	add.s32 	%r235, %r271, %r233;
	ld.shared.f64 	%fd93, [%r235];
	mul.f64 	%fd266, %fd29, %fd93;
	fma.rn.f64 	%fd267, %fd30, %fd349, %fd266;
	mul.f64 	%fd268, %fd28, %fd353;
	sub.f64 	%fd94, %fd267, %fd268;
	mul.f64 	%fd269, %fd94, 0d3FA47AE147AE147B;
	mul.f64 	%fd270, %fd94, %fd269;
	mov.f64 	%fd271, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd334, %fd271, %fd334, %fd270;
	setp.leu.f64 	%p66, %fd334, 0d0000000000000000;
	@%p66 bra 	$L__BB0_67;

	mov.f32 	%f67, 0f00000000;
	abs.f64 	%fd272, %fd334;
	setp.geu.f64 	%p67, %fd272, 0d7FF0000000000000;
	@%p67 bra 	$L__BB0_67;

	mul.f64 	%fd315, %fd29, %fd93;
	mul.f64 	%fd314, %fd28, %fd353;
	fma.rn.f64 	%fd313, %fd30, %fd349, %fd315;
	sub.f64 	%fd312, %fd313, %fd314;
	sqrt.rn.f64 	%fd273, %fd334;
	div.rn.f64 	%fd274, %fd312, %fd273;
	cvt.rn.ftz.f32.f64 	%f67, %fd274;

$L__BB0_67:
	st.global.f32 	[%rd10+4], %f67;
	sub.f64 	%fd349, %fd349, %fd93;
	add.s32 	%r236, %r290, 1;
	setp.eq.s32 	%p68, %r236, %r20;
	selp.b32 	%r237, %r20, 0, %p68;
	sub.s32 	%r290, %r236, %r237;

$L__BB0_68:
	add.f64 	%fd353, %fd353, %fd349;
	add.s32 	%r238, %r307, 1;
	setp.eq.s32 	%p69, %r238, %r20;
	selp.b32 	%r239, %r20, 0, %p69;
	sub.s32 	%r307, %r238, %r239;
	add.s32 	%r240, %r308, 1;
	setp.eq.s32 	%p70, %r240, %r20;
	selp.b32 	%r241, %r20, 0, %p70;
	sub.s32 	%r308, %r240, %r241;
	add.s32 	%r242, %r309, 1;
	setp.eq.s32 	%p71, %r242, %r20;
	selp.b32 	%r243, %r20, 0, %p71;
	sub.s32 	%r309, %r242, %r243;
	add.s32 	%r311, %r298, 2;
	setp.eq.s32 	%p72, %r27, 2;
	@%p72 bra 	$L__BB0_75;

	mul.wide.s32 	%rd46, %r298, 4;
	add.s64 	%rd45, %rd11, %rd46;
	mov.u32 	%r272, sdata;
	add.s64 	%rd42, %rd45, 8;

	ld.global.nc.f32 %f38, [%rd42];

	cvt.ftz.f64.f32 	%fd100, %f38;
	add.f64 	%fd275, %fd355, %fd100;
	mul.f64 	%fd276, %fd22, %fd275;
	shl.b32 	%r244, %r309, 3;
	add.s32 	%r246, %r272, %r244;
	ld.shared.f64 	%fd277, [%r246];
	fma.rn.f64 	%fd278, %fd33, %fd277, %fd276;
	shl.b32 	%r247, %r308, 3;
	add.s32 	%r248, %r272, %r247;
	ld.shared.f64 	%fd279, [%r248];
	fma.rn.f64 	%fd351, %fd21, %fd279, %fd278;
	shl.b32 	%r249, %r307, 3;
	add.s32 	%r250, %r272, %r249;
	st.shared.f64 	[%r250], %fd351;
	setp.lt.s32 	%p73, %r311, %r93;
	@%p73 bra 	$L__BB0_74;

	mov.f32 	%f68, 0f00000000;
	mov.u32 	%r273, sdata;
	shl.b32 	%r251, %r290, 3;
	add.s32 	%r253, %r273, %r251;
	ld.shared.f64 	%fd102, [%r253];
	mul.f64 	%fd280, %fd29, %fd102;
	fma.rn.f64 	%fd281, %fd30, %fd351, %fd280;
	mul.f64 	%fd282, %fd28, %fd353;
	sub.f64 	%fd103, %fd281, %fd282;
	mul.f64 	%fd283, %fd103, 0d3FA47AE147AE147B;
	mul.f64 	%fd284, %fd103, %fd283;
	mov.f64 	%fd285, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd334, %fd285, %fd334, %fd284;
	setp.leu.f64 	%p74, %fd334, 0d0000000000000000;
	@%p74 bra 	$L__BB0_73;

	mov.f32 	%f68, 0f00000000;
	abs.f64 	%fd286, %fd334;
	setp.geu.f64 	%p75, %fd286, 0d7FF0000000000000;
	@%p75 bra 	$L__BB0_73;

	mul.f64 	%fd319, %fd29, %fd102;
	mul.f64 	%fd318, %fd28, %fd353;
	fma.rn.f64 	%fd317, %fd30, %fd351, %fd319;
	sub.f64 	%fd316, %fd317, %fd318;
	sqrt.rn.f64 	%fd287, %fd334;
	div.rn.f64 	%fd288, %fd316, %fd287;
	cvt.rn.ftz.f32.f64 	%f68, %fd288;

$L__BB0_73:
	st.global.f32 	[%rd10+8], %f68;
	sub.f64 	%fd351, %fd351, %fd102;
	add.s32 	%r254, %r290, 1;
	setp.eq.s32 	%p76, %r254, %r20;
	selp.b32 	%r255, %r20, 0, %p76;
	sub.s32 	%r290, %r254, %r255;

$L__BB0_74:
	add.f64 	%fd353, %fd353, %fd351;
	add.s32 	%r256, %r307, 1;
	setp.eq.s32 	%p77, %r256, %r20;
	selp.b32 	%r257, %r20, 0, %p77;
	sub.s32 	%r307, %r256, %r257;
	add.s32 	%r258, %r308, 1;
	setp.eq.s32 	%p78, %r258, %r20;
	selp.b32 	%r259, %r20, 0, %p78;
	sub.s32 	%r308, %r258, %r259;
	add.s32 	%r260, %r309, 1;
	setp.eq.s32 	%p79, %r260, %r20;
	selp.b32 	%r261, %r20, 0, %p79;
	sub.s32 	%r309, %r260, %r261;
	add.s32 	%r311, %r298, 3;
	mov.f64 	%fd355, %fd100;

$L__BB0_75:
	setp.lt.s32 	%p80, %r311, %r90;
	@%p80 bra 	$L__BB0_32;

$L__BB0_76:
	ret;

}

.visible .entry reflex_batch_f32_precomp(
	.param .u64 reflex_batch_f32_precomp_param_0,
	.param .u64 reflex_batch_f32_precomp_param_1,
	.param .u64 reflex_batch_f32_precomp_param_2,
	.param .u64 reflex_batch_f32_precomp_param_3,
	.param .u64 reflex_batch_f32_precomp_param_4,
	.param .u32 reflex_batch_f32_precomp_param_5,
	.param .u32 reflex_batch_f32_precomp_param_6,
	.param .u32 reflex_batch_f32_precomp_param_7,
	.param .u64 reflex_batch_f32_precomp_param_8
)
{
	.reg .pred 	%p<74>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<282>;
	.reg .f64 	%fd<264>;
	.reg .b64 	%rd<53>;


	ld.param.u64 	%rd12, [reflex_batch_f32_precomp_param_0];
	ld.param.u64 	%rd13, [reflex_batch_f32_precomp_param_1];
	ld.param.u64 	%rd14, [reflex_batch_f32_precomp_param_2];
	ld.param.u64 	%rd15, [reflex_batch_f32_precomp_param_3];
	ld.param.u64 	%rd16, [reflex_batch_f32_precomp_param_4];
	ld.param.u32 	%r83, [reflex_batch_f32_precomp_param_5];
	ld.param.u32 	%r84, [reflex_batch_f32_precomp_param_6];
	ld.param.u64 	%rd17, [reflex_batch_f32_precomp_param_8];
	cvta.to.global.u64 	%rd1, %rd17;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r84;
	mov.u32 	%r85, %tid.x;
	setp.ne.s32 	%p2, %r85, 0;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB1_65;

	cvt.s64.s32 	%rd2, %r1;
	mul.wide.s32 	%rd19, %r1, 4;
	add.s64 	%rd18, %rd13, %rd19;

	ld.global.nc.s32 %r86, [%rd18];

	setp.lt.s32 	%p4, %r86, 2;
	setp.lt.s32 	%p5, %r83, 1;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB1_65;

	mul.lo.s32 	%r87, %r1, %r83;
	cvt.s64.s32 	%rd3, %r87;
	min.s32 	%r3, %r86, %r83;
	setp.lt.s32 	%p7, %r3, 1;
	@%p7 bra 	$L__BB1_9;

	add.s32 	%r89, %r3, -1;
	and.b32  	%r248, %r3, 3;
	setp.lt.u32 	%p8, %r89, 3;
	mov.u32 	%r247, 0;
	@%p8 bra 	$L__BB1_6;

	sub.s32 	%r246, %r3, %r248;
	mov.u32 	%r90, 0;
	mov.u32 	%r247, %r90;

$L__BB1_5:
	cvt.s64.s32 	%rd20, %r247;
	add.s64 	%rd21, %rd20, %rd3;
	shl.b64 	%rd22, %rd21, 2;
	add.s64 	%rd23, %rd1, %rd22;
	st.global.u32 	[%rd23], %r90;
	st.global.u32 	[%rd23+4], %r90;
	st.global.u32 	[%rd23+8], %r90;
	st.global.u32 	[%rd23+12], %r90;
	add.s32 	%r247, %r247, 4;
	add.s32 	%r246, %r246, -4;
	setp.ne.s32 	%p9, %r246, 0;
	@%p9 bra 	$L__BB1_5;

$L__BB1_6:
	setp.eq.s32 	%p10, %r248, 0;
	@%p10 bra 	$L__BB1_9;

	cvt.s64.s32 	%rd24, %r247;
	add.s64 	%rd25, %rd24, %rd3;
	shl.b64 	%rd26, %rd25, 2;
	add.s64 	%rd52, %rd1, %rd26;

$L__BB1_8:
	.pragma "nounroll";
	mov.u32 	%r92, 0;
	st.global.u32 	[%rd52], %r92;
	add.s64 	%rd52, %rd52, 4;
	add.s32 	%r248, %r248, -1;
	setp.ne.s32 	%p11, %r248, 0;
	@%p11 bra 	$L__BB1_8;

$L__BB1_9:
	shl.b64 	%rd30, %rd2, 3;
	add.s64 	%rd27, %rd14, %rd30;

	ld.global.nc.f64 %fd93, [%rd27];

	add.s64 	%rd28, %rd15, %rd30;

	ld.global.nc.f64 %fd94, [%rd28];

	add.s64 	%rd29, %rd16, %rd30;

	ld.global.nc.f64 %fd95, [%rd29];

	add.s32 	%r13, %r86, 1;
	@%p5 bra 	$L__BB1_11;


	ld.global.nc.f32 %f15, [%rd12];

	cvt.ftz.f64.f32 	%fd96, %f15;
	st.shared.f64 	[sdata], %fd96;

$L__BB1_11:
	setp.lt.s32 	%p13, %r83, 2;
	@%p13 bra 	$L__BB1_13;

	add.s64 	%rd32, %rd12, 4;

	ld.global.nc.f32 %f16, [%rd32];

	cvt.ftz.f64.f32 	%fd97, %f16;
	st.shared.f64 	[sdata+8], %fd97;

$L__BB1_13:
	mov.f64 	%fd233, 0d0000000000000000;
	mov.f64 	%fd232, %fd233;
	@%p5 bra 	$L__BB1_15;

	ld.shared.f64 	%fd232, [sdata];

$L__BB1_15:
	@%p13 bra 	$L__BB1_17;

	ld.shared.f64 	%fd233, [sdata+8];

$L__BB1_17:
	add.f64 	%fd261, %fd232, %fd233;
	cvt.rn.f64.s32 	%fd101, %r86;
	rcp.rn.f64 	%fd9, %fd101;
	mov.f64 	%fd102, 0d3FF0000000000000;
	add.f64 	%fd103, %fd9, 0d3FF0000000000000;
	mul.f64 	%fd10, %fd103, 0d3FE0000000000000;
	sub.f64 	%fd11, %fd102, %fd10;
	mov.f64 	%fd263, 0d0000000000000000;
	@%p13 bra 	$L__BB1_19;

	add.s64 	%rd33, %rd12, 4;

	ld.global.nc.f32 %f17, [%rd33];

	cvt.ftz.f64.f32 	%fd263, %f17;

$L__BB1_19:
	setp.lt.s32 	%p17, %r83, 3;
	@%p17 bra 	$L__BB1_65;

	neg.f64 	%fd14, %fd93;
	mov.f64 	%fd242, 0d0000000000000000;
	mov.u32 	%r281, 2;
	mov.u32 	%r278, 1;
	mov.u32 	%r260, 0;
	mov.u32 	%r279, %r260;
	mov.u32 	%r277, %r281;

$L__BB1_21:
	setp.ge.s32 	%p18, %r281, %r83;
	@%p18 bra 	$L__BB1_64;

	sub.s32 	%r99, %r281, %r83;
	setp.gt.u32 	%p19, %r99, -4;
	neg.s32 	%r100, %r99;
	selp.b32 	%r19, %r100, 4, %p19;
	and.b32  	%r20, %r19, 3;
	mov.u32 	%r268, %r281;
	@%p19 bra 	$L__BB1_45;

	sub.s32 	%r259, %r19, %r20;
	mov.u32 	%r268, %r281;

$L__BB1_24:
	.pragma "nounroll";
	cvt.s64.s32 	%rd7, %r268;
	mul.wide.s32 	%rd35, %r268, 4;
	add.s64 	%rd34, %rd12, %rd35;

	ld.global.nc.f32 %f18, [%rd34];

	cvt.ftz.f64.f32 	%fd21, %f18;
	add.f64 	%fd106, %fd263, %fd21;
	mul.f64 	%fd107, %fd95, %fd106;
	shl.b32 	%r101, %r279, 3;
	mov.u32 	%r102, sdata;
	add.s32 	%r103, %r102, %r101;
	ld.shared.f64 	%fd108, [%r103];
	fma.rn.f64 	%fd109, %fd14, %fd108, %fd107;
	shl.b32 	%r104, %r278, 3;
	add.s32 	%r105, %r102, %r104;
	ld.shared.f64 	%fd110, [%r105];
	fma.rn.f64 	%fd241, %fd94, %fd110, %fd109;
	shl.b32 	%r106, %r277, 3;
	add.s32 	%r107, %r102, %r106;
	st.shared.f64 	[%r107], %fd241;
	add.s64 	%rd36, %rd7, %rd3;
	shl.b64 	%rd37, %rd36, 2;
	add.s64 	%rd9, %rd1, %rd37;
	setp.lt.s32 	%p20, %r268, %r86;
	@%p20 bra 	$L__BB1_29;

	mov.f32 	%f60, 0f00000000;
	shl.b32 	%r108, %r260, 3;
	add.s32 	%r110, %r102, %r108;
	ld.shared.f64 	%fd23, [%r110];
	mul.f64 	%fd111, %fd10, %fd23;
	fma.rn.f64 	%fd112, %fd11, %fd241, %fd111;
	mul.f64 	%fd113, %fd9, %fd261;
	sub.f64 	%fd24, %fd112, %fd113;
	mul.f64 	%fd114, %fd24, 0d3FA47AE147AE147B;
	mul.f64 	%fd115, %fd24, %fd114;
	mov.f64 	%fd116, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd242, %fd116, %fd242, %fd115;
	setp.leu.f64 	%p21, %fd242, 0d0000000000000000;
	@%p21 bra 	$L__BB1_28;

	mov.f32 	%f60, 0f00000000;
	abs.f64 	%fd117, %fd242;
	setp.geu.f64 	%p22, %fd117, 0d7FF0000000000000;
	@%p22 bra 	$L__BB1_28;

	mul.f64 	%fd207, %fd10, %fd23;
	mul.f64 	%fd206, %fd9, %fd261;
	fma.rn.f64 	%fd205, %fd11, %fd241, %fd207;
	sub.f64 	%fd204, %fd205, %fd206;
	sqrt.rn.f64 	%fd118, %fd242;
	div.rn.f64 	%fd119, %fd204, %fd118;
	cvt.rn.ftz.f32.f64 	%f60, %fd119;

$L__BB1_28:
	st.global.f32 	[%rd9], %f60;
	sub.f64 	%fd241, %fd241, %fd23;
	add.s32 	%r111, %r260, 1;
	setp.eq.s32 	%p23, %r111, %r13;
	selp.b32 	%r112, %r13, 0, %p23;
	sub.s32 	%r260, %r111, %r112;

$L__BB1_29:
	mov.u32 	%r234, sdata;
	add.f64 	%fd29, %fd261, %fd241;
	add.s32 	%r113, %r277, 1;
	setp.eq.s32 	%p24, %r113, %r13;
	selp.b32 	%r114, %r13, 0, %p24;
	sub.s32 	%r30, %r113, %r114;
	add.s32 	%r115, %r278, 1;
	setp.eq.s32 	%p25, %r115, %r13;
	selp.b32 	%r116, %r13, 0, %p25;
	sub.s32 	%r31, %r115, %r116;
	add.s32 	%r117, %r279, 1;
	setp.eq.s32 	%p26, %r117, %r13;
	selp.b32 	%r118, %r13, 0, %p26;
	sub.s32 	%r32, %r117, %r118;
	cvt.u32.u64 	%r119, %rd7;
	add.s32 	%r120, %r119, 1;
	add.s64 	%rd38, %rd34, 4;

	ld.global.nc.f32 %f21, [%rd38];

	cvt.ftz.f64.f32 	%fd30, %f21;
	shl.b32 	%r121, %r31, 3;
	add.s32 	%r123, %r234, %r121;
	shl.b32 	%r124, %r32, 3;
	add.s32 	%r125, %r234, %r124;
	add.f64 	%fd120, %fd21, %fd30;
	mul.f64 	%fd121, %fd95, %fd120;
	ld.shared.f64 	%fd122, [%r125];
	fma.rn.f64 	%fd123, %fd14, %fd122, %fd121;
	ld.shared.f64 	%fd124, [%r123];
	fma.rn.f64 	%fd243, %fd94, %fd124, %fd123;
	shl.b32 	%r126, %r30, 3;
	add.s32 	%r127, %r234, %r126;
	st.shared.f64 	[%r127], %fd243;
	setp.lt.s32 	%p27, %r120, %r86;
	@%p27 bra 	$L__BB1_34;

	mov.f32 	%f61, 0f00000000;
	mov.u32 	%r235, sdata;
	shl.b32 	%r128, %r260, 3;
	add.s32 	%r130, %r235, %r128;
	ld.shared.f64 	%fd32, [%r130];
	mul.f64 	%fd125, %fd10, %fd32;
	fma.rn.f64 	%fd126, %fd11, %fd243, %fd125;
	mul.f64 	%fd127, %fd9, %fd29;
	sub.f64 	%fd33, %fd126, %fd127;
	mul.f64 	%fd128, %fd33, 0d3FA47AE147AE147B;
	mul.f64 	%fd129, %fd33, %fd128;
	mov.f64 	%fd130, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd242, %fd130, %fd242, %fd129;
	setp.leu.f64 	%p28, %fd242, 0d0000000000000000;
	@%p28 bra 	$L__BB1_33;

	mov.f32 	%f61, 0f00000000;
	abs.f64 	%fd131, %fd242;
	setp.geu.f64 	%p29, %fd131, 0d7FF0000000000000;
	@%p29 bra 	$L__BB1_33;

	mul.f64 	%fd211, %fd10, %fd32;
	mul.f64 	%fd210, %fd9, %fd29;
	fma.rn.f64 	%fd209, %fd11, %fd243, %fd211;
	sub.f64 	%fd208, %fd209, %fd210;
	sqrt.rn.f64 	%fd132, %fd242;
	div.rn.f64 	%fd133, %fd208, %fd132;
	cvt.rn.ftz.f32.f64 	%f61, %fd133;

$L__BB1_33:
	st.global.f32 	[%rd9+4], %f61;
	sub.f64 	%fd243, %fd243, %fd32;
	add.s32 	%r131, %r260, 1;
	setp.eq.s32 	%p30, %r131, %r13;
	selp.b32 	%r132, %r13, 0, %p30;
	sub.s32 	%r260, %r131, %r132;

$L__BB1_34:
	mov.u32 	%r236, sdata;
	add.f64 	%fd38, %fd29, %fd243;
	add.s32 	%r133, %r30, 1;
	setp.eq.s32 	%p31, %r133, %r13;
	selp.b32 	%r134, %r13, 0, %p31;
	sub.s32 	%r35, %r133, %r134;
	add.s32 	%r135, %r31, 1;
	setp.eq.s32 	%p32, %r135, %r13;
	selp.b32 	%r136, %r13, 0, %p32;
	sub.s32 	%r36, %r135, %r136;
	add.s32 	%r137, %r32, 1;
	setp.eq.s32 	%p33, %r137, %r13;
	selp.b32 	%r138, %r13, 0, %p33;
	sub.s32 	%r37, %r137, %r138;
	add.s32 	%r140, %r119, 2;
	add.s64 	%rd39, %rd34, 8;

	ld.global.nc.f32 %f24, [%rd39];

	cvt.ftz.f64.f32 	%fd39, %f24;
	shl.b32 	%r141, %r36, 3;
	add.s32 	%r143, %r236, %r141;
	shl.b32 	%r144, %r37, 3;
	add.s32 	%r145, %r236, %r144;
	add.f64 	%fd134, %fd30, %fd39;
	mul.f64 	%fd135, %fd95, %fd134;
	ld.shared.f64 	%fd136, [%r145];
	fma.rn.f64 	%fd137, %fd14, %fd136, %fd135;
	ld.shared.f64 	%fd138, [%r143];
	fma.rn.f64 	%fd245, %fd94, %fd138, %fd137;
	shl.b32 	%r146, %r35, 3;
	add.s32 	%r147, %r236, %r146;
	st.shared.f64 	[%r147], %fd245;
	setp.lt.s32 	%p34, %r140, %r86;
	@%p34 bra 	$L__BB1_39;

	mov.f32 	%f62, 0f00000000;
	mov.u32 	%r237, sdata;
	shl.b32 	%r148, %r260, 3;
	add.s32 	%r150, %r237, %r148;
	ld.shared.f64 	%fd41, [%r150];
	mul.f64 	%fd139, %fd10, %fd41;
	fma.rn.f64 	%fd140, %fd11, %fd245, %fd139;
	mul.f64 	%fd141, %fd9, %fd38;
	sub.f64 	%fd42, %fd140, %fd141;
	mul.f64 	%fd142, %fd42, 0d3FA47AE147AE147B;
	mul.f64 	%fd143, %fd42, %fd142;
	mov.f64 	%fd144, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd242, %fd144, %fd242, %fd143;
	setp.leu.f64 	%p35, %fd242, 0d0000000000000000;
	@%p35 bra 	$L__BB1_38;

	mov.f32 	%f62, 0f00000000;
	abs.f64 	%fd145, %fd242;
	setp.geu.f64 	%p36, %fd145, 0d7FF0000000000000;
	@%p36 bra 	$L__BB1_38;

	mul.f64 	%fd215, %fd10, %fd41;
	mul.f64 	%fd214, %fd9, %fd38;
	fma.rn.f64 	%fd213, %fd11, %fd245, %fd215;
	sub.f64 	%fd212, %fd213, %fd214;
	sqrt.rn.f64 	%fd146, %fd242;
	div.rn.f64 	%fd147, %fd212, %fd146;
	cvt.rn.ftz.f32.f64 	%f62, %fd147;

$L__BB1_38:
	st.global.f32 	[%rd9+8], %f62;
	sub.f64 	%fd245, %fd245, %fd41;
	add.s32 	%r151, %r260, 1;
	setp.eq.s32 	%p37, %r151, %r13;
	selp.b32 	%r152, %r13, 0, %p37;
	sub.s32 	%r260, %r151, %r152;

$L__BB1_39:
	mov.u32 	%r238, sdata;
	add.f64 	%fd47, %fd38, %fd245;
	add.s32 	%r153, %r35, 1;
	setp.eq.s32 	%p38, %r153, %r13;
	selp.b32 	%r154, %r13, 0, %p38;
	sub.s32 	%r40, %r153, %r154;
	add.s32 	%r155, %r36, 1;
	setp.eq.s32 	%p39, %r155, %r13;
	selp.b32 	%r156, %r13, 0, %p39;
	sub.s32 	%r41, %r155, %r156;
	add.s32 	%r157, %r37, 1;
	setp.eq.s32 	%p40, %r157, %r13;
	selp.b32 	%r158, %r13, 0, %p40;
	sub.s32 	%r42, %r157, %r158;
	add.s32 	%r160, %r119, 3;
	add.s64 	%rd40, %rd34, 12;

	ld.global.nc.f32 %f27, [%rd40];

	cvt.ftz.f64.f32 	%fd263, %f27;
	shl.b32 	%r161, %r41, 3;
	add.s32 	%r163, %r238, %r161;
	shl.b32 	%r164, %r42, 3;
	add.s32 	%r165, %r238, %r164;
	add.f64 	%fd148, %fd39, %fd263;
	mul.f64 	%fd149, %fd95, %fd148;
	ld.shared.f64 	%fd150, [%r165];
	fma.rn.f64 	%fd151, %fd14, %fd150, %fd149;
	ld.shared.f64 	%fd152, [%r163];
	fma.rn.f64 	%fd247, %fd94, %fd152, %fd151;
	shl.b32 	%r166, %r40, 3;
	add.s32 	%r167, %r238, %r166;
	st.shared.f64 	[%r167], %fd247;
	setp.lt.s32 	%p41, %r160, %r86;
	@%p41 bra 	$L__BB1_44;

	mov.f32 	%f63, 0f00000000;
	mov.u32 	%r239, sdata;
	shl.b32 	%r168, %r260, 3;
	add.s32 	%r170, %r239, %r168;
	ld.shared.f64 	%fd50, [%r170];
	mul.f64 	%fd153, %fd10, %fd50;
	fma.rn.f64 	%fd154, %fd11, %fd247, %fd153;
	mul.f64 	%fd155, %fd9, %fd47;
	sub.f64 	%fd51, %fd154, %fd155;
	mul.f64 	%fd156, %fd51, 0d3FA47AE147AE147B;
	mul.f64 	%fd157, %fd51, %fd156;
	mov.f64 	%fd158, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd242, %fd158, %fd242, %fd157;
	setp.leu.f64 	%p42, %fd242, 0d0000000000000000;
	@%p42 bra 	$L__BB1_43;

	mov.f32 	%f63, 0f00000000;
	abs.f64 	%fd159, %fd242;
	setp.geu.f64 	%p43, %fd159, 0d7FF0000000000000;
	@%p43 bra 	$L__BB1_43;

	mul.f64 	%fd219, %fd10, %fd50;
	mul.f64 	%fd218, %fd9, %fd47;
	fma.rn.f64 	%fd217, %fd11, %fd247, %fd219;
	sub.f64 	%fd216, %fd217, %fd218;
	sqrt.rn.f64 	%fd160, %fd242;
	div.rn.f64 	%fd161, %fd216, %fd160;
	cvt.rn.ftz.f32.f64 	%f63, %fd161;

$L__BB1_43:
	st.global.f32 	[%rd9+12], %f63;
	sub.f64 	%fd247, %fd247, %fd50;
	add.s32 	%r171, %r260, 1;
	setp.eq.s32 	%p44, %r171, %r13;
	selp.b32 	%r172, %r13, 0, %p44;
	sub.s32 	%r260, %r171, %r172;

$L__BB1_44:
	add.f64 	%fd261, %fd47, %fd247;
	add.s32 	%r173, %r40, 1;
	setp.eq.s32 	%p45, %r173, %r13;
	selp.b32 	%r174, %r13, 0, %p45;
	sub.s32 	%r277, %r173, %r174;
	add.s32 	%r175, %r41, 1;
	setp.eq.s32 	%p46, %r175, %r13;
	selp.b32 	%r176, %r13, 0, %p46;
	sub.s32 	%r278, %r175, %r176;
	add.s32 	%r177, %r42, 1;
	setp.eq.s32 	%p47, %r177, %r13;
	selp.b32 	%r178, %r13, 0, %p47;
	sub.s32 	%r279, %r177, %r178;
	add.s32 	%r268, %r119, 4;
	add.s32 	%r259, %r259, -4;
	setp.ne.s32 	%p48, %r259, 0;
	@%p48 bra 	$L__BB1_24;

$L__BB1_45:
	setp.eq.s32 	%p49, %r20, 0;
	mov.u32 	%r281, %r268;
	@%p49 bra 	$L__BB1_64;

	cvt.s64.s32 	%rd42, %r268;
	mul.wide.s32 	%rd43, %r268, 4;
	add.s64 	%rd41, %rd12, %rd43;

	ld.global.nc.f32 %f30, [%rd41];

	cvt.ftz.f64.f32 	%fd63, %f30;
	add.f64 	%fd162, %fd263, %fd63;
	mul.f64 	%fd163, %fd95, %fd162;
	shl.b32 	%r180, %r279, 3;
	mov.u32 	%r181, sdata;
	add.s32 	%r182, %r181, %r180;
	ld.shared.f64 	%fd164, [%r182];
	fma.rn.f64 	%fd165, %fd14, %fd164, %fd163;
	shl.b32 	%r183, %r278, 3;
	add.s32 	%r184, %r181, %r183;
	ld.shared.f64 	%fd166, [%r184];
	fma.rn.f64 	%fd255, %fd94, %fd166, %fd165;
	shl.b32 	%r185, %r277, 3;
	add.s32 	%r186, %r181, %r185;
	st.shared.f64 	[%r186], %fd255;
	add.s64 	%rd44, %rd42, %rd3;
	shl.b64 	%rd45, %rd44, 2;
	add.s64 	%rd11, %rd1, %rd45;
	setp.lt.s32 	%p50, %r268, %r86;
	@%p50 bra 	$L__BB1_51;

	mov.f32 	%f64, 0f00000000;
	mov.u32 	%r240, sdata;
	shl.b32 	%r187, %r260, 3;
	add.s32 	%r189, %r240, %r187;
	ld.shared.f64 	%fd65, [%r189];
	mul.f64 	%fd167, %fd10, %fd65;
	fma.rn.f64 	%fd168, %fd11, %fd255, %fd167;
	mul.f64 	%fd169, %fd9, %fd261;
	sub.f64 	%fd66, %fd168, %fd169;
	mul.f64 	%fd170, %fd66, 0d3FA47AE147AE147B;
	mul.f64 	%fd171, %fd66, %fd170;
	mov.f64 	%fd172, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd242, %fd172, %fd242, %fd171;
	setp.leu.f64 	%p51, %fd242, 0d0000000000000000;
	@%p51 bra 	$L__BB1_50;

	mov.f32 	%f64, 0f00000000;
	abs.f64 	%fd173, %fd242;
	setp.geu.f64 	%p52, %fd173, 0d7FF0000000000000;
	@%p52 bra 	$L__BB1_50;

	mul.f64 	%fd223, %fd10, %fd65;
	mul.f64 	%fd222, %fd9, %fd261;
	fma.rn.f64 	%fd221, %fd11, %fd255, %fd223;
	sub.f64 	%fd220, %fd221, %fd222;
	sqrt.rn.f64 	%fd174, %fd242;
	div.rn.f64 	%fd175, %fd220, %fd174;
	cvt.rn.ftz.f32.f64 	%f64, %fd175;

$L__BB1_50:
	st.global.f32 	[%rd11], %f64;
	sub.f64 	%fd255, %fd255, %fd65;
	add.s32 	%r190, %r260, 1;
	setp.eq.s32 	%p53, %r190, %r13;
	selp.b32 	%r191, %r13, 0, %p53;
	sub.s32 	%r260, %r190, %r191;

$L__BB1_51:
	add.f64 	%fd261, %fd261, %fd255;
	add.s32 	%r192, %r277, 1;
	setp.eq.s32 	%p54, %r192, %r13;
	selp.b32 	%r193, %r13, 0, %p54;
	sub.s32 	%r277, %r192, %r193;
	add.s32 	%r194, %r278, 1;
	setp.eq.s32 	%p55, %r194, %r13;
	selp.b32 	%r195, %r13, 0, %p55;
	sub.s32 	%r278, %r194, %r195;
	add.s32 	%r196, %r279, 1;
	setp.eq.s32 	%p56, %r196, %r13;
	selp.b32 	%r197, %r13, 0, %p56;
	sub.s32 	%r279, %r196, %r197;
	add.s32 	%r281, %r268, 1;
	setp.eq.s32 	%p57, %r20, 1;
	mov.f64 	%fd263, %fd63;
	@%p57 bra 	$L__BB1_64;

	mul.wide.s32 	%rd49, %r268, 4;
	add.s64 	%rd48, %rd12, %rd49;
	mov.u32 	%r241, sdata;
	add.s64 	%rd46, %rd48, 4;

	ld.global.nc.f32 %f33, [%rd46];

	cvt.ftz.f64.f32 	%fd263, %f33;
	add.f64 	%fd176, %fd63, %fd263;
	mul.f64 	%fd177, %fd95, %fd176;
	shl.b32 	%r198, %r279, 3;
	add.s32 	%r200, %r241, %r198;
	ld.shared.f64 	%fd178, [%r200];
	fma.rn.f64 	%fd179, %fd14, %fd178, %fd177;
	shl.b32 	%r201, %r278, 3;
	add.s32 	%r202, %r241, %r201;
	ld.shared.f64 	%fd180, [%r202];
	fma.rn.f64 	%fd257, %fd94, %fd180, %fd179;
	shl.b32 	%r203, %r277, 3;
	add.s32 	%r204, %r241, %r203;
	st.shared.f64 	[%r204], %fd257;
	setp.lt.s32 	%p58, %r281, %r86;
	@%p58 bra 	$L__BB1_57;

	mov.f32 	%f65, 0f00000000;
	mov.u32 	%r242, sdata;
	shl.b32 	%r205, %r260, 3;
	add.s32 	%r207, %r242, %r205;
	ld.shared.f64 	%fd74, [%r207];
	mul.f64 	%fd181, %fd10, %fd74;
	fma.rn.f64 	%fd182, %fd11, %fd257, %fd181;
	mul.f64 	%fd183, %fd9, %fd261;
	sub.f64 	%fd75, %fd182, %fd183;
	mul.f64 	%fd184, %fd75, 0d3FA47AE147AE147B;
	mul.f64 	%fd185, %fd75, %fd184;
	mov.f64 	%fd186, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd242, %fd186, %fd242, %fd185;
	setp.leu.f64 	%p59, %fd242, 0d0000000000000000;
	@%p59 bra 	$L__BB1_56;

	mov.f32 	%f65, 0f00000000;
	abs.f64 	%fd187, %fd242;
	setp.geu.f64 	%p60, %fd187, 0d7FF0000000000000;
	@%p60 bra 	$L__BB1_56;

	mul.f64 	%fd227, %fd10, %fd74;
	mul.f64 	%fd226, %fd9, %fd261;
	fma.rn.f64 	%fd225, %fd11, %fd257, %fd227;
	sub.f64 	%fd224, %fd225, %fd226;
	sqrt.rn.f64 	%fd188, %fd242;
	div.rn.f64 	%fd189, %fd224, %fd188;
	cvt.rn.ftz.f32.f64 	%f65, %fd189;

$L__BB1_56:
	st.global.f32 	[%rd11+4], %f65;
	sub.f64 	%fd257, %fd257, %fd74;
	add.s32 	%r208, %r260, 1;
	setp.eq.s32 	%p61, %r208, %r13;
	selp.b32 	%r209, %r13, 0, %p61;
	sub.s32 	%r260, %r208, %r209;

$L__BB1_57:
	add.f64 	%fd261, %fd261, %fd257;
	add.s32 	%r210, %r277, 1;
	setp.eq.s32 	%p62, %r210, %r13;
	selp.b32 	%r211, %r13, 0, %p62;
	sub.s32 	%r277, %r210, %r211;
	add.s32 	%r212, %r278, 1;
	setp.eq.s32 	%p63, %r212, %r13;
	selp.b32 	%r213, %r13, 0, %p63;
	sub.s32 	%r278, %r212, %r213;
	add.s32 	%r214, %r279, 1;
	setp.eq.s32 	%p64, %r214, %r13;
	selp.b32 	%r215, %r13, 0, %p64;
	sub.s32 	%r279, %r214, %r215;
	add.s32 	%r281, %r268, 2;
	setp.eq.s32 	%p65, %r20, 2;
	@%p65 bra 	$L__BB1_64;

	mul.wide.s32 	%rd51, %r268, 4;
	add.s64 	%rd50, %rd12, %rd51;
	mov.u32 	%r243, sdata;
	add.s64 	%rd47, %rd50, 8;

	ld.global.nc.f32 %f36, [%rd47];

	cvt.ftz.f64.f32 	%fd81, %f36;
	add.f64 	%fd190, %fd263, %fd81;
	mul.f64 	%fd191, %fd95, %fd190;
	shl.b32 	%r216, %r279, 3;
	add.s32 	%r218, %r243, %r216;
	ld.shared.f64 	%fd192, [%r218];
	fma.rn.f64 	%fd193, %fd14, %fd192, %fd191;
	shl.b32 	%r219, %r278, 3;
	add.s32 	%r220, %r243, %r219;
	ld.shared.f64 	%fd194, [%r220];
	fma.rn.f64 	%fd259, %fd94, %fd194, %fd193;
	shl.b32 	%r221, %r277, 3;
	add.s32 	%r222, %r243, %r221;
	st.shared.f64 	[%r222], %fd259;
	setp.lt.s32 	%p66, %r281, %r86;
	@%p66 bra 	$L__BB1_63;

	mov.f32 	%f66, 0f00000000;
	mov.u32 	%r244, sdata;
	shl.b32 	%r223, %r260, 3;
	add.s32 	%r225, %r244, %r223;
	ld.shared.f64 	%fd83, [%r225];
	mul.f64 	%fd195, %fd10, %fd83;
	fma.rn.f64 	%fd196, %fd11, %fd259, %fd195;
	mul.f64 	%fd197, %fd9, %fd261;
	sub.f64 	%fd84, %fd196, %fd197;
	mul.f64 	%fd198, %fd84, 0d3FA47AE147AE147B;
	mul.f64 	%fd199, %fd84, %fd198;
	mov.f64 	%fd200, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd242, %fd200, %fd242, %fd199;
	setp.leu.f64 	%p67, %fd242, 0d0000000000000000;
	@%p67 bra 	$L__BB1_62;

	mov.f32 	%f66, 0f00000000;
	abs.f64 	%fd201, %fd242;
	setp.geu.f64 	%p68, %fd201, 0d7FF0000000000000;
	@%p68 bra 	$L__BB1_62;

	mul.f64 	%fd231, %fd10, %fd83;
	mul.f64 	%fd230, %fd9, %fd261;
	fma.rn.f64 	%fd229, %fd11, %fd259, %fd231;
	sub.f64 	%fd228, %fd229, %fd230;
	sqrt.rn.f64 	%fd202, %fd242;
	div.rn.f64 	%fd203, %fd228, %fd202;
	cvt.rn.ftz.f32.f64 	%f66, %fd203;

$L__BB1_62:
	st.global.f32 	[%rd11+8], %f66;
	sub.f64 	%fd259, %fd259, %fd83;
	add.s32 	%r226, %r260, 1;
	setp.eq.s32 	%p69, %r226, %r13;
	selp.b32 	%r227, %r13, 0, %p69;
	sub.s32 	%r260, %r226, %r227;

$L__BB1_63:
	add.f64 	%fd261, %fd261, %fd259;
	add.s32 	%r228, %r277, 1;
	setp.eq.s32 	%p70, %r228, %r13;
	selp.b32 	%r229, %r13, 0, %p70;
	sub.s32 	%r277, %r228, %r229;
	add.s32 	%r230, %r278, 1;
	setp.eq.s32 	%p71, %r230, %r13;
	selp.b32 	%r231, %r13, 0, %p71;
	sub.s32 	%r278, %r230, %r231;
	add.s32 	%r232, %r279, 1;
	setp.eq.s32 	%p72, %r232, %r13;
	selp.b32 	%r233, %r13, 0, %p72;
	sub.s32 	%r279, %r232, %r233;
	add.s32 	%r281, %r268, 3;
	mov.f64 	%fd263, %fd81;

$L__BB1_64:
	setp.lt.s32 	%p73, %r281, %r83;
	@%p73 bra 	$L__BB1_21;

$L__BB1_65:
	ret;

}

.visible .entry reflex_many_series_one_param_f32(
	.param .u64 reflex_many_series_one_param_f32_param_0,
	.param .u32 reflex_many_series_one_param_f32_param_1,
	.param .u32 reflex_many_series_one_param_f32_param_2,
	.param .u32 reflex_many_series_one_param_f32_param_3,
	.param .u64 reflex_many_series_one_param_f32_param_4,
	.param .u64 reflex_many_series_one_param_f32_param_5
)
{
	.reg .pred 	%p<42>;
	.reg .f32 	%f<28>;
	.reg .b32 	%r<145>;
	.reg .f64 	%fd<200>;
	.reg .b64 	%rd<55>;


	ld.param.u64 	%rd16, [reflex_many_series_one_param_f32_param_0];
	ld.param.u32 	%r40, [reflex_many_series_one_param_f32_param_1];
	ld.param.u32 	%r41, [reflex_many_series_one_param_f32_param_2];
	ld.param.u32 	%r42, [reflex_many_series_one_param_f32_param_3];
	ld.param.u64 	%rd17, [reflex_many_series_one_param_f32_param_5];
	cvta.to.global.u64 	%rd1, %rd17;
	cvta.to.global.u64 	%rd2, %rd16;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r41;
	mov.u32 	%r43, %tid.x;
	setp.ne.s32 	%p2, %r43, 0;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB2_58;

	setp.lt.s32 	%p4, %r40, 2;
	setp.lt.s32 	%p5, %r42, 1;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB2_58;

	add.s32 	%r45, %r42, -1;
	and.b32  	%r136, %r42, 3;
	setp.lt.u32 	%p7, %r45, 3;
	mov.u32 	%r135, 0;
	@%p7 bra 	$L__BB2_5;

	sub.s32 	%r134, %r42, %r136;
	mul.wide.s32 	%rd3, %r41, 4;
	mov.u32 	%r46, 0;
	mov.u32 	%r135, %r46;

$L__BB2_4:
	mad.lo.s32 	%r47, %r135, %r41, %r1;
	mul.wide.s32 	%rd18, %r47, 4;
	add.s64 	%rd19, %rd1, %rd18;
	st.global.u32 	[%rd19], %r46;
	add.s64 	%rd20, %rd19, %rd3;
	st.global.u32 	[%rd20], %r46;
	add.s64 	%rd21, %rd20, %rd3;
	st.global.u32 	[%rd21], %r46;
	add.s64 	%rd22, %rd21, %rd3;
	st.global.u32 	[%rd22], %r46;
	add.s32 	%r135, %r135, 4;
	add.s32 	%r134, %r134, -4;
	setp.ne.s32 	%p8, %r134, 0;
	@%p8 bra 	$L__BB2_4;

$L__BB2_5:
	setp.eq.s32 	%p9, %r136, 0;
	@%p9 bra 	$L__BB2_8;

	mad.lo.s32 	%r49, %r135, %r41, %r1;
	mul.wide.s32 	%rd23, %r49, 4;
	add.s64 	%rd53, %rd1, %rd23;
	mul.wide.s32 	%rd5, %r41, 4;

$L__BB2_7:
	.pragma "nounroll";
	mov.u32 	%r50, 0;
	st.global.u32 	[%rd53], %r50;
	add.s64 	%rd53, %rd53, %rd5;
	add.s32 	%r136, %r136, -1;
	setp.ne.s32 	%p10, %r136, 0;
	@%p10 bra 	$L__BB2_7;

$L__BB2_8:
	min.s32 	%r11, %r40, %r42;
	setp.lt.s32 	%p11, %r11, 1;
	@%p11 bra 	$L__BB2_15;

	add.s32 	%r52, %r11, -1;
	and.b32  	%r140, %r11, 3;
	setp.lt.u32 	%p12, %r52, 3;
	mov.u32 	%r139, 0;
	@%p12 bra 	$L__BB2_12;

	sub.s32 	%r138, %r11, %r140;
	mul.wide.s32 	%rd8, %r41, 4;
	mov.u32 	%r53, 0;
	mov.u32 	%r139, %r53;

$L__BB2_11:
	mad.lo.s32 	%r54, %r139, %r41, %r1;
	mul.wide.s32 	%rd24, %r54, 4;
	add.s64 	%rd25, %rd1, %rd24;
	st.global.u32 	[%rd25], %r53;
	add.s64 	%rd26, %rd25, %rd8;
	st.global.u32 	[%rd26], %r53;
	add.s64 	%rd27, %rd26, %rd8;
	st.global.u32 	[%rd27], %r53;
	add.s64 	%rd28, %rd27, %rd8;
	st.global.u32 	[%rd28], %r53;
	add.s32 	%r139, %r139, 4;
	add.s32 	%r138, %r138, -4;
	setp.ne.s32 	%p13, %r138, 0;
	@%p13 bra 	$L__BB2_11;

$L__BB2_12:
	setp.eq.s32 	%p14, %r140, 0;
	@%p14 bra 	$L__BB2_15;

	mad.lo.s32 	%r56, %r139, %r41, %r1;
	mul.wide.s32 	%rd29, %r56, 4;
	add.s64 	%rd54, %rd1, %rd29;
	mul.wide.s32 	%rd10, %r41, 4;

$L__BB2_14:
	.pragma "nounroll";
	mov.u32 	%r57, 0;
	st.global.u32 	[%rd54], %r57;
	add.s64 	%rd54, %rd54, %rd10;
	add.s32 	%r140, %r140, -1;
	setp.ne.s32 	%p15, %r140, 0;
	@%p15 bra 	$L__BB2_14;

$L__BB2_15:
	shr.u32 	%r58, %r40, 31;
	add.s32 	%r59, %r40, %r58;
	shr.s32 	%r60, %r59, 1;
	max.s32 	%r61, %r60, 1;
	cvt.rn.f64.s32 	%fd1, %r61;
	mov.f64 	%fd57, 0dC011C4D339C8C6CB;
	div.rn.f64 	%fd2, %fd57, %fd1;
	mov.f64 	%fd58, 0d4338000000000000;
	mov.f64 	%fd59, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd60, %fd2, %fd59, %fd58;
	{
	.reg .b32 %temp;
	mov.b64 	{%r21, %temp}, %fd60;
	}
	mov.f64 	%fd61, 0dC338000000000000;
	add.rn.f64 	%fd62, %fd60, %fd61;
	mov.f64 	%fd63, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd64, %fd62, %fd63, %fd2;
	mov.f64 	%fd65, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd66, %fd62, %fd65, %fd64;
	mov.f64 	%fd67, 0d3E928AF3FCA213EA;
	mov.f64 	%fd68, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd69, %fd68, %fd66, %fd67;
	mov.f64 	%fd70, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd71, %fd69, %fd66, %fd70;
	mov.f64 	%fd72, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd73, %fd71, %fd66, %fd72;
	mov.f64 	%fd74, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd75, %fd73, %fd66, %fd74;
	mov.f64 	%fd76, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd77, %fd75, %fd66, %fd76;
	mov.f64 	%fd78, 0d3F81111111122322;
	fma.rn.f64 	%fd79, %fd77, %fd66, %fd78;
	mov.f64 	%fd80, 0d3FA55555555502A1;
	fma.rn.f64 	%fd81, %fd79, %fd66, %fd80;
	mov.f64 	%fd82, 0d3FC5555555555511;
	fma.rn.f64 	%fd83, %fd81, %fd66, %fd82;
	mov.f64 	%fd84, 0d3FE000000000000B;
	fma.rn.f64 	%fd85, %fd83, %fd66, %fd84;
	mov.f64 	%fd86, 0d3FF0000000000000;
	fma.rn.f64 	%fd87, %fd85, %fd66, %fd86;
	fma.rn.f64 	%fd88, %fd87, %fd66, %fd86;
	{
	.reg .b32 %temp;
	mov.b64 	{%r22, %temp}, %fd88;
	}
	{
	.reg .b32 %temp;
	mov.b64 	{%temp, %r23}, %fd88;
	}
	shl.b32 	%r62, %r21, 20;
	add.s32 	%r63, %r23, %r62;
	mov.b64 	%fd185, {%r22, %r63};
	{
	.reg .b32 %temp;
	mov.b64 	{%temp, %r64}, %fd2;
	}
	mov.b32 	%f8, %r64;
	abs.ftz.f32 	%f1, %f8;
	setp.lt.ftz.f32 	%p16, %f1, 0f4086232B;
	@%p16 bra 	$L__BB2_18;

	setp.lt.f64 	%p17, %fd2, 0d0000000000000000;
	add.f64 	%fd89, %fd2, 0d7FF0000000000000;
	selp.f64 	%fd185, 0d0000000000000000, %fd89, %p17;
	setp.geu.ftz.f32 	%p18, %f1, 0f40874800;
	@%p18 bra 	$L__BB2_18;

	shr.u32 	%r65, %r21, 31;
	add.s32 	%r66, %r21, %r65;
	shr.s32 	%r67, %r66, 1;
	shl.b32 	%r68, %r67, 20;
	add.s32 	%r69, %r23, %r68;
	mov.b64 	%fd90, {%r22, %r69};
	sub.s32 	%r70, %r21, %r67;
	shl.b32 	%r71, %r70, 20;
	add.s32 	%r72, %r71, 1072693248;
	mov.u32 	%r73, 0;
	mov.b64 	%fd91, {%r73, %r72};
	mul.f64 	%fd185, %fd90, %fd91;

$L__BB2_18:
	mul.f64 	%fd7, %fd185, %fd185;
	mov.f64 	%fd92, 0d4011C4D339C8C6CB;
	div.rn.f64 	%fd8, %fd92, %fd1;
	abs.f64 	%fd9, %fd8;
	setp.eq.f64 	%p19, %fd9, 0d7FF0000000000000;
	@%p19 bra 	$L__BB2_21;
	bra.uni 	$L__BB2_19;

$L__BB2_21:
	mov.f64 	%fd101, 0d0000000000000000;
	mul.rn.f64 	%fd186, %fd8, %fd101;
	mov.u32 	%r141, 0;
	bra.uni 	$L__BB2_22;

$L__BB2_19:
	mul.f64 	%fd93, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r141, %fd93;
	cvt.rn.f64.s32 	%fd94, %r141;
	neg.f64 	%fd95, %fd94;
	mov.f64 	%fd96, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd97, %fd95, %fd96, %fd8;
	mov.f64 	%fd98, 0d3C91A62633145C00;
	fma.rn.f64 	%fd99, %fd95, %fd98, %fd97;
	mov.f64 	%fd100, 0d397B839A252049C0;
	fma.rn.f64 	%fd186, %fd95, %fd100, %fd99;
	setp.ltu.f64 	%p20, %fd9, 0d41E0000000000000;
	@%p20 bra 	$L__BB2_22;

	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .align 8 .b8 retval0[16];
	call.uni (retval0),
	__internal_trig_reduction_slowpathd,
	(
	param0
	);
	ld.param.f64 	%fd186, [retval0+0];
	ld.param.b32 	%r141, [retval0+8];
	}

$L__BB2_22:
	add.s32 	%r27, %r141, 1;
	and.b32  	%r75, %r27, 1;
	shl.b32 	%r76, %r27, 3;
	and.b32  	%r77, %r76, 8;
	mul.wide.u32 	%rd30, %r77, 8;
	mov.u64 	%rd31, __cudart_sin_cos_coeffs;
	add.s64 	%rd32, %rd31, %rd30;
	setp.eq.s32 	%p21, %r75, 0;
	selp.f64 	%fd102, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p21;
	ld.global.nc.v2.f64 	{%fd103, %fd104}, [%rd32];
	mul.rn.f64 	%fd14, %fd186, %fd186;
	fma.rn.f64 	%fd107, %fd102, %fd14, %fd103;
	fma.rn.f64 	%fd108, %fd107, %fd14, %fd104;
	ld.global.nc.v2.f64 	{%fd109, %fd110}, [%rd32+16];
	fma.rn.f64 	%fd113, %fd108, %fd14, %fd109;
	fma.rn.f64 	%fd114, %fd113, %fd14, %fd110;
	ld.global.nc.v2.f64 	{%fd115, %fd116}, [%rd32+32];
	fma.rn.f64 	%fd119, %fd114, %fd14, %fd115;
	fma.rn.f64 	%fd15, %fd119, %fd14, %fd116;
	fma.rn.f64 	%fd188, %fd15, %fd186, %fd186;
	@%p21 bra 	$L__BB2_24;

	mov.f64 	%fd120, 0d3FF0000000000000;
	fma.rn.f64 	%fd188, %fd15, %fd14, %fd120;

$L__BB2_24:
	and.b32  	%r78, %r27, 2;
	setp.eq.s32 	%p22, %r78, 0;
	@%p22 bra 	$L__BB2_26;

	mov.f64 	%fd121, 0d0000000000000000;
	mov.f64 	%fd122, 0dBFF0000000000000;
	fma.rn.f64 	%fd188, %fd188, %fd122, %fd121;

$L__BB2_26:
	add.f64 	%fd123, %fd7, 0d3FF0000000000000;
	add.f64 	%fd124, %fd185, %fd185;
	mul.f64 	%fd21, %fd124, %fd188;
	sub.f64 	%fd125, %fd123, %fd21;
	mul.f64 	%fd22, %fd125, 0d3FE0000000000000;
	add.s32 	%r28, %r40, 1;
	@%p5 bra 	$L__BB2_28;

	mul.wide.s32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd2, %rd33;
	ld.global.nc.f32 	%f9, [%rd34];
	cvt.ftz.f64.f32 	%fd126, %f9;
	st.shared.f64 	[sdata], %fd126;

$L__BB2_28:
	setp.lt.s32 	%p24, %r42, 2;
	@%p24 bra 	$L__BB2_30;

	add.s32 	%r79, %r1, %r41;
	mul.wide.s32 	%rd35, %r79, 4;
	add.s64 	%rd36, %rd2, %rd35;
	ld.global.nc.f32 	%f10, [%rd36];
	cvt.ftz.f64.f32 	%fd127, %f10;
	st.shared.f64 	[sdata+8], %fd127;

$L__BB2_30:
	setp.eq.s32 	%p25, %r40, 1;
	@%p25 bra 	$L__BB2_36;
	bra.uni 	$L__BB2_31;

$L__BB2_36:
	mov.f64 	%fd199, 0d0000000000000000;
	@%p5 bra 	$L__BB2_38;

	ld.shared.f64 	%fd199, [sdata];
	bra.uni 	$L__BB2_38;

$L__BB2_31:
	mov.f64 	%fd190, 0d0000000000000000;
	mov.f64 	%fd189, %fd190;
	@%p5 bra 	$L__BB2_33;

	ld.shared.f64 	%fd189, [sdata];

$L__BB2_33:
	@%p24 bra 	$L__BB2_35;

	ld.shared.f64 	%fd190, [sdata+8];

$L__BB2_35:
	add.f64 	%fd199, %fd189, %fd190;

$L__BB2_38:
	cvt.rn.f64.s32 	%fd131, %r40;
	rcp.rn.f64 	%fd30, %fd131;
	mov.f64 	%fd132, 0d3FF0000000000000;
	add.f64 	%fd133, %fd30, 0d3FF0000000000000;
	mul.f64 	%fd31, %fd133, 0d3FE0000000000000;
	sub.f64 	%fd32, %fd132, %fd31;
	setp.lt.s32 	%p29, %r42, 3;
	@%p29 bra 	$L__BB2_58;

	add.s32 	%r29, %r42, -2;
	and.b32  	%r30, %r29, 1;
	setp.eq.s32 	%p30, %r42, 3;
	mov.f64 	%fd195, 0d0000000000000000;
	mov.u32 	%r144, 2;
	@%p30 bra 	$L__BB2_52;

	sub.s32 	%r143, %r29, %r30;
	mov.f64 	%fd195, 0d0000000000000000;
	mov.u32 	%r144, 2;

$L__BB2_41:
	add.s32 	%r82, %r144, -1;
	rem.s32 	%r83, %r82, %r28;
	add.s32 	%r84, %r144, -2;
	rem.s32 	%r85, %r84, %r28;
	mul.lo.s32 	%r86, %r144, %r41;
	add.s32 	%r87, %r86, %r1;
	cvt.s64.s32 	%rd13, %r87;
	mul.wide.s32 	%rd37, %r87, 4;
	add.s64 	%rd38, %rd2, %rd37;
	ld.global.nc.f32 	%f11, [%rd38];
	cvt.ftz.f64.f32 	%fd35, %f11;
	sub.s32 	%r88, %r86, %r41;
	add.s32 	%r34, %r88, %r1;
	mul.wide.s32 	%rd39, %r34, 4;
	add.s64 	%rd40, %rd2, %rd39;
	ld.global.nc.f32 	%f12, [%rd40];
	cvt.ftz.f64.f32 	%fd136, %f12;
	shl.b32 	%r89, %r83, 3;
	mov.u32 	%r90, sdata;
	add.s32 	%r35, %r90, %r89;
	shl.b32 	%r91, %r85, 3;
	add.s32 	%r92, %r90, %r91;
	add.f64 	%fd137, %fd35, %fd136;
	mul.f64 	%fd138, %fd22, %fd137;
	ld.shared.f64 	%fd139, [%r92];
	mul.f64 	%fd140, %fd7, %fd139;
	sub.f64 	%fd141, %fd138, %fd140;
	ld.shared.f64 	%fd142, [%r35];
	fma.rn.f64 	%fd36, %fd21, %fd142, %fd141;
	rem.s32 	%r93, %r144, %r28;
	shl.b32 	%r94, %r93, 3;
	add.s32 	%r95, %r90, %r94;
	st.shared.f64 	[%r95], %fd36;
	setp.lt.s32 	%p31, %r144, %r40;
	mov.f32 	%f25, 0f00000000;
	mov.f64 	%fd194, %fd36;
	@%p31 bra 	$L__BB2_46;

	sub.s32 	%r96, %r144, %r40;
	rem.s32 	%r97, %r96, %r28;
	shl.b32 	%r98, %r97, 3;
	add.s32 	%r100, %r90, %r98;
	ld.shared.f64 	%fd37, [%r100];
	mul.f64 	%fd143, %fd31, %fd37;
	fma.rn.f64 	%fd144, %fd32, %fd36, %fd143;
	mul.f64 	%fd145, %fd30, %fd199;
	sub.f64 	%fd38, %fd144, %fd145;
	mul.f64 	%fd146, %fd38, 0d3FA47AE147AE147B;
	mul.f64 	%fd147, %fd38, %fd146;
	mov.f64 	%fd148, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd195, %fd148, %fd195, %fd147;
	setp.leu.f64 	%p32, %fd195, 0d0000000000000000;
	@%p32 bra 	$L__BB2_45;

	abs.f64 	%fd149, %fd195;
	setp.geu.f64 	%p33, %fd149, 0d7FF0000000000000;
	@%p33 bra 	$L__BB2_45;

	sqrt.rn.f64 	%fd150, %fd195;
	div.rn.f64 	%fd151, %fd38, %fd150;
	cvt.rn.ftz.f32.f64 	%f25, %fd151;

$L__BB2_45:
	shl.b64 	%rd41, %rd13, 2;
	add.s64 	%rd42, %rd1, %rd41;
	st.global.f32 	[%rd42], %f25;
	sub.f64 	%fd194, %fd36, %fd37;

$L__BB2_46:
	add.f64 	%fd43, %fd199, %fd194;
	add.s32 	%r36, %r144, 1;
	rem.s32 	%r101, %r36, %r28;
	shl.b32 	%r102, %r41, 1;
	add.s32 	%r103, %r34, %r102;
	cvt.s64.s32 	%rd14, %r103;
	mul.wide.s32 	%rd43, %r103, 4;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.nc.f32 	%f15, [%rd44];
	cvt.ftz.f64.f32 	%fd152, %f15;
	add.f64 	%fd153, %fd152, %fd35;
	mul.f64 	%fd154, %fd22, %fd153;
	ld.shared.f64 	%fd155, [%r35];
	mul.f64 	%fd156, %fd7, %fd155;
	sub.f64 	%fd157, %fd154, %fd156;
	fma.rn.f64 	%fd196, %fd21, %fd36, %fd157;
	shl.b32 	%r104, %r101, 3;
	add.s32 	%r106, %r90, %r104;
	st.shared.f64 	[%r106], %fd196;
	setp.lt.s32 	%p34, %r36, %r40;
	mov.f32 	%f26, 0f00000000;
	@%p34 bra 	$L__BB2_51;

	sub.s32 	%r107, %r36, %r40;
	rem.s32 	%r108, %r107, %r28;
	shl.b32 	%r109, %r108, 3;
	add.s32 	%r111, %r90, %r109;
	ld.shared.f64 	%fd45, [%r111];
	mul.f64 	%fd158, %fd31, %fd45;
	fma.rn.f64 	%fd159, %fd32, %fd196, %fd158;
	mul.f64 	%fd160, %fd30, %fd43;
	sub.f64 	%fd46, %fd159, %fd160;
	mul.f64 	%fd161, %fd46, 0d3FA47AE147AE147B;
	mul.f64 	%fd162, %fd46, %fd161;
	mov.f64 	%fd163, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd195, %fd163, %fd195, %fd162;
	setp.leu.f64 	%p35, %fd195, 0d0000000000000000;
	@%p35 bra 	$L__BB2_50;

	abs.f64 	%fd164, %fd195;
	setp.geu.f64 	%p36, %fd164, 0d7FF0000000000000;
	@%p36 bra 	$L__BB2_50;

	sqrt.rn.f64 	%fd165, %fd195;
	div.rn.f64 	%fd166, %fd46, %fd165;
	cvt.rn.ftz.f32.f64 	%f26, %fd166;

$L__BB2_50:
	shl.b64 	%rd45, %rd14, 2;
	add.s64 	%rd46, %rd1, %rd45;
	st.global.f32 	[%rd46], %f26;
	sub.f64 	%fd196, %fd196, %fd45;

$L__BB2_51:
	add.f64 	%fd199, %fd43, %fd196;
	add.s32 	%r144, %r144, 2;
	add.s32 	%r143, %r143, -2;
	setp.ne.s32 	%p37, %r143, 0;
	@%p37 bra 	$L__BB2_41;

$L__BB2_52:
	setp.eq.s32 	%p38, %r30, 0;
	@%p38 bra 	$L__BB2_58;

	rem.s32 	%r112, %r144, %r28;
	add.s32 	%r113, %r144, -1;
	rem.s32 	%r114, %r113, %r28;
	add.s32 	%r115, %r144, -2;
	rem.s32 	%r116, %r115, %r28;
	mul.lo.s32 	%r117, %r144, %r41;
	add.s32 	%r118, %r117, %r1;
	cvt.s64.s32 	%rd15, %r118;
	mul.wide.s32 	%rd47, %r118, 4;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.nc.f32 	%f18, [%rd48];
	cvt.ftz.f64.f32 	%fd167, %f18;
	sub.s32 	%r119, %r117, %r41;
	add.s32 	%r120, %r119, %r1;
	mul.wide.s32 	%rd49, %r120, 4;
	add.s64 	%rd50, %rd2, %rd49;
	ld.global.nc.f32 	%f19, [%rd50];
	cvt.ftz.f64.f32 	%fd168, %f19;
	shl.b32 	%r121, %r114, 3;
	mov.u32 	%r122, sdata;
	add.s32 	%r123, %r122, %r121;
	shl.b32 	%r124, %r116, 3;
	add.s32 	%r125, %r122, %r124;
	add.f64 	%fd169, %fd167, %fd168;
	mul.f64 	%fd170, %fd22, %fd169;
	ld.shared.f64 	%fd171, [%r125];
	mul.f64 	%fd172, %fd7, %fd171;
	sub.f64 	%fd173, %fd170, %fd172;
	ld.shared.f64 	%fd174, [%r123];
	fma.rn.f64 	%fd54, %fd21, %fd174, %fd173;
	shl.b32 	%r126, %r112, 3;
	add.s32 	%r127, %r122, %r126;
	st.shared.f64 	[%r127], %fd54;
	setp.lt.s32 	%p39, %r144, %r40;
	mov.f32 	%f27, 0f00000000;
	@%p39 bra 	$L__BB2_58;

	sub.s32 	%r128, %r144, %r40;
	rem.s32 	%r129, %r128, %r28;
	shl.b32 	%r130, %r129, 3;
	add.s32 	%r132, %r122, %r130;
	ld.shared.f64 	%fd175, [%r132];
	mul.f64 	%fd176, %fd31, %fd175;
	fma.rn.f64 	%fd177, %fd32, %fd54, %fd176;
	mul.f64 	%fd178, %fd30, %fd199;
	sub.f64 	%fd55, %fd177, %fd178;
	mul.f64 	%fd179, %fd55, 0d3FA47AE147AE147B;
	mul.f64 	%fd180, %fd55, %fd179;
	mov.f64 	%fd181, 0d3FEEB851EB851EB8;
	fma.rn.f64 	%fd56, %fd181, %fd195, %fd180;
	setp.leu.f64 	%p40, %fd56, 0d0000000000000000;
	@%p40 bra 	$L__BB2_57;

	abs.f64 	%fd182, %fd56;
	setp.geu.f64 	%p41, %fd182, 0d7FF0000000000000;
	@%p41 bra 	$L__BB2_57;

	sqrt.rn.f64 	%fd183, %fd56;
	div.rn.f64 	%fd184, %fd55, %fd183;
	cvt.rn.ftz.f32.f64 	%f27, %fd184;

$L__BB2_57:
	shl.b64 	%rd51, %rd15, 2;
	add.s64 	%rd52, %rd1, %rd51;
	st.global.f32 	[%rd52], %f27;

$L__BB2_58:
	ret;

}
.func  (.param .align 8 .b8 func_retval0[16]) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0
)
{
	.local .align 8 .b8 	__local_depot3[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<38>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<77>;


	mov.u64 	%SPL, __local_depot3;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp;
	mov.b64 	{%temp, %r1}, %fd4;
	}
	shr.u32 	%r12, %r1, 20;
	and.b32  	%r2, %r12, 2047;
	setp.eq.s32 	%p1, %r2, 2047;
	mov.u32 	%r37, 0;
	@%p1 bra 	$L__BB3_7;

	add.s32 	%r13, %r2, -1024;
	shr.u32 	%r14, %r13, 6;
	mov.u32 	%r15, 16;
	sub.s32 	%r16, %r15, %r14;
	mov.u32 	%r17, 15;
	sub.s32 	%r3, %r17, %r14;
	mov.u32 	%r18, 19;
	sub.s32 	%r19, %r18, %r14;
	setp.gt.s32 	%p2, %r16, 14;
	selp.b32 	%r4, 18, %r19, %p2;
	setp.gt.s32 	%p3, %r16, %r4;
	mov.u64 	%rd74, 0;
	mov.u32 	%r36, %r3;
	@%p3 bra 	$L__BB3_4;

	mul.wide.s32 	%rd21, %r3, 8;
	mov.u64 	%rd22, __cudart_i2opi_d;
	add.s64 	%rd72, %rd22, %rd21;
	mov.b64 	%rd23, %fd4;
	shl.b64 	%rd24, %rd23, 11;
	or.b64  	%rd3, %rd24, -9223372036854775808;
	mov.u64 	%rd74, 0;
	mov.u64 	%rd71, %rd1;
	mov.u32 	%r36, %r3;

$L__BB3_3:
	.pragma "nounroll";
	ld.global.nc.u64 	%rd25, [%rd72];
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
	mov.b64 	{%alo,%ahi}, %rd25;
	mov.b64 	{%blo,%bhi}, %rd3;
	mov.b64 	{%clo,%chi}, %rd74;
	mad.lo.cc.u32 	%r0, %alo, %blo, %clo;
	madc.hi.cc.u32 	%r1, %alo, %blo, %chi;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd26, {%r0,%r1};
	mov.b64 	%rd74, {%r2,%r3};
	}
	st.local.u64 	[%rd71], %rd26;
	add.s64 	%rd72, %rd72, 8;
	add.s64 	%rd71, %rd71, 8;
	add.s32 	%r36, %r36, 1;
	setp.lt.s32 	%p4, %r36, %r4;
	@%p4 bra 	$L__BB3_3;

$L__BB3_4:
	sub.s32 	%r20, %r36, %r3;
	mul.wide.s32 	%rd27, %r20, 8;
	add.s64 	%rd28, %rd1, %rd27;
	st.local.u64 	[%rd28], %rd74;
	add.s32 	%r22, %r12, -1024;
	and.b32  	%r8, %r22, 63;
	ld.local.u64 	%rd76, [%rd1+16];
	ld.local.u64 	%rd75, [%rd1+24];
	setp.eq.s32 	%p5, %r8, 0;
	@%p5 bra 	$L__BB3_6;

	mov.u32 	%r23, 64;
	sub.s32 	%r24, %r23, %r8;
	shl.b64 	%rd29, %rd75, %r8;
	shr.u64 	%rd30, %rd76, %r24;
	or.b64  	%rd75, %rd29, %rd30;
	shl.b64 	%rd31, %rd76, %r8;
	ld.local.u64 	%rd32, [%rd1+8];
	shr.u64 	%rd33, %rd32, %r24;
	or.b64  	%rd76, %rd33, %rd31;

$L__BB3_6:
	shr.u64 	%rd34, %rd75, 62;
	cvt.u32.u64 	%r25, %rd34;
	shr.u64 	%rd35, %rd76, 62;
	shl.b64 	%rd36, %rd75, 2;
	or.b64  	%rd37, %rd35, %rd36;
	shr.u64 	%rd38, %rd75, 61;
	cvt.u32.u64 	%r26, %rd38;
	and.b32  	%r27, %r26, 1;
	add.s32 	%r28, %r27, %r25;
	and.b32  	%r29, %r1, -2147483648;
	setp.eq.s32 	%p6, %r29, 0;
	neg.s32 	%r30, %r28;
	selp.b32 	%r37, %r28, %r30, %p6;
	setp.eq.s32 	%p7, %r27, 0;
	shl.b64 	%rd39, %rd76, 2;
	mov.u64 	%rd40, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd40;
	mov.b64 	{%a2,%a3}, %rd40;
	mov.b64 	{%b0,%b1}, %rd39;
	mov.b64 	{%b2,%b3}, %rd37;
	sub.cc.u32 	%r0, %a0, %b0;
	subc.cc.u32 	%r1, %a1, %b1;
	subc.cc.u32 	%r2, %a2, %b2;
	subc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd41, {%r0,%r1};
	mov.b64 	%rd42, {%r2,%r3};
	}
	xor.b32  	%r31, %r29, -2147483648;
	selp.b64 	%rd43, %rd37, %rd42, %p7;
	selp.b64 	%rd44, %rd39, %rd41, %p7;
	selp.b32 	%r32, %r29, %r31, %p7;
	clz.b64 	%r33, %rd43;
	cvt.u64.u32 	%rd45, %r33;
	setp.eq.s64 	%p8, %rd45, 0;
	shl.b64 	%rd46, %rd43, %r33;
	mov.u64 	%rd47, 64;
	sub.s64 	%rd48, %rd47, %rd45;
	cvt.u32.u64 	%r34, %rd48;
	shr.u64 	%rd49, %rd44, %r34;
	or.b64  	%rd50, %rd49, %rd46;
	selp.b64 	%rd51, %rd43, %rd50, %p8;
	mov.u64 	%rd52, -3958705157555305931;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
	mov.b64 	{%alo,%ahi}, %rd51;
	mov.b64 	{%blo,%bhi}, %rd52;
	mul.lo.u32 	%r0, %alo, %blo;
	mul.hi.u32 	%r1, %alo, %blo;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd53, {%r0,%r1};
	mov.b64 	%rd54, {%r2,%r3};
	}
	setp.gt.s64 	%p9, %rd54, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd53;
	mov.b64 	{%a2,%a3}, %rd54;
	mov.b64 	{%b0,%b1}, %rd53;
	mov.b64 	{%b2,%b3}, %rd54;
	add.cc.u32 	%r0, %a0, %b0;
	addc.cc.u32 	%r1, %a1, %b1;
	addc.cc.u32 	%r2, %a2, %b2;
	addc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd55, {%r0,%r1};
	mov.b64 	%rd56, {%r2,%r3};
	}
	selp.b64 	%rd57, %rd56, %rd54, %p9;
	selp.u64 	%rd58, 1, 0, %p9;
	add.s64 	%rd59, %rd45, %rd58;
	cvt.u64.u32 	%rd60, %r32;
	shl.b64 	%rd61, %rd60, 32;
	shl.b64 	%rd62, %rd59, 52;
	mov.u64 	%rd63, 4602678819172646912;
	sub.s64 	%rd64, %rd63, %rd62;
	add.s64 	%rd65, %rd57, 1;
	shr.u64 	%rd66, %rd65, 10;
	add.s64 	%rd67, %rd66, 1;
	shr.u64 	%rd68, %rd67, 1;
	add.s64 	%rd69, %rd64, %rd68;
	or.b64  	%rd70, %rd69, %rd61;
	mov.b64 	%fd4, %rd70;

$L__BB3_7:
	st.param.f64 	[func_retval0+0], %fd4;
	st.param.b32 	[func_retval0+8], %r37;
	ret;

}

