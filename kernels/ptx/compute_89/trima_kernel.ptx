







.version 9.0
.target sm_89
.address_size 64

	
.extern .shared .align 16 .b8 weights[];
.extern .shared .align 16 .b8 smem[];
.extern .shared .align 16 .b8 shared_weights[];

.visible .entry trima_batch_f32(
	.param .u64 trima_batch_f32_param_0,
	.param .u64 trima_batch_f32_param_1,
	.param .u64 trima_batch_f32_param_2,
	.param .u32 trima_batch_f32_param_3,
	.param .u32 trima_batch_f32_param_4,
	.param .u32 trima_batch_f32_param_5,
	.param .u64 trima_batch_f32_param_6
)
{
	.reg .pred 	%p<27>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<85>;
	.reg .b64 	%rd<31>;


	ld.param.u64 	%rd12, [trima_batch_f32_param_0];
	ld.param.u64 	%rd10, [trima_batch_f32_param_1];
	ld.param.u64 	%rd11, [trima_batch_f32_param_2];
	ld.param.u32 	%r37, [trima_batch_f32_param_3];
	ld.param.u32 	%r39, [trima_batch_f32_param_4];
	ld.param.u32 	%r38, [trima_batch_f32_param_5];
	ld.param.u64 	%rd13, [trima_batch_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd12;
	cvta.to.global.u64 	%rd2, %rd13;
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r39;
	@%p1 bra 	$L__BB0_24;

	cvta.to.global.u64 	%rd14, %rd10;
	cvt.s64.s32 	%rd3, %r1;
	mul.wide.s32 	%rd15, %r1, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.u32 	%r2, [%rd16];
	setp.lt.s32 	%p2, %r2, 1;
	setp.gt.s32 	%p3, %r2, %r38;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_24;

	cvta.to.global.u64 	%rd17, %rd11;
	shl.b64 	%rd18, %rd3, 2;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.u32 	%r3, [%rd19];
	add.s32 	%r40, %r2, 1;
	shr.u32 	%r41, %r40, 31;
	add.s32 	%r42, %r40, %r41;
	shr.s32 	%r4, %r42, 1;
	sub.s32 	%r5, %r2, %r4;
	mov.u32 	%r6, %tid.x;
	setp.gt.s32 	%p5, %r2, %r6;
	@%p5 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_5;

$L__BB0_3:
	mov.u32 	%r7, %ntid.x;
	add.s32 	%r43, %r5, 1;
	mul.lo.s32 	%r44, %r43, %r4;
	cvt.rn.f32.s32 	%f10, %r44;
	rcp.approx.ftz.f32 	%f1, %f10;
	mov.u32 	%r75, %r6;

$L__BB0_4:
	sub.s32 	%r45, %r2, %r75;
	setp.gt.s32 	%p6, %r75, %r5;
	selp.b32 	%r46, %r45, %r4, %p6;
	add.s32 	%r47, %r75, 1;
	setp.lt.s32 	%p7, %r75, %r4;
	selp.b32 	%r48, %r47, %r46, %p7;
	max.s32 	%r49, %r48, 0;
	cvt.rn.f32.s32 	%f11, %r49;
	mul.ftz.f32 	%f12, %f1, %f11;
	shl.b32 	%r50, %r75, 2;
	mov.u32 	%r51, weights;
	add.s32 	%r52, %r51, %r50;
	st.shared.f32 	[%r52], %f12;
	add.s32 	%r75, %r75, %r7;
	setp.gt.s32 	%p8, %r2, %r75;
	@%p8 bra 	$L__BB0_4;

$L__BB0_5:
	mov.u32 	%r53, %ntid.x;
	bar.sync 	0;
	mul.lo.s32 	%r10, %r1, %r37;
	mov.u32 	%r54, %ctaid.x;
	mad.lo.s32 	%r78, %r54, %r53, %r6;
	mov.u32 	%r55, %nctaid.x;
	mul.lo.s32 	%r12, %r53, %r55;
	setp.ge.s32 	%p9, %r78, %r37;
	@%p9 bra 	$L__BB0_24;

	setp.gt.s32 	%p10, %r2, 0;
	@%p10 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_7;

$L__BB0_12:
	add.s32 	%r22, %r2, -1;
	and.b32  	%r23, %r2, 3;
	sub.s32 	%r24, %r2, %r23;
	mov.u32 	%r66, 1;
	sub.s32 	%r25, %r66, %r2;

$L__BB0_13:
	add.s32 	%r67, %r78, %r10;
	mul.wide.s32 	%rd27, %r67, 4;
	add.s64 	%rd5, %rd2, %rd27;
	setp.lt.s32 	%p20, %r78, %r3;
	@%p20 bra 	$L__BB0_22;
	bra.uni 	$L__BB0_14;

$L__BB0_22:
	mov.u32 	%r74, 2143289344;
	st.global.u32 	[%rd5], %r74;
	bra.uni 	$L__BB0_23;

$L__BB0_14:
	setp.lt.u32 	%p21, %r22, 3;
	add.s32 	%r27, %r25, %r78;
	mov.f32 	%f45, 0f00000000;
	mov.u32 	%r84, 0;
	@%p21 bra 	$L__BB0_17;

	mul.wide.s32 	%rd28, %r27, 4;
	add.s64 	%rd30, %rd1, %rd28;
	mov.f32 	%f45, 0f00000000;
	mov.u32 	%r84, 0;
	mov.u32 	%r81, weights;
	mov.u32 	%r83, %r24;

$L__BB0_16:
	.pragma "nounroll";
	ld.shared.v4.f32 	{%f21, %f22, %f23, %f24}, [%r81];
	ld.global.nc.f32 	%f29, [%rd30];
	fma.rn.ftz.f32 	%f30, %f29, %f21, %f45;
	ld.global.nc.f32 	%f31, [%rd30+4];
	fma.rn.ftz.f32 	%f32, %f31, %f22, %f30;
	ld.global.nc.f32 	%f33, [%rd30+8];
	fma.rn.ftz.f32 	%f34, %f33, %f23, %f32;
	ld.global.nc.f32 	%f35, [%rd30+12];
	fma.rn.ftz.f32 	%f45, %f35, %f24, %f34;
	add.s32 	%r84, %r84, 4;
	add.s32 	%r81, %r81, 16;
	add.s64 	%rd30, %rd30, 16;
	add.s32 	%r83, %r83, -4;
	setp.ne.s32 	%p22, %r83, 0;
	@%p22 bra 	$L__BB0_16;

$L__BB0_17:
	setp.eq.s32 	%p23, %r23, 0;
	@%p23 bra 	$L__BB0_21;

	setp.eq.s32 	%p24, %r23, 1;
	add.s32 	%r71, %r27, %r84;
	mul.wide.s32 	%rd29, %r71, 4;
	add.s64 	%rd9, %rd1, %rd29;
	shl.b32 	%r72, %r84, 2;
	mov.u32 	%r73, weights;
	add.s32 	%r35, %r73, %r72;
	ld.shared.f32 	%f36, [%r35];
	ld.global.nc.f32 	%f37, [%rd9];
	fma.rn.ftz.f32 	%f45, %f37, %f36, %f45;
	@%p24 bra 	$L__BB0_21;

	setp.eq.s32 	%p25, %r23, 2;
	ld.shared.f32 	%f38, [%r35+4];
	ld.global.nc.f32 	%f39, [%rd9+4];
	fma.rn.ftz.f32 	%f45, %f39, %f38, %f45;
	@%p25 bra 	$L__BB0_21;

	ld.shared.f32 	%f40, [%r35+8];
	ld.global.nc.f32 	%f41, [%rd9+8];
	fma.rn.ftz.f32 	%f45, %f41, %f40, %f45;

$L__BB0_21:
	st.global.f32 	[%rd5], %f45;

$L__BB0_23:
	add.s32 	%r78, %r78, %r12;
	setp.lt.s32 	%p26, %r78, %r37;
	@%p26 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_24;

$L__BB0_7:
	add.s32 	%r56, %r12, %r37;
	add.s32 	%r57, %r78, %r12;
	not.b32 	%r58, %r57;
	add.s32 	%r59, %r56, %r58;
	div.u32 	%r13, %r59, %r12;
	add.s32 	%r60, %r13, 1;
	and.b32  	%r77, %r60, 3;
	setp.eq.s32 	%p11, %r77, 0;
	@%p11 bra 	$L__BB0_9;

$L__BB0_8:
	.pragma "nounroll";
	add.s32 	%r61, %r78, %r10;
	mul.wide.s32 	%rd20, %r61, 4;
	add.s64 	%rd21, %rd2, %rd20;
	setp.lt.s32 	%p12, %r78, %r3;
	selp.f32 	%f13, 0f7FC00000, 0f00000000, %p12;
	st.global.f32 	[%rd21], %f13;
	add.s32 	%r78, %r78, %r12;
	add.s32 	%r77, %r77, -1;
	setp.ne.s32 	%p13, %r77, 0;
	@%p13 bra 	$L__BB0_8;

$L__BB0_9:
	setp.lt.u32 	%p14, %r13, 3;
	@%p14 bra 	$L__BB0_24;

	mul.wide.s32 	%rd4, %r12, 4;

$L__BB0_11:
	add.s32 	%r62, %r78, %r10;
	mul.wide.s32 	%rd22, %r62, 4;
	add.s64 	%rd23, %rd2, %rd22;
	setp.lt.s32 	%p15, %r78, %r3;
	selp.f32 	%f14, 0f7FC00000, 0f00000000, %p15;
	st.global.f32 	[%rd23], %f14;
	add.s32 	%r63, %r78, %r12;
	setp.lt.s32 	%p16, %r63, %r3;
	selp.f32 	%f15, 0f7FC00000, 0f00000000, %p16;
	add.s64 	%rd24, %rd23, %rd4;
	st.global.f32 	[%rd24], %f15;
	add.s32 	%r64, %r63, %r12;
	setp.lt.s32 	%p17, %r64, %r3;
	selp.f32 	%f16, 0f7FC00000, 0f00000000, %p17;
	add.s64 	%rd25, %rd24, %rd4;
	st.global.f32 	[%rd25], %f16;
	add.s32 	%r65, %r64, %r12;
	setp.lt.s32 	%p18, %r65, %r3;
	selp.f32 	%f17, 0f7FC00000, 0f00000000, %p18;
	add.s64 	%rd26, %rd25, %rd4;
	st.global.f32 	[%rd26], %f17;
	add.s32 	%r78, %r65, %r12;
	setp.lt.s32 	%p19, %r78, %r37;
	@%p19 bra 	$L__BB0_11;

$L__BB0_24:
	ret;

}
	
.visible .entry trima_batch_f32_tiled(
	.param .u64 trima_batch_f32_tiled_param_0,
	.param .u64 trima_batch_f32_tiled_param_1,
	.param .u64 trima_batch_f32_tiled_param_2,
	.param .u32 trima_batch_f32_tiled_param_3,
	.param .u32 trima_batch_f32_tiled_param_4,
	.param .u32 trima_batch_f32_tiled_param_5,
	.param .u64 trima_batch_f32_tiled_param_6
)
{
	.reg .pred 	%p<19>;
	.reg .f32 	%f<39>;
	.reg .b32 	%r<93>;
	.reg .b64 	%rd<18>;


	ld.param.u64 	%rd4, [trima_batch_f32_tiled_param_0];
	ld.param.u64 	%rd5, [trima_batch_f32_tiled_param_1];
	ld.param.u64 	%rd6, [trima_batch_f32_tiled_param_2];
	ld.param.u32 	%r36, [trima_batch_f32_tiled_param_3];
	ld.param.u32 	%r38, [trima_batch_f32_tiled_param_4];
	ld.param.u32 	%r37, [trima_batch_f32_tiled_param_5];
	ld.param.u64 	%rd7, [trima_batch_f32_tiled_param_6];
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32 	%p1, %r1, %r38;
	@%p1 bra 	$L__BB1_20;

	cvta.to.global.u64 	%rd8, %rd5;
	cvt.s64.s32 	%rd1, %r1;
	mul.wide.s32 	%rd9, %r1, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.u32 	%r2, [%rd10];
	setp.lt.s32 	%p2, %r2, 1;
	setp.gt.s32 	%p3, %r2, %r37;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB1_20;

	cvta.to.global.u64 	%rd11, %rd6;
	shl.b64 	%rd12, %rd1, 2;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.nc.u32 	%r3, [%rd13];
	add.s32 	%r39, %r2, 1;
	shr.u32 	%r40, %r39, 31;
	add.s32 	%r41, %r39, %r40;
	shr.s32 	%r4, %r41, 1;
	sub.s32 	%r5, %r2, %r4;
	mov.u32 	%r6, %tid.x;
	setp.gt.s32 	%p5, %r2, %r6;
	@%p5 bra 	$L__BB1_3;
	bra.uni 	$L__BB1_5;

$L__BB1_3:
	mov.u32 	%r7, %ntid.x;
	add.s32 	%r42, %r5, 1;
	mul.lo.s32 	%r43, %r42, %r4;
	cvt.rn.f32.s32 	%f9, %r43;
	rcp.approx.ftz.f32 	%f1, %f9;
	mov.u32 	%r84, %r6;

$L__BB1_4:
	sub.s32 	%r44, %r2, %r84;
	setp.gt.s32 	%p6, %r84, %r5;
	selp.b32 	%r45, %r44, %r4, %p6;
	add.s32 	%r46, %r84, 1;
	setp.lt.s32 	%p7, %r84, %r4;
	selp.b32 	%r47, %r46, %r45, %p7;
	max.s32 	%r48, %r47, 0;
	cvt.rn.f32.s32 	%f10, %r48;
	mul.ftz.f32 	%f11, %f1, %f10;
	shl.b32 	%r49, %r84, 2;
	mov.u32 	%r50, smem;
	add.s32 	%r51, %r50, %r49;
	st.shared.f32 	[%r51], %f11;
	add.s32 	%r84, %r84, %r7;
	setp.gt.s32 	%p8, %r2, %r84;
	@%p8 bra 	$L__BB1_4;

$L__BB1_5:
	mov.u32 	%r10, %ntid.x;
	bar.sync 	0;
	mov.u32 	%r52, %ctaid.x;
	mul.lo.s32 	%r11, %r52, %r10;
	setp.ge.s32 	%p9, %r11, %r36;
	@%p9 bra 	$L__BB1_20;

	add.s32 	%r53, %r11, %r10;
	min.s32 	%r12, %r53, %r36;
	sub.s32 	%r54, %r11, %r2;
	add.s32 	%r55, %r54, 1;
	max.s32 	%r13, %r55, 0;
	not.b32 	%r56, %r13;
	add.s32 	%r14, %r12, %r56;
	setp.gt.s32 	%p10, %r6, %r14;
	@%p10 bra 	$L__BB1_9;

	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r85, %r6;

$L__BB1_8:
	add.s32 	%r57, %r85, %r13;
	mul.wide.s32 	%rd14, %r57, 4;
	add.s64 	%rd15, %rd2, %rd14;
	ld.global.nc.f32 	%f12, [%rd15];
	add.s32 	%r58, %r85, %r37;
	shl.b32 	%r59, %r58, 2;
	mov.u32 	%r60, smem;
	add.s32 	%r61, %r60, %r59;
	st.shared.f32 	[%r61], %f12;
	add.s32 	%r85, %r85, %r10;
	setp.le.s32 	%p11, %r85, %r14;
	@%p11 bra 	$L__BB1_8;

$L__BB1_9:
	bar.sync 	0;
	add.s32 	%r17, %r11, %r6;
	setp.ge.s32 	%p12, %r17, %r12;
	@%p12 bra 	$L__BB1_20;

	mad.lo.s32 	%r62, %r1, %r36, %r17;
	cvta.to.global.u64 	%rd16, %rd7;
	mul.wide.s32 	%rd17, %r62, 4;
	add.s64 	%rd3, %rd16, %rd17;
	setp.lt.s32 	%p13, %r17, %r3;
	@%p13 bra 	$L__BB1_19;
	bra.uni 	$L__BB1_11;

$L__BB1_19:
	mov.u32 	%r83, 2143289344;
	st.global.u32 	[%rd3], %r83;
	bra.uni 	$L__BB1_20;

$L__BB1_11:
	mov.f32 	%f38, 0f00000000;
	@%p2 bra 	$L__BB1_18;

	add.s32 	%r64, %r2, -1;
	and.b32  	%r92, %r2, 3;
	setp.lt.u32 	%p15, %r64, 3;
	mov.f32 	%f38, 0f00000000;
	mov.u32 	%r89, 0;
	@%p15 bra 	$L__BB1_15;

	sub.s32 	%r88, %r2, %r92;
	add.s32 	%r67, %r6, %r37;
	add.s32 	%r68, %r67, %r11;
	shl.b32 	%r69, %r68, 2;
	add.s32 	%r70, %r69, 8;
	add.s32 	%r71, %r2, %r13;
	shl.b32 	%r72, %r71, 2;
	sub.s32 	%r20, %r70, %r72;
	mov.f32 	%f38, 0f00000000;
	mov.u32 	%r89, 0;
	mov.u32 	%r86, smem;

$L__BB1_14:
	.pragma "nounroll";
	ld.shared.v4.f32 	{%f17, %f18, %f19, %f20}, [%r86];
	add.s32 	%r73, %r86, %r20;
	ld.shared.f32 	%f25, [%r73+-4];
	fma.rn.ftz.f32 	%f26, %f25, %f17, %f38;
	ld.shared.f32 	%f27, [%r73];
	fma.rn.ftz.f32 	%f28, %f27, %f18, %f26;
	ld.shared.f32 	%f29, [%r73+4];
	fma.rn.ftz.f32 	%f30, %f29, %f19, %f28;
	ld.shared.f32 	%f31, [%r73+8];
	fma.rn.ftz.f32 	%f38, %f31, %f20, %f30;
	add.s32 	%r89, %r89, 4;
	add.s32 	%r86, %r86, 16;
	add.s32 	%r88, %r88, -4;
	setp.ne.s32 	%p16, %r88, 0;
	@%p16 bra 	$L__BB1_14;

$L__BB1_15:
	setp.eq.s32 	%p17, %r92, 0;
	@%p17 bra 	$L__BB1_18;

	shl.b32 	%r74, %r89, 2;
	mov.u32 	%r75, smem;
	add.s32 	%r91, %r75, %r74;
	add.s32 	%r76, %r6, %r89;
	add.s32 	%r77, %r76, %r37;
	add.s32 	%r78, %r77, %r11;
	add.s32 	%r79, %r78, 1;
	add.s32 	%r80, %r2, %r13;
	sub.s32 	%r81, %r79, %r80;
	shl.b32 	%r82, %r81, 2;
	add.s32 	%r90, %r75, %r82;

$L__BB1_17:
	.pragma "nounroll";
	ld.shared.f32 	%f32, [%r91];
	ld.shared.f32 	%f33, [%r90];
	fma.rn.ftz.f32 	%f38, %f33, %f32, %f38;
	add.s32 	%r91, %r91, 4;
	add.s32 	%r90, %r90, 4;
	add.s32 	%r92, %r92, -1;
	setp.ne.s32 	%p18, %r92, 0;
	@%p18 bra 	$L__BB1_17;

$L__BB1_18:
	st.global.f32 	[%rd3], %f38;

$L__BB1_20:
	ret;

}
	
.visible .entry trima_multi_series_one_param_f32(
	.param .u64 trima_multi_series_one_param_f32_param_0,
	.param .u64 trima_multi_series_one_param_f32_param_1,
	.param .u32 trima_multi_series_one_param_f32_param_2,
	.param .u32 trima_multi_series_one_param_f32_param_3,
	.param .u32 trima_multi_series_one_param_f32_param_4,
	.param .u64 trima_multi_series_one_param_f32_param_5,
	.param .u64 trima_multi_series_one_param_f32_param_6
)
{
	.reg .pred 	%p<22>;
	.reg .f32 	%f<43>;
	.reg .b32 	%r<82>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd9, [trima_multi_series_one_param_f32_param_0];
	ld.param.u64 	%rd7, [trima_multi_series_one_param_f32_param_1];
	ld.param.u32 	%r37, [trima_multi_series_one_param_f32_param_2];
	ld.param.u32 	%r38, [trima_multi_series_one_param_f32_param_3];
	ld.param.u32 	%r39, [trima_multi_series_one_param_f32_param_4];
	ld.param.u64 	%rd8, [trima_multi_series_one_param_f32_param_5];
	ld.param.u64 	%rd10, [trima_multi_series_one_param_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd2, %rd10;
	mov.u32 	%r1, %tid.x;
	setp.ge.s32 	%p1, %r1, %r37;
	@%p1 bra 	$L__BB2_3;

	mov.u32 	%r2, %ntid.x;
	cvta.to.global.u64 	%rd3, %rd7;
	mov.u32 	%r72, %r1;

$L__BB2_2:
	mul.wide.s32 	%rd11, %r72, 4;
	add.s64 	%rd12, %rd3, %rd11;
	ld.global.nc.f32 	%f9, [%rd12];
	shl.b32 	%r40, %r72, 2;
	mov.u32 	%r41, shared_weights;
	add.s32 	%r42, %r41, %r40;
	st.shared.f32 	[%r42], %f9;
	add.s32 	%r72, %r72, %r2;
	setp.lt.s32 	%p2, %r72, %r37;
	@%p2 bra 	$L__BB2_2;

$L__BB2_3:
	bar.sync 	0;
	mov.u32 	%r5, %ctaid.y;
	setp.ge.s32 	%p3, %r5, %r38;
	@%p3 bra 	$L__BB2_23;

	mov.u32 	%r43, %ctaid.x;
	mov.u32 	%r6, %ntid.x;
	mad.lo.s32 	%r75, %r43, %r6, %r1;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r9, %r8, %r6;
	cvta.to.global.u64 	%rd13, %rd8;
	mul.wide.s32 	%rd14, %r5, 4;
	add.s64 	%rd15, %rd13, %rd14;
	add.s32 	%r10, %r37, -1;
	ld.global.nc.u32 	%r44, [%rd15];
	add.s32 	%r11, %r10, %r44;
	setp.ge.s32 	%p4, %r75, %r39;
	@%p4 bra 	$L__BB2_23;

	setp.gt.s32 	%p5, %r37, 0;
	@%p5 bra 	$L__BB2_11;
	bra.uni 	$L__BB2_6;

$L__BB2_11:
	and.b32  	%r21, %r37, 3;
	sub.s32 	%r22, %r21, %r37;
	mul.wide.s32 	%rd5, %r38, 4;

$L__BB2_12:
	mad.lo.s32 	%r57, %r75, %r38, %r5;
	mul.wide.s32 	%rd23, %r57, 4;
	add.s64 	%rd6, %rd2, %rd23;
	setp.lt.s32 	%p15, %r75, %r11;
	@%p15 bra 	$L__BB2_21;
	bra.uni 	$L__BB2_13;

$L__BB2_21:
	mov.u32 	%r71, 2143289344;
	st.global.u32 	[%rd6], %r71;
	bra.uni 	$L__BB2_22;

$L__BB2_13:
	setp.lt.u32 	%p16, %r10, 3;
	mov.u32 	%r59, 1;
	sub.s32 	%r60, %r59, %r37;
	add.s32 	%r24, %r60, %r75;
	mov.f32 	%f42, 0f00000000;
	mov.u32 	%r81, 0;
	@%p16 bra 	$L__BB2_16;

	mad.lo.s32 	%r78, %r38, %r24, %r5;
	shl.b32 	%r26, %r38, 2;
	mov.f32 	%f42, 0f00000000;
	mov.u32 	%r81, 0;
	mov.u32 	%r79, shared_weights;

$L__BB2_15:
	.pragma "nounroll";
	mul.wide.s32 	%rd24, %r78, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.shared.v4.f32 	{%f18, %f19, %f20, %f21}, [%r79];
	ld.global.nc.f32 	%f26, [%rd25];
	fma.rn.ftz.f32 	%f27, %f26, %f18, %f42;
	add.s64 	%rd26, %rd25, %rd5;
	ld.global.nc.f32 	%f28, [%rd26];
	fma.rn.ftz.f32 	%f29, %f28, %f19, %f27;
	add.s64 	%rd27, %rd26, %rd5;
	ld.global.nc.f32 	%f30, [%rd27];
	fma.rn.ftz.f32 	%f31, %f30, %f20, %f29;
	add.s64 	%rd28, %rd27, %rd5;
	ld.global.nc.f32 	%f32, [%rd28];
	fma.rn.ftz.f32 	%f42, %f32, %f21, %f31;
	add.s32 	%r79, %r79, 16;
	add.s32 	%r78, %r78, %r26;
	add.s32 	%r81, %r81, 4;
	add.s32 	%r63, %r22, %r81;
	setp.ne.s32 	%p17, %r63, 0;
	@%p17 bra 	$L__BB2_15;

$L__BB2_16:
	setp.eq.s32 	%p18, %r21, 0;
	@%p18 bra 	$L__BB2_20;

	setp.eq.s32 	%p19, %r21, 1;
	add.s32 	%r34, %r24, %r81;
	mad.lo.s32 	%r64, %r34, %r38, %r5;
	mul.wide.s32 	%rd29, %r64, 4;
	add.s64 	%rd30, %rd1, %rd29;
	shl.b32 	%r65, %r81, 2;
	mov.u32 	%r66, shared_weights;
	add.s32 	%r35, %r66, %r65;
	ld.shared.f32 	%f33, [%r35];
	ld.global.nc.f32 	%f34, [%rd30];
	fma.rn.ftz.f32 	%f42, %f34, %f33, %f42;
	@%p19 bra 	$L__BB2_20;

	setp.eq.s32 	%p20, %r21, 2;
	add.s32 	%r67, %r34, 1;
	mad.lo.s32 	%r68, %r67, %r38, %r5;
	mul.wide.s32 	%rd31, %r68, 4;
	add.s64 	%rd32, %rd1, %rd31;
	ld.shared.f32 	%f35, [%r35+4];
	ld.global.nc.f32 	%f36, [%rd32];
	fma.rn.ftz.f32 	%f42, %f36, %f35, %f42;
	@%p20 bra 	$L__BB2_20;

	add.s32 	%r69, %r34, 2;
	mad.lo.s32 	%r70, %r69, %r38, %r5;
	mul.wide.s32 	%rd33, %r70, 4;
	add.s64 	%rd34, %rd1, %rd33;
	ld.shared.f32 	%f37, [%r35+8];
	ld.global.nc.f32 	%f38, [%rd34];
	fma.rn.ftz.f32 	%f42, %f38, %f37, %f42;

$L__BB2_20:
	st.global.f32 	[%rd6], %f42;

$L__BB2_22:
	add.s32 	%r75, %r75, %r9;
	setp.lt.s32 	%p21, %r75, %r39;
	@%p21 bra 	$L__BB2_12;
	bra.uni 	$L__BB2_23;

$L__BB2_6:
	add.s32 	%r45, %r9, %r39;
	add.s32 	%r46, %r75, %r9;
	not.b32 	%r47, %r46;
	add.s32 	%r48, %r45, %r47;
	div.u32 	%r12, %r48, %r9;
	add.s32 	%r49, %r12, 1;
	and.b32  	%r74, %r49, 3;
	setp.eq.s32 	%p6, %r74, 0;
	@%p6 bra 	$L__BB2_8;

$L__BB2_7:
	.pragma "nounroll";
	mad.lo.s32 	%r50, %r75, %r38, %r5;
	mul.wide.s32 	%rd16, %r50, 4;
	add.s64 	%rd17, %rd2, %rd16;
	setp.lt.s32 	%p7, %r75, %r11;
	selp.f32 	%f10, 0f7FC00000, 0f00000000, %p7;
	st.global.f32 	[%rd17], %f10;
	add.s32 	%r75, %r75, %r9;
	add.s32 	%r74, %r74, -1;
	setp.ne.s32 	%p8, %r74, 0;
	@%p8 bra 	$L__BB2_7;

$L__BB2_8:
	setp.lt.u32 	%p9, %r12, 3;
	@%p9 bra 	$L__BB2_23;

	mul.lo.s32 	%r51, %r6, %r8;
	mul.lo.s32 	%r52, %r51, %r38;
	mul.wide.s32 	%rd4, %r52, 4;

$L__BB2_10:
	mad.lo.s32 	%r53, %r75, %r38, %r5;
	mul.wide.s32 	%rd18, %r53, 4;
	add.s64 	%rd19, %rd2, %rd18;
	setp.lt.s32 	%p10, %r75, %r11;
	selp.f32 	%f11, 0f7FC00000, 0f00000000, %p10;
	st.global.f32 	[%rd19], %f11;
	add.s32 	%r54, %r75, %r9;
	setp.lt.s32 	%p11, %r54, %r11;
	selp.f32 	%f12, 0f7FC00000, 0f00000000, %p11;
	add.s64 	%rd20, %rd19, %rd4;
	st.global.f32 	[%rd20], %f12;
	add.s32 	%r55, %r54, %r9;
	setp.lt.s32 	%p12, %r55, %r11;
	selp.f32 	%f13, 0f7FC00000, 0f00000000, %p12;
	add.s64 	%rd21, %rd20, %rd4;
	st.global.f32 	[%rd21], %f13;
	add.s32 	%r56, %r55, %r9;
	setp.lt.s32 	%p13, %r56, %r11;
	selp.f32 	%f14, 0f7FC00000, 0f00000000, %p13;
	add.s64 	%rd22, %rd21, %rd4;
	st.global.f32 	[%rd22], %f14;
	add.s32 	%r75, %r56, %r9;
	setp.lt.s32 	%p14, %r75, %r39;
	@%p14 bra 	$L__BB2_10;

$L__BB2_23:
	ret;

}
	
.visible .entry trima_multi_series_one_param_f32_tm_tiled(
	.param .u64 trima_multi_series_one_param_f32_tm_tiled_param_0,
	.param .u64 trima_multi_series_one_param_f32_tm_tiled_param_1,
	.param .u32 trima_multi_series_one_param_f32_tm_tiled_param_2,
	.param .u32 trima_multi_series_one_param_f32_tm_tiled_param_3,
	.param .u32 trima_multi_series_one_param_f32_tm_tiled_param_4,
	.param .u64 trima_multi_series_one_param_f32_tm_tiled_param_5,
	.param .u64 trima_multi_series_one_param_f32_tm_tiled_param_6
)
{
	.reg .pred 	%p<28>;
	.reg .f32 	%f<49>;
	.reg .b32 	%r<138>;
	.reg .b64 	%rd<31>;


	ld.param.u64 	%rd8, [trima_multi_series_one_param_f32_tm_tiled_param_0];
	ld.param.u64 	%rd6, [trima_multi_series_one_param_f32_tm_tiled_param_1];
	ld.param.u32 	%r52, [trima_multi_series_one_param_f32_tm_tiled_param_2];
	ld.param.u32 	%r53, [trima_multi_series_one_param_f32_tm_tiled_param_3];
	ld.param.u32 	%r54, [trima_multi_series_one_param_f32_tm_tiled_param_4];
	ld.param.u64 	%rd7, [trima_multi_series_one_param_f32_tm_tiled_param_5];
	ld.param.u64 	%rd9, [trima_multi_series_one_param_f32_tm_tiled_param_6];
	cvta.to.global.u64 	%rd1, %rd8;
	cvta.to.global.u64 	%rd2, %rd9;
	mov.u32 	%r1, %tid.x;
	setp.ge.s32 	%p1, %r1, %r52;
	@%p1 bra 	$L__BB3_3;

	mov.u32 	%r2, %ntid.x;
	cvta.to.global.u64 	%rd3, %rd6;
	mov.u32 	%r122, %r1;

$L__BB3_2:
	mul.wide.s32 	%rd10, %r122, 4;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.nc.f32 	%f9, [%rd11];
	shl.b32 	%r55, %r122, 2;
	mov.u32 	%r56, smem;
	add.s32 	%r57, %r56, %r55;
	st.shared.f32 	[%r57], %f9;
	add.s32 	%r122, %r122, %r2;
	setp.lt.s32 	%p2, %r122, %r52;
	@%p2 bra 	$L__BB3_2;

$L__BB3_3:
	bar.sync 	0;
	mov.u32 	%r58, %ctaid.x;
	shl.b32 	%r59, %r58, 7;
	add.s32 	%r5, %r59, %r1;
	setp.ge.s32 	%p3, %r5, %r53;
	@%p3 bra 	$L__BB3_30;

	mov.u32 	%r60, %ctaid.y;
	shl.b32 	%r132, %r60, 6;
	setp.ge.s32 	%p4, %r132, %r54;
	@%p4 bra 	$L__BB3_30;

	add.s32 	%r61, %r132, 64;
	min.s32 	%r7, %r61, %r54;
	sub.s32 	%r62, %r132, %r52;
	add.s32 	%r63, %r62, 1;
	max.s32 	%r8, %r63, 0;
	setp.le.s32 	%p5, %r7, %r8;
	@%p5 bra 	$L__BB3_12;

	add.s32 	%r9, %r1, %r52;
	mov.u32 	%r65, -65;
	sub.s32 	%r66, %r65, %r132;
	not.b32 	%r67, %r54;
	max.s32 	%r68, %r66, %r67;
	not.b32 	%r69, %r8;
	sub.s32 	%r10, %r69, %r68;
	mov.u32 	%r70, -2;
	sub.s32 	%r71, %r70, %r8;
	sub.s32 	%r72, %r71, %r68;
	and.b32  	%r127, %r10, 3;
	setp.lt.u32 	%p6, %r72, 3;
	mov.u32 	%r125, 0;
	@%p6 bra 	$L__BB3_9;

	sub.s32 	%r124, %r10, %r127;
	mul.wide.s32 	%rd4, %r53, 4;
	mov.u32 	%r125, 0;

$L__BB3_8:
	add.s32 	%r74, %r125, %r8;
	mad.lo.s32 	%r75, %r74, %r53, %r5;
	mul.wide.s32 	%rd12, %r75, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.nc.f32 	%f10, [%rd13];
	shl.b32 	%r76, %r125, 7;
	add.s32 	%r77, %r9, %r76;
	shl.b32 	%r78, %r77, 2;
	mov.u32 	%r79, smem;
	add.s32 	%r80, %r79, %r78;
	st.shared.f32 	[%r80], %f10;
	add.s64 	%rd14, %rd13, %rd4;
	ld.global.nc.f32 	%f11, [%rd14];
	st.shared.f32 	[%r80+512], %f11;
	add.s64 	%rd15, %rd14, %rd4;
	ld.global.nc.f32 	%f12, [%rd15];
	st.shared.f32 	[%r80+1024], %f12;
	add.s64 	%rd16, %rd15, %rd4;
	ld.global.nc.f32 	%f13, [%rd16];
	st.shared.f32 	[%r80+1536], %f13;
	add.s32 	%r125, %r125, 4;
	add.s32 	%r124, %r124, -4;
	setp.ne.s32 	%p7, %r124, 0;
	@%p7 bra 	$L__BB3_8;

$L__BB3_9:
	setp.eq.s32 	%p8, %r127, 0;
	@%p8 bra 	$L__BB3_12;

	mov.u32 	%r86, smem;

$L__BB3_11:
	.pragma "nounroll";
	add.s32 	%r81, %r125, %r8;
	mad.lo.s32 	%r82, %r81, %r53, %r5;
	mul.wide.s32 	%rd17, %r82, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.nc.f32 	%f14, [%rd18];
	shl.b32 	%r83, %r125, 7;
	add.s32 	%r84, %r9, %r83;
	shl.b32 	%r85, %r84, 2;
	add.s32 	%r87, %r86, %r85;
	st.shared.f32 	[%r87], %f14;
	add.s32 	%r125, %r125, 1;
	add.s32 	%r127, %r127, -1;
	setp.ne.s32 	%p9, %r127, 0;
	@%p9 bra 	$L__BB3_11;

$L__BB3_12:
	bar.sync 	0;
	cvta.to.global.u64 	%rd19, %rd7;
	mul.wide.s32 	%rd20, %r5, 4;
	add.s64 	%rd21, %rd19, %rd20;
	add.s32 	%r22, %r52, -1;
	ld.global.nc.u32 	%r88, [%rd21];
	add.s32 	%r23, %r22, %r88;
	setp.ge.s32 	%p10, %r132, %r7;
	@%p10 bra 	$L__BB3_30;

	setp.gt.s32 	%p11, %r52, 0;
	@%p11 bra 	$L__BB3_20;
	bra.uni 	$L__BB3_14;

$L__BB3_20:
	and.b32  	%r33, %r52, 3;
	sub.s32 	%r34, %r52, %r33;
	mul.lo.s32 	%r101, %r52, 127;
	add.s32 	%r102, %r1, 256;
	sub.s32 	%r103, %r102, %r101;
	shl.b32 	%r104, %r8, 7;
	sub.s32 	%r105, %r103, %r104;
	shl.b32 	%r106, %r105, 2;
	mov.u32 	%r107, smem;
	add.s32 	%r35, %r107, %r106;
	add.s32 	%r36, %r1, %r52;
	mov.u32 	%r108, 1;
	sub.s32 	%r109, %r108, %r52;
	sub.s32 	%r37, %r109, %r8;

$L__BB3_21:
	setp.lt.s32 	%p21, %r132, %r23;
	mov.f32 	%f48, 0f7FC00000;
	@%p21 bra 	$L__BB3_29;

	setp.lt.u32 	%p22, %r22, 3;
	mov.f32 	%f48, 0f00000000;
	mov.u32 	%r137, 0;
	@%p22 bra 	$L__BB3_25;

	shl.b32 	%r113, %r132, 9;
	add.s32 	%r133, %r35, %r113;
	mov.f32 	%f48, 0f00000000;
	mov.u32 	%r137, 0;
	mov.u32 	%r134, %r107;
	mov.u32 	%r136, %r34;

$L__BB3_24:
	.pragma "nounroll";
	ld.shared.v4.f32 	{%f24, %f25, %f26, %f27}, [%r134];
	ld.shared.f32 	%f32, [%r133+-512];
	fma.rn.ftz.f32 	%f33, %f32, %f24, %f48;
	ld.shared.f32 	%f34, [%r133];
	fma.rn.ftz.f32 	%f35, %f34, %f25, %f33;
	ld.shared.f32 	%f36, [%r133+512];
	fma.rn.ftz.f32 	%f37, %f36, %f26, %f35;
	ld.shared.f32 	%f38, [%r133+1024];
	fma.rn.ftz.f32 	%f48, %f38, %f27, %f37;
	add.s32 	%r137, %r137, 4;
	add.s32 	%r134, %r134, 16;
	add.s32 	%r133, %r133, 2048;
	add.s32 	%r136, %r136, -4;
	setp.ne.s32 	%p23, %r136, 0;
	@%p23 bra 	$L__BB3_24;

$L__BB3_25:
	setp.eq.s32 	%p24, %r33, 0;
	@%p24 bra 	$L__BB3_29;

	setp.eq.s32 	%p25, %r33, 1;
	add.s32 	%r114, %r37, %r132;
	add.s32 	%r115, %r114, %r137;
	shl.b32 	%r116, %r115, 7;
	add.s32 	%r117, %r36, %r116;
	shl.b32 	%r118, %r117, 2;
	add.s32 	%r49, %r107, %r118;
	shl.b32 	%r120, %r137, 2;
	add.s32 	%r50, %r107, %r120;
	ld.shared.f32 	%f39, [%r50];
	ld.shared.f32 	%f40, [%r49];
	fma.rn.ftz.f32 	%f48, %f40, %f39, %f48;
	@%p25 bra 	$L__BB3_29;

	setp.eq.s32 	%p26, %r33, 2;
	ld.shared.f32 	%f41, [%r50+4];
	ld.shared.f32 	%f42, [%r49+512];
	fma.rn.ftz.f32 	%f48, %f42, %f41, %f48;
	@%p26 bra 	$L__BB3_29;

	ld.shared.f32 	%f43, [%r50+8];
	ld.shared.f32 	%f44, [%r49+1024];
	fma.rn.ftz.f32 	%f48, %f44, %f43, %f48;

$L__BB3_29:
	mad.lo.s32 	%r121, %r132, %r53, %r5;
	mul.wide.s32 	%rd29, %r121, 4;
	add.s64 	%rd30, %rd2, %rd29;
	st.global.f32 	[%rd30], %f48;
	add.s32 	%r132, %r132, 1;
	setp.lt.s32 	%p27, %r132, %r7;
	@%p27 bra 	$L__BB3_21;
	bra.uni 	$L__BB3_30;

$L__BB3_14:
	not.b32 	%r89, %r54;
	mov.u32 	%r90, -65;
	sub.s32 	%r91, %r90, %r132;
	max.s32 	%r24, %r91, %r89;
	and.b32  	%r92, %r24, 3;
	xor.b32  	%r129, %r92, 3;
	setp.eq.s32 	%p12, %r92, 3;
	mov.u32 	%r130, %r132;
	@%p12 bra 	$L__BB3_17;

	mov.u32 	%r130, %r132;

$L__BB3_16:
	.pragma "nounroll";
	mad.lo.s32 	%r93, %r130, %r53, %r5;
	setp.lt.s32 	%p13, %r130, %r23;
	selp.f32 	%f15, 0f7FC00000, 0f00000000, %p13;
	mul.wide.s32 	%rd22, %r93, 4;
	add.s64 	%rd23, %rd2, %rd22;
	st.global.f32 	[%rd23], %f15;
	add.s32 	%r130, %r130, 1;
	add.s32 	%r129, %r129, -1;
	setp.ne.s32 	%p14, %r129, 0;
	@%p14 bra 	$L__BB3_16;

$L__BB3_17:
	mov.u32 	%r94, -2;
	sub.s32 	%r95, %r94, %r24;
	sub.s32 	%r96, %r95, %r132;
	setp.lt.u32 	%p15, %r96, 3;
	@%p15 bra 	$L__BB3_30;

	mul.wide.s32 	%rd5, %r53, 4;

$L__BB3_19:
	mad.lo.s32 	%r97, %r130, %r53, %r5;
	setp.lt.s32 	%p16, %r130, %r23;
	selp.f32 	%f16, 0f7FC00000, 0f00000000, %p16;
	mul.wide.s32 	%rd24, %r97, 4;
	add.s64 	%rd25, %rd2, %rd24;
	st.global.f32 	[%rd25], %f16;
	add.s32 	%r98, %r130, 1;
	setp.lt.s32 	%p17, %r98, %r23;
	selp.f32 	%f17, 0f7FC00000, 0f00000000, %p17;
	add.s64 	%rd26, %rd25, %rd5;
	st.global.f32 	[%rd26], %f17;
	add.s32 	%r99, %r130, 2;
	setp.lt.s32 	%p18, %r99, %r23;
	selp.f32 	%f18, 0f7FC00000, 0f00000000, %p18;
	add.s64 	%rd27, %rd26, %rd5;
	st.global.f32 	[%rd27], %f18;
	add.s32 	%r100, %r130, 3;
	setp.lt.s32 	%p19, %r100, %r23;
	selp.f32 	%f19, 0f7FC00000, 0f00000000, %p19;
	add.s64 	%rd28, %rd27, %rd5;
	st.global.f32 	[%rd28], %f19;
	add.s32 	%r130, %r130, 4;
	setp.lt.s32 	%p20, %r130, %r7;
	@%p20 bra 	$L__BB3_19;

$L__BB3_30:
	ret;

}
	
.visible .entry sma_from_prefix_exclusive_f32(
	.param .u64 sma_from_prefix_exclusive_f32_param_0,
	.param .u32 sma_from_prefix_exclusive_f32_param_1,
	.param .u32 sma_from_prefix_exclusive_f32_param_2,
	.param .u32 sma_from_prefix_exclusive_f32_param_3,
	.param .u64 sma_from_prefix_exclusive_f32_param_4
)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd2, [sma_from_prefix_exclusive_f32_param_0];
	ld.param.u32 	%r4, [sma_from_prefix_exclusive_f32_param_1];
	ld.param.u32 	%r2, [sma_from_prefix_exclusive_f32_param_2];
	ld.param.u32 	%r3, [sma_from_prefix_exclusive_f32_param_3];
	ld.param.u64 	%rd3, [sma_from_prefix_exclusive_f32_param_4];
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r6, %r5, %r7;
	setp.ge.s32 	%p1, %r1, %r4;
	@%p1 bra 	$L__BB4_4;

	add.s32 	%r8, %r2, %r3;
	add.s32 	%r9, %r8, -1;
	setp.lt.s32 	%p2, %r1, %r9;
	cvta.to.global.u64 	%rd4, %rd3;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd1, %rd4, %rd5;
	@%p2 bra 	$L__BB4_3;
	bra.uni 	$L__BB4_2;

$L__BB4_3:
	mov.u32 	%r12, 2143289344;
	st.global.u32 	[%rd1], %r12;
	bra.uni 	$L__BB4_4;

$L__BB4_2:
	cvta.to.global.u64 	%rd6, %rd2;
	add.s32 	%r10, %r1, 1;
	add.s64 	%rd8, %rd6, %rd5;
	sub.s32 	%r11, %r10, %r2;
	mul.wide.s32 	%rd9, %r11, 4;
	add.s64 	%rd10, %rd6, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	ld.global.nc.f32 	%f2, [%rd8+4];
	sub.ftz.f32 	%f3, %f2, %f1;
	cvt.rn.f32.s32 	%f4, %r2;
	rcp.approx.ftz.f32 	%f5, %f4;
	mul.ftz.f32 	%f6, %f5, %f3;
	st.global.f32 	[%rd1], %f6;

$L__BB4_4:
	ret;

}
	
.visible .entry trima_from_prefix_exclusive_f32(
	.param .u64 trima_from_prefix_exclusive_f32_param_0,
	.param .u32 trima_from_prefix_exclusive_f32_param_1,
	.param .u32 trima_from_prefix_exclusive_f32_param_2,
	.param .u32 trima_from_prefix_exclusive_f32_param_3,
	.param .u64 trima_from_prefix_exclusive_f32_param_4
)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd2, [trima_from_prefix_exclusive_f32_param_0];
	ld.param.u32 	%r4, [trima_from_prefix_exclusive_f32_param_1];
	ld.param.u32 	%r2, [trima_from_prefix_exclusive_f32_param_2];
	ld.param.u32 	%r3, [trima_from_prefix_exclusive_f32_param_3];
	ld.param.u64 	%rd3, [trima_from_prefix_exclusive_f32_param_4];
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r6, %r5, %r7;
	setp.ge.s32 	%p1, %r1, %r4;
	@%p1 bra 	$L__BB5_4;

	add.s32 	%r8, %r2, %r3;
	add.s32 	%r9, %r8, -1;
	setp.lt.s32 	%p2, %r1, %r9;
	cvta.to.global.u64 	%rd4, %rd3;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd1, %rd4, %rd5;
	@%p2 bra 	$L__BB5_3;
	bra.uni 	$L__BB5_2;

$L__BB5_3:
	mov.u32 	%r12, 2143289344;
	st.global.u32 	[%rd1], %r12;
	bra.uni 	$L__BB5_4;

$L__BB5_2:
	cvta.to.global.u64 	%rd6, %rd2;
	add.s32 	%r10, %r1, 1;
	add.s64 	%rd8, %rd6, %rd5;
	sub.s32 	%r11, %r10, %r2;
	mul.wide.s32 	%rd9, %r11, 4;
	add.s64 	%rd10, %rd6, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	ld.global.nc.f32 	%f2, [%rd8+4];
	sub.ftz.f32 	%f3, %f2, %f1;
	cvt.rn.f32.s32 	%f4, %r2;
	rcp.approx.ftz.f32 	%f5, %f4;
	mul.ftz.f32 	%f6, %f5, %f3;
	st.global.f32 	[%rd1], %f6;

$L__BB5_4:
	ret;

}

