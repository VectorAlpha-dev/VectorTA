//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36424714
// Cuda compilation tools, release 13.0, V13.0.88
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_89
.address_size 64

	// .globl	highpass2_batch_f32

.visible .entry highpass2_batch_f32(
	.param .u64 highpass2_batch_f32_param_0,
	.param .u64 highpass2_batch_f32_param_1,
	.param .u64 highpass2_batch_f32_param_2,
	.param .u64 highpass2_batch_f32_param_3,
	.param .u64 highpass2_batch_f32_param_4,
	.param .u64 highpass2_batch_f32_param_5,
	.param .u32 highpass2_batch_f32_param_6,
	.param .u32 highpass2_batch_f32_param_7,
	.param .u32 highpass2_batch_f32_param_8,
	.param .u64 highpass2_batch_f32_param_9
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<93>;
	.reg .b32 	%r<76>;
	.reg .b64 	%rd<70>;


	ld.param.u64 	%rd28, [highpass2_batch_f32_param_0];
	ld.param.u64 	%rd24, [highpass2_batch_f32_param_2];
	ld.param.u64 	%rd25, [highpass2_batch_f32_param_3];
	ld.param.u64 	%rd26, [highpass2_batch_f32_param_4];
	ld.param.u64 	%rd27, [highpass2_batch_f32_param_5];
	ld.param.u32 	%r36, [highpass2_batch_f32_param_6];
	ld.param.u32 	%r37, [highpass2_batch_f32_param_7];
	ld.param.u32 	%r38, [highpass2_batch_f32_param_8];
	ld.param.u64 	%rd29, [highpass2_batch_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd29;
	cvta.to.global.u64 	%rd2, %rd28;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r39, %ctaid.x;
	mov.u32 	%r40, %tid.x;
	mad.lo.s32 	%r64, %r39, %r1, %r40;
	setp.ge.s32 	%p2, %r64, %r37;
	@%p2 bra 	$L__BB0_34;

	mov.u32 	%r41, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r41;
	cvt.s64.s32 	%rd3, %r38;
	add.s32 	%r4, %r38, 2;
	setp.lt.s32 	%p3, %r36, 1;
	@%p3 bra 	$L__BB0_33;

	shl.b64 	%rd30, %rd3, 2;
	add.s64 	%rd4, %rd2, %rd30;
	add.s32 	%r6, %r36, -1;
	and.b32  	%r7, %r36, 3;
	sub.s32 	%r8, %r36, %r7;
	and.b32  	%r9, %r38, 3;
	sub.s32 	%r10, %r38, %r9;
	cvta.to.global.u64 	%rd6, %rd27;
	cvta.to.global.u64 	%rd7, %rd26;
	cvta.to.global.u64 	%rd8, %rd25;
	cvta.to.global.u64 	%rd9, %rd24;
	add.s32 	%r42, %r38, 1;
	cvt.s64.s32 	%rd10, %r42;
	setp.lt.s32 	%p4, %r38, 0;
	setp.ge.s32 	%p5, %r38, %r36;
	or.pred  	%p1, %p4, %p5;
	cvt.s64.s32 	%rd11, %r36;

$L__BB0_3:
	cvt.s64.s32 	%rd31, %r64;
	mul.wide.s32 	%rd32, %r64, 4;
	add.s64 	%rd33, %rd9, %rd32;
	ld.global.nc.f32 	%f1, [%rd33];
	add.s64 	%rd34, %rd8, %rd32;
	ld.global.nc.f32 	%f2, [%rd34];
	add.s64 	%rd35, %rd7, %rd32;
	ld.global.nc.f32 	%f3, [%rd35];
	add.s64 	%rd36, %rd6, %rd32;
	ld.global.nc.f32 	%f4, [%rd36];
	mul.lo.s64 	%rd12, %rd31, %rd11;
	@%p1 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_4;

$L__BB0_24:
	@%p3 bra 	$L__BB0_32;

	setp.lt.u32 	%p22, %r6, 3;
	mov.u32 	%r74, 0;
	@%p22 bra 	$L__BB0_28;

	mov.u32 	%r74, 0;
	mov.u32 	%r73, %r8;

$L__BB0_27:
	cvt.s64.s32 	%rd60, %r74;
	add.s64 	%rd61, %rd12, %rd60;
	shl.b64 	%rd62, %rd61, 2;
	add.s64 	%rd63, %rd1, %rd62;
	mov.u32 	%r55, 2147483647;
	st.global.u32 	[%rd63], %r55;
	st.global.u32 	[%rd63+4], %r55;
	st.global.u32 	[%rd63+8], %r55;
	st.global.u32 	[%rd63+12], %r55;
	add.s32 	%r74, %r74, 4;
	add.s32 	%r73, %r73, -4;
	setp.ne.s32 	%p23, %r73, 0;
	@%p23 bra 	$L__BB0_27;

$L__BB0_28:
	setp.eq.s32 	%p24, %r7, 0;
	@%p24 bra 	$L__BB0_32;

	setp.eq.s32 	%p25, %r7, 1;
	cvt.s64.s32 	%rd64, %r74;
	add.s64 	%rd65, %rd12, %rd64;
	shl.b64 	%rd66, %rd65, 2;
	add.s64 	%rd23, %rd1, %rd66;
	mov.u32 	%r56, 2147483647;
	st.global.u32 	[%rd23], %r56;
	@%p25 bra 	$L__BB0_32;

	setp.eq.s32 	%p26, %r7, 2;
	st.global.u32 	[%rd23+4], %r56;
	@%p26 bra 	$L__BB0_32;

	mov.u32 	%r58, 2147483647;
	st.global.u32 	[%rd23+8], %r58;
	bra.uni 	$L__BB0_32;

$L__BB0_4:
	ld.param.u32 	%r59, [highpass2_batch_f32_param_8];
	setp.lt.s32 	%p6, %r59, 1;
	@%p6 bra 	$L__BB0_12;

	ld.param.u32 	%r63, [highpass2_batch_f32_param_8];
	add.s32 	%r62, %r63, -1;
	setp.lt.u32 	%p7, %r62, 3;
	mov.u32 	%r67, 0;
	@%p7 bra 	$L__BB0_8;

	mov.u32 	%r67, 0;
	mov.u32 	%r66, %r10;

$L__BB0_7:
	cvt.s64.s32 	%rd37, %r67;
	add.s64 	%rd38, %rd12, %rd37;
	shl.b64 	%rd39, %rd38, 2;
	add.s64 	%rd40, %rd1, %rd39;
	mov.u32 	%r45, 2147483647;
	st.global.u32 	[%rd40], %r45;
	st.global.u32 	[%rd40+4], %r45;
	st.global.u32 	[%rd40+8], %r45;
	st.global.u32 	[%rd40+12], %r45;
	add.s32 	%r67, %r67, 4;
	add.s32 	%r66, %r66, -4;
	setp.ne.s32 	%p8, %r66, 0;
	@%p8 bra 	$L__BB0_7;

$L__BB0_8:
	setp.eq.s32 	%p9, %r9, 0;
	@%p9 bra 	$L__BB0_12;

	setp.eq.s32 	%p10, %r9, 1;
	cvt.s64.s32 	%rd41, %r67;
	add.s64 	%rd42, %rd12, %rd41;
	shl.b64 	%rd43, %rd42, 2;
	add.s64 	%rd13, %rd1, %rd43;
	mov.u32 	%r46, 2147483647;
	st.global.u32 	[%rd13], %r46;
	@%p10 bra 	$L__BB0_12;

	setp.eq.s32 	%p11, %r9, 2;
	st.global.u32 	[%rd13+4], %r46;
	@%p11 bra 	$L__BB0_12;

	mov.u32 	%r48, 2147483647;
	st.global.u32 	[%rd13+8], %r48;

$L__BB0_12:
	cvt.u32.u64 	%r49, %rd10;
	setp.ge.s32 	%p12, %r49, %r36;
	ld.global.nc.f32 	%f88, [%rd4];
	add.s64 	%rd44, %rd12, %rd3;
	shl.b64 	%rd45, %rd44, 2;
	add.s64 	%rd14, %rd1, %rd45;
	st.global.f32 	[%rd14], %f88;
	@%p12 bra 	$L__BB0_32;

	ld.param.u32 	%r61, [highpass2_batch_f32_param_8];
	add.s32 	%r60, %r61, 3;
	setp.ge.s32 	%p13, %r60, %r36;
	ld.global.nc.f32 	%f82, [%rd4+4];
	st.global.f32 	[%rd14+4], %f82;
	mov.f32 	%f86, %f88;
	mov.f32 	%f84, %f82;
	mov.u32 	%r69, %r4;
	@%p13 bra 	$L__BB0_16;

	mov.u32 	%r68, %r4;
	mov.f32 	%f84, %f82;
	mov.f32 	%f86, %f88;
	mov.f32 	%f79, %f82;
	mov.f32 	%f80, %f88;

$L__BB0_15:
	cvt.s64.s32 	%rd46, %r68;
	mul.wide.s32 	%rd47, %r68, 4;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.nc.f32 	%f88, [%rd48];
	mul.ftz.f32 	%f37, %f1, %f88;
	fma.rn.ftz.f32 	%f38, %f2, %f79, %f37;
	fma.rn.ftz.f32 	%f39, %f1, %f80, %f38;
	fma.rn.ftz.f32 	%f40, %f4, %f86, %f39;
	fma.rn.ftz.f32 	%f86, %f3, %f84, %f40;
	add.s64 	%rd49, %rd12, %rd46;
	shl.b64 	%rd50, %rd49, 2;
	add.s64 	%rd51, %rd1, %rd50;
	st.global.f32 	[%rd51], %f86;
	ld.global.nc.f32 	%f82, [%rd48+4];
	mul.ftz.f32 	%f41, %f1, %f82;
	fma.rn.ftz.f32 	%f42, %f2, %f88, %f41;
	fma.rn.ftz.f32 	%f43, %f1, %f79, %f42;
	fma.rn.ftz.f32 	%f44, %f4, %f84, %f43;
	fma.rn.ftz.f32 	%f84, %f3, %f86, %f44;
	st.global.f32 	[%rd51+4], %f84;
	add.s32 	%r69, %r68, 2;
	add.s32 	%r50, %r68, 3;
	setp.lt.s32 	%p14, %r50, %r36;
	mov.u32 	%r68, %r69;
	mov.f32 	%f79, %f82;
	mov.f32 	%f80, %f88;
	@%p14 bra 	$L__BB0_15;

$L__BB0_16:
	setp.ge.s32 	%p15, %r69, %r36;
	@%p15 bra 	$L__BB0_32;

	sub.s32 	%r51, %r36, %r69;
	and.b32  	%r21, %r51, 3;
	setp.eq.s32 	%p16, %r21, 0;
	mov.u32 	%r70, %r69;
	mov.f32 	%f85, %f84;
	mov.f32 	%f87, %f82;
	@%p16 bra 	$L__BB0_21;

	cvt.s64.s32 	%rd52, %r69;
	mul.wide.s32 	%rd53, %r69, 4;
	add.s64 	%rd15, %rd2, %rd53;
	ld.global.nc.f32 	%f19, [%rd15];
	mul.ftz.f32 	%f45, %f1, %f19;
	fma.rn.ftz.f32 	%f46, %f2, %f82, %f45;
	fma.rn.ftz.f32 	%f47, %f1, %f88, %f46;
	fma.rn.ftz.f32 	%f48, %f4, %f86, %f47;
	fma.rn.ftz.f32 	%f20, %f3, %f84, %f48;
	add.s64 	%rd54, %rd12, %rd52;
	shl.b64 	%rd55, %rd54, 2;
	add.s64 	%rd16, %rd1, %rd55;
	st.global.f32 	[%rd16], %f20;
	add.s32 	%r70, %r69, 1;
	setp.eq.s32 	%p17, %r21, 1;
	mov.f32 	%f85, %f20;
	mov.f32 	%f86, %f84;
	mov.f32 	%f87, %f19;
	mov.f32 	%f88, %f82;
	@%p17 bra 	$L__BB0_21;

	ld.global.nc.f32 	%f21, [%rd15+4];
	mul.ftz.f32 	%f49, %f1, %f21;
	fma.rn.ftz.f32 	%f50, %f2, %f19, %f49;
	fma.rn.ftz.f32 	%f51, %f1, %f82, %f50;
	fma.rn.ftz.f32 	%f52, %f4, %f84, %f51;
	fma.rn.ftz.f32 	%f22, %f3, %f20, %f52;
	st.global.f32 	[%rd16+4], %f22;
	add.s32 	%r70, %r69, 2;
	setp.eq.s32 	%p18, %r21, 2;
	mov.f32 	%f85, %f22;
	mov.f32 	%f86, %f20;
	mov.f32 	%f87, %f21;
	mov.f32 	%f88, %f19;
	@%p18 bra 	$L__BB0_21;

	ld.global.nc.f32 	%f87, [%rd15+8];
	mul.ftz.f32 	%f53, %f1, %f87;
	fma.rn.ftz.f32 	%f54, %f2, %f21, %f53;
	fma.rn.ftz.f32 	%f55, %f1, %f19, %f54;
	fma.rn.ftz.f32 	%f56, %f4, %f20, %f55;
	fma.rn.ftz.f32 	%f85, %f3, %f22, %f56;
	st.global.f32 	[%rd16+8], %f85;
	add.s32 	%r70, %r69, 3;
	mov.f32 	%f86, %f22;
	mov.f32 	%f88, %f21;

$L__BB0_21:
	sub.s32 	%r52, %r6, %r69;
	setp.lt.u32 	%p19, %r52, 3;
	@%p19 bra 	$L__BB0_32;

	add.s64 	%rd67, %rd2, 8;
	cvt.s64.s32 	%rd56, %r70;
	add.s64 	%rd57, %rd12, %rd56;
	shl.b64 	%rd58, %rd57, 2;
	add.s64 	%rd69, %rd1, %rd58;
	mul.wide.s32 	%rd59, %r70, 4;
	add.s64 	%rd68, %rd67, %rd59;

$L__BB0_23:
	ld.global.nc.f32 	%f57, [%rd68+-8];
	mul.ftz.f32 	%f58, %f1, %f57;
	fma.rn.ftz.f32 	%f59, %f2, %f87, %f58;
	fma.rn.ftz.f32 	%f60, %f1, %f88, %f59;
	fma.rn.ftz.f32 	%f61, %f4, %f86, %f60;
	fma.rn.ftz.f32 	%f62, %f3, %f85, %f61;
	st.global.f32 	[%rd69], %f62;
	ld.global.nc.f32 	%f63, [%rd68+-4];
	mul.ftz.f32 	%f64, %f1, %f63;
	fma.rn.ftz.f32 	%f65, %f2, %f57, %f64;
	fma.rn.ftz.f32 	%f66, %f1, %f87, %f65;
	fma.rn.ftz.f32 	%f67, %f4, %f85, %f66;
	fma.rn.ftz.f32 	%f68, %f3, %f62, %f67;
	st.global.f32 	[%rd69+4], %f68;
	ld.global.nc.f32 	%f88, [%rd68];
	mul.ftz.f32 	%f69, %f1, %f88;
	fma.rn.ftz.f32 	%f70, %f2, %f63, %f69;
	fma.rn.ftz.f32 	%f71, %f1, %f57, %f70;
	fma.rn.ftz.f32 	%f72, %f4, %f62, %f71;
	fma.rn.ftz.f32 	%f86, %f3, %f68, %f72;
	st.global.f32 	[%rd69+8], %f86;
	ld.global.nc.f32 	%f87, [%rd68+4];
	mul.ftz.f32 	%f73, %f1, %f87;
	fma.rn.ftz.f32 	%f74, %f2, %f88, %f73;
	fma.rn.ftz.f32 	%f75, %f1, %f63, %f74;
	fma.rn.ftz.f32 	%f76, %f4, %f68, %f75;
	fma.rn.ftz.f32 	%f85, %f3, %f86, %f76;
	st.global.f32 	[%rd69+12], %f85;
	add.s64 	%rd69, %rd69, 16;
	add.s64 	%rd68, %rd68, 16;
	add.s32 	%r70, %r70, 4;
	setp.lt.s32 	%p20, %r70, %r36;
	@%p20 bra 	$L__BB0_23;

$L__BB0_32:
	add.s32 	%r64, %r64, %r3;
	setp.lt.s32 	%p27, %r64, %r37;
	@%p27 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_34;

$L__BB0_33:
	add.s32 	%r64, %r64, %r3;
	setp.lt.s32 	%p28, %r64, %r37;
	@%p28 bra 	$L__BB0_33;

$L__BB0_34:
	ret;

}
	// .globl	highpass2_batch_warp_scan_f32
.visible .entry highpass2_batch_warp_scan_f32(
	.param .u64 highpass2_batch_warp_scan_f32_param_0,
	.param .u64 highpass2_batch_warp_scan_f32_param_1,
	.param .u64 highpass2_batch_warp_scan_f32_param_2,
	.param .u64 highpass2_batch_warp_scan_f32_param_3,
	.param .u64 highpass2_batch_warp_scan_f32_param_4,
	.param .u64 highpass2_batch_warp_scan_f32_param_5,
	.param .u32 highpass2_batch_warp_scan_f32_param_6,
	.param .u32 highpass2_batch_warp_scan_f32_param_7,
	.param .u32 highpass2_batch_warp_scan_f32_param_8,
	.param .u64 highpass2_batch_warp_scan_f32_param_9
)
{
	.reg .pred 	%p<69>;
	.reg .f32 	%f<179>;
	.reg .b32 	%r<206>;
	.reg .b64 	%rd<73>;


	ld.param.u64 	%rd29, [highpass2_batch_warp_scan_f32_param_0];
	ld.param.u64 	%rd28, [highpass2_batch_warp_scan_f32_param_5];
	ld.param.u32 	%r125, [highpass2_batch_warp_scan_f32_param_6];
	ld.param.u32 	%r127, [highpass2_batch_warp_scan_f32_param_7];
	ld.param.u32 	%r126, [highpass2_batch_warp_scan_f32_param_8];
	ld.param.u64 	%rd30, [highpass2_batch_warp_scan_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd30;
	cvta.to.global.u64 	%rd2, %rd29;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p33, %r1, %r127;
	setp.lt.s32 	%p34, %r125, 1;
	or.pred  	%p35, %p34, %p33;
	mov.u32 	%r2, %tid.x;
	setp.gt.u32 	%p36, %r2, 31;
	or.pred  	%p37, %p36, %p35;
	@%p37 bra 	$L__BB1_39;
	bra.uni 	$L__BB1_1;

$L__BB1_39:
	ret;

$L__BB1_1:
	and.b32  	%r204, %r2, 31;
	cvt.s64.s32 	%rd3, %r1;
	mul.wide.s32 	%rd4, %r125, %r1;
	setp.ge.s32 	%p38, %r126, %r125;
	setp.lt.s32 	%p39, %r126, 0;
	or.pred  	%p40, %p39, %p38;
	@%p40 bra 	$L__BB1_32;
	bra.uni 	$L__BB1_2;

$L__BB1_32:
	setp.ge.s32 	%p63, %r204, %r125;
	@%p63 bra 	$L__BB1_39;

	not.b32 	%r163, %r204;
	add.s32 	%r116, %r163, %r125;
	shr.u32 	%r164, %r116, 5;
	add.s32 	%r165, %r164, 1;
	and.b32  	%r203, %r165, 3;
	setp.eq.s32 	%p64, %r203, 0;
	@%p64 bra 	$L__BB1_36;

	cvt.u64.u32 	%rd56, %r2;
	and.b64  	%rd57, %rd56, 31;
	add.s64 	%rd58, %rd4, %rd57;
	shl.b64 	%rd59, %rd58, 2;
	add.s64 	%rd71, %rd1, %rd59;

$L__BB1_35:
	.pragma "nounroll";
	mov.u32 	%r166, 2147483647;
	st.global.u32 	[%rd71], %r166;
	add.s32 	%r204, %r204, 32;
	add.s64 	%rd71, %rd71, 128;
	add.s32 	%r203, %r203, -1;
	setp.ne.s32 	%p65, %r203, 0;
	@%p65 bra 	$L__BB1_35;

$L__BB1_36:
	setp.lt.u32 	%p66, %r116, 96;
	@%p66 bra 	$L__BB1_39;

	cvt.u64.u32 	%rd60, %r204;
	add.s64 	%rd61, %rd4, %rd60;
	shl.b64 	%rd62, %rd61, 2;
	add.s64 	%rd63, %rd1, %rd62;
	add.s64 	%rd72, %rd63, 256;

$L__BB1_38:
	mov.u32 	%r167, 2147483647;
	st.global.u32 	[%rd72+-256], %r167;
	st.global.u32 	[%rd72+-128], %r167;
	st.global.u32 	[%rd72], %r167;
	st.global.u32 	[%rd72+128], %r167;
	add.s64 	%rd72, %rd72, 512;
	add.s32 	%r204, %r204, 128;
	setp.lt.s32 	%p67, %r204, %r125;
	@%p67 bra 	$L__BB1_38;
	bra.uni 	$L__BB1_39;

$L__BB1_2:
	setp.ge.s32 	%p41, %r204, %r126;
	@%p41 bra 	$L__BB1_9;

	not.b32 	%r128, %r204;
	add.s32 	%r4, %r128, %r126;
	shr.u32 	%r129, %r4, 5;
	add.s32 	%r130, %r129, 1;
	and.b32  	%r169, %r130, 3;
	setp.eq.s32 	%p42, %r169, 0;
	mov.u32 	%r170, %r204;
	@%p42 bra 	$L__BB1_6;

	cvt.u64.u32 	%rd31, %r2;
	and.b64  	%rd32, %rd31, 31;
	add.s64 	%rd33, %rd4, %rd32;
	shl.b64 	%rd34, %rd33, 2;
	add.s64 	%rd67, %rd1, %rd34;
	mov.u32 	%r170, %r204;

$L__BB1_5:
	.pragma "nounroll";
	mov.u32 	%r131, 2147483647;
	st.global.u32 	[%rd67], %r131;
	add.s32 	%r170, %r170, 32;
	add.s64 	%rd67, %rd67, 128;
	add.s32 	%r169, %r169, -1;
	setp.ne.s32 	%p43, %r169, 0;
	@%p43 bra 	$L__BB1_5;

$L__BB1_6:
	setp.lt.u32 	%p44, %r4, 96;
	@%p44 bra 	$L__BB1_9;

	cvt.u64.u32 	%rd35, %r170;
	add.s64 	%rd36, %rd4, %rd35;
	shl.b64 	%rd37, %rd36, 2;
	add.s64 	%rd38, %rd1, %rd37;
	add.s64 	%rd68, %rd38, 256;

$L__BB1_8:
	mov.u32 	%r132, 2147483647;
	st.global.u32 	[%rd68+-256], %r132;
	st.global.u32 	[%rd68+-128], %r132;
	st.global.u32 	[%rd68], %r132;
	st.global.u32 	[%rd68+128], %r132;
	add.s64 	%rd68, %rd68, 512;
	add.s32 	%r170, %r170, 128;
	setp.lt.s32 	%p45, %r170, %r126;
	@%p45 bra 	$L__BB1_8;

$L__BB1_9:
	setp.eq.s32 	%p46, %r204, 0;
	mul.wide.s32 	%rd39, %r126, 4;
	add.s64 	%rd11, %rd2, %rd39;
	@%p46 bra 	$L__BB1_10;
	bra.uni 	$L__BB1_12;

$L__BB1_10:
	cvt.s64.s32 	%rd40, %r126;
	ld.global.nc.f32 	%f74, [%rd11];
	add.s64 	%rd41, %rd4, %rd40;
	shl.b64 	%rd42, %rd41, 2;
	add.s64 	%rd12, %rd1, %rd42;
	st.global.f32 	[%rd12], %f74;
	add.s32 	%r133, %r126, 1;
	setp.ge.s32 	%p47, %r133, %r125;
	@%p47 bra 	$L__BB1_12;

	ld.global.nc.f32 	%f75, [%rd11+4];
	st.global.f32 	[%rd12+4], %f75;

$L__BB1_12:
	add.s32 	%r134, %r126, 1;
	setp.ge.s32 	%p48, %r134, %r125;
	@%p48 bra 	$L__BB1_39;

	ld.param.u64 	%rd66, [highpass2_batch_warp_scan_f32_param_4];
	ld.param.u64 	%rd65, [highpass2_batch_warp_scan_f32_param_3];
	ld.param.u64 	%rd64, [highpass2_batch_warp_scan_f32_param_2];
	setp.ne.s32 	%p49, %r204, 0;
	mov.u32 	%r136, 0;
	cvta.to.global.u64 	%rd43, %rd64;
	shl.b64 	%rd44, %rd3, 2;
	add.s64 	%rd45, %rd43, %rd44;
	ld.global.nc.f32 	%f1, [%rd45];
	cvta.to.global.u64 	%rd46, %rd65;
	add.s64 	%rd47, %rd46, %rd44;
	ld.global.nc.f32 	%f2, [%rd47];
	cvta.to.global.u64 	%rd48, %rd66;
	add.s64 	%rd49, %rd48, %rd44;
	ld.global.nc.f32 	%f3, [%rd49];
	cvta.to.global.u64 	%rd50, %rd28;
	add.s64 	%rd51, %rd50, %rd44;
	ld.global.nc.f32 	%f4, [%rd51];
	mov.u32 	%r172, %r136;
	mov.u32 	%r173, %r136;
	@%p49 bra 	$L__BB1_15;

	ld.global.nc.u32 	%r173, [%rd11];
	ld.global.nc.u32 	%r172, [%rd11+4];

$L__BB1_15:
	mov.u32 	%r137, 31;
	mov.u32 	%r139, -1;
	shfl.sync.idx.b32 	%r176|%p1, %r172, %r136, %r137, %r139;
	shfl.sync.idx.b32 	%r177|%p2, %r173, %r136, %r137, %r139;
	add.s32 	%r178, %r126, 2;
	setp.ge.s32 	%p50, %r178, %r125;
	@%p50 bra 	$L__BB1_39;

	add.s32 	%r140, %r125, -3;
	sub.s32 	%r175, %r140, %r126;
	add.s32 	%r141, %r126, %r204;
	add.s32 	%r174, %r141, 2;
	cvt.s64.s32 	%rd52, %r174;
	mul.wide.s32 	%rd53, %r174, 4;
	add.s64 	%rd70, %rd2, %rd53;
	add.s64 	%rd54, %rd4, %rd52;
	shl.b64 	%rd55, %rd54, 2;
	add.s64 	%rd69, %rd1, %rd55;

$L__BB1_17:
	setp.ge.s32 	%p51, %r174, %r125;
	mov.f32 	%f160, 0f00000000;
	mov.f32 	%f148, %f160;
	@%p51 bra 	$L__BB1_19;

	ld.global.nc.f32 	%f77, [%rd70];
	mul.ftz.f32 	%f78, %f1, %f77;
	ld.global.nc.f32 	%f79, [%rd70+-4];
	fma.rn.ftz.f32 	%f80, %f2, %f79, %f78;
	ld.global.nc.f32 	%f81, [%rd70+-8];
	fma.rn.ftz.f32 	%f148, %f1, %f81, %f80;

$L__BB1_19:
	setp.lt.s32 	%p52, %r174, %r125;
	selp.f32 	%f155, %f3, 0f3F800000, %p52;
	selp.f32 	%f156, %f4, 0f00000000, %p52;
	selp.f32 	%f157, 0f3F800000, 0f00000000, %p52;
	selp.f32 	%f158, 0f00000000, 0f3F800000, %p52;
	selp.f32 	%f159, %f148, 0f00000000, %p52;
	mov.b32 	%r189, %f155;
	mov.u32 	%r142, 0;
	mov.u32 	%r143, 1;
	mov.u32 	%r144, -1;
	shfl.sync.up.b32 	%r30|%p3, %r189, %r143, %r142, %r144;
	mov.b32 	%r188, %f156;
	shfl.sync.up.b32 	%r32|%p4, %r188, %r143, %r142, %r144;
	mov.b32 	%r187, %f157;
	shfl.sync.up.b32 	%r34|%p5, %r187, %r143, %r142, %r144;
	mov.b32 	%r186, %f158;
	shfl.sync.up.b32 	%r36|%p6, %r186, %r143, %r142, %r144;
	mov.b32 	%r185, %f159;
	shfl.sync.up.b32 	%r38|%p7, %r185, %r143, %r142, %r144;
	shfl.sync.up.b32 	%r39|%p8, %r142, %r143, %r142, %r144;
	@%p46 bra 	$L__BB1_21;

	mov.b32 	%f83, %r30;
	mov.b32 	%f84, %r32;
	mov.b32 	%f85, %r34;
	mov.b32 	%f86, %r36;
	mov.b32 	%f87, %r38;
	mov.b32 	%f88, %r39;
	mul.ftz.f32 	%f89, %f156, %f85;
	fma.rn.ftz.f32 	%f12, %f155, %f83, %f89;
	mul.ftz.f32 	%f90, %f156, %f86;
	fma.rn.ftz.f32 	%f13, %f155, %f84, %f90;
	mul.ftz.f32 	%f91, %f158, %f85;
	fma.rn.ftz.f32 	%f14, %f157, %f83, %f91;
	mul.ftz.f32 	%f92, %f158, %f86;
	fma.rn.ftz.f32 	%f15, %f157, %f84, %f92;
	fma.rn.ftz.f32 	%f93, %f156, %f88, %f159;
	fma.rn.ftz.f32 	%f159, %f155, %f87, %f93;
	mov.f32 	%f94, 0f00000000;
	fma.rn.ftz.f32 	%f95, %f158, %f88, %f94;
	fma.rn.ftz.f32 	%f160, %f157, %f87, %f95;
	mov.b32 	%r189, %f12;
	mov.b32 	%r188, %f13;
	mov.b32 	%r187, %f14;
	mov.b32 	%r186, %f15;
	mov.b32 	%r185, %f159;
	mov.f32 	%f155, %f12;
	mov.f32 	%f156, %f13;
	mov.f32 	%f157, %f14;
	mov.f32 	%f158, %f15;

$L__BB1_21:
	mov.u32 	%r146, 2;
	shfl.sync.up.b32 	%r50|%p9, %r189, %r146, %r142, %r144;
	shfl.sync.up.b32 	%r51|%p10, %r188, %r146, %r142, %r144;
	shfl.sync.up.b32 	%r52|%p11, %r187, %r146, %r142, %r144;
	shfl.sync.up.b32 	%r53|%p12, %r186, %r146, %r142, %r144;
	shfl.sync.up.b32 	%r54|%p13, %r185, %r146, %r142, %r144;
	mov.b32 	%r190, %f160;
	shfl.sync.up.b32 	%r56|%p14, %r190, %r146, %r142, %r144;
	setp.lt.u32 	%p54, %r204, 2;
	@%p54 bra 	$L__BB1_23;

	mov.b32 	%f96, %r50;
	mov.b32 	%f97, %r51;
	mov.b32 	%f98, %r52;
	mov.b32 	%f99, %r53;
	mov.b32 	%f100, %r54;
	mov.b32 	%f101, %r56;
	mul.ftz.f32 	%f102, %f156, %f98;
	fma.rn.ftz.f32 	%f24, %f155, %f96, %f102;
	mul.ftz.f32 	%f103, %f156, %f99;
	fma.rn.ftz.f32 	%f25, %f155, %f97, %f103;
	mul.ftz.f32 	%f104, %f158, %f98;
	fma.rn.ftz.f32 	%f26, %f157, %f96, %f104;
	mul.ftz.f32 	%f105, %f158, %f99;
	fma.rn.ftz.f32 	%f27, %f157, %f97, %f105;
	fma.rn.ftz.f32 	%f106, %f156, %f101, %f159;
	fma.rn.ftz.f32 	%f159, %f155, %f100, %f106;
	fma.rn.ftz.f32 	%f107, %f158, %f101, %f160;
	fma.rn.ftz.f32 	%f160, %f157, %f100, %f107;
	mov.b32 	%r189, %f24;
	mov.b32 	%r188, %f25;
	mov.b32 	%r187, %f26;
	mov.b32 	%r186, %f27;
	mov.b32 	%r185, %f159;
	mov.b32 	%r190, %f160;
	mov.f32 	%f155, %f24;
	mov.f32 	%f156, %f25;
	mov.f32 	%f157, %f26;
	mov.f32 	%f158, %f27;

$L__BB1_23:
	mov.u32 	%r148, 0;
	mov.u32 	%r149, 4;
	mov.u32 	%r150, -1;
	shfl.sync.up.b32 	%r69|%p15, %r189, %r149, %r148, %r150;
	shfl.sync.up.b32 	%r70|%p16, %r188, %r149, %r148, %r150;
	shfl.sync.up.b32 	%r71|%p17, %r187, %r149, %r148, %r150;
	shfl.sync.up.b32 	%r72|%p18, %r186, %r149, %r148, %r150;
	shfl.sync.up.b32 	%r73|%p19, %r185, %r149, %r148, %r150;
	shfl.sync.up.b32 	%r74|%p20, %r190, %r149, %r148, %r150;
	setp.lt.u32 	%p55, %r204, 4;
	@%p55 bra 	$L__BB1_25;

	mov.b32 	%f108, %r69;
	mov.b32 	%f109, %r70;
	mov.b32 	%f110, %r71;
	mov.b32 	%f111, %r72;
	mov.b32 	%f112, %r73;
	mov.b32 	%f113, %r74;
	mul.ftz.f32 	%f114, %f156, %f110;
	fma.rn.ftz.f32 	%f36, %f155, %f108, %f114;
	mul.ftz.f32 	%f115, %f156, %f111;
	fma.rn.ftz.f32 	%f37, %f155, %f109, %f115;
	mul.ftz.f32 	%f116, %f158, %f110;
	fma.rn.ftz.f32 	%f38, %f157, %f108, %f116;
	mul.ftz.f32 	%f117, %f158, %f111;
	fma.rn.ftz.f32 	%f39, %f157, %f109, %f117;
	fma.rn.ftz.f32 	%f118, %f156, %f113, %f159;
	fma.rn.ftz.f32 	%f159, %f155, %f112, %f118;
	fma.rn.ftz.f32 	%f119, %f158, %f113, %f160;
	fma.rn.ftz.f32 	%f160, %f157, %f112, %f119;
	mov.b32 	%r189, %f36;
	mov.b32 	%r188, %f37;
	mov.b32 	%r187, %f38;
	mov.b32 	%r186, %f39;
	mov.b32 	%r185, %f159;
	mov.b32 	%r190, %f160;
	mov.f32 	%f155, %f36;
	mov.f32 	%f156, %f37;
	mov.f32 	%f157, %f38;
	mov.f32 	%f158, %f39;

$L__BB1_25:
	mov.u32 	%r152, 8;
	shfl.sync.up.b32 	%r87|%p21, %r189, %r152, %r148, %r150;
	shfl.sync.up.b32 	%r88|%p22, %r188, %r152, %r148, %r150;
	shfl.sync.up.b32 	%r89|%p23, %r187, %r152, %r148, %r150;
	shfl.sync.up.b32 	%r90|%p24, %r186, %r152, %r148, %r150;
	shfl.sync.up.b32 	%r91|%p25, %r185, %r152, %r148, %r150;
	shfl.sync.up.b32 	%r92|%p26, %r190, %r152, %r148, %r150;
	setp.lt.u32 	%p56, %r204, 8;
	@%p56 bra 	$L__BB1_27;

	mov.b32 	%f120, %r87;
	mov.b32 	%f121, %r88;
	mov.b32 	%f122, %r89;
	mov.b32 	%f123, %r90;
	mov.b32 	%f124, %r91;
	mov.b32 	%f125, %r92;
	mul.ftz.f32 	%f126, %f156, %f122;
	fma.rn.ftz.f32 	%f48, %f155, %f120, %f126;
	mul.ftz.f32 	%f127, %f156, %f123;
	fma.rn.ftz.f32 	%f49, %f155, %f121, %f127;
	mul.ftz.f32 	%f128, %f158, %f122;
	fma.rn.ftz.f32 	%f50, %f157, %f120, %f128;
	mul.ftz.f32 	%f129, %f158, %f123;
	fma.rn.ftz.f32 	%f51, %f157, %f121, %f129;
	fma.rn.ftz.f32 	%f130, %f156, %f125, %f159;
	fma.rn.ftz.f32 	%f159, %f155, %f124, %f130;
	fma.rn.ftz.f32 	%f131, %f158, %f125, %f160;
	fma.rn.ftz.f32 	%f160, %f157, %f124, %f131;
	mov.b32 	%r189, %f48;
	mov.b32 	%r188, %f49;
	mov.b32 	%r187, %f50;
	mov.b32 	%r186, %f51;
	mov.b32 	%r185, %f159;
	mov.b32 	%r190, %f160;
	mov.f32 	%f155, %f48;
	mov.f32 	%f156, %f49;
	mov.f32 	%f157, %f50;
	mov.f32 	%f158, %f51;

$L__BB1_27:
	mov.u32 	%r154, 0;
	mov.u32 	%r155, 16;
	mov.u32 	%r156, -1;
	shfl.sync.up.b32 	%r105|%p27, %r189, %r155, %r154, %r156;
	shfl.sync.up.b32 	%r106|%p28, %r188, %r155, %r154, %r156;
	shfl.sync.up.b32 	%r107|%p29, %r187, %r155, %r154, %r156;
	shfl.sync.up.b32 	%r108|%p30, %r186, %r155, %r154, %r156;
	shfl.sync.up.b32 	%r109|%p31, %r185, %r155, %r154, %r156;
	shfl.sync.up.b32 	%r110|%p32, %r190, %r155, %r154, %r156;
	setp.lt.u32 	%p57, %r204, 16;
	@%p57 bra 	$L__BB1_29;

	mov.b32 	%f132, %r105;
	mov.b32 	%f133, %r106;
	mov.b32 	%f134, %r107;
	mov.b32 	%f135, %r108;
	mov.b32 	%f136, %r109;
	mov.b32 	%f137, %r110;
	mul.ftz.f32 	%f138, %f156, %f134;
	fma.rn.ftz.f32 	%f60, %f155, %f132, %f138;
	mul.ftz.f32 	%f139, %f156, %f135;
	fma.rn.ftz.f32 	%f61, %f155, %f133, %f139;
	mul.ftz.f32 	%f140, %f158, %f134;
	fma.rn.ftz.f32 	%f62, %f157, %f132, %f140;
	mul.ftz.f32 	%f141, %f158, %f135;
	fma.rn.ftz.f32 	%f63, %f157, %f133, %f141;
	fma.rn.ftz.f32 	%f142, %f156, %f137, %f159;
	fma.rn.ftz.f32 	%f159, %f155, %f136, %f142;
	fma.rn.ftz.f32 	%f143, %f158, %f137, %f160;
	fma.rn.ftz.f32 	%f160, %f157, %f136, %f143;
	mov.f32 	%f155, %f60;
	mov.f32 	%f156, %f61;
	mov.f32 	%f157, %f62;
	mov.f32 	%f158, %f63;

$L__BB1_29:
	setp.ge.s32 	%p68, %r174, %r125;
	mov.b32 	%f144, %r177;
	mov.b32 	%f145, %r176;
	fma.rn.ftz.f32 	%f146, %f156, %f144, %f159;
	fma.rn.ftz.f32 	%f72, %f155, %f145, %f146;
	fma.rn.ftz.f32 	%f147, %f158, %f144, %f160;
	fma.rn.ftz.f32 	%f73, %f157, %f145, %f147;
	@%p68 bra 	$L__BB1_31;

	st.global.f32 	[%rd69], %f72;

$L__BB1_31:
	add.s32 	%r157, %r175, 1;
	setp.gt.s32 	%p59, %r157, 31;
	mov.u32 	%r158, 31;
	selp.b32 	%r159, 31, %r175, %p59;
	mov.b32 	%r160, %f72;
	mov.u32 	%r161, -1;
	shfl.sync.idx.b32 	%r176|%p60, %r160, %r159, %r158, %r161;
	mov.b32 	%r162, %f73;
	shfl.sync.idx.b32 	%r177|%p61, %r162, %r159, %r158, %r161;
	add.s32 	%r175, %r175, -32;
	add.s64 	%rd70, %rd70, 128;
	add.s64 	%rd69, %rd69, 128;
	add.s32 	%r174, %r174, 32;
	add.s32 	%r178, %r178, 32;
	setp.lt.s32 	%p62, %r178, %r125;
	@%p62 bra 	$L__BB1_17;
	bra.uni 	$L__BB1_39;

}
	// .globl	highpass2_many_series_one_param_f32
.visible .entry highpass2_many_series_one_param_f32(
	.param .u64 highpass2_many_series_one_param_f32_param_0,
	.param .u64 highpass2_many_series_one_param_f32_param_1,
	.param .u32 highpass2_many_series_one_param_f32_param_2,
	.param .f32 highpass2_many_series_one_param_f32_param_3,
	.param .f32 highpass2_many_series_one_param_f32_param_4,
	.param .f32 highpass2_many_series_one_param_f32_param_5,
	.param .f32 highpass2_many_series_one_param_f32_param_6,
	.param .u32 highpass2_many_series_one_param_f32_param_7,
	.param .u32 highpass2_many_series_one_param_f32_param_8,
	.param .u64 highpass2_many_series_one_param_f32_param_9
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<93>;
	.reg .b32 	%r<95>;
	.reg .b64 	%rd<88>;


	ld.param.u64 	%rd14, [highpass2_many_series_one_param_f32_param_0];
	ld.param.u64 	%rd13, [highpass2_many_series_one_param_f32_param_1];
	ld.param.f32 	%f33, [highpass2_many_series_one_param_f32_param_3];
	ld.param.f32 	%f34, [highpass2_many_series_one_param_f32_param_4];
	ld.param.f32 	%f35, [highpass2_many_series_one_param_f32_param_5];
	ld.param.f32 	%f36, [highpass2_many_series_one_param_f32_param_6];
	ld.param.u32 	%r45, [highpass2_many_series_one_param_f32_param_7];
	ld.param.u32 	%r46, [highpass2_many_series_one_param_f32_param_8];
	ld.param.u64 	%rd15, [highpass2_many_series_one_param_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd15;
	cvta.to.global.u64 	%rd2, %rd14;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r47, %ctaid.x;
	mov.u32 	%r48, %tid.x;
	mad.lo.s32 	%r94, %r47, %r1, %r48;
	setp.ge.s32 	%p1, %r94, %r45;
	@%p1 bra 	$L__BB2_33;

	setp.lt.s32 	%p2, %r46, 1;
	mov.u32 	%r3, %nctaid.x;
	mul.lo.s32 	%r4, %r1, %r3;
	cvt.s64.s32 	%rd3, %r45;
	@%p2 bra 	$L__BB2_32;

	add.s32 	%r5, %r46, -1;
	and.b32  	%r6, %r46, 3;
	sub.s32 	%r7, %r46, %r6;
	shl.b64 	%rd4, %rd3, 2;
	cvta.to.global.u64 	%rd5, %rd13;
	mov.u32 	%r81, 0;
	mov.u32 	%r82, %r94;

$L__BB2_3:
	cvt.s64.s32 	%rd6, %r82;
	mul.wide.s32 	%rd16, %r82, 4;
	add.s64 	%rd17, %rd5, %rd16;
	ld.global.nc.u32 	%r11, [%rd17];
	setp.lt.s32 	%p3, %r11, 0;
	setp.ge.s32 	%p4, %r11, %r46;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	$L__BB2_23;
	bra.uni 	$L__BB2_4;

$L__BB2_23:
	@%p2 bra 	$L__BB2_31;

	setp.lt.u32 	%p22, %r5, 3;
	mov.u32 	%r93, 0;
	@%p22 bra 	$L__BB2_27;

	mad.lo.s32 	%r73, %r4, %r81, %r94;
	mul.wide.s32 	%rd67, %r73, 4;
	add.s64 	%rd87, %rd1, %rd67;
	mov.u32 	%r93, 0;
	mov.u32 	%r92, %r7;

$L__BB2_26:
	mov.u32 	%r74, 2147483647;
	st.global.u32 	[%rd87], %r74;
	add.s64 	%rd68, %rd87, %rd4;
	st.global.u32 	[%rd68], %r74;
	add.s64 	%rd69, %rd68, %rd4;
	st.global.u32 	[%rd69], %r74;
	add.s64 	%rd70, %rd69, %rd4;
	add.s64 	%rd87, %rd70, %rd4;
	st.global.u32 	[%rd70], %r74;
	add.s32 	%r93, %r93, 4;
	add.s32 	%r92, %r92, -4;
	setp.ne.s32 	%p23, %r92, 0;
	@%p23 bra 	$L__BB2_26;

$L__BB2_27:
	setp.eq.s32 	%p24, %r6, 0;
	@%p24 bra 	$L__BB2_31;

	setp.eq.s32 	%p25, %r6, 1;
	cvt.s64.s32 	%rd71, %r93;
	mul.lo.s64 	%rd72, %rd71, %rd3;
	add.s64 	%rd73, %rd72, %rd6;
	shl.b64 	%rd74, %rd73, 2;
	add.s64 	%rd75, %rd1, %rd74;
	mov.u32 	%r75, 2147483647;
	st.global.u32 	[%rd75], %r75;
	@%p25 bra 	$L__BB2_31;

	setp.eq.s32 	%p26, %r6, 2;
	add.s32 	%r76, %r93, 1;
	cvt.s64.s32 	%rd76, %r76;
	mul.lo.s64 	%rd77, %rd76, %rd3;
	add.s64 	%rd78, %rd77, %rd6;
	shl.b64 	%rd79, %rd78, 2;
	add.s64 	%rd80, %rd1, %rd79;
	st.global.u32 	[%rd80], %r75;
	@%p26 bra 	$L__BB2_31;

	add.s32 	%r78, %r93, 2;
	cvt.s64.s32 	%rd81, %r78;
	mul.lo.s64 	%rd82, %rd81, %rd3;
	add.s64 	%rd83, %rd82, %rd6;
	shl.b64 	%rd84, %rd83, 2;
	add.s64 	%rd85, %rd1, %rd84;
	mov.u32 	%r79, 2147483647;
	st.global.u32 	[%rd85], %r79;
	bra.uni 	$L__BB2_31;

$L__BB2_4:
	setp.lt.s32 	%p6, %r11, 1;
	@%p6 bra 	$L__BB2_12;

	add.s32 	%r51, %r11, -1;
	and.b32  	%r12, %r11, 3;
	setp.lt.u32 	%p7, %r51, 3;
	mov.u32 	%r85, 0;
	@%p7 bra 	$L__BB2_8;

	sub.s32 	%r84, %r11, %r12;
	shl.b64 	%rd18, %rd6, 2;
	add.s64 	%rd86, %rd1, %rd18;
	mov.u32 	%r85, 0;

$L__BB2_7:
	mov.u32 	%r53, 2147483647;
	st.global.u32 	[%rd86], %r53;
	add.s64 	%rd19, %rd86, %rd4;
	st.global.u32 	[%rd19], %r53;
	add.s64 	%rd20, %rd19, %rd4;
	st.global.u32 	[%rd20], %r53;
	add.s64 	%rd21, %rd20, %rd4;
	add.s64 	%rd86, %rd21, %rd4;
	st.global.u32 	[%rd21], %r53;
	add.s32 	%r85, %r85, 4;
	add.s32 	%r84, %r84, -4;
	setp.ne.s32 	%p8, %r84, 0;
	@%p8 bra 	$L__BB2_7;

$L__BB2_8:
	setp.eq.s32 	%p9, %r12, 0;
	@%p9 bra 	$L__BB2_12;

	cvt.s64.s32 	%rd22, %r85;
	mul.lo.s64 	%rd23, %rd22, %rd3;
	add.s64 	%rd24, %rd23, %rd6;
	shl.b64 	%rd25, %rd24, 2;
	add.s64 	%rd26, %rd1, %rd25;
	mov.u32 	%r54, 2147483647;
	st.global.u32 	[%rd26], %r54;
	setp.eq.s32 	%p10, %r12, 1;
	@%p10 bra 	$L__BB2_12;

	add.s32 	%r55, %r85, 1;
	cvt.s64.s32 	%rd27, %r55;
	mul.lo.s64 	%rd28, %rd27, %rd3;
	add.s64 	%rd29, %rd28, %rd6;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd1, %rd30;
	st.global.u32 	[%rd31], %r54;
	setp.eq.s32 	%p11, %r12, 2;
	@%p11 bra 	$L__BB2_12;

	add.s32 	%r57, %r85, 2;
	cvt.s64.s32 	%rd32, %r57;
	mul.lo.s64 	%rd33, %rd32, %rd3;
	add.s64 	%rd34, %rd33, %rd6;
	shl.b64 	%rd35, %rd34, 2;
	add.s64 	%rd36, %rd1, %rd35;
	mov.u32 	%r58, 2147483647;
	st.global.u32 	[%rd36], %r58;

$L__BB2_12:
	cvt.u32.u64 	%r59, %rd6;
	mad.lo.s32 	%r19, %r11, %r45, %r59;
	mul.wide.s32 	%rd37, %r19, 4;
	add.s64 	%rd38, %rd2, %rd37;
	ld.global.nc.f32 	%f88, [%rd38];
	add.s64 	%rd39, %rd1, %rd37;
	st.global.f32 	[%rd39], %f88;
	add.s32 	%r60, %r11, 1;
	setp.ge.s32 	%p12, %r60, %r46;
	@%p12 bra 	$L__BB2_31;

	add.s32 	%r61, %r19, %r45;
	mul.wide.s32 	%rd40, %r61, 4;
	add.s64 	%rd41, %rd2, %rd40;
	ld.global.nc.f32 	%f82, [%rd41];
	add.s64 	%rd42, %rd1, %rd40;
	st.global.f32 	[%rd42], %f82;
	add.s32 	%r88, %r11, 2;
	add.s32 	%r86, %r11, 3;
	setp.ge.s32 	%p13, %r86, %r46;
	mov.f32 	%f86, %f88;
	mov.f32 	%f84, %f82;
	@%p13 bra 	$L__BB2_16;

	mov.u32 	%r87, %r88;
	mov.f32 	%f84, %f82;
	mov.f32 	%f86, %f88;
	mov.f32 	%f79, %f82;
	mov.f32 	%f80, %f88;

$L__BB2_15:
	mad.lo.s32 	%r63, %r87, %r45, %r59;
	mul.wide.s32 	%rd43, %r63, 4;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.nc.f32 	%f88, [%rd44];
	mul.ftz.f32 	%f37, %f88, %f33;
	fma.rn.ftz.f32 	%f38, %f34, %f79, %f37;
	fma.rn.ftz.f32 	%f39, %f33, %f80, %f38;
	fma.rn.ftz.f32 	%f40, %f36, %f86, %f39;
	fma.rn.ftz.f32 	%f86, %f35, %f84, %f40;
	add.s64 	%rd45, %rd1, %rd43;
	st.global.f32 	[%rd45], %f86;
	mad.lo.s32 	%r64, %r86, %r45, %r59;
	mul.wide.s32 	%rd46, %r64, 4;
	add.s64 	%rd47, %rd2, %rd46;
	ld.global.nc.f32 	%f82, [%rd47];
	mul.ftz.f32 	%f41, %f82, %f33;
	fma.rn.ftz.f32 	%f42, %f34, %f88, %f41;
	fma.rn.ftz.f32 	%f43, %f33, %f79, %f42;
	fma.rn.ftz.f32 	%f44, %f36, %f84, %f43;
	fma.rn.ftz.f32 	%f84, %f35, %f86, %f44;
	add.s64 	%rd48, %rd1, %rd46;
	st.global.f32 	[%rd48], %f84;
	add.s32 	%r88, %r87, 2;
	add.s32 	%r86, %r87, 3;
	setp.lt.s32 	%p14, %r86, %r46;
	mov.u32 	%r87, %r88;
	mov.f32 	%f79, %f82;
	mov.f32 	%f80, %f88;
	@%p14 bra 	$L__BB2_15;

$L__BB2_16:
	setp.ge.s32 	%p15, %r88, %r46;
	@%p15 bra 	$L__BB2_31;

	sub.s32 	%r65, %r46, %r88;
	and.b32  	%r27, %r65, 3;
	setp.eq.s32 	%p16, %r27, 0;
	mov.u32 	%r89, %r88;
	mov.f32 	%f85, %f84;
	mov.f32 	%f87, %f82;
	@%p16 bra 	$L__BB2_21;

	mad.lo.s32 	%r28, %r88, %r45, %r59;
	mul.wide.s32 	%rd49, %r28, 4;
	add.s64 	%rd50, %rd2, %rd49;
	ld.global.nc.f32 	%f15, [%rd50];
	mul.ftz.f32 	%f45, %f15, %f33;
	fma.rn.ftz.f32 	%f46, %f34, %f82, %f45;
	fma.rn.ftz.f32 	%f47, %f33, %f88, %f46;
	fma.rn.ftz.f32 	%f48, %f36, %f86, %f47;
	fma.rn.ftz.f32 	%f16, %f35, %f84, %f48;
	add.s64 	%rd51, %rd1, %rd49;
	st.global.f32 	[%rd51], %f16;
	add.s32 	%r89, %r88, 1;
	setp.eq.s32 	%p17, %r27, 1;
	mov.f32 	%f85, %f16;
	mov.f32 	%f86, %f84;
	mov.f32 	%f87, %f15;
	mov.f32 	%f88, %f82;
	@%p17 bra 	$L__BB2_21;

	add.s32 	%r30, %r28, %r45;
	mul.wide.s32 	%rd52, %r30, 4;
	add.s64 	%rd53, %rd2, %rd52;
	ld.global.nc.f32 	%f17, [%rd53];
	mul.ftz.f32 	%f49, %f17, %f33;
	fma.rn.ftz.f32 	%f50, %f34, %f15, %f49;
	fma.rn.ftz.f32 	%f51, %f33, %f82, %f50;
	fma.rn.ftz.f32 	%f52, %f36, %f84, %f51;
	fma.rn.ftz.f32 	%f18, %f35, %f16, %f52;
	add.s64 	%rd54, %rd1, %rd52;
	st.global.f32 	[%rd54], %f18;
	add.s32 	%r89, %r88, 2;
	setp.eq.s32 	%p18, %r27, 2;
	mov.f32 	%f85, %f18;
	mov.f32 	%f86, %f16;
	mov.f32 	%f87, %f17;
	mov.f32 	%f88, %f15;
	@%p18 bra 	$L__BB2_21;

	add.s32 	%r67, %r30, %r45;
	mul.wide.s32 	%rd55, %r67, 4;
	add.s64 	%rd56, %rd2, %rd55;
	ld.global.nc.f32 	%f87, [%rd56];
	mul.ftz.f32 	%f53, %f87, %f33;
	fma.rn.ftz.f32 	%f54, %f34, %f17, %f53;
	fma.rn.ftz.f32 	%f55, %f33, %f15, %f54;
	fma.rn.ftz.f32 	%f56, %f36, %f16, %f55;
	fma.rn.ftz.f32 	%f85, %f35, %f18, %f56;
	add.s64 	%rd57, %rd1, %rd55;
	st.global.f32 	[%rd57], %f85;
	add.s32 	%r89, %r88, 3;
	mov.f32 	%f86, %f18;
	mov.f32 	%f88, %f17;

$L__BB2_21:
	sub.s32 	%r68, %r5, %r88;
	setp.lt.u32 	%p19, %r68, 3;
	@%p19 bra 	$L__BB2_31;

$L__BB2_22:
	mad.lo.s32 	%r70, %r89, %r45, %r59;
	mul.wide.s32 	%rd58, %r70, 4;
	add.s64 	%rd59, %rd2, %rd58;
	ld.global.nc.f32 	%f57, [%rd59];
	mul.ftz.f32 	%f58, %f57, %f33;
	fma.rn.ftz.f32 	%f59, %f34, %f87, %f58;
	fma.rn.ftz.f32 	%f60, %f33, %f88, %f59;
	fma.rn.ftz.f32 	%f61, %f36, %f86, %f60;
	fma.rn.ftz.f32 	%f62, %f35, %f85, %f61;
	add.s64 	%rd60, %rd1, %rd58;
	st.global.f32 	[%rd60], %f62;
	add.s64 	%rd61, %rd59, %rd4;
	ld.global.nc.f32 	%f63, [%rd61];
	mul.ftz.f32 	%f64, %f63, %f33;
	fma.rn.ftz.f32 	%f65, %f34, %f57, %f64;
	fma.rn.ftz.f32 	%f66, %f33, %f87, %f65;
	fma.rn.ftz.f32 	%f67, %f36, %f85, %f66;
	fma.rn.ftz.f32 	%f68, %f35, %f62, %f67;
	add.s64 	%rd62, %rd60, %rd4;
	st.global.f32 	[%rd62], %f68;
	add.s64 	%rd63, %rd61, %rd4;
	ld.global.nc.f32 	%f88, [%rd63];
	mul.ftz.f32 	%f69, %f88, %f33;
	fma.rn.ftz.f32 	%f70, %f34, %f63, %f69;
	fma.rn.ftz.f32 	%f71, %f33, %f57, %f70;
	fma.rn.ftz.f32 	%f72, %f36, %f62, %f71;
	fma.rn.ftz.f32 	%f86, %f35, %f68, %f72;
	add.s64 	%rd64, %rd62, %rd4;
	st.global.f32 	[%rd64], %f86;
	add.s64 	%rd65, %rd63, %rd4;
	ld.global.nc.f32 	%f87, [%rd65];
	mul.ftz.f32 	%f73, %f87, %f33;
	fma.rn.ftz.f32 	%f74, %f34, %f88, %f73;
	fma.rn.ftz.f32 	%f75, %f33, %f63, %f74;
	fma.rn.ftz.f32 	%f76, %f36, %f68, %f75;
	fma.rn.ftz.f32 	%f85, %f35, %f86, %f76;
	add.s64 	%rd66, %rd64, %rd4;
	st.global.f32 	[%rd66], %f85;
	add.s32 	%r89, %r89, 4;
	setp.lt.s32 	%p20, %r89, %r46;
	@%p20 bra 	$L__BB2_22;

$L__BB2_31:
	cvt.u32.u64 	%r80, %rd6;
	add.s32 	%r82, %r80, %r4;
	setp.lt.s32 	%p27, %r82, %r45;
	add.s32 	%r81, %r81, 1;
	@%p27 bra 	$L__BB2_3;
	bra.uni 	$L__BB2_33;

$L__BB2_32:
	add.s32 	%r94, %r94, %r4;
	setp.lt.s32 	%p28, %r94, %r45;
	@%p28 bra 	$L__BB2_32;

$L__BB2_33:
	ret;

}

